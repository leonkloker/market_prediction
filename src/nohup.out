Traceback (most recent call last):
  File "train.py", line 12, in <module>
    from data import *
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/data.py", line 3, in <module>
    import pandas as pd
ModuleNotFoundError: No module named 'pandas'
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1694, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 856, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 591, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1932, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingStandard: 2-2             [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingStandard: 2-4             [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─MyIdentity: 2-5                             [1, 200, 64]              --
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-1                        --                        41,984
│    │    └─LayerNorm: 3-2                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
====================================================================================================
Total params: 44,545
Trainable params: 44,545
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.87
Params size (MB): 0.05
Estimated Total Size (MB): 0.92
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 89, in <module>
    torch.save(model.state_dict(), 
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/serialization.py", line 440, in save
    with _open_zipfile_writer(f) as opened_zipfile:
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/serialization.py", line 315, in _open_zipfile_writer
    return container(name_or_buffer)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/serialization.py", line 288, in __init__
    super().__init__(torch._C.PyTorchFileWriter(str(name)))
RuntimeError: Parent directory ../outputs/models does not exist.
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1694, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1932, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 591, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 856, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 328, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingStandard: 2-2             [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingStandard: 2-4             [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─MyIdentity: 2-5                             [1, 200, 64]              --
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-1                        --                        41,984
│    │    └─LayerNorm: 3-2                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
====================================================================================================
Total params: 44,545
Trainable params: 44,545
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.87
Params size (MB): 0.05
Estimated Total Size (MB): 0.92
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 112, in <module>
    out = model(x, x, enc_window=ENC_WINDOW, dec_window=DEC_WINDOW, mem_window=MEM_WINDOW)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/transformer.py", line 53, in forward
    src = self.embedding(src)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/utils.py", line 40, in forward
    return x + self.pos_encoding[:x.size(-2), :]
RuntimeError: The size of tensor a (10733) must match the size of tensor b (10000) at non-singleton dimension 1
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 591, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 857, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1933, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1694, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 329, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 476, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1074, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 941, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingStandard: 2-2             [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingStandard: 2-4             [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─MyIdentity: 2-5                             [1, 200, 64]              --
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-1                        --                        41,984
│    │    └─LayerNorm: 3-2                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
====================================================================================================
Total params: 44,545
Trainable params: 44,545
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.87
Params size (MB): 0.05
Estimated Total Size (MB): 0.92
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 8, in <module>
    from ignite.metrics import Accuracy
ModuleNotFoundError: No module named 'ignite.metrics'
Traceback (most recent call last):
  File "train.py", line 8, in <module>
    from ignite.metrics import Accuracy
ModuleNotFoundError: No module named 'ignite.metrics'
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingStandard: 2-2             [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingStandard: 2-4             [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─MyIdentity: 2-5                             [1, 200, 64]              --
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-1                        --                        41,984
│    │    └─LayerNorm: 3-2                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Sigmoid: 1-5                                     [1, 200, 1]               --
====================================================================================================
Total params: 44,545
Trainable params: 44,545
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.87
Params size (MB): 0.05
Estimated Total Size (MB): 0.92
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 85, in <module>
    val_loss += criterion(out[:,int(x.size(-2)*TRAIN_INTERVAL[1]):,:], y[:,int(x.size(-2)*TRAIN_INTERVAL[1]),:])
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 619, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/functional.py", line 3089, in binary_cross_entropy
    raise ValueError(
ValueError: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 1186, 1])) is deprecated. Please ensure they have the same size.
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingStandard: 2-2             [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingStandard: 2-4             [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─MyIdentity: 2-5                             [1, 200, 64]              --
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-1                        --                        41,984
│    │    └─LayerNorm: 3-2                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Sigmoid: 1-5                                     [1, 200, 1]               --
====================================================================================================
Total params: 44,545
Trainable params: 44,545
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.87
Params size (MB): 0.05
Estimated Total Size (MB): 0.92
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 127, in <module>
    test_loss += criterion(out[:,int(x.size(-2)*VAL_INTERVAL[1]):,:], y[:,int(x.size(-2)*VAL_INTERVAL[1]),:])
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 619, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/functional.py", line 3089, in binary_cross_entropy
    raise ValueError(
ValueError: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 659, 1])) is deprecated. Please ensure they have the same size.
Traceback (most recent call last):
  File "train.py", line 53, in <module>
    model = Transformer(N_FEATURES, N_EMBEDDING, N_HEADS, N_ENC_LAYERS, N_DEC_LAYERS, N_FORWARD)
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/transformer.py", line 20, in __init__
    PositionalEncodingNLP(d_model))
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/utils.py", line 33, in __init__
    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))
NameError: name 'math' is not defined
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingNLP: 2-2                  [1, 200, 64]              --
│    │    └─Dropout: 3-1                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingNLP: 2-4                  [1, 200, 64]              --
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-3                        --                        50,432
│    │    └─LayerNorm: 3-4                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        83,968
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Sigmoid: 1-5                                     [1, 200, 1]               --
====================================================================================================
Total params: 137,089
Trainable params: 137,089
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.49
Params size (MB): 0.08
Estimated Total Size (MB): 1.57
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 72, in <module>
    outputs = model(x, x, enc_window=ENC_WINDOW, dec_window=DEC_WINDOW, mem_window=MEM_WINDOW)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/transformer.py", line 54, in forward
    src = self.embedding(src)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ansysai/lkloker/transformersPDE/test/market_prediction/src/utils.py", line 41, in forward
    x = x + self.pe[:x.size(-2), :]
RuntimeError: The size of tensor a (8590) must match the size of tensor b (5000) at non-singleton dimension 1
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingNLP: 2-2                  [1, 200, 64]              --
│    │    └─Dropout: 3-1                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingNLP: 2-4                  [1, 200, 64]              --
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-3                        --                        50,432
│    │    └─LayerNorm: 3-4                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        83,968
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Sigmoid: 1-5                                     [1, 200, 1]               --
====================================================================================================
Total params: 137,089
Trainable params: 137,089
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.49
Params size (MB): 0.08
Estimated Total Size (MB): 1.57
====================================================================================================
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingNLP: 2-2                  [1, 200, 64]              --
│    │    └─Dropout: 3-1                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingNLP: 2-4                  [1, 200, 64]              --
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-3                        --                        50,432
│    │    └─LayerNorm: 3-4                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        83,968
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Identity: 1-5                                    [1, 200, 1]               --
====================================================================================================
Total params: 137,089
Trainable params: 137,089
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.49
Params size (MB): 0.08
Estimated Total Size (MB): 1.57
====================================================================================================
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingNLP: 2-2                  [1, 200, 64]              --
│    │    └─Dropout: 3-1                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingNLP: 2-4                  [1, 200, 64]              --
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-3                        --                        50,432
│    │    └─LayerNorm: 3-4                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        83,968
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Identity: 1-5                                    [1, 200, 1]               --
====================================================================================================
Total params: 137,089
Trainable params: 137,089
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.49
Params size (MB): 0.08
Estimated Total Size (MB): 1.57
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 75, in <module>
    loss.backward()
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 39.59 GiB total capacity; 771.41 MiB already allocated; 94.19 MiB free; 798.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingNLP: 2-2                  [1, 200, 64]              --
│    │    └─Dropout: 3-1                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingNLP: 2-4                  [1, 200, 64]              --
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-3                        --                        50,432
│    │    └─LayerNorm: 3-4                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        83,968
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Identity: 1-5                                    [1, 200, 1]               --
====================================================================================================
Total params: 137,089
Trainable params: 137,089
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.49
Params size (MB): 0.08
Estimated Total Size (MB): 1.57
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 75, in <module>
    loss.backward()
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 39.59 GiB total capacity; 771.41 MiB already allocated; 94.19 MiB free; 798.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingLearned: 2-2              [1, 200, 64]              --
│    │    └─Sequential: 3-1                        [15000, 64]               8,320
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingLearned: 2-4              [1, 200, 64]              (recursive)
│    │    └─Sequential: 3-3                        [15000, 64]               (recursive)
│    │    └─Dropout: 3-4                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        50,432
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-7                        --                        83,968
│    │    └─LayerNorm: 3-8                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Identity: 1-5                                    [1, 200, 1]               --
====================================================================================================
Total params: 145,409
Trainable params: 145,409
Non-trainable params: 0
Total mult-adds (M): 249.62
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 32.21
Params size (MB): 0.11
Estimated Total Size (MB): 32.33
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 76, in <module>
    loss.backward()
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 39.59 GiB total capacity; 786.46 MiB already allocated; 74.19 MiB free; 818.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Sequential: 1-1                                  [1, 200, 64]              --
│    └─Linear: 2-1                                 [1, 200, 64]              320
│    └─PositionalEncodingLearned: 2-2              [1, 200, 64]              --
│    │    └─Sequential: 3-1                        [15000, 64]               8,320
│    │    └─Dropout: 3-2                           [1, 200, 64]              --
├─Sequential: 1-2                                  [1, 200, 64]              (recursive)
│    └─Linear: 2-3                                 [1, 200, 64]              (recursive)
│    └─PositionalEncodingLearned: 2-4              [1, 200, 64]              (recursive)
│    │    └─Sequential: 3-3                        [15000, 64]               (recursive)
│    │    └─Dropout: 3-4                           [1, 200, 64]              --
├─Transformer: 1-3                                 [1, 200, 64]              --
│    └─TransformerEncoder: 2-5                     [1, 200, 64]              --
│    │    └─ModuleList: 3-5                        --                        50,432
│    │    └─LayerNorm: 3-6                         [1, 200, 64]              128
│    └─TransformerDecoder: 2-6                     [1, 200, 64]              --
│    │    └─ModuleList: 3-7                        --                        83,968
│    │    └─LayerNorm: 3-8                         [1, 200, 64]              128
├─Sequential: 1-4                                  [1, 200, 1]               --
│    └─Linear: 2-7                                 [1, 200, 32]              2,080
│    └─Dropout: 2-8                                [1, 200, 32]              --
│    └─ReLU: 2-9                                   [1, 200, 32]              --
│    └─Linear: 2-10                                [1, 200, 1]               33
├─Identity: 1-5                                    [1, 200, 1]               --
====================================================================================================
Total params: 145,409
Trainable params: 145,409
Non-trainable params: 0
Total mult-adds (M): 249.62
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 32.21
Params size (MB): 0.11
Estimated Total Size (MB): 32.33
====================================================================================================
Traceback (most recent call last):
  File "train.py", line 76, in <module>
    loss.backward()
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/ansysai/lkloker/transformersPDE/torch_leon/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 106.00 MiB (GPU 0; 39.59 GiB total capacity; 786.46 MiB already allocated; 74.19 MiB free; 818.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
