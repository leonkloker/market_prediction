Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─MyIdentity: 2-3                             [1, 100, 72]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        155,496
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 161,929
Trainable params: 161,929
Non-trainable params: 0
Total mult-adds (M): 0.05
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.05
Params size (MB): 0.14
Estimated Total Size (MB): 1.23
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.8761512637138367
Epoch 1 / 200, val loss: 0.19935652613639832
Epoch 1 / 200, val acc: 0.6035502958579881
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.48132288455963135
Epoch 2 / 200, val loss: 0.22774748504161835
Epoch 2 / 200, val acc: 0.5384615384615384
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.32512980699539185
Epoch 3 / 200, val loss: 0.3579740822315216
Epoch 3 / 200, val acc: 0.5325443786982249
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.2749680280685425
Epoch 4 / 200, val loss: 0.44358888268470764
Epoch 4 / 200, val acc: 0.5266272189349113
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.24372296035289764
Epoch 5 / 200, val loss: 0.4635728895664215
Epoch 5 / 200, val acc: 0.5088757396449705
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.22672387957572937
Epoch 6 / 200, val loss: 0.41839465498924255
Epoch 6 / 200, val acc: 0.5088757396449705
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.20186305046081543
Epoch 7 / 200, val loss: 0.33788591623306274
Epoch 7 / 200, val acc: 0.5088757396449705
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.1716299057006836
Epoch 8 / 200, val loss: 0.2838379442691803
Epoch 8 / 200, val acc: 0.5088757396449705
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.16127824783325195
Epoch 9 / 200, val loss: 0.3035338819026947
Epoch 9 / 200, val acc: 0.4911242603550296
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.1489669680595398
Epoch 10 / 200, val loss: 0.4040113687515259
Epoch 10 / 200, val acc: 0.48520710059171596
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.14014914631843567
Epoch 11 / 200, val loss: 0.5576242208480835
Epoch 11 / 200, val acc: 0.4556213017751479
Epoch 12 / 200, learning rate: 0.0005
Epoch 12 / 200, train loss: 0.12124662846326828
Epoch 12 / 200, val loss: 0.6704252362251282
Epoch 12 / 200, val acc: 0.44970414201183434
Epoch 13 / 200, learning rate: 0.0005
Epoch 13 / 200, train loss: 0.11546622961759567
Epoch 13 / 200, val loss: 0.6789554357528687
Epoch 13 / 200, val acc: 0.4437869822485207
Epoch 14 / 200, learning rate: 0.0005
Epoch 14 / 200, train loss: 0.1148376539349556
Epoch 14 / 200, val loss: 0.6402021646499634
Epoch 14 / 200, val acc: 0.4378698224852071
Epoch 15 / 200, learning rate: 0.0005
Epoch 15 / 200, train loss: 0.11281333863735199
Epoch 15 / 200, val loss: 0.5676242709159851
Epoch 15 / 200, val acc: 0.44970414201183434
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.10046683996915817
Epoch 16 / 200, val loss: 0.4790462851524353
Epoch 16 / 200, val acc: 0.4437869822485207
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.09776581078767776
Epoch 17 / 200, val loss: 0.38836896419525146
Epoch 17 / 200, val acc: 0.44970414201183434
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.10381893068552017
Epoch 18 / 200, val loss: 0.3215876519680023
Epoch 18 / 200, val acc: 0.46745562130177515
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.0945030152797699
Epoch 19 / 200, val loss: 0.27378252148628235
Epoch 19 / 200, val acc: 0.46745562130177515
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.09868635982275009
Epoch 20 / 200, val loss: 0.247953400015831
Epoch 20 / 200, val acc: 0.4556213017751479
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.09387095272541046
Epoch 21 / 200, val loss: 0.2363722026348114
Epoch 21 / 200, val acc: 0.44970414201183434
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.0850895568728447
Epoch 22 / 200, val loss: 0.2367045283317566
Epoch 22 / 200, val acc: 0.44970414201183434
Epoch 23 / 200, learning rate: 0.00025
Epoch 23 / 200, train loss: 0.09230440109968185
Epoch 23 / 200, val loss: 0.2421550303697586
Epoch 23 / 200, val acc: 0.44970414201183434
Epoch 24 / 200, learning rate: 0.00025
Epoch 24 / 200, train loss: 0.09005482494831085
Epoch 24 / 200, val loss: 0.24442560970783234
Epoch 24 / 200, val acc: 0.44970414201183434
Epoch 25 / 200, learning rate: 0.00025
Epoch 25 / 200, train loss: 0.08402161300182343
Epoch 25 / 200, val loss: 0.2448306381702423
Epoch 25 / 200, val acc: 0.44970414201183434
Epoch 26 / 200, learning rate: 0.00025
Epoch 26 / 200, train loss: 0.08622242510318756
Epoch 26 / 200, val loss: 0.24317100644111633
Epoch 26 / 200, val acc: 0.44970414201183434
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.08930273354053497
Epoch 27 / 200, val loss: 0.2389770746231079
Epoch 27 / 200, val acc: 0.44970414201183434
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.08436348289251328
Epoch 28 / 200, val loss: 0.23303665220737457
Epoch 28 / 200, val acc: 0.4556213017751479
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.08743380010128021
Epoch 29 / 200, val loss: 0.22439293563365936
Epoch 29 / 200, val acc: 0.4556213017751479
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.08356530964374542
Epoch 30 / 200, val loss: 0.21505582332611084
Epoch 30 / 200, val acc: 0.4556213017751479
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.08758393675088882
Epoch 31 / 200, val loss: 0.2056431919336319
Epoch 31 / 200, val acc: 0.4556213017751479
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.07964292913675308
Epoch 32 / 200, val loss: 0.1963430941104889
Epoch 32 / 200, val acc: 0.46745562130177515
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.08223037421703339
Epoch 33 / 200, val loss: 0.18812750279903412
Epoch 33 / 200, val acc: 0.47337278106508873
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.0786953717470169
Epoch 34 / 200, val loss: 0.18054738640785217
Epoch 34 / 200, val acc: 0.46745562130177515
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.08267977833747864
Epoch 35 / 200, val loss: 0.17514333128929138
Epoch 35 / 200, val acc: 0.46745562130177515
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.07845047861337662
Epoch 36 / 200, val loss: 0.17021381855010986
Epoch 36 / 200, val acc: 0.46745562130177515
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.08206160366535187
Epoch 37 / 200, val loss: 0.16587506234645844
Epoch 37 / 200, val acc: 0.46745562130177515
Epoch 38 / 200, learning rate: 0.00025
Epoch 38 / 200, train loss: 0.08371832221746445
Epoch 38 / 200, val loss: 0.1620788425207138
Epoch 38 / 200, val acc: 0.47337278106508873
Epoch 39 / 200, learning rate: 0.00025
Epoch 39 / 200, train loss: 0.0807744637131691
Epoch 39 / 200, val loss: 0.15993379056453705
Epoch 39 / 200, val acc: 0.47337278106508873
Epoch 40 / 200, learning rate: 0.00025
Epoch 40 / 200, train loss: 0.08255085349082947
Epoch 40 / 200, val loss: 0.158715158700943
Epoch 40 / 200, val acc: 0.46745562130177515
Epoch 41 / 200, learning rate: 0.00025
Epoch 41 / 200, train loss: 0.08184333890676498
Epoch 41 / 200, val loss: 0.15687188506126404
Epoch 41 / 200, val acc: 0.47337278106508873
Epoch 42 / 200, learning rate: 0.00025
Epoch 42 / 200, train loss: 0.07730281352996826
Epoch 42 / 200, val loss: 0.15428054332733154
Epoch 42 / 200, val acc: 0.47337278106508873
Epoch 43 / 200, learning rate: 0.00025
Epoch 43 / 200, train loss: 0.07931423932313919
Epoch 43 / 200, val loss: 0.15131449699401855
Epoch 43 / 200, val acc: 0.47928994082840237
Epoch 44 / 200, learning rate: 0.00025
Epoch 44 / 200, train loss: 0.07668174058198929
Epoch 44 / 200, val loss: 0.14907677471637726
Epoch 44 / 200, val acc: 0.47928994082840237
Epoch 45 / 200, learning rate: 0.00025
Epoch 45 / 200, train loss: 0.0763242244720459
Epoch 45 / 200, val loss: 0.14679478108882904
Epoch 45 / 200, val acc: 0.47928994082840237
Epoch 46 / 200, learning rate: 0.00025
Epoch 46 / 200, train loss: 0.0730365663766861
Epoch 46 / 200, val loss: 0.1450197547674179
Epoch 46 / 200, val acc: 0.48520710059171596
Epoch 47 / 200, learning rate: 0.00025
Epoch 47 / 200, train loss: 0.07466854155063629
Epoch 47 / 200, val loss: 0.1419835239648819
Epoch 47 / 200, val acc: 0.4911242603550296
Epoch 48 / 200, learning rate: 0.00025
Epoch 48 / 200, train loss: 0.07032831758260727
Epoch 48 / 200, val loss: 0.1370518058538437
Epoch 48 / 200, val acc: 0.4911242603550296
Epoch 49 / 200, learning rate: 0.00025
Epoch 49 / 200, train loss: 0.07276879251003265
Epoch 49 / 200, val loss: 0.13199475407600403
Epoch 49 / 200, val acc: 0.5088757396449705
Epoch 50 / 200, learning rate: 0.00025
Epoch 50 / 200, train loss: 0.07354726642370224
Epoch 50 / 200, val loss: 0.12685884535312653
Epoch 50 / 200, val acc: 0.5029585798816568
Epoch 51 / 200, learning rate: 0.00025
Epoch 51 / 200, train loss: 0.07562033832073212
Epoch 51 / 200, val loss: 0.12351814657449722
Epoch 51 / 200, val acc: 0.5088757396449705
Epoch 52 / 200, learning rate: 0.00025
Epoch 52 / 200, train loss: 0.07274244725704193
Epoch 52 / 200, val loss: 0.12157823890447617
Epoch 52 / 200, val acc: 0.514792899408284
Epoch 53 / 200, learning rate: 0.00025
Epoch 53 / 200, train loss: 0.07284998893737793
Epoch 53 / 200, val loss: 0.12027810513973236
Epoch 53 / 200, val acc: 0.514792899408284
Epoch 54 / 200, learning rate: 0.00025
Epoch 54 / 200, train loss: 0.07184093445539474
Epoch 54 / 200, val loss: 0.11948417127132416
Epoch 54 / 200, val acc: 0.514792899408284
Epoch 55 / 200, learning rate: 0.00025
Epoch 55 / 200, train loss: 0.07333835959434509
Epoch 55 / 200, val loss: 0.11920751631259918
Epoch 55 / 200, val acc: 0.5088757396449705
Epoch 56 / 200, learning rate: 0.00025
Epoch 56 / 200, train loss: 0.07378621399402618
Epoch 56 / 200, val loss: 0.11886178702116013
Epoch 56 / 200, val acc: 0.5029585798816568
Epoch 57 / 200, learning rate: 0.00025
Epoch 57 / 200, train loss: 0.07116218656301498
Epoch 57 / 200, val loss: 0.12054160982370377
Epoch 57 / 200, val acc: 0.5029585798816568
Epoch 58 / 200, learning rate: 0.00025
Epoch 58 / 200, train loss: 0.06867767125368118
Epoch 58 / 200, val loss: 0.121147520840168
Epoch 58 / 200, val acc: 0.4970414201183432
Epoch 59 / 200, learning rate: 0.00025
Epoch 59 / 200, train loss: 0.06879482418298721
Epoch 59 / 200, val loss: 0.11963169276714325
Epoch 59 / 200, val acc: 0.4970414201183432
Epoch 60 / 200, learning rate: 0.00025
Epoch 60 / 200, train loss: 0.07145357877016068
Epoch 60 / 200, val loss: 0.11583459377288818
Epoch 60 / 200, val acc: 0.5029585798816568
Epoch 61 / 200, learning rate: 0.00025
Epoch 61 / 200, train loss: 0.07205331325531006
Epoch 61 / 200, val loss: 0.11134009063243866
Epoch 61 / 200, val acc: 0.5029585798816568
Epoch 62 / 200, learning rate: 0.00025
Epoch 62 / 200, train loss: 0.0735233798623085
Epoch 62 / 200, val loss: 0.10801911354064941
Epoch 62 / 200, val acc: 0.4970414201183432
Epoch 63 / 200, learning rate: 0.00025
Epoch 63 / 200, train loss: 0.06755398213863373
Epoch 63 / 200, val loss: 0.10495755076408386
Epoch 63 / 200, val acc: 0.4970414201183432
Epoch 64 / 200, learning rate: 0.00025
Epoch 64 / 200, train loss: 0.0687185600399971
Epoch 64 / 200, val loss: 0.10179976373910904
Epoch 64 / 200, val acc: 0.4911242603550296
Epoch 65 / 200, learning rate: 0.00025
Epoch 65 / 200, train loss: 0.0679696649312973
Epoch 65 / 200, val loss: 0.09991394728422165
Epoch 65 / 200, val acc: 0.48520710059171596
Epoch 66 / 200, learning rate: 0.00025
Epoch 66 / 200, train loss: 0.06879964470863342
Epoch 66 / 200, val loss: 0.09730061143636703
Epoch 66 / 200, val acc: 0.4911242603550296
Epoch 67 / 200, learning rate: 0.00025
Epoch 67 / 200, train loss: 0.06606201082468033
Epoch 67 / 200, val loss: 0.09459870308637619
Epoch 67 / 200, val acc: 0.4911242603550296
Epoch 68 / 200, learning rate: 0.00025
Epoch 68 / 200, train loss: 0.06425121426582336
Epoch 68 / 200, val loss: 0.09231651574373245
Epoch 68 / 200, val acc: 0.48520710059171596
Epoch 69 / 200, learning rate: 0.00025
Epoch 69 / 200, train loss: 0.06621333211660385
Epoch 69 / 200, val loss: 0.08933631330728531
Epoch 69 / 200, val acc: 0.47928994082840237
Epoch 70 / 200, learning rate: 0.00025
Epoch 70 / 200, train loss: 0.06758914142847061
Epoch 70 / 200, val loss: 0.08753440529108047
Epoch 70 / 200, val acc: 0.47337278106508873
Epoch 71 / 200, learning rate: 0.00025
Epoch 71 / 200, train loss: 0.06750011444091797
Epoch 71 / 200, val loss: 0.08622850477695465
Epoch 71 / 200, val acc: 0.47337278106508873
Epoch 72 / 200, learning rate: 0.00025
Epoch 72 / 200, train loss: 0.06944859772920609
Epoch 72 / 200, val loss: 0.08465208858251572
Epoch 72 / 200, val acc: 0.47337278106508873
Epoch 73 / 200, learning rate: 0.00025
Epoch 73 / 200, train loss: 0.07031022757291794
Epoch 73 / 200, val loss: 0.08324791491031647
Epoch 73 / 200, val acc: 0.47337278106508873
Epoch 74 / 200, learning rate: 0.00025
Epoch 74 / 200, train loss: 0.06301145255565643
Epoch 74 / 200, val loss: 0.08260658383369446
Epoch 74 / 200, val acc: 0.47928994082840237
Epoch 75 / 200, learning rate: 0.00025
Epoch 75 / 200, train loss: 0.06161904335021973
Epoch 75 / 200, val loss: 0.08219199627637863
Epoch 75 / 200, val acc: 0.48520710059171596
Epoch 76 / 200, learning rate: 0.00025
Epoch 76 / 200, train loss: 0.06598397344350815
Epoch 76 / 200, val loss: 0.08214253187179565
Epoch 76 / 200, val acc: 0.47928994082840237
Epoch 77 / 200, learning rate: 0.00025
Epoch 77 / 200, train loss: 0.061294469982385635
Epoch 77 / 200, val loss: 0.08153510093688965
Epoch 77 / 200, val acc: 0.47928994082840237
Epoch 78 / 200, learning rate: 0.00025
Epoch 78 / 200, train loss: 0.06606438010931015
Epoch 78 / 200, val loss: 0.08023189008235931
Epoch 78 / 200, val acc: 0.47928994082840237
Epoch 79 / 200, learning rate: 0.00025
Epoch 79 / 200, train loss: 0.06374576687812805
Epoch 79 / 200, val loss: 0.07906381785869598
Epoch 79 / 200, val acc: 0.47337278106508873
Epoch 80 / 200, learning rate: 0.00025
Epoch 80 / 200, train loss: 0.06024368852376938
Epoch 80 / 200, val loss: 0.07833615690469742
Epoch 80 / 200, val acc: 0.46745562130177515
Epoch 81 / 200, learning rate: 0.00025
Epoch 81 / 200, train loss: 0.06102810800075531
Epoch 81 / 200, val loss: 0.0766468495130539
Epoch 81 / 200, val acc: 0.46745562130177515
Epoch 82 / 200, learning rate: 0.00025
Epoch 82 / 200, train loss: 0.06202177330851555
Epoch 82 / 200, val loss: 0.07369633764028549
Epoch 82 / 200, val acc: 0.47337278106508873
Epoch 83 / 200, learning rate: 0.00025
Epoch 83 / 200, train loss: 0.06282161176204681
Epoch 83 / 200, val loss: 0.0710536539554596
Epoch 83 / 200, val acc: 0.4970414201183432
Epoch 84 / 200, learning rate: 0.00025
Epoch 84 / 200, train loss: 0.06259003281593323
Epoch 84 / 200, val loss: 0.06938475370407104
Epoch 84 / 200, val acc: 0.4911242603550296
Epoch 85 / 200, learning rate: 0.00025
Epoch 85 / 200, train loss: 0.06257239729166031
Epoch 85 / 200, val loss: 0.06819459050893784
Epoch 85 / 200, val acc: 0.4911242603550296
Epoch 86 / 200, learning rate: 0.00025
Epoch 86 / 200, train loss: 0.06122893467545509
Epoch 86 / 200, val loss: 0.06779364496469498
Epoch 86 / 200, val acc: 0.4911242603550296
Epoch 87 / 200, learning rate: 0.00025
Epoch 87 / 200, train loss: 0.06207961216568947
Epoch 87 / 200, val loss: 0.06844151765108109
Epoch 87 / 200, val acc: 0.4911242603550296
Epoch 88 / 200, learning rate: 0.00025
Epoch 88 / 200, train loss: 0.06246011331677437
Epoch 88 / 200, val loss: 0.06893457472324371
Epoch 88 / 200, val acc: 0.4911242603550296
Epoch 89 / 200, learning rate: 0.00025
Epoch 89 / 200, train loss: 0.06530338525772095
Epoch 89 / 200, val loss: 0.06749720871448517
Epoch 89 / 200, val acc: 0.4911242603550296
Epoch 90 / 200, learning rate: 0.00025
Epoch 90 / 200, train loss: 0.06516651809215546
Epoch 90 / 200, val loss: 0.06542923301458359
Epoch 90 / 200, val acc: 0.4911242603550296
Epoch 91 / 200, learning rate: 0.00025
Epoch 91 / 200, train loss: 0.05956675857305527
Epoch 91 / 200, val loss: 0.06354335695505142
Epoch 91 / 200, val acc: 0.48520710059171596
Epoch 92 / 200, learning rate: 0.00025
Epoch 92 / 200, train loss: 0.058752626180648804
Epoch 92 / 200, val loss: 0.06234476715326309
Epoch 92 / 200, val acc: 0.48520710059171596
Epoch 93 / 200, learning rate: 0.00025
Epoch 93 / 200, train loss: 0.056357961148023605
Epoch 93 / 200, val loss: 0.06193795055150986
Epoch 93 / 200, val acc: 0.48520710059171596
Epoch 94 / 200, learning rate: 0.00025
Epoch 94 / 200, train loss: 0.05992564558982849
Epoch 94 / 200, val loss: 0.0617532804608345
Epoch 94 / 200, val acc: 0.48520710059171596
Epoch 95 / 200, learning rate: 0.00025
Epoch 95 / 200, train loss: 0.05926422029733658
Epoch 95 / 200, val loss: 0.062135230749845505
Epoch 95 / 200, val acc: 0.48520710059171596
Epoch 96 / 200, learning rate: 0.00025
Epoch 96 / 200, train loss: 0.05854709818959236
Epoch 96 / 200, val loss: 0.06286157667636871
Epoch 96 / 200, val acc: 0.48520710059171596
Epoch 97 / 200, learning rate: 0.00025
Epoch 97 / 200, train loss: 0.0623244047164917
Epoch 97 / 200, val loss: 0.06250427663326263
Epoch 97 / 200, val acc: 0.48520710059171596
Epoch 98 / 200, learning rate: 0.00025
Epoch 98 / 200, train loss: 0.05776102468371391
Epoch 98 / 200, val loss: 0.061802152544260025
Epoch 98 / 200, val acc: 0.4911242603550296
Epoch 99 / 200, learning rate: 0.00025
Epoch 99 / 200, train loss: 0.05816752463579178
Epoch 99 / 200, val loss: 0.06141003593802452
Epoch 99 / 200, val acc: 0.4911242603550296
Epoch 100 / 200, learning rate: 0.00025
Epoch 100 / 200, train loss: 0.057713985443115234
Epoch 100 / 200, val loss: 0.06176562234759331
Epoch 100 / 200, val acc: 0.4911242603550296
Epoch 101 / 200, learning rate: 0.00025
Epoch 101 / 200, train loss: 0.059301912784576416
Epoch 101 / 200, val loss: 0.061813049018383026
Epoch 101 / 200, val acc: 0.48520710059171596
Epoch 102 / 200, learning rate: 0.00025
Epoch 102 / 200, train loss: 0.0586889274418354
Epoch 102 / 200, val loss: 0.061912111937999725
Epoch 102 / 200, val acc: 0.48520710059171596
Epoch 103 / 200, learning rate: 0.00025
Epoch 103 / 200, train loss: 0.054487407207489014
Epoch 103 / 200, val loss: 0.06255772709846497
Epoch 103 / 200, val acc: 0.48520710059171596
Epoch 104 / 200, learning rate: 0.00025
Epoch 104 / 200, train loss: 0.05579321086406708
Epoch 104 / 200, val loss: 0.06322946399450302
Epoch 104 / 200, val acc: 0.4911242603550296
Epoch 105 / 200, learning rate: 0.00025
Epoch 105 / 200, train loss: 0.05981066823005676
Epoch 105 / 200, val loss: 0.0628015547990799
Epoch 105 / 200, val acc: 0.4911242603550296
Epoch 106 / 200, learning rate: 0.00025
Epoch 106 / 200, train loss: 0.0579482838511467
Epoch 106 / 200, val loss: 0.061849046498537064
Epoch 106 / 200, val acc: 0.48520710059171596
Epoch 107 / 200, learning rate: 0.00025
Epoch 107 / 200, train loss: 0.058348871767520905
Epoch 107 / 200, val loss: 0.06123654916882515
Epoch 107 / 200, val acc: 0.47928994082840237
Epoch 108 / 200, learning rate: 0.00025
Epoch 108 / 200, train loss: 0.05708947032690048
Epoch 108 / 200, val loss: 0.060527633875608444
Epoch 108 / 200, val acc: 0.47928994082840237
Epoch 109 / 200, learning rate: 0.00025
Epoch 109 / 200, train loss: 0.05706325173377991
Epoch 109 / 200, val loss: 0.060376573354005814
Epoch 109 / 200, val acc: 0.47928994082840237
Epoch 110 / 200, learning rate: 0.00025
Epoch 110 / 200, train loss: 0.055950239300727844
Epoch 110 / 200, val loss: 0.06025305017828941
Epoch 110 / 200, val acc: 0.48520710059171596
Epoch 111 / 200, learning rate: 0.00025
Epoch 111 / 200, train loss: 0.056489694863557816
Epoch 111 / 200, val loss: 0.05991720035672188
Epoch 111 / 200, val acc: 0.5029585798816568
Epoch 112 / 200, learning rate: 0.00025
Epoch 112 / 200, train loss: 0.05563622713088989
Epoch 112 / 200, val loss: 0.06050551310181618
Epoch 112 / 200, val acc: 0.5088757396449705
Epoch 113 / 200, learning rate: 0.00025
Epoch 113 / 200, train loss: 0.05585813894867897
Epoch 113 / 200, val loss: 0.06036434695124626
Epoch 113 / 200, val acc: 0.4970414201183432
Epoch 114 / 200, learning rate: 0.00025
Epoch 114 / 200, train loss: 0.05818339064717293
Epoch 114 / 200, val loss: 0.06029225140810013
Epoch 114 / 200, val acc: 0.4911242603550296
Epoch 115 / 200, learning rate: 0.00025
Epoch 115 / 200, train loss: 0.053517889231443405
Epoch 115 / 200, val loss: 0.05992185324430466
Epoch 115 / 200, val acc: 0.4911242603550296
Epoch 116 / 200, learning rate: 0.00025
Epoch 116 / 200, train loss: 0.057514797896146774
Epoch 116 / 200, val loss: 0.058902863413095474
Epoch 116 / 200, val acc: 0.47337278106508873
Epoch 117 / 200, learning rate: 0.00025
Epoch 117 / 200, train loss: 0.053106844425201416
Epoch 117 / 200, val loss: 0.05736314505338669
Epoch 117 / 200, val acc: 0.48520710059171596
Epoch 118 / 200, learning rate: 0.00025
Epoch 118 / 200, train loss: 0.05573711544275284
Epoch 118 / 200, val loss: 0.05685663968324661
Epoch 118 / 200, val acc: 0.48520710059171596
Epoch 119 / 200, learning rate: 0.00025
Epoch 119 / 200, train loss: 0.05368862301111221
Epoch 119 / 200, val loss: 0.05616038292646408
Epoch 119 / 200, val acc: 0.47928994082840237
Epoch 120 / 200, learning rate: 0.00025
Epoch 120 / 200, train loss: 0.05314772203564644
Epoch 120 / 200, val loss: 0.05572323128581047
Epoch 120 / 200, val acc: 0.47928994082840237
Epoch 121 / 200, learning rate: 0.00025
Epoch 121 / 200, train loss: 0.05504684895277023
Epoch 121 / 200, val loss: 0.05453793704509735
Epoch 121 / 200, val acc: 0.47928994082840237
Epoch 122 / 200, learning rate: 0.00025
Epoch 122 / 200, train loss: 0.05131988599896431
Epoch 122 / 200, val loss: 0.053630441427230835
Epoch 122 / 200, val acc: 0.47928994082840237
Epoch 123 / 200, learning rate: 0.00025
Epoch 123 / 200, train loss: 0.05414101108908653
Epoch 123 / 200, val loss: 0.05311928316950798
Epoch 123 / 200, val acc: 0.48520710059171596
Epoch 124 / 200, learning rate: 0.00025
Epoch 124 / 200, train loss: 0.05345283821225166
Epoch 124 / 200, val loss: 0.052963100373744965
Epoch 124 / 200, val acc: 0.48520710059171596
Epoch 125 / 200, learning rate: 0.00025
Epoch 125 / 200, train loss: 0.05190115049481392
Epoch 125 / 200, val loss: 0.05293925851583481
Epoch 125 / 200, val acc: 0.47928994082840237
Epoch 126 / 200, learning rate: 0.00025
Epoch 126 / 200, train loss: 0.05320141837000847
Epoch 126 / 200, val loss: 0.053166940808296204
Epoch 126 / 200, val acc: 0.47337278106508873
Epoch 127 / 200, learning rate: 0.00025
Epoch 127 / 200, train loss: 0.05109396204352379
Epoch 127 / 200, val loss: 0.05394592881202698
Epoch 127 / 200, val acc: 0.46745562130177515
Epoch 128 / 200, learning rate: 0.00025
Epoch 128 / 200, train loss: 0.05492419749498367
Epoch 128 / 200, val loss: 0.05551004409790039
Epoch 128 / 200, val acc: 0.47928994082840237
Epoch 129 / 200, learning rate: 0.00025
Epoch 129 / 200, train loss: 0.05068765580654144
Epoch 129 / 200, val loss: 0.056821588426828384
Epoch 129 / 200, val acc: 0.47337278106508873
Epoch 130 / 200, learning rate: 0.00025
Epoch 130 / 200, train loss: 0.053749650716781616
Epoch 130 / 200, val loss: 0.05795910954475403
Epoch 130 / 200, val acc: 0.47928994082840237
Epoch 131 / 200, learning rate: 0.00025
Epoch 131 / 200, train loss: 0.05063965544104576
Epoch 131 / 200, val loss: 0.05851857364177704
Epoch 131 / 200, val acc: 0.4911242603550296
Epoch 132 / 200, learning rate: 0.00025
Epoch 132 / 200, train loss: 0.05336548015475273
Epoch 132 / 200, val loss: 0.058447305113077164
Epoch 132 / 200, val acc: 0.47928994082840237
Epoch 133 / 200, learning rate: 0.00025
Epoch 133 / 200, train loss: 0.0534171462059021
Epoch 133 / 200, val loss: 0.05716898292303085
Epoch 133 / 200, val acc: 0.47337278106508873
Epoch 134 / 200, learning rate: 0.00025
Epoch 134 / 200, train loss: 0.05126260221004486
Epoch 134 / 200, val loss: 0.05575360730290413
Epoch 134 / 200, val acc: 0.47337278106508873
Epoch 135 / 200, learning rate: 0.00025
Epoch 135 / 200, train loss: 0.05381732061505318
Epoch 135 / 200, val loss: 0.05484270304441452
Epoch 135 / 200, val acc: 0.47928994082840237
Epoch 136 / 200, learning rate: 0.000125
Epoch 136 / 200, train loss: 0.05139855667948723
Epoch 136 / 200, val loss: 0.054284725338220596
Epoch 136 / 200, val acc: 0.47337278106508873
Epoch 137 / 200, learning rate: 0.000125
Epoch 137 / 200, train loss: 0.04898817837238312
Epoch 137 / 200, val loss: 0.053977008908987045
Epoch 137 / 200, val acc: 0.47337278106508873
Epoch 138 / 200, learning rate: 0.000125
Epoch 138 / 200, train loss: 0.04997623339295387
Epoch 138 / 200, val loss: 0.054256390780210495
Epoch 138 / 200, val acc: 0.47337278106508873
Epoch 139 / 200, learning rate: 0.000125
Epoch 139 / 200, train loss: 0.05083753541111946
Epoch 139 / 200, val loss: 0.054906778037548065
Epoch 139 / 200, val acc: 0.4970414201183432
Epoch 140 / 200, learning rate: 0.000125
Epoch 140 / 200, train loss: 0.05174605920910835
Epoch 140 / 200, val loss: 0.055487342178821564
Epoch 140 / 200, val acc: 0.4970414201183432
Epoch 141 / 200, learning rate: 0.000125
Epoch 141 / 200, train loss: 0.05121583491563797
Epoch 141 / 200, val loss: 0.05605519935488701
Epoch 141 / 200, val acc: 0.48520710059171596
Epoch 142 / 200, learning rate: 0.000125
Epoch 142 / 200, train loss: 0.04965491592884064
Epoch 142 / 200, val loss: 0.05605047941207886
Epoch 142 / 200, val acc: 0.48520710059171596
Epoch 143 / 200, learning rate: 0.000125
Epoch 143 / 200, train loss: 0.049566492438316345
Epoch 143 / 200, val loss: 0.05574064329266548
Epoch 143 / 200, val acc: 0.48520710059171596
Epoch 144 / 200, learning rate: 0.000125
Epoch 144 / 200, train loss: 0.048926595598459244
Epoch 144 / 200, val loss: 0.05539582297205925
Epoch 144 / 200, val acc: 0.4911242603550296
Epoch 145 / 200, learning rate: 0.000125
Epoch 145 / 200, train loss: 0.05048075318336487
Epoch 145 / 200, val loss: 0.05474530905485153
Epoch 145 / 200, val acc: 0.47337278106508873
Epoch 146 / 200, learning rate: 0.000125
Epoch 146 / 200, train loss: 0.051681485027074814
Epoch 146 / 200, val loss: 0.054071810096502304
Epoch 146 / 200, val acc: 0.46153846153846156
Epoch 147 / 200, learning rate: 6.25e-05
Epoch 147 / 200, train loss: 0.05365494638681412
Epoch 147 / 200, val loss: 0.05381563678383827
Epoch 147 / 200, val acc: 0.46745562130177515
Epoch 148 / 200, learning rate: 6.25e-05
Epoch 148 / 200, train loss: 0.050039611756801605
Epoch 148 / 200, val loss: 0.053713396191596985
Epoch 148 / 200, val acc: 0.47337278106508873
Epoch 149 / 200, learning rate: 6.25e-05
Epoch 149 / 200, train loss: 0.05071340501308441
Epoch 149 / 200, val loss: 0.053485456854104996
Epoch 149 / 200, val acc: 0.47928994082840237
Epoch 150 / 200, learning rate: 6.25e-05
Epoch 150 / 200, train loss: 0.04802427440881729
Epoch 150 / 200, val loss: 0.053339775651693344
Epoch 150 / 200, val acc: 0.47928994082840237
Epoch 151 / 200, learning rate: 6.25e-05
Epoch 151 / 200, train loss: 0.04836926609277725
Epoch 151 / 200, val loss: 0.053343094885349274
Epoch 151 / 200, val acc: 0.47928994082840237
Epoch 152 / 200, learning rate: 6.25e-05
Epoch 152 / 200, train loss: 0.05086943507194519
Epoch 152 / 200, val loss: 0.0534563846886158
Epoch 152 / 200, val acc: 0.47928994082840237
Epoch 153 / 200, learning rate: 6.25e-05
Epoch 153 / 200, train loss: 0.04897557944059372
Epoch 153 / 200, val loss: 0.05371875315904617
Epoch 153 / 200, val acc: 0.47337278106508873
Epoch 154 / 200, learning rate: 6.25e-05
Epoch 154 / 200, train loss: 0.05215277895331383
Epoch 154 / 200, val loss: 0.05404543876647949
Epoch 154 / 200, val acc: 0.47337278106508873
Epoch 155 / 200, learning rate: 6.25e-05
Epoch 155 / 200, train loss: 0.050116803497076035
Epoch 155 / 200, val loss: 0.05456948280334473
Epoch 155 / 200, val acc: 0.47337278106508873
Epoch 156 / 200, learning rate: 6.25e-05
Epoch 156 / 200, train loss: 0.04943403601646423
Epoch 156 / 200, val loss: 0.055214401334524155
Epoch 156 / 200, val acc: 0.47337278106508873
Epoch 157 / 200, learning rate: 6.25e-05
Epoch 157 / 200, train loss: 0.048004280775785446
Epoch 157 / 200, val loss: 0.05574732646346092
Epoch 157 / 200, val acc: 0.47928994082840237
Epoch 158 / 200, learning rate: 3.125e-05
Epoch 158 / 200, train loss: 0.050802040845155716
Epoch 158 / 200, val loss: 0.05621457099914551
Epoch 158 / 200, val acc: 0.47928994082840237
Epoch 159 / 200, learning rate: 3.125e-05
Epoch 159 / 200, train loss: 0.05252882093191147
Epoch 159 / 200, val loss: 0.05628944933414459
Epoch 159 / 200, val acc: 0.47928994082840237
Epoch 160 / 200, learning rate: 3.125e-05
Epoch 160 / 200, train loss: 0.045663587749004364
Epoch 160 / 200, val loss: 0.05618777498602867
Epoch 160 / 200, val acc: 0.47928994082840237
Epoch 161 / 200, learning rate: 3.125e-05
Epoch 161 / 200, train loss: 0.04943682253360748
Epoch 161 / 200, val loss: 0.056050654500722885
Epoch 161 / 200, val acc: 0.47928994082840237
Epoch 162 / 200, learning rate: 3.125e-05
Epoch 162 / 200, train loss: 0.047795601189136505
Epoch 162 / 200, val loss: 0.05574391037225723
Epoch 162 / 200, val acc: 0.47928994082840237
Epoch 163 / 200, learning rate: 3.125e-05
Epoch 163 / 200, train loss: 0.0488896481692791
Epoch 163 / 200, val loss: 0.05529741570353508
Epoch 163 / 200, val acc: 0.47928994082840237
Epoch 164 / 200, learning rate: 3.125e-05
Epoch 164 / 200, train loss: 0.04816741123795509
Epoch 164 / 200, val loss: 0.054736487567424774
Epoch 164 / 200, val acc: 0.46745562130177515
Epoch 165 / 200, learning rate: 3.125e-05
Epoch 165 / 200, train loss: 0.04876865819096565
Epoch 165 / 200, val loss: 0.05424584448337555
Epoch 165 / 200, val acc: 0.46745562130177515
Epoch 166 / 200, learning rate: 3.125e-05
Epoch 166 / 200, train loss: 0.04912327975034714
Epoch 166 / 200, val loss: 0.05395619571208954
Epoch 166 / 200, val acc: 0.46153846153846156
Epoch 167 / 200, learning rate: 3.125e-05
Epoch 167 / 200, train loss: 0.05120670422911644
Epoch 167 / 200, val loss: 0.05370406061410904
Epoch 167 / 200, val acc: 0.46153846153846156
Epoch 168 / 200, learning rate: 3.125e-05
Epoch 168 / 200, train loss: 0.05015859752893448
Epoch 168 / 200, val loss: 0.05351480096578598
Epoch 168 / 200, val acc: 0.46745562130177515
Epoch 169 / 200, learning rate: 1.5625e-05
Epoch 169 / 200, train loss: 0.05031814053654671
Epoch 169 / 200, val loss: 0.053372062742710114
Epoch 169 / 200, val acc: 0.46745562130177515
Epoch 170 / 200, learning rate: 1.5625e-05
Epoch 170 / 200, train loss: 0.05126732215285301
Epoch 170 / 200, val loss: 0.05331418663263321
Epoch 170 / 200, val acc: 0.46745562130177515
Epoch 171 / 200, learning rate: 1.5625e-05
Epoch 171 / 200, train loss: 0.04919315129518509
Epoch 171 / 200, val loss: 0.05324362590909004
Epoch 171 / 200, val acc: 0.46745562130177515
Epoch 172 / 200, learning rate: 1.5625e-05
Epoch 172 / 200, train loss: 0.047584276646375656
Epoch 172 / 200, val loss: 0.053203560411930084
Epoch 172 / 200, val acc: 0.47337278106508873
Epoch 173 / 200, learning rate: 1.5625e-05
Epoch 173 / 200, train loss: 0.047009654343128204
Epoch 173 / 200, val loss: 0.053181812167167664
Epoch 173 / 200, val acc: 0.47928994082840237
Epoch 174 / 200, learning rate: 1.5625e-05
Epoch 174 / 200, train loss: 0.05042484775185585
Epoch 174 / 200, val loss: 0.05313856527209282
Epoch 174 / 200, val acc: 0.47928994082840237
Epoch 175 / 200, learning rate: 1.5625e-05
Epoch 175 / 200, train loss: 0.05051887780427933
Epoch 175 / 200, val loss: 0.05314283072948456
Epoch 175 / 200, val acc: 0.47928994082840237
Epoch 176 / 200, learning rate: 1.5625e-05
Epoch 176 / 200, train loss: 0.047198645770549774
Epoch 176 / 200, val loss: 0.05313679203391075
Epoch 176 / 200, val acc: 0.47928994082840237
Epoch 177 / 200, learning rate: 1.5625e-05
Epoch 177 / 200, train loss: 0.04849819093942642
Epoch 177 / 200, val loss: 0.05307547003030777
Epoch 177 / 200, val acc: 0.47928994082840237
Epoch 178 / 200, learning rate: 1.5625e-05
Epoch 178 / 200, train loss: 0.04989247769117355
Epoch 178 / 200, val loss: 0.05301393195986748
Epoch 178 / 200, val acc: 0.47337278106508873
Epoch 179 / 200, learning rate: 1.5625e-05
Epoch 179 / 200, train loss: 0.05017011985182762
Epoch 179 / 200, val loss: 0.05294722318649292
Epoch 179 / 200, val acc: 0.47337278106508873
Epoch 180 / 200, learning rate: 1.5625e-05
Epoch 180 / 200, train loss: 0.05287330225110054
Epoch 180 / 200, val loss: 0.052865371108055115
Epoch 180 / 200, val acc: 0.47337278106508873
Epoch 181 / 200, learning rate: 1.5625e-05
Epoch 181 / 200, train loss: 0.04839882627129555
Epoch 181 / 200, val loss: 0.052811432629823685
Epoch 181 / 200, val acc: 0.47337278106508873
Epoch 182 / 200, learning rate: 1.5625e-05
Epoch 182 / 200, train loss: 0.049424681812524796
Epoch 182 / 200, val loss: 0.05270996317267418
Epoch 182 / 200, val acc: 0.47337278106508873
Epoch 183 / 200, learning rate: 1.5625e-05
Epoch 183 / 200, train loss: 0.05025000497698784
Epoch 183 / 200, val loss: 0.052653729915618896
Epoch 183 / 200, val acc: 0.47337278106508873
Epoch 184 / 200, learning rate: 1.5625e-05
Epoch 184 / 200, train loss: 0.049410708248615265
Epoch 184 / 200, val loss: 0.0526045523583889
Epoch 184 / 200, val acc: 0.47337278106508873
Epoch 185 / 200, learning rate: 1.5625e-05
Epoch 185 / 200, train loss: 0.050199832767248154
Epoch 185 / 200, val loss: 0.05246439576148987
Epoch 185 / 200, val acc: 0.46153846153846156
Epoch 186 / 200, learning rate: 1.5625e-05
Epoch 186 / 200, train loss: 0.051018521189689636
Epoch 186 / 200, val loss: 0.05235718563199043
Epoch 186 / 200, val acc: 0.46153846153846156
Epoch 187 / 200, learning rate: 1.5625e-05
Epoch 187 / 200, train loss: 0.05255568027496338
Epoch 187 / 200, val loss: 0.05223296955227852
Epoch 187 / 200, val acc: 0.46153846153846156
Epoch 188 / 200, learning rate: 1.5625e-05
Epoch 188 / 200, train loss: 0.04756929725408554
Epoch 188 / 200, val loss: 0.05216866731643677
Epoch 188 / 200, val acc: 0.46153846153846156
Epoch 189 / 200, learning rate: 1.5625e-05
Epoch 189 / 200, train loss: 0.05091838538646698
Epoch 189 / 200, val loss: 0.05212361365556717
Epoch 189 / 200, val acc: 0.46153846153846156
Epoch 190 / 200, learning rate: 1.5625e-05
Epoch 190 / 200, train loss: 0.052074678242206573
Epoch 190 / 200, val loss: 0.05208771675825119
Epoch 190 / 200, val acc: 0.46153846153846156
Epoch 191 / 200, learning rate: 1.5625e-05
Epoch 191 / 200, train loss: 0.05114389583468437
Epoch 191 / 200, val loss: 0.052054502069950104
Epoch 191 / 200, val acc: 0.46153846153846156
Epoch 192 / 200, learning rate: 1.5625e-05
Epoch 192 / 200, train loss: 0.04851207137107849
Epoch 192 / 200, val loss: 0.052042074501514435
Epoch 192 / 200, val acc: 0.46153846153846156
Epoch 193 / 200, learning rate: 1.5625e-05
Epoch 193 / 200, train loss: 0.05024183169007301
Epoch 193 / 200, val loss: 0.05201614275574684
Epoch 193 / 200, val acc: 0.46153846153846156
Epoch 194 / 200, learning rate: 1.5625e-05
Epoch 194 / 200, train loss: 0.05324077606201172
Epoch 194 / 200, val loss: 0.05204415321350098
Epoch 194 / 200, val acc: 0.46153846153846156
Epoch 195 / 200, learning rate: 1.5625e-05
Epoch 195 / 200, train loss: 0.05202404782176018
Epoch 195 / 200, val loss: 0.05209321528673172
Epoch 195 / 200, val acc: 0.46153846153846156
Epoch 196 / 200, learning rate: 1.5625e-05
Epoch 196 / 200, train loss: 0.04957231134176254
Epoch 196 / 200, val loss: 0.05214279517531395
Epoch 196 / 200, val acc: 0.46745562130177515
Epoch 197 / 200, learning rate: 1.5625e-05
Epoch 197 / 200, train loss: 0.04926363378763199
Epoch 197 / 200, val loss: 0.05219918116927147
Epoch 197 / 200, val acc: 0.47337278106508873
Epoch 198 / 200, learning rate: 1.5625e-05
Epoch 198 / 200, train loss: 0.04941816255450249
Epoch 198 / 200, val loss: 0.05217168107628822
Epoch 198 / 200, val acc: 0.47337278106508873
Epoch 199 / 200, learning rate: 1.5625e-05
Epoch 199 / 200, train loss: 0.047938644886016846
Epoch 199 / 200, val loss: 0.05217311158776283
Epoch 199 / 200, val acc: 0.47337278106508873
Epoch 200 / 200, learning rate: 1.5625e-05
Epoch 200 / 200, train loss: 0.05038296803832054
Epoch 200 / 200, val loss: 0.052135441452264786
Epoch 200 / 200, val acc: 0.47337278106508873
Training finished

Evaluating best model
Trading strategy for stock POAHY:
After 3405 trading days
Binary accuracy: 0.50734
Fraction of long signals: 0.49192
Fraction of short signals: 0.50778
Overall long return: 1.49014
Overall return: 2.67484
Yearly long return: 0.11028
Yearly return: 0.19796
Daily volatility: 0.02456
Max drawdown baseline: 0.38664
Max drawdown: 0.56368
Sharpe ratio: 0.01418
L1 error baseline: 0.05437
L1 error: 0.10573
Average prediction: -0.00355
Std prediction: 1.00630


Trading strategy for stock POAHY:
After 171 trading days
Binary accuracy: 0.46471
Fraction of long signals: 0.15205
Fraction of short signals: 0.84795
Overall long return: 0.03482
Overall return: -0.02517
Yearly long return: 0.05131
Yearly return: -0.03709
Daily volatility: 0.01565
Max drawdown baseline: 0.15030
Max drawdown: 0.17134
Sharpe ratio: -0.02248
L1 error baseline: 0.03983
L1 error: 0.14151
Average prediction: -0.10877
Std prediction: 0.20804


