Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              384
├─Time2Vec: 1-2                                    [1, 100, 36]              --
│    └─Linear: 2-1                                 [100, 4]                  8
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 36]              (recursive)
│    └─Linear: 2-2                                 [100, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 36]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 36]              --
│    │    └─ModuleList: 3-1                        --                        23,532
│    │    └─LayerNorm: 3-2                         [1, 100, 36]              72
│    └─TransformerDecoder: 2-4                     [1, 100, 36]              --
│    │    └─ModuleList: 3-3                        --                        39,732
│    │    └─LayerNorm: 3-4                         [1, 100, 36]              72
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 18]              666
│    └─Dropout: 2-6                                [1, 100, 18]              --
│    └─ReLU: 2-7                                   [1, 100, 18]              --
│    └─Linear: 2-8                                 [1, 100, 1]               19
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 64,485
Trainable params: 64,485
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.55
Params size (MB): 0.04
Estimated Total Size (MB): 0.60
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.4317267835140228
Epoch 1 / 200, val loss: 7.49627685546875
Epoch 1 / 200, val acc: 0.46475195822454307
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.4206913709640503
Epoch 2 / 200, val loss: 7.383487224578857
Epoch 2 / 200, val acc: 0.46736292428198434
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.4155299663543701
Epoch 3 / 200, val loss: 7.091498374938965
Epoch 3 / 200, val acc: 0.46736292428198434
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.4081399738788605
Epoch 4 / 200, val loss: 6.805083751678467
Epoch 4 / 200, val acc: 0.49869451697127937
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.40446123480796814
Epoch 5 / 200, val loss: 6.614952087402344
Epoch 5 / 200, val acc: 0.5456919060052219
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.4037773013114929
Epoch 6 / 200, val loss: 6.519466400146484
Epoch 6 / 200, val acc: 0.46475195822454307
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.40445786714553833
Epoch 7 / 200, val loss: 6.495159149169922
Epoch 7 / 200, val acc: 0.5117493472584856
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.40554600954055786
Epoch 8 / 200, val loss: 6.469532012939453
Epoch 8 / 200, val acc: 0.48825065274151436
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.4037303328514099
Epoch 9 / 200, val loss: 6.456439971923828
Epoch 9 / 200, val acc: 0.5300261096605744
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.40226733684539795
Epoch 10 / 200, val loss: 6.493685722351074
Epoch 10 / 200, val acc: 0.5796344647519582
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.40162110328674316
Epoch 11 / 200, val loss: 6.550930023193359
Epoch 11 / 200, val acc: 0.5352480417754569
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.4004926085472107
Epoch 12 / 200, val loss: 6.620325088500977
Epoch 12 / 200, val acc: 0.4751958224543081
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.40124380588531494
Epoch 13 / 200, val loss: 6.675809383392334
Epoch 13 / 200, val acc: 0.5091383812010444
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.4007216691970825
Epoch 14 / 200, val loss: 6.700873851776123
Epoch 14 / 200, val acc: 0.5117493472584856
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.4019947052001953
Epoch 15 / 200, val loss: 6.695287227630615
Epoch 15 / 200, val acc: 0.45691906005221933
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.40016603469848633
Epoch 16 / 200, val loss: 6.6829328536987305
Epoch 16 / 200, val acc: 0.5169712793733682
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.4003714323043823
Epoch 17 / 200, val loss: 6.6695780754089355
Epoch 17 / 200, val acc: 0.46736292428198434
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.40005895495414734
Epoch 18 / 200, val loss: 6.654384613037109
Epoch 18 / 200, val acc: 0.4830287206266319
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.40031498670578003
Epoch 19 / 200, val loss: 6.633864402770996
Epoch 19 / 200, val acc: 0.4751958224543081
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.4011150002479553
Epoch 20 / 200, val loss: 6.608544826507568
Epoch 20 / 200, val acc: 0.49869451697127937
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.40011194348335266
Epoch 21 / 200, val loss: 6.597182273864746
Epoch 21 / 200, val acc: 0.4830287206266319
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.4009893238544464
Epoch 22 / 200, val loss: 6.58625602722168
Epoch 22 / 200, val acc: 0.4699738903394256
Epoch 23 / 200, learning rate: 0.0005
Epoch 23 / 200, train loss: 0.4008755087852478
Epoch 23 / 200, val loss: 6.5731611251831055
Epoch 23 / 200, val acc: 0.4856396866840731
Epoch 24 / 200, learning rate: 0.0005
Epoch 24 / 200, train loss: 0.3994078040122986
Epoch 24 / 200, val loss: 6.56467342376709
Epoch 24 / 200, val acc: 0.5143603133159269
Epoch 25 / 200, learning rate: 0.0005
Epoch 25 / 200, train loss: 0.3999125063419342
Epoch 25 / 200, val loss: 6.555904388427734
Epoch 25 / 200, val acc: 0.5195822454308094
Epoch 26 / 200, learning rate: 0.0005
Epoch 26 / 200, train loss: 0.3998391926288605
Epoch 26 / 200, val loss: 6.5466532707214355
Epoch 26 / 200, val acc: 0.4856396866840731
Epoch 27 / 200, learning rate: 0.0005
Epoch 27 / 200, train loss: 0.4006373882293701
Epoch 27 / 200, val loss: 6.538557052612305
Epoch 27 / 200, val acc: 0.4934725848563969
Epoch 28 / 200, learning rate: 0.0005
Epoch 28 / 200, train loss: 0.3995458781719208
Epoch 28 / 200, val loss: 6.533209800720215
Epoch 28 / 200, val acc: 0.5248041775456919
Epoch 29 / 200, learning rate: 0.0005
Epoch 29 / 200, train loss: 0.39951661229133606
Epoch 29 / 200, val loss: 6.532561302185059
Epoch 29 / 200, val acc: 0.5300261096605744
Epoch 30 / 200, learning rate: 0.0005
Epoch 30 / 200, train loss: 0.3989831507205963
Epoch 30 / 200, val loss: 6.5331244468688965
Epoch 30 / 200, val acc: 0.4751958224543081
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.39949262142181396
Epoch 31 / 200, val loss: 6.546838283538818
Epoch 31 / 200, val acc: 0.47780678851174935
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.3986119031906128
Epoch 32 / 200, val loss: 6.5531721115112305
Epoch 32 / 200, val acc: 0.47780678851174935
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.3996676802635193
Epoch 33 / 200, val loss: 6.559523582458496
Epoch 33 / 200, val acc: 0.4725848563968668
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.39957624673843384
Epoch 34 / 200, val loss: 6.566339015960693
Epoch 34 / 200, val acc: 0.4934725848563969
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.3992292284965515
Epoch 35 / 200, val loss: 6.574645042419434
Epoch 35 / 200, val acc: 0.49869451697127937
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.3978707194328308
Epoch 36 / 200, val loss: 6.584149360656738
Epoch 36 / 200, val acc: 0.48825065274151436
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.3980966806411743
Epoch 37 / 200, val loss: 6.596529960632324
Epoch 37 / 200, val acc: 0.49869451697127937
Epoch 38 / 200, learning rate: 0.00025
Epoch 38 / 200, train loss: 0.3996955454349518
Epoch 38 / 200, val loss: 6.607940673828125
Epoch 38 / 200, val acc: 0.4934725848563969
Epoch 39 / 200, learning rate: 0.00025
Epoch 39 / 200, train loss: 0.39803075790405273
Epoch 39 / 200, val loss: 6.616710662841797
Epoch 39 / 200, val acc: 0.5013054830287206
Epoch 40 / 200, learning rate: 0.00025
Epoch 40 / 200, train loss: 0.3970809876918793
Epoch 40 / 200, val loss: 6.624711513519287
Epoch 40 / 200, val acc: 0.5039164490861618
Epoch 41 / 200, learning rate: 0.00025
Epoch 41 / 200, train loss: 0.3986872732639313
Epoch 41 / 200, val loss: 6.630527019500732
Epoch 41 / 200, val acc: 0.49869451697127937
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.398101806640625
Epoch 42 / 200, val loss: 6.634095668792725
Epoch 42 / 200, val acc: 0.5117493472584856
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.3973475694656372
Epoch 43 / 200, val loss: 6.634352684020996
Epoch 43 / 200, val acc: 0.5065274151436031
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.39641356468200684
Epoch 44 / 200, val loss: 6.635055065155029
Epoch 44 / 200, val acc: 0.5248041775456919
Epoch 45 / 200, learning rate: 0.000125
Epoch 45 / 200, train loss: 0.39753028750419617
Epoch 45 / 200, val loss: 6.636128902435303
Epoch 45 / 200, val acc: 0.5248041775456919
Epoch 46 / 200, learning rate: 0.000125
Epoch 46 / 200, train loss: 0.3978351056575775
Epoch 46 / 200, val loss: 6.636038780212402
Epoch 46 / 200, val acc: 0.4960835509138381
Epoch 47 / 200, learning rate: 0.000125
Epoch 47 / 200, train loss: 0.3971579670906067
Epoch 47 / 200, val loss: 6.63454532623291
Epoch 47 / 200, val acc: 0.5091383812010444
Epoch 48 / 200, learning rate: 0.000125
Epoch 48 / 200, train loss: 0.39729538559913635
Epoch 48 / 200, val loss: 6.63116979598999
Epoch 48 / 200, val acc: 0.5013054830287206
Epoch 49 / 200, learning rate: 0.000125
Epoch 49 / 200, train loss: 0.39832204580307007
Epoch 49 / 200, val loss: 6.62665319442749
Epoch 49 / 200, val acc: 0.5169712793733682
Epoch 50 / 200, learning rate: 0.000125
Epoch 50 / 200, train loss: 0.39829835295677185
Epoch 50 / 200, val loss: 6.621306896209717
Epoch 50 / 200, val acc: 0.5065274151436031
Epoch 51 / 200, learning rate: 0.000125
Epoch 51 / 200, train loss: 0.39711347222328186
Epoch 51 / 200, val loss: 6.615943908691406
Epoch 51 / 200, val acc: 0.5195822454308094
Epoch 52 / 200, learning rate: 0.000125
Epoch 52 / 200, train loss: 0.39583519101142883
Epoch 52 / 200, val loss: 6.611090660095215
Epoch 52 / 200, val acc: 0.5091383812010444
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.39534255862236023
Epoch 53 / 200, val loss: 6.605822563171387
Epoch 53 / 200, val acc: 0.5143603133159269
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.3979842960834503
Epoch 54 / 200, val loss: 6.6030731201171875
Epoch 54 / 200, val acc: 0.5195822454308094
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.39629530906677246
Epoch 55 / 200, val loss: 6.600669860839844
Epoch 55 / 200, val acc: 0.5169712793733682
Epoch 56 / 200, learning rate: 6.25e-05
Epoch 56 / 200, train loss: 0.3958779573440552
Epoch 56 / 200, val loss: 6.597960948944092
Epoch 56 / 200, val acc: 0.5248041775456919
Epoch 57 / 200, learning rate: 6.25e-05
Epoch 57 / 200, train loss: 0.39551475644111633
Epoch 57 / 200, val loss: 6.595966339111328
Epoch 57 / 200, val acc: 0.5248041775456919
Epoch 58 / 200, learning rate: 6.25e-05
Epoch 58 / 200, train loss: 0.39564216136932373
Epoch 58 / 200, val loss: 6.59393835067749
Epoch 58 / 200, val acc: 0.5117493472584856
Epoch 59 / 200, learning rate: 6.25e-05
Epoch 59 / 200, train loss: 0.39573559165000916
Epoch 59 / 200, val loss: 6.592963695526123
Epoch 59 / 200, val acc: 0.5169712793733682
Epoch 60 / 200, learning rate: 6.25e-05
Epoch 60 / 200, train loss: 0.39525914192199707
Epoch 60 / 200, val loss: 6.592870235443115
Epoch 60 / 200, val acc: 0.5065274151436031
Epoch 61 / 200, learning rate: 6.25e-05
Epoch 61 / 200, train loss: 0.39500412344932556
Epoch 61 / 200, val loss: 6.5934343338012695
Epoch 61 / 200, val acc: 0.5065274151436031
Epoch 62 / 200, learning rate: 6.25e-05
Epoch 62 / 200, train loss: 0.39681369066238403
Epoch 62 / 200, val loss: 6.594022274017334
Epoch 62 / 200, val acc: 0.5117493472584856
Epoch 63 / 200, learning rate: 6.25e-05
Epoch 63 / 200, train loss: 0.3944006562232971
Epoch 63 / 200, val loss: 6.595415115356445
Epoch 63 / 200, val acc: 0.5065274151436031
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.39486727118492126
Epoch 64 / 200, val loss: 6.598058700561523
Epoch 64 / 200, val acc: 0.5195822454308094
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.39520877599716187
Epoch 65 / 200, val loss: 6.599748134613037
Epoch 65 / 200, val acc: 0.5117493472584856
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.3954480290412903
Epoch 66 / 200, val loss: 6.601308345794678
Epoch 66 / 200, val acc: 0.5221932114882507
Epoch 67 / 200, learning rate: 3.125e-05
Epoch 67 / 200, train loss: 0.39329993724823
Epoch 67 / 200, val loss: 6.60359001159668
Epoch 67 / 200, val acc: 0.5221932114882507
Epoch 68 / 200, learning rate: 3.125e-05
Epoch 68 / 200, train loss: 0.39498040080070496
Epoch 68 / 200, val loss: 6.605826377868652
Epoch 68 / 200, val acc: 0.5300261096605744
Epoch 69 / 200, learning rate: 3.125e-05
Epoch 69 / 200, train loss: 0.39462268352508545
Epoch 69 / 200, val loss: 6.607730388641357
Epoch 69 / 200, val acc: 0.5248041775456919
Epoch 70 / 200, learning rate: 3.125e-05
Epoch 70 / 200, train loss: 0.393557608127594
Epoch 70 / 200, val loss: 6.609969139099121
Epoch 70 / 200, val acc: 0.5274151436031331
Epoch 71 / 200, learning rate: 3.125e-05
Epoch 71 / 200, train loss: 0.3963660001754761
Epoch 71 / 200, val loss: 6.611791133880615
Epoch 71 / 200, val acc: 0.5300261096605744
Epoch 72 / 200, learning rate: 3.125e-05
Epoch 72 / 200, train loss: 0.3941538631916046
Epoch 72 / 200, val loss: 6.613539695739746
Epoch 72 / 200, val acc: 0.5300261096605744
Epoch 73 / 200, learning rate: 3.125e-05
Epoch 73 / 200, train loss: 0.3944387435913086
Epoch 73 / 200, val loss: 6.6154608726501465
Epoch 73 / 200, val acc: 0.5274151436031331
Epoch 74 / 200, learning rate: 3.125e-05
Epoch 74 / 200, train loss: 0.39421314001083374
Epoch 74 / 200, val loss: 6.617133140563965
Epoch 74 / 200, val acc: 0.5352480417754569
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.39399316906929016
Epoch 75 / 200, val loss: 6.618772029876709
Epoch 75 / 200, val acc: 0.5483028720626631
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.39362671971321106
Epoch 76 / 200, val loss: 6.619674205780029
Epoch 76 / 200, val acc: 0.5587467362924282
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.39442846179008484
Epoch 77 / 200, val loss: 6.620368003845215
Epoch 77 / 200, val acc: 0.5613577023498695
Epoch 78 / 200, learning rate: 1.5625e-05
Epoch 78 / 200, train loss: 0.3946790397167206
Epoch 78 / 200, val loss: 6.620778560638428
Epoch 78 / 200, val acc: 0.556135770234987
Epoch 79 / 200, learning rate: 1.5625e-05
Epoch 79 / 200, train loss: 0.393311083316803
Epoch 79 / 200, val loss: 6.621070384979248
Epoch 79 / 200, val acc: 0.5587467362924282
Epoch 80 / 200, learning rate: 1.5625e-05
Epoch 80 / 200, train loss: 0.3931959569454193
Epoch 80 / 200, val loss: 6.6212615966796875
Epoch 80 / 200, val acc: 0.5483028720626631
Epoch 81 / 200, learning rate: 1.5625e-05
Epoch 81 / 200, train loss: 0.39476144313812256
Epoch 81 / 200, val loss: 6.621036529541016
Epoch 81 / 200, val acc: 0.5404699738903395
Epoch 82 / 200, learning rate: 1.5625e-05
Epoch 82 / 200, train loss: 0.39303532242774963
Epoch 82 / 200, val loss: 6.620875358581543
Epoch 82 / 200, val acc: 0.5430809399477807
Epoch 83 / 200, learning rate: 1.5625e-05
Epoch 83 / 200, train loss: 0.3933456838130951
Epoch 83 / 200, val loss: 6.620781898498535
Epoch 83 / 200, val acc: 0.5326370757180157
Epoch 84 / 200, learning rate: 1.5625e-05
Epoch 84 / 200, train loss: 0.3936842381954193
Epoch 84 / 200, val loss: 6.620746612548828
Epoch 84 / 200, val acc: 0.5195822454308094
Epoch 85 / 200, learning rate: 1.5625e-05
Epoch 85 / 200, train loss: 0.3949722349643707
Epoch 85 / 200, val loss: 6.620512962341309
Epoch 85 / 200, val acc: 0.5326370757180157
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.3928593099117279
Epoch 86 / 200, val loss: 6.620051383972168
Epoch 86 / 200, val acc: 0.5248041775456919
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.3932364284992218
Epoch 87 / 200, val loss: 6.619968414306641
Epoch 87 / 200, val acc: 0.5274151436031331
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.3943008482456207
Epoch 88 / 200, val loss: 6.61988639831543
Epoch 88 / 200, val acc: 0.5221932114882507
Epoch 89 / 200, learning rate: 7.8125e-06
Epoch 89 / 200, train loss: 0.3932967185974121
Epoch 89 / 200, val loss: 6.6197028160095215
Epoch 89 / 200, val acc: 0.5326370757180157
Epoch 90 / 200, learning rate: 7.8125e-06
Epoch 90 / 200, train loss: 0.3950943946838379
Epoch 90 / 200, val loss: 6.619416236877441
Epoch 90 / 200, val acc: 0.5221932114882507
Epoch 91 / 200, learning rate: 7.8125e-06
Epoch 91 / 200, train loss: 0.39255356788635254
Epoch 91 / 200, val loss: 6.6191558837890625
Epoch 91 / 200, val acc: 0.5221932114882507
Epoch 92 / 200, learning rate: 7.8125e-06
Epoch 92 / 200, train loss: 0.39379799365997314
Epoch 92 / 200, val loss: 6.618821620941162
Epoch 92 / 200, val acc: 0.5248041775456919
Epoch 93 / 200, learning rate: 7.8125e-06
Epoch 93 / 200, train loss: 0.39279705286026
Epoch 93 / 200, val loss: 6.618478775024414
Epoch 93 / 200, val acc: 0.5143603133159269
Epoch 94 / 200, learning rate: 7.8125e-06
Epoch 94 / 200, train loss: 0.3940737843513489
Epoch 94 / 200, val loss: 6.618033409118652
Epoch 94 / 200, val acc: 0.5065274151436031
Epoch 95 / 200, learning rate: 7.8125e-06
Epoch 95 / 200, train loss: 0.3926961421966553
Epoch 95 / 200, val loss: 6.6176557540893555
Epoch 95 / 200, val acc: 0.5065274151436031
Epoch 96 / 200, learning rate: 7.8125e-06
Epoch 96 / 200, train loss: 0.39299482107162476
Epoch 96 / 200, val loss: 6.617218017578125
Epoch 96 / 200, val acc: 0.5065274151436031
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.3931650221347809
Epoch 97 / 200, val loss: 6.616761207580566
Epoch 97 / 200, val acc: 0.5117493472584856
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.39333048462867737
Epoch 98 / 200, val loss: 6.616561412811279
Epoch 98 / 200, val acc: 0.5143603133159269
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.39237335324287415
Epoch 99 / 200, val loss: 6.616371154785156
Epoch 99 / 200, val acc: 0.5195822454308094
Epoch 100 / 200, learning rate: 3.90625e-06
Epoch 100 / 200, train loss: 0.393837571144104
Epoch 100 / 200, val loss: 6.616083145141602
Epoch 100 / 200, val acc: 0.5195822454308094
Epoch 101 / 200, learning rate: 3.90625e-06
Epoch 101 / 200, train loss: 0.3925130069255829
Epoch 101 / 200, val loss: 6.615839958190918
Epoch 101 / 200, val acc: 0.5221932114882507
Epoch 102 / 200, learning rate: 3.90625e-06
Epoch 102 / 200, train loss: 0.39371123909950256
Epoch 102 / 200, val loss: 6.61557149887085
Epoch 102 / 200, val acc: 0.5221932114882507
Epoch 103 / 200, learning rate: 3.90625e-06
Epoch 103 / 200, train loss: 0.3928775489330292
Epoch 103 / 200, val loss: 6.615306854248047
Epoch 103 / 200, val acc: 0.5248041775456919
Epoch 104 / 200, learning rate: 3.90625e-06
Epoch 104 / 200, train loss: 0.39378196001052856
Epoch 104 / 200, val loss: 6.615094184875488
Epoch 104 / 200, val acc: 0.5300261096605744
Epoch 105 / 200, learning rate: 3.90625e-06
Epoch 105 / 200, train loss: 0.39325469732284546
Epoch 105 / 200, val loss: 6.614823818206787
Epoch 105 / 200, val acc: 0.5300261096605744
Epoch 106 / 200, learning rate: 3.90625e-06
Epoch 106 / 200, train loss: 0.3933354318141937
Epoch 106 / 200, val loss: 6.614588737487793
Epoch 106 / 200, val acc: 0.5300261096605744
Epoch 107 / 200, learning rate: 3.90625e-06
Epoch 107 / 200, train loss: 0.393646776676178
Epoch 107 / 200, val loss: 6.6143341064453125
Epoch 107 / 200, val acc: 0.5221932114882507
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.3914519250392914
Epoch 108 / 200, val loss: 6.6140875816345215
Epoch 108 / 200, val acc: 0.5195822454308094
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.39346370100975037
Epoch 109 / 200, val loss: 6.613982200622559
Epoch 109 / 200, val acc: 0.5195822454308094
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.3941129148006439
Epoch 110 / 200, val loss: 6.61386251449585
Epoch 110 / 200, val acc: 0.5221932114882507
Epoch 111 / 200, learning rate: 1.953125e-06
Epoch 111 / 200, train loss: 0.39276647567749023
Epoch 111 / 200, val loss: 6.6137542724609375
Epoch 111 / 200, val acc: 0.5274151436031331
Epoch 112 / 200, learning rate: 1.953125e-06
Epoch 112 / 200, train loss: 0.39399856328964233
Epoch 112 / 200, val loss: 6.61362361907959
Epoch 112 / 200, val acc: 0.5248041775456919
Epoch 113 / 200, learning rate: 1.953125e-06
Epoch 113 / 200, train loss: 0.3923611640930176
Epoch 113 / 200, val loss: 6.613515853881836
Epoch 113 / 200, val acc: 0.5221932114882507
Epoch 114 / 200, learning rate: 1.953125e-06
Epoch 114 / 200, train loss: 0.39305007457733154
Epoch 114 / 200, val loss: 6.6134185791015625
Epoch 114 / 200, val acc: 0.5221932114882507
Epoch 115 / 200, learning rate: 1.953125e-06
Epoch 115 / 200, train loss: 0.39228689670562744
Epoch 115 / 200, val loss: 6.613337516784668
Epoch 115 / 200, val acc: 0.5248041775456919
Epoch 116 / 200, learning rate: 1.953125e-06
Epoch 116 / 200, train loss: 0.39373284578323364
Epoch 116 / 200, val loss: 6.613275527954102
Epoch 116 / 200, val acc: 0.5221932114882507
Epoch 117 / 200, learning rate: 1.953125e-06
Epoch 117 / 200, train loss: 0.3931206166744232
Epoch 117 / 200, val loss: 6.613197326660156
Epoch 117 / 200, val acc: 0.5248041775456919
Epoch 118 / 200, learning rate: 1.953125e-06
Epoch 118 / 200, train loss: 0.39604535698890686
Epoch 118 / 200, val loss: 6.613072395324707
Epoch 118 / 200, val acc: 0.5248041775456919
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.3931891620159149
Epoch 119 / 200, val loss: 6.61293888092041
Epoch 119 / 200, val acc: 0.5221932114882507
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.39148902893066406
Epoch 120 / 200, val loss: 6.6128950119018555
Epoch 120 / 200, val acc: 0.5248041775456919
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.3924904465675354
Epoch 121 / 200, val loss: 6.612863063812256
Epoch 121 / 200, val acc: 0.5248041775456919
Epoch 122 / 200, learning rate: 9.765625e-07
Epoch 122 / 200, train loss: 0.3937309980392456
Epoch 122 / 200, val loss: 6.6128339767456055
Epoch 122 / 200, val acc: 0.5195822454308094
Epoch 123 / 200, learning rate: 9.765625e-07
Epoch 123 / 200, train loss: 0.3944208025932312
Epoch 123 / 200, val loss: 6.61280632019043
Epoch 123 / 200, val acc: 0.5274151436031331
Epoch 124 / 200, learning rate: 9.765625e-07
Epoch 124 / 200, train loss: 0.393836110830307
Epoch 124 / 200, val loss: 6.612782955169678
Epoch 124 / 200, val acc: 0.5274151436031331
Epoch 125 / 200, learning rate: 9.765625e-07
Epoch 125 / 200, train loss: 0.3925005793571472
Epoch 125 / 200, val loss: 6.612777233123779
Epoch 125 / 200, val acc: 0.5274151436031331
Epoch 126 / 200, learning rate: 9.765625e-07
Epoch 126 / 200, train loss: 0.39265432953834534
Epoch 126 / 200, val loss: 6.612771511077881
Epoch 126 / 200, val acc: 0.5248041775456919
Epoch 127 / 200, learning rate: 9.765625e-07
Epoch 127 / 200, train loss: 0.3939268887042999
Epoch 127 / 200, val loss: 6.612742900848389
Epoch 127 / 200, val acc: 0.5221932114882507
Epoch 128 / 200, learning rate: 9.765625e-07
Epoch 128 / 200, train loss: 0.39165833592414856
Epoch 128 / 200, val loss: 6.612730979919434
Epoch 128 / 200, val acc: 0.5274151436031331
Epoch 129 / 200, learning rate: 9.765625e-07
Epoch 129 / 200, train loss: 0.394316166639328
Epoch 129 / 200, val loss: 6.612701416015625
Epoch 129 / 200, val acc: 0.5248041775456919
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.39255744218826294
Epoch 130 / 200, val loss: 6.612687587738037
Epoch 130 / 200, val acc: 0.5221932114882507
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.3933939039707184
Epoch 131 / 200, val loss: 6.612682342529297
Epoch 131 / 200, val acc: 0.5195822454308094
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.39420366287231445
Epoch 132 / 200, val loss: 6.612677574157715
Epoch 132 / 200, val acc: 0.5221932114882507
Epoch 133 / 200, learning rate: 4.8828125e-07
Epoch 133 / 200, train loss: 0.39239436388015747
Epoch 133 / 200, val loss: 6.612674236297607
Epoch 133 / 200, val acc: 0.5221932114882507
Epoch 134 / 200, learning rate: 4.8828125e-07
Epoch 134 / 200, train loss: 0.3942132890224457
Epoch 134 / 200, val loss: 6.612664699554443
Epoch 134 / 200, val acc: 0.5169712793733682
Epoch 135 / 200, learning rate: 4.8828125e-07
Epoch 135 / 200, train loss: 0.392183780670166
Epoch 135 / 200, val loss: 6.612657070159912
Epoch 135 / 200, val acc: 0.5169712793733682
Epoch 136 / 200, learning rate: 4.8828125e-07
Epoch 136 / 200, train loss: 0.39454716444015503
Epoch 136 / 200, val loss: 6.612648010253906
Epoch 136 / 200, val acc: 0.5195822454308094
Epoch 137 / 200, learning rate: 4.8828125e-07
Epoch 137 / 200, train loss: 0.3925919830799103
Epoch 137 / 200, val loss: 6.612634181976318
Epoch 137 / 200, val acc: 0.5195822454308094
Epoch 138 / 200, learning rate: 4.8828125e-07
Epoch 138 / 200, train loss: 0.3928339183330536
Epoch 138 / 200, val loss: 6.6126251220703125
Epoch 138 / 200, val acc: 0.5169712793733682
Epoch 139 / 200, learning rate: 4.8828125e-07
Epoch 139 / 200, train loss: 0.39233383536338806
Epoch 139 / 200, val loss: 6.612617492675781
Epoch 139 / 200, val acc: 0.5195822454308094
Epoch 140 / 200, learning rate: 4.8828125e-07
Epoch 140 / 200, train loss: 0.3960418999195099
Epoch 140 / 200, val loss: 6.612601280212402
Epoch 140 / 200, val acc: 0.5221932114882507
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.3924911618232727
Epoch 141 / 200, val loss: 6.612588405609131
Epoch 141 / 200, val acc: 0.5195822454308094
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.3933001160621643
Epoch 142 / 200, val loss: 6.612583160400391
Epoch 142 / 200, val acc: 0.5195822454308094
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.3949092924594879
Epoch 143 / 200, val loss: 6.612578392028809
Epoch 143 / 200, val acc: 0.5169712793733682
Epoch 144 / 200, learning rate: 2.44140625e-07
Epoch 144 / 200, train loss: 0.39324086904525757
Epoch 144 / 200, val loss: 6.612575054168701
Epoch 144 / 200, val acc: 0.5169712793733682
Epoch 145 / 200, learning rate: 2.44140625e-07
Epoch 145 / 200, train loss: 0.392259806394577
Epoch 145 / 200, val loss: 6.612571716308594
Epoch 145 / 200, val acc: 0.5195822454308094
Epoch 146 / 200, learning rate: 2.44140625e-07
Epoch 146 / 200, train loss: 0.39184364676475525
Epoch 146 / 200, val loss: 6.6125640869140625
Epoch 146 / 200, val acc: 0.5221932114882507
Epoch 147 / 200, learning rate: 2.44140625e-07
Epoch 147 / 200, train loss: 0.3926829397678375
Epoch 147 / 200, val loss: 6.612555980682373
Epoch 147 / 200, val acc: 0.5143603133159269
Epoch 148 / 200, learning rate: 2.44140625e-07
Epoch 148 / 200, train loss: 0.39336445927619934
Epoch 148 / 200, val loss: 6.612548828125
Epoch 148 / 200, val acc: 0.5169712793733682
Epoch 149 / 200, learning rate: 2.44140625e-07
Epoch 149 / 200, train loss: 0.392545223236084
Epoch 149 / 200, val loss: 6.612539291381836
Epoch 149 / 200, val acc: 0.5221932114882507
Epoch 150 / 200, learning rate: 2.44140625e-07
Epoch 150 / 200, train loss: 0.3943624198436737
Epoch 150 / 200, val loss: 6.612527370452881
Epoch 150 / 200, val acc: 0.5248041775456919
Epoch 151 / 200, learning rate: 2.44140625e-07
Epoch 151 / 200, train loss: 0.3920377194881439
Epoch 151 / 200, val loss: 6.612519264221191
Epoch 151 / 200, val acc: 0.5195822454308094
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.393164724111557
Epoch 152 / 200, val loss: 6.612504959106445
Epoch 152 / 200, val acc: 0.5195822454308094
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.3926292955875397
Epoch 153 / 200, val loss: 6.612499237060547
Epoch 153 / 200, val acc: 0.5169712793733682
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.394864946603775
Epoch 154 / 200, val loss: 6.612495422363281
Epoch 154 / 200, val acc: 0.5248041775456919
Epoch 155 / 200, learning rate: 1.220703125e-07
Epoch 155 / 200, train loss: 0.39170658588409424
Epoch 155 / 200, val loss: 6.612491607666016
Epoch 155 / 200, val acc: 0.5221932114882507
Epoch 156 / 200, learning rate: 1.220703125e-07
Epoch 156 / 200, train loss: 0.3934786021709442
Epoch 156 / 200, val loss: 6.612487316131592
Epoch 156 / 200, val acc: 0.5221932114882507
Epoch 157 / 200, learning rate: 1.220703125e-07
Epoch 157 / 200, train loss: 0.3942660987377167
Epoch 157 / 200, val loss: 6.612481594085693
Epoch 157 / 200, val acc: 0.5195822454308094
Epoch 158 / 200, learning rate: 1.220703125e-07
Epoch 158 / 200, train loss: 0.39213693141937256
Epoch 158 / 200, val loss: 6.612477779388428
Epoch 158 / 200, val acc: 0.5221932114882507
Epoch 159 / 200, learning rate: 1.220703125e-07
Epoch 159 / 200, train loss: 0.39358460903167725
Epoch 159 / 200, val loss: 6.612473964691162
Epoch 159 / 200, val acc: 0.5221932114882507
Epoch 160 / 200, learning rate: 1.220703125e-07
Epoch 160 / 200, train loss: 0.3929104804992676
Epoch 160 / 200, val loss: 6.612472057342529
Epoch 160 / 200, val acc: 0.5195822454308094
Epoch 161 / 200, learning rate: 1.220703125e-07
Epoch 161 / 200, train loss: 0.39196303486824036
Epoch 161 / 200, val loss: 6.612471580505371
Epoch 161 / 200, val acc: 0.5221932114882507
Epoch 162 / 200, learning rate: 1.220703125e-07
Epoch 162 / 200, train loss: 0.39362987875938416
Epoch 162 / 200, val loss: 6.612468719482422
Epoch 162 / 200, val acc: 0.5169712793733682
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.3929799199104309
Epoch 163 / 200, val loss: 6.612466812133789
Epoch 163 / 200, val acc: 0.5248041775456919
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.39441362023353577
Epoch 164 / 200, val loss: 6.612465858459473
Epoch 164 / 200, val acc: 0.5195822454308094
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.3927825391292572
Epoch 165 / 200, val loss: 6.612464427947998
Epoch 165 / 200, val acc: 0.5248041775456919
Epoch 166 / 200, learning rate: 6.103515625e-08
Epoch 166 / 200, train loss: 0.39433911442756653
Epoch 166 / 200, val loss: 6.612464427947998
Epoch 166 / 200, val acc: 0.5195822454308094
Epoch 167 / 200, learning rate: 6.103515625e-08
Epoch 167 / 200, train loss: 0.392099529504776
Epoch 167 / 200, val loss: 6.612462520599365
Epoch 167 / 200, val acc: 0.5221932114882507
Epoch 168 / 200, learning rate: 6.103515625e-08
Epoch 168 / 200, train loss: 0.39265480637550354
Epoch 168 / 200, val loss: 6.612461090087891
Epoch 168 / 200, val acc: 0.5221932114882507
Epoch 169 / 200, learning rate: 6.103515625e-08
Epoch 169 / 200, train loss: 0.3932497203350067
Epoch 169 / 200, val loss: 6.612460613250732
Epoch 169 / 200, val acc: 0.5221932114882507
Epoch 170 / 200, learning rate: 6.103515625e-08
Epoch 170 / 200, train loss: 0.39184799790382385
Epoch 170 / 200, val loss: 6.612460136413574
Epoch 170 / 200, val acc: 0.5195822454308094
Epoch 171 / 200, learning rate: 6.103515625e-08
Epoch 171 / 200, train loss: 0.392846018075943
Epoch 171 / 200, val loss: 6.6124587059021
Epoch 171 / 200, val acc: 0.5195822454308094
Epoch 172 / 200, learning rate: 6.103515625e-08
Epoch 172 / 200, train loss: 0.39339107275009155
Epoch 172 / 200, val loss: 6.612454891204834
Epoch 172 / 200, val acc: 0.5221932114882507
Epoch 173 / 200, learning rate: 6.103515625e-08
Epoch 173 / 200, train loss: 0.39338400959968567
Epoch 173 / 200, val loss: 6.612451076507568
Epoch 173 / 200, val acc: 0.5195822454308094
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.39318105578422546
Epoch 174 / 200, val loss: 6.6124467849731445
Epoch 174 / 200, val acc: 0.5221932114882507
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.39353957772254944
Epoch 175 / 200, val loss: 6.612444877624512
Epoch 175 / 200, val acc: 0.5221932114882507
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.39380118250846863
Epoch 176 / 200, val loss: 6.6124420166015625
Epoch 176 / 200, val acc: 0.5248041775456919
Epoch 177 / 200, learning rate: 3.0517578125e-08
Epoch 177 / 200, train loss: 0.3937198519706726
Epoch 177 / 200, val loss: 6.6124396324157715
Epoch 177 / 200, val acc: 0.5195822454308094
Epoch 178 / 200, learning rate: 3.0517578125e-08
Epoch 178 / 200, train loss: 0.3925914168357849
Epoch 178 / 200, val loss: 6.612438201904297
Epoch 178 / 200, val acc: 0.5221932114882507
Epoch 179 / 200, learning rate: 3.0517578125e-08
Epoch 179 / 200, train loss: 0.39380359649658203
Epoch 179 / 200, val loss: 6.612435817718506
Epoch 179 / 200, val acc: 0.5195822454308094
Epoch 180 / 200, learning rate: 3.0517578125e-08
Epoch 180 / 200, train loss: 0.3946119546890259
Epoch 180 / 200, val loss: 6.612433910369873
Epoch 180 / 200, val acc: 0.5195822454308094
Epoch 181 / 200, learning rate: 3.0517578125e-08
Epoch 181 / 200, train loss: 0.3922828137874603
Epoch 181 / 200, val loss: 6.61243200302124
Epoch 181 / 200, val acc: 0.5221932114882507
Epoch 182 / 200, learning rate: 3.0517578125e-08
Epoch 182 / 200, train loss: 0.39306747913360596
Epoch 182 / 200, val loss: 6.612429618835449
Epoch 182 / 200, val acc: 0.5195822454308094
Epoch 183 / 200, learning rate: 3.0517578125e-08
Epoch 183 / 200, train loss: 0.39476698637008667
Epoch 183 / 200, val loss: 6.612427711486816
Epoch 183 / 200, val acc: 0.5248041775456919
Epoch 184 / 200, learning rate: 3.0517578125e-08
Epoch 184 / 200, train loss: 0.39270657300949097
Epoch 184 / 200, val loss: 6.612425804138184
Epoch 184 / 200, val acc: 0.5169712793733682
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.39450985193252563
Epoch 185 / 200, val loss: 6.612424373626709
Epoch 185 / 200, val acc: 0.5195822454308094
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.3934973180294037
Epoch 186 / 200, val loss: 6.612422943115234
Epoch 186 / 200, val acc: 0.5195822454308094
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.3939273953437805
Epoch 187 / 200, val loss: 6.612422466278076
Epoch 187 / 200, val acc: 0.5169712793733682
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.3939189612865448
Epoch 188 / 200, val loss: 6.612421989440918
Epoch 188 / 200, val acc: 0.5221932114882507
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.39296969771385193
Epoch 189 / 200, val loss: 6.612421035766602
Epoch 189 / 200, val acc: 0.5195822454308094
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.3928723633289337
Epoch 190 / 200, val loss: 6.612420558929443
Epoch 190 / 200, val acc: 0.5195822454308094
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.39132437109947205
Epoch 191 / 200, val loss: 6.612420082092285
Epoch 191 / 200, val acc: 0.5195822454308094
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.3924790024757385
Epoch 192 / 200, val loss: 6.612419128417969
Epoch 192 / 200, val acc: 0.5195822454308094
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.39284801483154297
Epoch 193 / 200, val loss: 6.6124186515808105
Epoch 193 / 200, val acc: 0.5221932114882507
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.393060564994812
Epoch 194 / 200, val loss: 6.612418174743652
Epoch 194 / 200, val acc: 0.5195822454308094
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.3927100598812103
Epoch 195 / 200, val loss: 6.612418174743652
Epoch 195 / 200, val acc: 0.5195822454308094
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.393306702375412
Epoch 196 / 200, val loss: 6.612417221069336
Epoch 196 / 200, val acc: 0.5169712793733682
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.39350375533103943
Epoch 197 / 200, val loss: 6.612417221069336
Epoch 197 / 200, val acc: 0.5195822454308094
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.39358365535736084
Epoch 198 / 200, val loss: 6.6124162673950195
Epoch 198 / 200, val acc: 0.5195822454308094
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.3925936222076416
Epoch 199 / 200, val loss: 6.6124162673950195
Epoch 199 / 200, val acc: 0.5195822454308094
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.3938233256340027
Epoch 200 / 200, val loss: 6.612414836883545
Epoch 200 / 200, val acc: 0.5195822454308094
Training finished

Evaluating best model on entire dataset

Evaluating best model on test dataset
677 trading days
Binary accuracy: 0.49205
Fraction of long signals: 0.51739
Fraction of short signals: 0.48196
Overall long return: 3.42970
Overall return: 0.61666
Yearly long return: 0.11258
Yearly return: 0.02024
Daily volatility: 0.01188
Max drawdown baseline: 0.25668
Max drawdown: 0.97452
Sharpe ratio: -0.03085
L1 error baseline: 0.78800
L1 error: 0.72191
Average prediction: -0.20416
Std prediction: 0.00639
Trading strategy for stock SPY:
After 384 trading days
Binary accuracy: 0.50131
Fraction of long signals: 0.50521
Fraction of short signals: 0.49479
Overall long return: 0.03127
Overall return: 0.16233
Yearly long return: 0.02052
Yearly return: 0.10653
Daily volatility: 0.01338
Max drawdown baseline: 0.23197
Max drawdown: 0.19602
Sharpe ratio: 0.02560
L1 error baseline: 2.45427
L1 error: 2.65755
Average prediction: -0.20327
Std prediction: 0.00002
