Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              1,440
├─Time2Vec: 1-2                                    [1, 100, 36]              --
│    └─Linear: 2-1                                 [100, 4]                  8
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 36]              (recursive)
│    └─Linear: 2-2                                 [100, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 36]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 36]              --
│    │    └─ModuleList: 3-1                        --                        23,532
│    │    └─LayerNorm: 3-2                         [1, 100, 36]              72
│    └─TransformerDecoder: 2-4                     [1, 100, 36]              --
│    │    └─ModuleList: 3-3                        --                        39,732
│    │    └─LayerNorm: 3-4                         [1, 100, 36]              72
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 18]              666
│    └─Dropout: 2-6                                [1, 100, 18]              --
│    └─ReLU: 2-7                                   [1, 100, 18]              --
│    └─Linear: 2-8                                 [1, 100, 1]               19
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 65,541
Trainable params: 65,541
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 0.55
Params size (MB): 0.04
Estimated Total Size (MB): 0.63
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.557698667049408
Epoch 1 / 200, val loss: 6.594993591308594
Epoch 1 / 200, val acc: 0.5065274151436031
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.45813584327697754
Epoch 2 / 200, val loss: 6.174073219299316
Epoch 2 / 200, val acc: 0.5065274151436031
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.45107564330101013
Epoch 3 / 200, val loss: 6.684382915496826
Epoch 3 / 200, val acc: 0.4830287206266319
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.43634748458862305
Epoch 4 / 200, val loss: 6.895447731018066
Epoch 4 / 200, val acc: 0.5221932114882507
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.4221818149089813
Epoch 5 / 200, val loss: 6.916429042816162
Epoch 5 / 200, val acc: 0.49869451697127937
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.41769251227378845
Epoch 6 / 200, val loss: 6.889913558959961
Epoch 6 / 200, val acc: 0.49869451697127937
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.4117172062397003
Epoch 7 / 200, val loss: 6.868863105773926
Epoch 7 / 200, val acc: 0.4830287206266319
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.4101578891277313
Epoch 8 / 200, val loss: 6.855030059814453
Epoch 8 / 200, val acc: 0.556135770234987
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.41118812561035156
Epoch 9 / 200, val loss: 6.8303375244140625
Epoch 9 / 200, val acc: 0.47780678851174935
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.4080328941345215
Epoch 10 / 200, val loss: 6.796271324157715
Epoch 10 / 200, val acc: 0.5300261096605744
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.4061506390571594
Epoch 11 / 200, val loss: 6.758128643035889
Epoch 11 / 200, val acc: 0.4804177545691906
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.4037330150604248
Epoch 12 / 200, val loss: 6.717565536499023
Epoch 12 / 200, val acc: 0.556135770234987
Epoch 13 / 200, learning rate: 0.0005
Epoch 13 / 200, train loss: 0.40467196702957153
Epoch 13 / 200, val loss: 6.675515651702881
Epoch 13 / 200, val acc: 0.49869451697127937
Epoch 14 / 200, learning rate: 0.0005
Epoch 14 / 200, train loss: 0.403735876083374
Epoch 14 / 200, val loss: 6.655245780944824
Epoch 14 / 200, val acc: 0.4934725848563969
Epoch 15 / 200, learning rate: 0.0005
Epoch 15 / 200, train loss: 0.40436872839927673
Epoch 15 / 200, val loss: 6.635738372802734
Epoch 15 / 200, val acc: 0.46736292428198434
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.40494680404663086
Epoch 16 / 200, val loss: 6.616960048675537
Epoch 16 / 200, val acc: 0.4699738903394256
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.4029293954372406
Epoch 17 / 200, val loss: 6.598878383636475
Epoch 17 / 200, val acc: 0.5169712793733682
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.40410760045051575
Epoch 18 / 200, val loss: 6.58160924911499
Epoch 18 / 200, val acc: 0.5143603133159269
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.40174350142478943
Epoch 19 / 200, val loss: 6.565606594085693
Epoch 19 / 200, val acc: 0.5430809399477807
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.40323367714881897
Epoch 20 / 200, val loss: 6.551877975463867
Epoch 20 / 200, val acc: 0.5430809399477807
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.40229693055152893
Epoch 21 / 200, val loss: 6.539653778076172
Epoch 21 / 200, val acc: 0.5065274151436031
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.40299758315086365
Epoch 22 / 200, val loss: 6.528242111206055
Epoch 22 / 200, val acc: 0.4960835509138381
Epoch 23 / 200, learning rate: 0.0005
Epoch 23 / 200, train loss: 0.4018736481666565
Epoch 23 / 200, val loss: 6.519601821899414
Epoch 23 / 200, val acc: 0.5065274151436031
Epoch 24 / 200, learning rate: 0.00025
Epoch 24 / 200, train loss: 0.40197935700416565
Epoch 24 / 200, val loss: 6.512615203857422
Epoch 24 / 200, val acc: 0.5117493472584856
Epoch 25 / 200, learning rate: 0.00025
Epoch 25 / 200, train loss: 0.4020594358444214
Epoch 25 / 200, val loss: 6.5098419189453125
Epoch 25 / 200, val acc: 0.5091383812010444
Epoch 26 / 200, learning rate: 0.00025
Epoch 26 / 200, train loss: 0.4022093713283539
Epoch 26 / 200, val loss: 6.50872802734375
Epoch 26 / 200, val acc: 0.5117493472584856
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.40054479241371155
Epoch 27 / 200, val loss: 6.5093207359313965
Epoch 27 / 200, val acc: 0.5039164490861618
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.4010336101055145
Epoch 28 / 200, val loss: 6.510551452636719
Epoch 28 / 200, val acc: 0.5039164490861618
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.4024803042411804
Epoch 29 / 200, val loss: 6.512074947357178
Epoch 29 / 200, val acc: 0.5195822454308094
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.4019109606742859
Epoch 30 / 200, val loss: 6.514040946960449
Epoch 30 / 200, val acc: 0.5091383812010444
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.40148112177848816
Epoch 31 / 200, val loss: 6.517176628112793
Epoch 31 / 200, val acc: 0.5143603133159269
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.4013639986515045
Epoch 32 / 200, val loss: 6.520956039428711
Epoch 32 / 200, val acc: 0.5117493472584856
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.40203872323036194
Epoch 33 / 200, val loss: 6.524827480316162
Epoch 33 / 200, val acc: 0.49869451697127937
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.40203824639320374
Epoch 34 / 200, val loss: 6.5287322998046875
Epoch 34 / 200, val acc: 0.4960835509138381
Epoch 35 / 200, learning rate: 0.000125
Epoch 35 / 200, train loss: 0.4032236337661743
Epoch 35 / 200, val loss: 6.532276153564453
Epoch 35 / 200, val acc: 0.49869451697127937
Epoch 36 / 200, learning rate: 0.000125
Epoch 36 / 200, train loss: 0.40115419030189514
Epoch 36 / 200, val loss: 6.534566402435303
Epoch 36 / 200, val acc: 0.4856396866840731
Epoch 37 / 200, learning rate: 0.000125
Epoch 37 / 200, train loss: 0.4019204378128052
Epoch 37 / 200, val loss: 6.53725004196167
Epoch 37 / 200, val acc: 0.4908616187989556
Epoch 38 / 200, learning rate: 0.000125
Epoch 38 / 200, train loss: 0.40114617347717285
Epoch 38 / 200, val loss: 6.539955139160156
Epoch 38 / 200, val acc: 0.47780678851174935
Epoch 39 / 200, learning rate: 0.000125
Epoch 39 / 200, train loss: 0.40110984444618225
Epoch 39 / 200, val loss: 6.542657375335693
Epoch 39 / 200, val acc: 0.46736292428198434
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.4013173282146454
Epoch 40 / 200, val loss: 6.545811653137207
Epoch 40 / 200, val acc: 0.4699738903394256
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.4023437201976776
Epoch 41 / 200, val loss: 6.548745155334473
Epoch 41 / 200, val acc: 0.4725848563968668
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.40003684163093567
Epoch 42 / 200, val loss: 6.551944255828857
Epoch 42 / 200, val acc: 0.46475195822454307
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.4012638032436371
Epoch 43 / 200, val loss: 6.5554938316345215
Epoch 43 / 200, val acc: 0.46475195822454307
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.40134960412979126
Epoch 44 / 200, val loss: 6.558980464935303
Epoch 44 / 200, val acc: 0.46475195822454307
Epoch 45 / 200, learning rate: 0.000125
Epoch 45 / 200, train loss: 0.40168488025665283
Epoch 45 / 200, val loss: 6.562586784362793
Epoch 45 / 200, val acc: 0.46736292428198434
Epoch 46 / 200, learning rate: 6.25e-05
Epoch 46 / 200, train loss: 0.40021440386772156
Epoch 46 / 200, val loss: 6.566319942474365
Epoch 46 / 200, val acc: 0.4699738903394256
Epoch 47 / 200, learning rate: 6.25e-05
Epoch 47 / 200, train loss: 0.4007461369037628
Epoch 47 / 200, val loss: 6.568293571472168
Epoch 47 / 200, val acc: 0.46475195822454307
Epoch 48 / 200, learning rate: 6.25e-05
Epoch 48 / 200, train loss: 0.40062400698661804
Epoch 48 / 200, val loss: 6.5702033042907715
Epoch 48 / 200, val acc: 0.45691906005221933
Epoch 49 / 200, learning rate: 6.25e-05
Epoch 49 / 200, train loss: 0.4009242355823517
Epoch 49 / 200, val loss: 6.572196006774902
Epoch 49 / 200, val acc: 0.4699738903394256
Epoch 50 / 200, learning rate: 6.25e-05
Epoch 50 / 200, train loss: 0.40047788619995117
Epoch 50 / 200, val loss: 6.574226379394531
Epoch 50 / 200, val acc: 0.46736292428198434
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.4021035134792328
Epoch 51 / 200, val loss: 6.576272010803223
Epoch 51 / 200, val acc: 0.46475195822454307
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.4021444618701935
Epoch 52 / 200, val loss: 6.578304290771484
Epoch 52 / 200, val acc: 0.4725848563968668
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.4006645083427429
Epoch 53 / 200, val loss: 6.580445289611816
Epoch 53 / 200, val acc: 0.46736292428198434
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.39982184767723083
Epoch 54 / 200, val loss: 6.582627773284912
Epoch 54 / 200, val acc: 0.4699738903394256
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.4017601013183594
Epoch 55 / 200, val loss: 6.584836006164551
Epoch 55 / 200, val acc: 0.46736292428198434
Epoch 56 / 200, learning rate: 6.25e-05
Epoch 56 / 200, train loss: 0.40165504813194275
Epoch 56 / 200, val loss: 6.586940288543701
Epoch 56 / 200, val acc: 0.4699738903394256
Epoch 57 / 200, learning rate: 3.125e-05
Epoch 57 / 200, train loss: 0.4019196629524231
Epoch 57 / 200, val loss: 6.5890302658081055
Epoch 57 / 200, val acc: 0.46736292428198434
Epoch 58 / 200, learning rate: 3.125e-05
Epoch 58 / 200, train loss: 0.40199387073516846
Epoch 58 / 200, val loss: 6.590029716491699
Epoch 58 / 200, val acc: 0.45430809399477806
Epoch 59 / 200, learning rate: 3.125e-05
Epoch 59 / 200, train loss: 0.4007411301136017
Epoch 59 / 200, val loss: 6.591083526611328
Epoch 59 / 200, val acc: 0.4516971279373368
Epoch 60 / 200, learning rate: 3.125e-05
Epoch 60 / 200, train loss: 0.4007885456085205
Epoch 60 / 200, val loss: 6.592082500457764
Epoch 60 / 200, val acc: 0.4595300261096606
Epoch 61 / 200, learning rate: 3.125e-05
Epoch 61 / 200, train loss: 0.400986909866333
Epoch 61 / 200, val loss: 6.593070983886719
Epoch 61 / 200, val acc: 0.4464751958224543
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.4000944197177887
Epoch 62 / 200, val loss: 6.593923091888428
Epoch 62 / 200, val acc: 0.4490861618798956
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.3996083438396454
Epoch 63 / 200, val loss: 6.594760894775391
Epoch 63 / 200, val acc: 0.4595300261096606
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.4021438658237457
Epoch 64 / 200, val loss: 6.595574378967285
Epoch 64 / 200, val acc: 0.46736292428198434
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.401470422744751
Epoch 65 / 200, val loss: 6.596233367919922
Epoch 65 / 200, val acc: 0.45691906005221933
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.4009474217891693
Epoch 66 / 200, val loss: 6.596890449523926
Epoch 66 / 200, val acc: 0.4595300261096606
Epoch 67 / 200, learning rate: 3.125e-05
Epoch 67 / 200, train loss: 0.4005432724952698
Epoch 67 / 200, val loss: 6.597655296325684
Epoch 67 / 200, val acc: 0.45430809399477806
Epoch 68 / 200, learning rate: 1.5625e-05
Epoch 68 / 200, train loss: 0.40032216906547546
Epoch 68 / 200, val loss: 6.598442077636719
Epoch 68 / 200, val acc: 0.4595300261096606
Epoch 69 / 200, learning rate: 1.5625e-05
Epoch 69 / 200, train loss: 0.40060892701148987
Epoch 69 / 200, val loss: 6.598840236663818
Epoch 69 / 200, val acc: 0.4595300261096606
Epoch 70 / 200, learning rate: 1.5625e-05
Epoch 70 / 200, train loss: 0.4011639952659607
Epoch 70 / 200, val loss: 6.5992431640625
Epoch 70 / 200, val acc: 0.4595300261096606
Epoch 71 / 200, learning rate: 1.5625e-05
Epoch 71 / 200, train loss: 0.4014815390110016
Epoch 71 / 200, val loss: 6.599606990814209
Epoch 71 / 200, val acc: 0.4699738903394256
Epoch 72 / 200, learning rate: 1.5625e-05
Epoch 72 / 200, train loss: 0.39867955446243286
Epoch 72 / 200, val loss: 6.600044250488281
Epoch 72 / 200, val acc: 0.4725848563968668
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.399869441986084
Epoch 73 / 200, val loss: 6.600529670715332
Epoch 73 / 200, val acc: 0.4751958224543081
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.4008622169494629
Epoch 74 / 200, val loss: 6.601009368896484
Epoch 74 / 200, val acc: 0.4751958224543081
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.3999806344509125
Epoch 75 / 200, val loss: 6.6014838218688965
Epoch 75 / 200, val acc: 0.4751958224543081
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.4009115695953369
Epoch 76 / 200, val loss: 6.601975440979004
Epoch 76 / 200, val acc: 0.4751958224543081
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.40061891078948975
Epoch 77 / 200, val loss: 6.602395534515381
Epoch 77 / 200, val acc: 0.4699738903394256
Epoch 78 / 200, learning rate: 1.5625e-05
Epoch 78 / 200, train loss: 0.40172088146209717
Epoch 78 / 200, val loss: 6.602818489074707
Epoch 78 / 200, val acc: 0.4725848563968668
Epoch 79 / 200, learning rate: 7.8125e-06
Epoch 79 / 200, train loss: 0.40027129650115967
Epoch 79 / 200, val loss: 6.603278160095215
Epoch 79 / 200, val acc: 0.4725848563968668
Epoch 80 / 200, learning rate: 7.8125e-06
Epoch 80 / 200, train loss: 0.40146443247795105
Epoch 80 / 200, val loss: 6.603504180908203
Epoch 80 / 200, val acc: 0.4804177545691906
Epoch 81 / 200, learning rate: 7.8125e-06
Epoch 81 / 200, train loss: 0.4004484713077545
Epoch 81 / 200, val loss: 6.60374641418457
Epoch 81 / 200, val acc: 0.47780678851174935
Epoch 82 / 200, learning rate: 7.8125e-06
Epoch 82 / 200, train loss: 0.4014684557914734
Epoch 82 / 200, val loss: 6.603977203369141
Epoch 82 / 200, val acc: 0.4804177545691906
Epoch 83 / 200, learning rate: 7.8125e-06
Epoch 83 / 200, train loss: 0.4010012745857239
Epoch 83 / 200, val loss: 6.604201316833496
Epoch 83 / 200, val acc: 0.47780678851174935
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.4021947979927063
Epoch 84 / 200, val loss: 6.604409217834473
Epoch 84 / 200, val acc: 0.4751958224543081
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.39991042017936707
Epoch 85 / 200, val loss: 6.604644775390625
Epoch 85 / 200, val acc: 0.47780678851174935
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.40163522958755493
Epoch 86 / 200, val loss: 6.604882717132568
Epoch 86 / 200, val acc: 0.47780678851174935
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.4023610055446625
Epoch 87 / 200, val loss: 6.605092525482178
Epoch 87 / 200, val acc: 0.47780678851174935
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.4022596776485443
Epoch 88 / 200, val loss: 6.605284690856934
Epoch 88 / 200, val acc: 0.47780678851174935
Epoch 89 / 200, learning rate: 7.8125e-06
Epoch 89 / 200, train loss: 0.4001561105251312
Epoch 89 / 200, val loss: 6.605498313903809
Epoch 89 / 200, val acc: 0.47780678851174935
Epoch 90 / 200, learning rate: 3.90625e-06
Epoch 90 / 200, train loss: 0.4002915322780609
Epoch 90 / 200, val loss: 6.605688095092773
Epoch 90 / 200, val acc: 0.4830287206266319
Epoch 91 / 200, learning rate: 3.90625e-06
Epoch 91 / 200, train loss: 0.4002607762813568
Epoch 91 / 200, val loss: 6.605780601501465
Epoch 91 / 200, val acc: 0.4830287206266319
Epoch 92 / 200, learning rate: 3.90625e-06
Epoch 92 / 200, train loss: 0.3992035984992981
Epoch 92 / 200, val loss: 6.605870723724365
Epoch 92 / 200, val acc: 0.4856396866840731
Epoch 93 / 200, learning rate: 3.90625e-06
Epoch 93 / 200, train loss: 0.4011882245540619
Epoch 93 / 200, val loss: 6.605964660644531
Epoch 93 / 200, val acc: 0.4830287206266319
Epoch 94 / 200, learning rate: 3.90625e-06
Epoch 94 / 200, train loss: 0.40119117498397827
Epoch 94 / 200, val loss: 6.606051445007324
Epoch 94 / 200, val acc: 0.4830287206266319
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.40108928084373474
Epoch 95 / 200, val loss: 6.606136322021484
Epoch 95 / 200, val acc: 0.4830287206266319
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.4013098180294037
Epoch 96 / 200, val loss: 6.6062164306640625
Epoch 96 / 200, val acc: 0.4830287206266319
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.4020172357559204
Epoch 97 / 200, val loss: 6.606295585632324
Epoch 97 / 200, val acc: 0.47780678851174935
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.4014928936958313
Epoch 98 / 200, val loss: 6.606354713439941
Epoch 98 / 200, val acc: 0.4830287206266319
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.3997269570827484
Epoch 99 / 200, val loss: 6.606423377990723
Epoch 99 / 200, val acc: 0.4804177545691906
Epoch 100 / 200, learning rate: 3.90625e-06
Epoch 100 / 200, train loss: 0.4009470045566559
Epoch 100 / 200, val loss: 6.6064887046813965
Epoch 100 / 200, val acc: 0.4830287206266319
Epoch 101 / 200, learning rate: 1.953125e-06
Epoch 101 / 200, train loss: 0.4011869430541992
Epoch 101 / 200, val loss: 6.606548309326172
Epoch 101 / 200, val acc: 0.4856396866840731
Epoch 102 / 200, learning rate: 1.953125e-06
Epoch 102 / 200, train loss: 0.40032151341438293
Epoch 102 / 200, val loss: 6.6065778732299805
Epoch 102 / 200, val acc: 0.47780678851174935
Epoch 103 / 200, learning rate: 1.953125e-06
Epoch 103 / 200, train loss: 0.4013999104499817
Epoch 103 / 200, val loss: 6.606599807739258
Epoch 103 / 200, val acc: 0.4830287206266319
Epoch 104 / 200, learning rate: 1.953125e-06
Epoch 104 / 200, train loss: 0.3998711407184601
Epoch 104 / 200, val loss: 6.606629848480225
Epoch 104 / 200, val acc: 0.4804177545691906
Epoch 105 / 200, learning rate: 1.953125e-06
Epoch 105 / 200, train loss: 0.40002864599227905
Epoch 105 / 200, val loss: 6.6066741943359375
Epoch 105 / 200, val acc: 0.47780678851174935
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.4008435308933258
Epoch 106 / 200, val loss: 6.606714248657227
Epoch 106 / 200, val acc: 0.4751958224543081
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.40154436230659485
Epoch 107 / 200, val loss: 6.60675048828125
Epoch 107 / 200, val acc: 0.4830287206266319
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.4015713632106781
Epoch 108 / 200, val loss: 6.606783866882324
Epoch 108 / 200, val acc: 0.4725848563968668
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.4020393490791321
Epoch 109 / 200, val loss: 6.606812953948975
Epoch 109 / 200, val acc: 0.4804177545691906
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.40020421147346497
Epoch 110 / 200, val loss: 6.6068549156188965
Epoch 110 / 200, val acc: 0.4830287206266319
Epoch 111 / 200, learning rate: 1.953125e-06
Epoch 111 / 200, train loss: 0.399473637342453
Epoch 111 / 200, val loss: 6.606900691986084
Epoch 111 / 200, val acc: 0.4751958224543081
Epoch 112 / 200, learning rate: 9.765625e-07
Epoch 112 / 200, train loss: 0.40012410283088684
Epoch 112 / 200, val loss: 6.6069536209106445
Epoch 112 / 200, val acc: 0.4830287206266319
Epoch 113 / 200, learning rate: 9.765625e-07
Epoch 113 / 200, train loss: 0.4001423418521881
Epoch 113 / 200, val loss: 6.606980323791504
Epoch 113 / 200, val acc: 0.4751958224543081
Epoch 114 / 200, learning rate: 9.765625e-07
Epoch 114 / 200, train loss: 0.4005080759525299
Epoch 114 / 200, val loss: 6.607009410858154
Epoch 114 / 200, val acc: 0.4830287206266319
Epoch 115 / 200, learning rate: 9.765625e-07
Epoch 115 / 200, train loss: 0.40055927634239197
Epoch 115 / 200, val loss: 6.6070404052734375
Epoch 115 / 200, val acc: 0.4830287206266319
Epoch 116 / 200, learning rate: 9.765625e-07
Epoch 116 / 200, train loss: 0.4023665487766266
Epoch 116 / 200, val loss: 6.60706901550293
Epoch 116 / 200, val acc: 0.4830287206266319
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.4015137553215027
Epoch 117 / 200, val loss: 6.607095241546631
Epoch 117 / 200, val acc: 0.4830287206266319
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.39993876218795776
Epoch 118 / 200, val loss: 6.607121467590332
Epoch 118 / 200, val acc: 0.4751958224543081
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.3979628086090088
Epoch 119 / 200, val loss: 6.607154846191406
Epoch 119 / 200, val acc: 0.4804177545691906
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.4001842737197876
Epoch 120 / 200, val loss: 6.6071906089782715
Epoch 120 / 200, val acc: 0.47780678851174935
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.402860164642334
Epoch 121 / 200, val loss: 6.607219219207764
Epoch 121 / 200, val acc: 0.47780678851174935
Epoch 122 / 200, learning rate: 9.765625e-07
Epoch 122 / 200, train loss: 0.4014936089515686
Epoch 122 / 200, val loss: 6.607246398925781
Epoch 122 / 200, val acc: 0.47780678851174935
Epoch 123 / 200, learning rate: 4.8828125e-07
Epoch 123 / 200, train loss: 0.40110865235328674
Epoch 123 / 200, val loss: 6.607272148132324
Epoch 123 / 200, val acc: 0.4830287206266319
Epoch 124 / 200, learning rate: 4.8828125e-07
Epoch 124 / 200, train loss: 0.39996248483657837
Epoch 124 / 200, val loss: 6.6072845458984375
Epoch 124 / 200, val acc: 0.47780678851174935
Epoch 125 / 200, learning rate: 4.8828125e-07
Epoch 125 / 200, train loss: 0.40218257904052734
Epoch 125 / 200, val loss: 6.607297420501709
Epoch 125 / 200, val acc: 0.4804177545691906
Epoch 126 / 200, learning rate: 4.8828125e-07
Epoch 126 / 200, train loss: 0.40114328265190125
Epoch 126 / 200, val loss: 6.607308387756348
Epoch 126 / 200, val acc: 0.4856396866840731
Epoch 127 / 200, learning rate: 4.8828125e-07
Epoch 127 / 200, train loss: 0.40131181478500366
Epoch 127 / 200, val loss: 6.607320308685303
Epoch 127 / 200, val acc: 0.4830287206266319
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.4003918468952179
Epoch 128 / 200, val loss: 6.607330322265625
Epoch 128 / 200, val acc: 0.4804177545691906
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.4018363356590271
Epoch 129 / 200, val loss: 6.607342720031738
Epoch 129 / 200, val acc: 0.4856396866840731
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.40147432684898376
Epoch 130 / 200, val loss: 6.607354164123535
Epoch 130 / 200, val acc: 0.4856396866840731
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.4012906551361084
Epoch 131 / 200, val loss: 6.607364654541016
Epoch 131 / 200, val acc: 0.4804177545691906
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.4010150730609894
Epoch 132 / 200, val loss: 6.607373237609863
Epoch 132 / 200, val acc: 0.48825065274151436
Epoch 133 / 200, learning rate: 4.8828125e-07
Epoch 133 / 200, train loss: 0.4009062945842743
Epoch 133 / 200, val loss: 6.607381820678711
Epoch 133 / 200, val acc: 0.4804177545691906
Epoch 134 / 200, learning rate: 2.44140625e-07
Epoch 134 / 200, train loss: 0.4022388458251953
Epoch 134 / 200, val loss: 6.607388973236084
Epoch 134 / 200, val acc: 0.4830287206266319
Epoch 135 / 200, learning rate: 2.44140625e-07
Epoch 135 / 200, train loss: 0.4000096321105957
Epoch 135 / 200, val loss: 6.607393264770508
Epoch 135 / 200, val acc: 0.4830287206266319
Epoch 136 / 200, learning rate: 2.44140625e-07
Epoch 136 / 200, train loss: 0.40153101086616516
Epoch 136 / 200, val loss: 6.60739803314209
Epoch 136 / 200, val acc: 0.4830287206266319
Epoch 137 / 200, learning rate: 2.44140625e-07
Epoch 137 / 200, train loss: 0.4012066721916199
Epoch 137 / 200, val loss: 6.6074018478393555
Epoch 137 / 200, val acc: 0.4830287206266319
Epoch 138 / 200, learning rate: 2.44140625e-07
Epoch 138 / 200, train loss: 0.3994409441947937
Epoch 138 / 200, val loss: 6.607405662536621
Epoch 138 / 200, val acc: 0.4856396866840731
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.4012928605079651
Epoch 139 / 200, val loss: 6.607409477233887
Epoch 139 / 200, val acc: 0.4804177545691906
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.40097376704216003
Epoch 140 / 200, val loss: 6.607412338256836
Epoch 140 / 200, val acc: 0.48825065274151436
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.40089040994644165
Epoch 141 / 200, val loss: 6.607415676116943
Epoch 141 / 200, val acc: 0.4830287206266319
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.4019292891025543
Epoch 142 / 200, val loss: 6.607419967651367
Epoch 142 / 200, val acc: 0.4830287206266319
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.40059801936149597
Epoch 143 / 200, val loss: 6.607425212860107
Epoch 143 / 200, val acc: 0.4856396866840731
Epoch 144 / 200, learning rate: 2.44140625e-07
Epoch 144 / 200, train loss: 0.40051203966140747
Epoch 144 / 200, val loss: 6.607429504394531
Epoch 144 / 200, val acc: 0.4856396866840731
Epoch 145 / 200, learning rate: 1.220703125e-07
Epoch 145 / 200, train loss: 0.40133368968963623
Epoch 145 / 200, val loss: 6.6074347496032715
Epoch 145 / 200, val acc: 0.4856396866840731
Epoch 146 / 200, learning rate: 1.220703125e-07
Epoch 146 / 200, train loss: 0.40022826194763184
Epoch 146 / 200, val loss: 6.6074371337890625
Epoch 146 / 200, val acc: 0.4804177545691906
Epoch 147 / 200, learning rate: 1.220703125e-07
Epoch 147 / 200, train loss: 0.40115591883659363
Epoch 147 / 200, val loss: 6.607439994812012
Epoch 147 / 200, val acc: 0.4804177545691906
Epoch 148 / 200, learning rate: 1.220703125e-07
Epoch 148 / 200, train loss: 0.40102681517601013
Epoch 148 / 200, val loss: 6.607442378997803
Epoch 148 / 200, val acc: 0.4804177545691906
Epoch 149 / 200, learning rate: 1.220703125e-07
Epoch 149 / 200, train loss: 0.40109848976135254
Epoch 149 / 200, val loss: 6.607444763183594
Epoch 149 / 200, val acc: 0.4830287206266319
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.4008348286151886
Epoch 150 / 200, val loss: 6.607447624206543
Epoch 150 / 200, val acc: 0.4830287206266319
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.40102118253707886
Epoch 151 / 200, val loss: 6.607450008392334
Epoch 151 / 200, val acc: 0.47780678851174935
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.4006609320640564
Epoch 152 / 200, val loss: 6.607452392578125
Epoch 152 / 200, val acc: 0.4804177545691906
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.4016803205013275
Epoch 153 / 200, val loss: 6.607455253601074
Epoch 153 / 200, val acc: 0.4751958224543081
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.4019574522972107
Epoch 154 / 200, val loss: 6.607457637786865
Epoch 154 / 200, val acc: 0.4804177545691906
Epoch 155 / 200, learning rate: 1.220703125e-07
Epoch 155 / 200, train loss: 0.400294691324234
Epoch 155 / 200, val loss: 6.607460975646973
Epoch 155 / 200, val acc: 0.4804177545691906
Epoch 156 / 200, learning rate: 6.103515625e-08
Epoch 156 / 200, train loss: 0.40016764402389526
Epoch 156 / 200, val loss: 6.607463359832764
Epoch 156 / 200, val acc: 0.4830287206266319
Epoch 157 / 200, learning rate: 6.103515625e-08
Epoch 157 / 200, train loss: 0.4009847939014435
Epoch 157 / 200, val loss: 6.607464790344238
Epoch 157 / 200, val acc: 0.47780678851174935
Epoch 158 / 200, learning rate: 6.103515625e-08
Epoch 158 / 200, train loss: 0.4001011252403259
Epoch 158 / 200, val loss: 6.607466697692871
Epoch 158 / 200, val acc: 0.4804177545691906
Epoch 159 / 200, learning rate: 6.103515625e-08
Epoch 159 / 200, train loss: 0.40195584297180176
Epoch 159 / 200, val loss: 6.6074676513671875
Epoch 159 / 200, val acc: 0.4804177545691906
Epoch 160 / 200, learning rate: 6.103515625e-08
Epoch 160 / 200, train loss: 0.40023475885391235
Epoch 160 / 200, val loss: 6.607469081878662
Epoch 160 / 200, val acc: 0.4804177545691906
Epoch 161 / 200, learning rate: 6.103515625e-08
Epoch 161 / 200, train loss: 0.4014787971973419
Epoch 161 / 200, val loss: 6.607470512390137
Epoch 161 / 200, val acc: 0.4804177545691906
Epoch 162 / 200, learning rate: 6.103515625e-08
Epoch 162 / 200, train loss: 0.4008289575576782
Epoch 162 / 200, val loss: 6.607471466064453
Epoch 162 / 200, val acc: 0.47780678851174935
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.40190455317497253
Epoch 163 / 200, val loss: 6.607472896575928
Epoch 163 / 200, val acc: 0.4804177545691906
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.4017985463142395
Epoch 164 / 200, val loss: 6.607474327087402
Epoch 164 / 200, val acc: 0.4804177545691906
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.40205156803131104
Epoch 165 / 200, val loss: 6.6074748039245605
Epoch 165 / 200, val acc: 0.47780678851174935
Epoch 166 / 200, learning rate: 6.103515625e-08
Epoch 166 / 200, train loss: 0.4006993770599365
Epoch 166 / 200, val loss: 6.607476234436035
Epoch 166 / 200, val acc: 0.4830287206266319
Epoch 167 / 200, learning rate: 3.0517578125e-08
Epoch 167 / 200, train loss: 0.39988645911216736
Epoch 167 / 200, val loss: 6.607476711273193
Epoch 167 / 200, val acc: 0.4804177545691906
Epoch 168 / 200, learning rate: 3.0517578125e-08
Epoch 168 / 200, train loss: 0.4015503227710724
Epoch 168 / 200, val loss: 6.607477188110352
Epoch 168 / 200, val acc: 0.4804177545691906
Epoch 169 / 200, learning rate: 3.0517578125e-08
Epoch 169 / 200, train loss: 0.401390939950943
Epoch 169 / 200, val loss: 6.607477188110352
Epoch 169 / 200, val acc: 0.47780678851174935
Epoch 170 / 200, learning rate: 3.0517578125e-08
Epoch 170 / 200, train loss: 0.39932411909103394
Epoch 170 / 200, val loss: 6.607478141784668
Epoch 170 / 200, val acc: 0.4830287206266319
Epoch 171 / 200, learning rate: 3.0517578125e-08
Epoch 171 / 200, train loss: 0.40121981501579285
Epoch 171 / 200, val loss: 6.607478618621826
Epoch 171 / 200, val acc: 0.4856396866840731
Epoch 172 / 200, learning rate: 3.0517578125e-08
Epoch 172 / 200, train loss: 0.4015818238258362
Epoch 172 / 200, val loss: 6.607479095458984
Epoch 172 / 200, val acc: 0.47780678851174935
Epoch 173 / 200, learning rate: 3.0517578125e-08
Epoch 173 / 200, train loss: 0.40008100867271423
Epoch 173 / 200, val loss: 6.607480049133301
Epoch 173 / 200, val acc: 0.4856396866840731
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.4004676043987274
Epoch 174 / 200, val loss: 6.607480525970459
Epoch 174 / 200, val acc: 0.4856396866840731
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.4004312753677368
Epoch 175 / 200, val loss: 6.607481002807617
Epoch 175 / 200, val acc: 0.47780678851174935
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.40046268701553345
Epoch 176 / 200, val loss: 6.607481956481934
Epoch 176 / 200, val acc: 0.4751958224543081
Epoch 177 / 200, learning rate: 3.0517578125e-08
Epoch 177 / 200, train loss: 0.402218759059906
Epoch 177 / 200, val loss: 6.607481956481934
Epoch 177 / 200, val acc: 0.4751958224543081
Epoch 178 / 200, learning rate: 1.52587890625e-08
Epoch 178 / 200, train loss: 0.40085628628730774
Epoch 178 / 200, val loss: 6.60748291015625
Epoch 178 / 200, val acc: 0.4804177545691906
Epoch 179 / 200, learning rate: 1.52587890625e-08
Epoch 179 / 200, train loss: 0.40021729469299316
Epoch 179 / 200, val loss: 6.60748291015625
Epoch 179 / 200, val acc: 0.4804177545691906
Epoch 180 / 200, learning rate: 1.52587890625e-08
Epoch 180 / 200, train loss: 0.40088677406311035
Epoch 180 / 200, val loss: 6.607483863830566
Epoch 180 / 200, val acc: 0.4856396866840731
Epoch 181 / 200, learning rate: 1.52587890625e-08
Epoch 181 / 200, train loss: 0.40106070041656494
Epoch 181 / 200, val loss: 6.607484340667725
Epoch 181 / 200, val acc: 0.4804177545691906
Epoch 182 / 200, learning rate: 1.52587890625e-08
Epoch 182 / 200, train loss: 0.4012507200241089
Epoch 182 / 200, val loss: 6.607484340667725
Epoch 182 / 200, val acc: 0.4804177545691906
Epoch 183 / 200, learning rate: 1.52587890625e-08
Epoch 183 / 200, train loss: 0.4001671075820923
Epoch 183 / 200, val loss: 6.607484340667725
Epoch 183 / 200, val acc: 0.4804177545691906
Epoch 184 / 200, learning rate: 1.52587890625e-08
Epoch 184 / 200, train loss: 0.4003922641277313
Epoch 184 / 200, val loss: 6.607484817504883
Epoch 184 / 200, val acc: 0.4830287206266319
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.39999809861183167
Epoch 185 / 200, val loss: 6.607485771179199
Epoch 185 / 200, val acc: 0.4804177545691906
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.40228503942489624
Epoch 186 / 200, val loss: 6.607485771179199
Epoch 186 / 200, val acc: 0.4856396866840731
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.3995320796966553
Epoch 187 / 200, val loss: 6.607485771179199
Epoch 187 / 200, val acc: 0.4856396866840731
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.39983049035072327
Epoch 188 / 200, val loss: 6.607486248016357
Epoch 188 / 200, val acc: 0.4804177545691906
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.40126001834869385
Epoch 189 / 200, val loss: 6.607486724853516
Epoch 189 / 200, val acc: 0.4830287206266319
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.4008726477622986
Epoch 190 / 200, val loss: 6.607486724853516
Epoch 190 / 200, val acc: 0.4804177545691906
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.40249547362327576
Epoch 191 / 200, val loss: 6.607486724853516
Epoch 191 / 200, val acc: 0.4830287206266319
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.40078437328338623
Epoch 192 / 200, val loss: 6.607486724853516
Epoch 192 / 200, val acc: 0.4804177545691906
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.4010065197944641
Epoch 193 / 200, val loss: 6.60748815536499
Epoch 193 / 200, val acc: 0.4856396866840731
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.401103138923645
Epoch 194 / 200, val loss: 6.60748815536499
Epoch 194 / 200, val acc: 0.47780678851174935
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.4005792438983917
Epoch 195 / 200, val loss: 6.60748815536499
Epoch 195 / 200, val acc: 0.4856396866840731
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.4005718231201172
Epoch 196 / 200, val loss: 6.607488632202148
Epoch 196 / 200, val acc: 0.4804177545691906
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.400564044713974
Epoch 197 / 200, val loss: 6.607489585876465
Epoch 197 / 200, val acc: 0.4830287206266319
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.40164706110954285
Epoch 198 / 200, val loss: 6.607489585876465
Epoch 198 / 200, val acc: 0.4830287206266319
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.40250441431999207
Epoch 199 / 200, val loss: 6.607489585876465
Epoch 199 / 200, val acc: 0.4830287206266319
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.4018191993236542
Epoch 200 / 200, val loss: 6.607489585876465
Epoch 200 / 200, val acc: 0.4830287206266319
Training finished

Evaluating best model on entire dataset

Evaluating best model on test dataset
677 trading days
Binary accuracy: 0.48854
Fraction of long signals: 0.50996
Fraction of short signals: 0.48990
Overall long return: 3.42970
Overall return: -1.31969
Yearly long return: 0.11258
Yearly return: -0.04332
Daily volatility: 0.01188
Max drawdown baseline: 0.25668
Max drawdown: 1.74736
Sharpe ratio: -0.05208
L1 error baseline: 0.78800
L1 error: 0.73890
Average prediction: -0.14752
Std prediction: 0.02461
