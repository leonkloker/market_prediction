Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─MyIdentity: 2-3                             [1, 100, 72]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        259,160
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 265,593
Trainable params: 265,593
Non-trainable params: 0
Total mult-adds (M): 0.07
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.61
Params size (MB): 0.22
Estimated Total Size (MB): 1.88
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.0660826712846756
Epoch 1 / 200, val loss: 0.093107670545578
Epoch 1 / 200, val acc: 0.496
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.11230010539293289
Epoch 2 / 200, val loss: 0.015393458306789398
Epoch 2 / 200, val acc: 0.496
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.033071912825107574
Epoch 3 / 200, val loss: 0.001857138006016612
Epoch 3 / 200, val acc: 0.524
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.017841488122940063
Epoch 4 / 200, val loss: 0.01058578584343195
Epoch 4 / 200, val acc: 0.504
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.022266216576099396
Epoch 5 / 200, val loss: 0.012129038572311401
Epoch 5 / 200, val acc: 0.504
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.018818745389580727
Epoch 6 / 200, val loss: 0.0063956803642213345
Epoch 6 / 200, val acc: 0.504
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.011944222263991833
Epoch 7 / 200, val loss: 0.0015662896912544966
Epoch 7 / 200, val acc: 0.504
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.009516547434031963
Epoch 8 / 200, val loss: 0.0006133902934379876
Epoch 8 / 200, val acc: 0.54
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.00898017268627882
Epoch 9 / 200, val loss: 0.0006122048944234848
Epoch 9 / 200, val acc: 0.492
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.007435120642185211
Epoch 10 / 200, val loss: 0.0009359754621982574
Epoch 10 / 200, val acc: 0.504
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.006003443617373705
Epoch 11 / 200, val loss: 0.002351946895942092
Epoch 11 / 200, val acc: 0.504
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.004622810985893011
Epoch 12 / 200, val loss: 0.004334076773375273
Epoch 12 / 200, val acc: 0.504
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.004157723393291235
Epoch 13 / 200, val loss: 0.005930962041020393
Epoch 13 / 200, val acc: 0.504
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.004159264732152224
Epoch 14 / 200, val loss: 0.0069641671143472195
Epoch 14 / 200, val acc: 0.504
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.004304901231080294
Epoch 15 / 200, val loss: 0.007388243917375803
Epoch 15 / 200, val acc: 0.504
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.00407070480287075
Epoch 16 / 200, val loss: 0.007261682767421007
Epoch 16 / 200, val acc: 0.504
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.0038253029342740774
Epoch 17 / 200, val loss: 0.006713585928082466
Epoch 17 / 200, val acc: 0.504
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.0036845365539193153
Epoch 18 / 200, val loss: 0.005959165748208761
Epoch 18 / 200, val acc: 0.504
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.0033510264474898577
Epoch 19 / 200, val loss: 0.005084792152047157
Epoch 19 / 200, val acc: 0.504
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.0030207494273781776
Epoch 20 / 200, val loss: 0.004183030221611261
Epoch 20 / 200, val acc: 0.504
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.0027554475236684084
Epoch 21 / 200, val loss: 0.003778111655265093
Epoch 21 / 200, val acc: 0.504
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.002690841443836689
Epoch 22 / 200, val loss: 0.0034145975951105356
Epoch 22 / 200, val acc: 0.504
Epoch 23 / 200, learning rate: 0.0005
Epoch 23 / 200, train loss: 0.0027170961257070303
Epoch 23 / 200, val loss: 0.0031155096367001534
Epoch 23 / 200, val acc: 0.504
Epoch 24 / 200, learning rate: 0.0005
Epoch 24 / 200, train loss: 0.002683997852727771
Epoch 24 / 200, val loss: 0.0028834869153797626
Epoch 24 / 200, val acc: 0.504
Epoch 25 / 200, learning rate: 0.0005
Epoch 25 / 200, train loss: 0.002540236571803689
Epoch 25 / 200, val loss: 0.0027152555994689465
Epoch 25 / 200, val acc: 0.504
Epoch 26 / 200, learning rate: 0.0005
Epoch 26 / 200, train loss: 0.002526824129745364
Epoch 26 / 200, val loss: 0.0026126252487301826
Epoch 26 / 200, val acc: 0.504
Epoch 27 / 200, learning rate: 0.0005
Epoch 27 / 200, train loss: 0.0024694667663425207
Epoch 27 / 200, val loss: 0.0025555817410349846
Epoch 27 / 200, val acc: 0.504
Epoch 28 / 200, learning rate: 0.0005
Epoch 28 / 200, train loss: 0.0024815460201352835
Epoch 28 / 200, val loss: 0.0025567885022610426
Epoch 28 / 200, val acc: 0.504
Epoch 29 / 200, learning rate: 0.0005
Epoch 29 / 200, train loss: 0.0024130342062562704
Epoch 29 / 200, val loss: 0.0026089511811733246
Epoch 29 / 200, val acc: 0.504
Epoch 30 / 200, learning rate: 0.0005
Epoch 30 / 200, train loss: 0.0022933732252568007
Epoch 30 / 200, val loss: 0.0027046804316341877
Epoch 30 / 200, val acc: 0.504
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.0022619166411459446
Epoch 31 / 200, val loss: 0.0028346176259219646
Epoch 31 / 200, val acc: 0.504
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.0022650265600532293
Epoch 32 / 200, val loss: 0.002916963305324316
Epoch 32 / 200, val acc: 0.504
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.0022291112691164017
Epoch 33 / 200, val loss: 0.003008902072906494
Epoch 33 / 200, val acc: 0.504
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.0021594136487692595
Epoch 34 / 200, val loss: 0.0031125457026064396
Epoch 34 / 200, val acc: 0.504
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.002276784274727106
Epoch 35 / 200, val loss: 0.003224654123187065
Epoch 35 / 200, val acc: 0.504
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.002131106797605753
Epoch 36 / 200, val loss: 0.0033319764770567417
Epoch 36 / 200, val acc: 0.504
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.0021061592269688845
Epoch 37 / 200, val loss: 0.0034375416580587626
Epoch 37 / 200, val acc: 0.504
Epoch 38 / 200, learning rate: 0.00025
Epoch 38 / 200, train loss: 0.002087585860863328
Epoch 38 / 200, val loss: 0.00353371724486351
Epoch 38 / 200, val acc: 0.504
Epoch 39 / 200, learning rate: 0.00025
Epoch 39 / 200, train loss: 0.0021069329231977463
Epoch 39 / 200, val loss: 0.0036202045157551765
Epoch 39 / 200, val acc: 0.504
Epoch 40 / 200, learning rate: 0.00025
Epoch 40 / 200, train loss: 0.00211752625182271
Epoch 40 / 200, val loss: 0.003697031643241644
Epoch 40 / 200, val acc: 0.504
Epoch 41 / 200, learning rate: 0.00025
Epoch 41 / 200, train loss: 0.002020386978983879
Epoch 41 / 200, val loss: 0.0037606321275234222
Epoch 41 / 200, val acc: 0.504
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.0019937120378017426
Epoch 42 / 200, val loss: 0.0038134476635605097
Epoch 42 / 200, val acc: 0.504
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.0019919807091355324
Epoch 43 / 200, val loss: 0.0038343952037394047
Epoch 43 / 200, val acc: 0.504
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.0019471370615065098
Epoch 44 / 200, val loss: 0.0038458930794149637
Epoch 44 / 200, val acc: 0.504
Epoch 45 / 200, learning rate: 0.000125
Epoch 45 / 200, train loss: 0.0019836516585201025
Epoch 45 / 200, val loss: 0.0038441470824182034
Epoch 45 / 200, val acc: 0.504
Epoch 46 / 200, learning rate: 0.000125
Epoch 46 / 200, train loss: 0.0019851205870509148
Epoch 46 / 200, val loss: 0.0038289863150566816
Epoch 46 / 200, val acc: 0.504
Epoch 47 / 200, learning rate: 0.000125
Epoch 47 / 200, train loss: 0.0019633318297564983
Epoch 47 / 200, val loss: 0.0038026883266866207
Epoch 47 / 200, val acc: 0.504
Epoch 48 / 200, learning rate: 0.000125
Epoch 48 / 200, train loss: 0.0018778500379994512
Epoch 48 / 200, val loss: 0.003770972602069378
Epoch 48 / 200, val acc: 0.504
Epoch 49 / 200, learning rate: 0.000125
Epoch 49 / 200, train loss: 0.0019491242710500956
Epoch 49 / 200, val loss: 0.003737799124792218
Epoch 49 / 200, val acc: 0.504
Epoch 50 / 200, learning rate: 0.000125
Epoch 50 / 200, train loss: 0.0019299570703878999
Epoch 50 / 200, val loss: 0.0037033718544989824
Epoch 50 / 200, val acc: 0.504
Epoch 51 / 200, learning rate: 0.000125
Epoch 51 / 200, train loss: 0.001896824105642736
Epoch 51 / 200, val loss: 0.0036651126574724913
Epoch 51 / 200, val acc: 0.504
Epoch 52 / 200, learning rate: 0.000125
Epoch 52 / 200, train loss: 0.001904049189761281
Epoch 52 / 200, val loss: 0.0036206876393407583
Epoch 52 / 200, val acc: 0.504
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.001900242525152862
Epoch 53 / 200, val loss: 0.003569604828953743
Epoch 53 / 200, val acc: 0.504
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.001985570415854454
Epoch 54 / 200, val loss: 0.0035421797074377537
Epoch 54 / 200, val acc: 0.504
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.0018986325012519956
Epoch 55 / 200, val loss: 0.0035127659793943167
Epoch 55 / 200, val acc: 0.504
Epoch 56 / 200, learning rate: 6.25e-05
Epoch 56 / 200, train loss: 0.001816961681470275
Epoch 56 / 200, val loss: 0.0034817392006516457
Epoch 56 / 200, val acc: 0.504
Epoch 57 / 200, learning rate: 6.25e-05
Epoch 57 / 200, train loss: 0.0018665739335119724
Epoch 57 / 200, val loss: 0.003449987852945924
Epoch 57 / 200, val acc: 0.504
Epoch 58 / 200, learning rate: 6.25e-05
Epoch 58 / 200, train loss: 0.0018403922440484166
Epoch 58 / 200, val loss: 0.0034174697939306498
Epoch 58 / 200, val acc: 0.504
Epoch 59 / 200, learning rate: 6.25e-05
Epoch 59 / 200, train loss: 0.0018565072678029537
Epoch 59 / 200, val loss: 0.003384309122338891
Epoch 59 / 200, val acc: 0.504
Epoch 60 / 200, learning rate: 6.25e-05
Epoch 60 / 200, train loss: 0.0019165539415553212
Epoch 60 / 200, val loss: 0.003350852057337761
Epoch 60 / 200, val acc: 0.504
Epoch 61 / 200, learning rate: 6.25e-05
Epoch 61 / 200, train loss: 0.0018585455836728215
Epoch 61 / 200, val loss: 0.0033176562283188105
Epoch 61 / 200, val acc: 0.504
Epoch 62 / 200, learning rate: 6.25e-05
Epoch 62 / 200, train loss: 0.0018219725461676717
Epoch 62 / 200, val loss: 0.003284785198047757
Epoch 62 / 200, val acc: 0.504
Epoch 63 / 200, learning rate: 6.25e-05
Epoch 63 / 200, train loss: 0.0018906424520537257
Epoch 63 / 200, val loss: 0.0032519467640668154
Epoch 63 / 200, val acc: 0.504
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.0018591211410239339
Epoch 64 / 200, val loss: 0.00321937701664865
Epoch 64 / 200, val acc: 0.504
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.001788969268091023
Epoch 65 / 200, val loss: 0.0032033040188252926
Epoch 65 / 200, val acc: 0.504
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.001794136711396277
Epoch 66 / 200, val loss: 0.003187027294188738
Epoch 66 / 200, val acc: 0.504
Epoch 67 / 200, learning rate: 3.125e-05
Epoch 67 / 200, train loss: 0.0018783945124596357
Epoch 67 / 200, val loss: 0.0031707428861409426
Epoch 67 / 200, val acc: 0.504
Epoch 68 / 200, learning rate: 3.125e-05
Epoch 68 / 200, train loss: 0.0018189027905464172
Epoch 68 / 200, val loss: 0.0031545860692858696
Epoch 68 / 200, val acc: 0.504
Epoch 69 / 200, learning rate: 3.125e-05
Epoch 69 / 200, train loss: 0.0018591518746688962
Epoch 69 / 200, val loss: 0.0031384171452373266
Epoch 69 / 200, val acc: 0.504
Epoch 70 / 200, learning rate: 3.125e-05
Epoch 70 / 200, train loss: 0.0018657752079889178
Epoch 70 / 200, val loss: 0.003122058929875493
Epoch 70 / 200, val acc: 0.504
Epoch 71 / 200, learning rate: 3.125e-05
Epoch 71 / 200, train loss: 0.00189088040497154
Epoch 71 / 200, val loss: 0.003105629701167345
Epoch 71 / 200, val acc: 0.504
Epoch 72 / 200, learning rate: 3.125e-05
Epoch 72 / 200, train loss: 0.0018435949459671974
Epoch 72 / 200, val loss: 0.0030890421476215124
Epoch 72 / 200, val acc: 0.504
Epoch 73 / 200, learning rate: 3.125e-05
Epoch 73 / 200, train loss: 0.001868703169748187
Epoch 73 / 200, val loss: 0.003072518389672041
Epoch 73 / 200, val acc: 0.504
Epoch 74 / 200, learning rate: 3.125e-05
Epoch 74 / 200, train loss: 0.0018193414434790611
Epoch 74 / 200, val loss: 0.0030560509767383337
Epoch 74 / 200, val acc: 0.504
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.0018233363516628742
Epoch 75 / 200, val loss: 0.0030396219808608294
Epoch 75 / 200, val acc: 0.504
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.0017850447911769152
Epoch 76 / 200, val loss: 0.0030314521864056587
Epoch 76 / 200, val acc: 0.504
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.0018055707914754748
Epoch 77 / 200, val loss: 0.0030232358258217573
Epoch 77 / 200, val acc: 0.504
Epoch 78 / 200, learning rate: 1.5625e-05
Epoch 78 / 200, train loss: 0.0018320259405300021
Epoch 78 / 200, val loss: 0.003015087451785803
Epoch 78 / 200, val acc: 0.504
Epoch 79 / 200, learning rate: 1.5625e-05
Epoch 79 / 200, train loss: 0.0017656497657299042
Epoch 79 / 200, val loss: 0.0030069102067500353
Epoch 79 / 200, val acc: 0.504
Epoch 80 / 200, learning rate: 1.5625e-05
Epoch 80 / 200, train loss: 0.0017952260095626116
Epoch 80 / 200, val loss: 0.0029987781308591366
Epoch 80 / 200, val acc: 0.504
Epoch 81 / 200, learning rate: 1.5625e-05
Epoch 81 / 200, train loss: 0.0018671783618628979
Epoch 81 / 200, val loss: 0.002990724053233862
Epoch 81 / 200, val acc: 0.504
Epoch 82 / 200, learning rate: 1.5625e-05
Epoch 82 / 200, train loss: 0.0017520845867693424
Epoch 82 / 200, val loss: 0.00298256310634315
Epoch 82 / 200, val acc: 0.504
Epoch 83 / 200, learning rate: 1.5625e-05
Epoch 83 / 200, train loss: 0.0017474709311500192
Epoch 83 / 200, val loss: 0.0029743281193077564
Epoch 83 / 200, val acc: 0.504
Epoch 84 / 200, learning rate: 1.5625e-05
Epoch 84 / 200, train loss: 0.0018264862010255456
Epoch 84 / 200, val loss: 0.002966046566143632
Epoch 84 / 200, val acc: 0.504
Epoch 85 / 200, learning rate: 1.5625e-05
Epoch 85 / 200, train loss: 0.0017540155677124858
Epoch 85 / 200, val loss: 0.002957971766591072
Epoch 85 / 200, val acc: 0.504
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.001899269176647067
Epoch 86 / 200, val loss: 0.0029500098899006844
Epoch 86 / 200, val acc: 0.504
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.0017857925267890096
Epoch 87 / 200, val loss: 0.002946089720353484
Epoch 87 / 200, val acc: 0.504
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.0018116849241778255
Epoch 88 / 200, val loss: 0.0029422573279589415
Epoch 88 / 200, val acc: 0.504
Epoch 89 / 200, learning rate: 7.8125e-06
Epoch 89 / 200, train loss: 0.0018370961770415306
Epoch 89 / 200, val loss: 0.0029384170193225145
Epoch 89 / 200, val acc: 0.504
Epoch 90 / 200, learning rate: 7.8125e-06
Epoch 90 / 200, train loss: 0.0018287562998011708
Epoch 90 / 200, val loss: 0.0029345471411943436
Epoch 90 / 200, val acc: 0.504
Epoch 91 / 200, learning rate: 7.8125e-06
Epoch 91 / 200, train loss: 0.0018350143218412995
Epoch 91 / 200, val loss: 0.0029306875076144934
Epoch 91 / 200, val acc: 0.504
Epoch 92 / 200, learning rate: 7.8125e-06
Epoch 92 / 200, train loss: 0.0018523705657571554
Epoch 92 / 200, val loss: 0.0029267841018736362
Epoch 92 / 200, val acc: 0.504
Epoch 93 / 200, learning rate: 7.8125e-06
Epoch 93 / 200, train loss: 0.0017458493821322918
Epoch 93 / 200, val loss: 0.0029228210914880037
Epoch 93 / 200, val acc: 0.504
Epoch 94 / 200, learning rate: 7.8125e-06
Epoch 94 / 200, train loss: 0.001826237770728767
Epoch 94 / 200, val loss: 0.0029188720509409904
Epoch 94 / 200, val acc: 0.504
Epoch 95 / 200, learning rate: 7.8125e-06
Epoch 95 / 200, train loss: 0.0017534311627969146
Epoch 95 / 200, val loss: 0.002914923243224621
Epoch 95 / 200, val acc: 0.504
Epoch 96 / 200, learning rate: 7.8125e-06
Epoch 96 / 200, train loss: 0.0018279182258993387
Epoch 96 / 200, val loss: 0.002911027753725648
Epoch 96 / 200, val acc: 0.504
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.0018260651268064976
Epoch 97 / 200, val loss: 0.0029071399476379156
Epoch 97 / 200, val acc: 0.504
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.0017700274474918842
Epoch 98 / 200, val loss: 0.0029051995370537043
Epoch 98 / 200, val acc: 0.504
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.0017641581362113357
Epoch 99 / 200, val loss: 0.002903268439695239
Epoch 99 / 200, val acc: 0.504
Epoch 100 / 200, learning rate: 3.90625e-06
Epoch 100 / 200, train loss: 0.0017880859086290002
Epoch 100 / 200, val loss: 0.0029013368766754866
Epoch 100 / 200, val acc: 0.504
Epoch 101 / 200, learning rate: 3.90625e-06
Epoch 101 / 200, train loss: 0.0017832076409831643
Epoch 101 / 200, val loss: 0.002899402752518654
Epoch 101 / 200, val acc: 0.504
Epoch 102 / 200, learning rate: 3.90625e-06
Epoch 102 / 200, train loss: 0.0017900492530316114
Epoch 102 / 200, val loss: 0.0028974611777812243
Epoch 102 / 200, val acc: 0.504
Epoch 103 / 200, learning rate: 3.90625e-06
Epoch 103 / 200, train loss: 0.0018217749893665314
Epoch 103 / 200, val loss: 0.002895485144108534
Epoch 103 / 200, val acc: 0.504
Epoch 104 / 200, learning rate: 3.90625e-06
Epoch 104 / 200, train loss: 0.0017859251238405704
Epoch 104 / 200, val loss: 0.0028934970032423735
Epoch 104 / 200, val acc: 0.504
Epoch 105 / 200, learning rate: 3.90625e-06
Epoch 105 / 200, train loss: 0.00175582617521286
Epoch 105 / 200, val loss: 0.0028915212024003267
Epoch 105 / 200, val acc: 0.504
Epoch 106 / 200, learning rate: 3.90625e-06
Epoch 106 / 200, train loss: 0.0017905330751091242
Epoch 106 / 200, val loss: 0.002889559604227543
Epoch 106 / 200, val acc: 0.504
Epoch 107 / 200, learning rate: 3.90625e-06
Epoch 107 / 200, train loss: 0.0017764761578291655
Epoch 107 / 200, val loss: 0.0028875842690467834
Epoch 107 / 200, val acc: 0.504
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.0017645005136728287
Epoch 108 / 200, val loss: 0.002885586814954877
Epoch 108 / 200, val acc: 0.504
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.0018242179648950696
Epoch 109 / 200, val loss: 0.002884599845856428
Epoch 109 / 200, val acc: 0.504
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.0018364005954936147
Epoch 110 / 200, val loss: 0.002883595647290349
Epoch 110 / 200, val acc: 0.504
Epoch 111 / 200, learning rate: 1.953125e-06
Epoch 111 / 200, train loss: 0.0017129108309745789
Epoch 111 / 200, val loss: 0.002882580505684018
Epoch 111 / 200, val acc: 0.504
Epoch 112 / 200, learning rate: 1.953125e-06
Epoch 112 / 200, train loss: 0.0016974147874861956
Epoch 112 / 200, val loss: 0.002881561638787389
Epoch 112 / 200, val acc: 0.504
Epoch 113 / 200, learning rate: 1.953125e-06
Epoch 113 / 200, train loss: 0.0017789091216400266
Epoch 113 / 200, val loss: 0.002880529034882784
Epoch 113 / 200, val acc: 0.504
Epoch 114 / 200, learning rate: 1.953125e-06
Epoch 114 / 200, train loss: 0.0018158575985580683
Epoch 114 / 200, val loss: 0.002879498526453972
Epoch 114 / 200, val acc: 0.504
Epoch 115 / 200, learning rate: 1.953125e-06
Epoch 115 / 200, train loss: 0.0017690283711999655
Epoch 115 / 200, val loss: 0.00287847057916224
Epoch 115 / 200, val acc: 0.504
Epoch 116 / 200, learning rate: 1.953125e-06
Epoch 116 / 200, train loss: 0.001806597807444632
Epoch 116 / 200, val loss: 0.002877449616789818
Epoch 116 / 200, val acc: 0.504
Epoch 117 / 200, learning rate: 1.953125e-06
Epoch 117 / 200, train loss: 0.0017476931679993868
Epoch 117 / 200, val loss: 0.002876437734812498
Epoch 117 / 200, val acc: 0.504
Epoch 118 / 200, learning rate: 1.953125e-06
Epoch 118 / 200, train loss: 0.0018058476271107793
Epoch 118 / 200, val loss: 0.0028754312079399824
Epoch 118 / 200, val acc: 0.504
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.001861731056123972
Epoch 119 / 200, val loss: 0.002874435158446431
Epoch 119 / 200, val acc: 0.504
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.0018319833325222135
Epoch 120 / 200, val loss: 0.0028739392291754484
Epoch 120 / 200, val acc: 0.504
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.0017568562179803848
Epoch 121 / 200, val loss: 0.002873445162549615
Epoch 121 / 200, val acc: 0.504
Epoch 122 / 200, learning rate: 9.765625e-07
Epoch 122 / 200, train loss: 0.0018002035794779658
Epoch 122 / 200, val loss: 0.002872952027246356
Epoch 122 / 200, val acc: 0.504
Epoch 123 / 200, learning rate: 9.765625e-07
Epoch 123 / 200, train loss: 0.0017949702451005578
Epoch 123 / 200, val loss: 0.0028724514413625
Epoch 123 / 200, val acc: 0.504
Epoch 124 / 200, learning rate: 9.765625e-07
Epoch 124 / 200, train loss: 0.0018491145456209779
Epoch 124 / 200, val loss: 0.002871941775083542
Epoch 124 / 200, val acc: 0.504
Epoch 125 / 200, learning rate: 9.765625e-07
Epoch 125 / 200, train loss: 0.0018340161768719554
Epoch 125 / 200, val loss: 0.002871438395231962
Epoch 125 / 200, val acc: 0.504
Epoch 126 / 200, learning rate: 9.765625e-07
Epoch 126 / 200, train loss: 0.001790134236216545
Epoch 126 / 200, val loss: 0.0028709289617836475
Epoch 126 / 200, val acc: 0.504
Epoch 127 / 200, learning rate: 9.765625e-07
Epoch 127 / 200, train loss: 0.0018420986598357558
Epoch 127 / 200, val loss: 0.002870422787964344
Epoch 127 / 200, val acc: 0.504
Epoch 128 / 200, learning rate: 9.765625e-07
Epoch 128 / 200, train loss: 0.0017511749174445868
Epoch 128 / 200, val loss: 0.002869910793378949
Epoch 128 / 200, val acc: 0.504
Epoch 129 / 200, learning rate: 9.765625e-07
Epoch 129 / 200, train loss: 0.0018238122574985027
Epoch 129 / 200, val loss: 0.002869391581043601
Epoch 129 / 200, val acc: 0.504
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.001765000051818788
Epoch 130 / 200, val loss: 0.002868880517780781
Epoch 130 / 200, val acc: 0.504
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.0017799712950363755
Epoch 131 / 200, val loss: 0.002868623472750187
Epoch 131 / 200, val acc: 0.504
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.0018267956329509616
Epoch 132 / 200, val loss: 0.002868364565074444
Epoch 132 / 200, val acc: 0.504
Epoch 133 / 200, learning rate: 4.8828125e-07
Epoch 133 / 200, train loss: 0.0017644178587943316
Epoch 133 / 200, val loss: 0.0028681019321084023
Epoch 133 / 200, val acc: 0.504
Epoch 134 / 200, learning rate: 4.8828125e-07
Epoch 134 / 200, train loss: 0.001849615597166121
Epoch 134 / 200, val loss: 0.002867842325940728
Epoch 134 / 200, val acc: 0.504
Epoch 135 / 200, learning rate: 4.8828125e-07
Epoch 135 / 200, train loss: 0.0017575696110725403
Epoch 135 / 200, val loss: 0.0028675838839262724
Epoch 135 / 200, val acc: 0.504
Epoch 136 / 200, learning rate: 4.8828125e-07
Epoch 136 / 200, train loss: 0.0017909607850015163
Epoch 136 / 200, val loss: 0.002867326373234391
Epoch 136 / 200, val acc: 0.504
Epoch 137 / 200, learning rate: 4.8828125e-07
Epoch 137 / 200, train loss: 0.0018366276053711772
Epoch 137 / 200, val loss: 0.0028670679312199354
Epoch 137 / 200, val acc: 0.504
Epoch 138 / 200, learning rate: 4.8828125e-07
Epoch 138 / 200, train loss: 0.0017762468196451664
Epoch 138 / 200, val loss: 0.0028668066952377558
Epoch 138 / 200, val acc: 0.504
Epoch 139 / 200, learning rate: 4.8828125e-07
Epoch 139 / 200, train loss: 0.0017579930135980248
Epoch 139 / 200, val loss: 0.002866540104150772
Epoch 139 / 200, val acc: 0.504
Epoch 140 / 200, learning rate: 4.8828125e-07
Epoch 140 / 200, train loss: 0.0017576231621205807
Epoch 140 / 200, val loss: 0.0028662763070315123
Epoch 140 / 200, val acc: 0.504
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.0018226979300379753
Epoch 141 / 200, val loss: 0.002866014139726758
Epoch 141 / 200, val acc: 0.504
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.0017010062001645565
Epoch 142 / 200, val loss: 0.002865883056074381
Epoch 142 / 200, val acc: 0.504
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.0017680000746622682
Epoch 143 / 200, val loss: 0.002865750342607498
Epoch 143 / 200, val acc: 0.504
Epoch 144 / 200, learning rate: 2.44140625e-07
Epoch 144 / 200, train loss: 0.0018261950463056564
Epoch 144 / 200, val loss: 0.0028656183276325464
Epoch 144 / 200, val acc: 0.504
Epoch 145 / 200, learning rate: 2.44140625e-07
Epoch 145 / 200, train loss: 0.001786711160093546
Epoch 145 / 200, val loss: 0.002865484682843089
Epoch 145 / 200, val acc: 0.504
Epoch 146 / 200, learning rate: 2.44140625e-07
Epoch 146 / 200, train loss: 0.0018077988643199205
Epoch 146 / 200, val loss: 0.0028653510380536318
Epoch 146 / 200, val acc: 0.504
Epoch 147 / 200, learning rate: 2.44140625e-07
Epoch 147 / 200, train loss: 0.0017858153441920877
Epoch 147 / 200, val loss: 0.002865216927602887
Epoch 147 / 200, val acc: 0.504
Epoch 148 / 200, learning rate: 2.44140625e-07
Epoch 148 / 200, train loss: 0.0017493731575086713
Epoch 148 / 200, val loss: 0.0028650793246924877
Epoch 148 / 200, val acc: 0.504
Epoch 149 / 200, learning rate: 2.44140625e-07
Epoch 149 / 200, train loss: 0.0018597482703626156
Epoch 149 / 200, val loss: 0.0028649421874433756
Epoch 149 / 200, val acc: 0.504
Epoch 150 / 200, learning rate: 2.44140625e-07
Epoch 150 / 200, train loss: 0.0017703347839415073
Epoch 150 / 200, val loss: 0.002864803886041045
Epoch 150 / 200, val acc: 0.504
Epoch 151 / 200, learning rate: 2.44140625e-07
Epoch 151 / 200, train loss: 0.001819673110730946
Epoch 151 / 200, val loss: 0.002864667447283864
Epoch 151 / 200, val acc: 0.504
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.0017807057593017817
Epoch 152 / 200, val loss: 0.002864534268155694
Epoch 152 / 200, val acc: 0.504
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.0017812203150242567
Epoch 153 / 200, val loss: 0.0028644667472690344
Epoch 153 / 200, val acc: 0.504
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.0017661949386820197
Epoch 154 / 200, val loss: 0.0028644008561968803
Epoch 154 / 200, val acc: 0.504
Epoch 155 / 200, learning rate: 1.220703125e-07
Epoch 155 / 200, train loss: 0.001794639159925282
Epoch 155 / 200, val loss: 0.0028643333353102207
Epoch 155 / 200, val acc: 0.504
Epoch 156 / 200, learning rate: 1.220703125e-07
Epoch 156 / 200, train loss: 0.0018183556385338306
Epoch 156 / 200, val loss: 0.0028642660472542048
Epoch 156 / 200, val acc: 0.504
Epoch 157 / 200, learning rate: 1.220703125e-07
Epoch 157 / 200, train loss: 0.0017777018947526813
Epoch 157 / 200, val loss: 0.0028641994576901197
Epoch 157 / 200, val acc: 0.504
Epoch 158 / 200, learning rate: 1.220703125e-07
Epoch 158 / 200, train loss: 0.0018053322564810514
Epoch 158 / 200, val loss: 0.002864131471142173
Epoch 158 / 200, val acc: 0.504
Epoch 159 / 200, learning rate: 1.220703125e-07
Epoch 159 / 200, train loss: 0.0018170021940022707
Epoch 159 / 200, val loss: 0.002864063950255513
Epoch 159 / 200, val acc: 0.504
Epoch 160 / 200, learning rate: 1.220703125e-07
Epoch 160 / 200, train loss: 0.0018250738503411412
Epoch 160 / 200, val loss: 0.002863996895030141
Epoch 160 / 200, val acc: 0.504
Epoch 161 / 200, learning rate: 1.220703125e-07
Epoch 161 / 200, train loss: 0.0017758829053491354
Epoch 161 / 200, val loss: 0.002863929606974125
Epoch 161 / 200, val acc: 0.504
Epoch 162 / 200, learning rate: 1.220703125e-07
Epoch 162 / 200, train loss: 0.001771689159795642
Epoch 162 / 200, val loss: 0.002863861620426178
Epoch 162 / 200, val acc: 0.504
Epoch 163 / 200, learning rate: 1e-07
Epoch 163 / 200, train loss: 0.0017637198325246572
Epoch 163 / 200, val loss: 0.0028637934010475874
Epoch 163 / 200, val acc: 0.504
Epoch 164 / 200, learning rate: 1e-07
Epoch 164 / 200, train loss: 0.0018228323897346854
Epoch 164 / 200, val loss: 0.002863737288862467
Epoch 164 / 200, val acc: 0.504
Epoch 165 / 200, learning rate: 1e-07
Epoch 165 / 200, train loss: 0.0018643188523128629
Epoch 165 / 200, val loss: 0.0028636795468628407
Epoch 165 / 200, val acc: 0.504
Epoch 166 / 200, learning rate: 1e-07
Epoch 166 / 200, train loss: 0.0018679305212572217
Epoch 166 / 200, val loss: 0.002863620175048709
Epoch 166 / 200, val acc: 0.504
Epoch 167 / 200, learning rate: 1e-07
Epoch 167 / 200, train loss: 0.001846458064392209
Epoch 167 / 200, val loss: 0.002863561501726508
Epoch 167 / 200, val acc: 0.504
Epoch 168 / 200, learning rate: 1e-07
Epoch 168 / 200, train loss: 0.0017626641783863306
Epoch 168 / 200, val loss: 0.0028635025955736637
Epoch 168 / 200, val acc: 0.504
Epoch 169 / 200, learning rate: 1e-07
Epoch 169 / 200, train loss: 0.0018463281448930502
Epoch 169 / 200, val loss: 0.0028634436894208193
Epoch 169 / 200, val acc: 0.504
Epoch 170 / 200, learning rate: 1e-07
Epoch 170 / 200, train loss: 0.0018222135258838534
Epoch 170 / 200, val loss: 0.0028633843176066875
Epoch 170 / 200, val acc: 0.504
Epoch 171 / 200, learning rate: 1e-07
Epoch 171 / 200, train loss: 0.001800210797227919
Epoch 171 / 200, val loss: 0.002863324712961912
Epoch 171 / 200, val acc: 0.504
Epoch 172 / 200, learning rate: 1e-07
Epoch 172 / 200, train loss: 0.0018872700165957212
Epoch 172 / 200, val loss: 0.002863266272470355
Epoch 172 / 200, val acc: 0.504
Epoch 173 / 200, learning rate: 1e-07
Epoch 173 / 200, train loss: 0.0017986759776249528
Epoch 173 / 200, val loss: 0.002863208530470729
Epoch 173 / 200, val acc: 0.504
Epoch 174 / 200, learning rate: 1e-07
Epoch 174 / 200, train loss: 0.001785105443559587
Epoch 174 / 200, val loss: 0.0028631507884711027
Epoch 174 / 200, val acc: 0.504
Epoch 175 / 200, learning rate: 1e-07
Epoch 175 / 200, train loss: 0.0017957022646442056
Epoch 175 / 200, val loss: 0.0028630937449634075
Epoch 175 / 200, val acc: 0.504
Epoch 176 / 200, learning rate: 1e-07
Epoch 176 / 200, train loss: 0.0017398258205503225
Epoch 176 / 200, val loss: 0.0028630357701331377
Epoch 176 / 200, val acc: 0.504
Epoch 177 / 200, learning rate: 1e-07
Epoch 177 / 200, train loss: 0.0017622524173930287
Epoch 177 / 200, val loss: 0.0028629766311496496
Epoch 177 / 200, val acc: 0.504
Epoch 178 / 200, learning rate: 1e-07
Epoch 178 / 200, train loss: 0.001890003215521574
Epoch 178 / 200, val loss: 0.0028629181906580925
Epoch 178 / 200, val acc: 0.504
Epoch 179 / 200, learning rate: 1e-07
Epoch 179 / 200, train loss: 0.001786578563041985
Epoch 179 / 200, val loss: 0.0028628609143197536
Epoch 179 / 200, val acc: 0.504
Epoch 180 / 200, learning rate: 1e-07
Epoch 180 / 200, train loss: 0.0017859297804534435
Epoch 180 / 200, val loss: 0.0028628031723201275
Epoch 180 / 200, val acc: 0.504
Epoch 181 / 200, learning rate: 1e-07
Epoch 181 / 200, train loss: 0.001782352919690311
Epoch 181 / 200, val loss: 0.002862745663151145
Epoch 181 / 200, val acc: 0.504
Epoch 182 / 200, learning rate: 1e-07
Epoch 182 / 200, train loss: 0.0018018879927694798
Epoch 182 / 200, val loss: 0.0028626881539821625
Epoch 182 / 200, val acc: 0.504
Epoch 183 / 200, learning rate: 1e-07
Epoch 183 / 200, train loss: 0.0017753344727680087
Epoch 183 / 200, val loss: 0.002862629946321249
Epoch 183 / 200, val acc: 0.504
Epoch 184 / 200, learning rate: 1e-07
Epoch 184 / 200, train loss: 0.001762032276019454
Epoch 184 / 200, val loss: 0.0028625724371522665
Epoch 184 / 200, val acc: 0.504
Epoch 185 / 200, learning rate: 1e-07
Epoch 185 / 200, train loss: 0.0017650481313467026
Epoch 185 / 200, val loss: 0.002862514229491353
Epoch 185 / 200, val acc: 0.504
Epoch 186 / 200, learning rate: 1e-07
Epoch 186 / 200, train loss: 0.0017490385798737407
Epoch 186 / 200, val loss: 0.002862455788999796
Epoch 186 / 200, val acc: 0.504
Epoch 187 / 200, learning rate: 1e-07
Epoch 187 / 200, train loss: 0.0017413829918950796
Epoch 187 / 200, val loss: 0.002862397348508239
Epoch 187 / 200, val acc: 0.504
Epoch 188 / 200, learning rate: 1e-07
Epoch 188 / 200, train loss: 0.001835959148593247
Epoch 188 / 200, val loss: 0.002862339373677969
Epoch 188 / 200, val acc: 0.504
Epoch 189 / 200, learning rate: 1e-07
Epoch 189 / 200, train loss: 0.0018124699126929045
Epoch 189 / 200, val loss: 0.002862281398847699
Epoch 189 / 200, val acc: 0.504
Epoch 190 / 200, learning rate: 1e-07
Epoch 190 / 200, train loss: 0.001804498489946127
Epoch 190 / 200, val loss: 0.0028622217942029238
Epoch 190 / 200, val acc: 0.504
Epoch 191 / 200, learning rate: 1e-07
Epoch 191 / 200, train loss: 0.0017372004222124815
Epoch 191 / 200, val loss: 0.0028621626552194357
Epoch 191 / 200, val acc: 0.504
Epoch 192 / 200, learning rate: 1e-07
Epoch 192 / 200, train loss: 0.0017841873923316598
Epoch 192 / 200, val loss: 0.0028621030505746603
Epoch 192 / 200, val acc: 0.504
Epoch 193 / 200, learning rate: 1e-07
Epoch 193 / 200, train loss: 0.001808710745535791
Epoch 193 / 200, val loss: 0.0028620429802685976
Epoch 193 / 200, val acc: 0.504
Epoch 194 / 200, learning rate: 1e-07
Epoch 194 / 200, train loss: 0.0018812594935297966
Epoch 194 / 200, val loss: 0.0028619838412851095
Epoch 194 / 200, val acc: 0.504
Epoch 195 / 200, learning rate: 1e-07
Epoch 195 / 200, train loss: 0.0018007999751716852
Epoch 195 / 200, val loss: 0.002861924469470978
Epoch 195 / 200, val acc: 0.504
Epoch 196 / 200, learning rate: 1e-07
Epoch 196 / 200, train loss: 0.0017414101166650653
Epoch 196 / 200, val loss: 0.002861865097656846
Epoch 196 / 200, val acc: 0.504
Epoch 197 / 200, learning rate: 1e-07
Epoch 197 / 200, train loss: 0.0017886146670207381
Epoch 197 / 200, val loss: 0.0028618054930120707
Epoch 197 / 200, val acc: 0.504
Epoch 198 / 200, learning rate: 1e-07
Epoch 198 / 200, train loss: 0.0017407421255484223
Epoch 198 / 200, val loss: 0.002861746121197939
Epoch 198 / 200, val acc: 0.504
Epoch 199 / 200, learning rate: 1e-07
Epoch 199 / 200, train loss: 0.0018069602083414793
Epoch 199 / 200, val loss: 0.002861687680706382
Epoch 199 / 200, val acc: 0.504
Epoch 200 / 200, learning rate: 1e-07
Epoch 200 / 200, train loss: 0.001787422806955874
Epoch 200 / 200, val loss: 0.002861629007384181
Epoch 200 / 200, val acc: 0.504
Training finished

Evaluating best model
Trading strategy for stock MBGAF:
After 4999 trading days
Binary accuracy: 0.48650
Fraction of long signals: 0.20204
Fraction of short signals: 0.79796
Overall long return: 2.62811
Overall return: -3.03782
Yearly long return: 0.13248
Yearly return: -0.15314
Daily volatility: 0.02289
Max drawdown baseline: 0.59476
Max drawdown: 2.95831
Sharpe ratio: -0.04952
L1 error baseline: 0.01543
L1 error: 0.03315
Average prediction: -0.02334
Std prediction: 0.03066


Trading strategy for stock MBGAF:
After 250 trading days
Binary accuracy: 0.48000
Fraction of long signals: 0.52800
Fraction of short signals: 0.47200
Overall long return: 0.42943
Overall return: -0.38104
Yearly long return: 0.43287
Yearly return: -0.38409
Daily volatility: 0.01933
Max drawdown baseline: 0.19124
Max drawdown: 0.49937
Sharpe ratio: -0.16906
L1 error baseline: 0.01429
L1 error: 0.01455
Average prediction: 0.00095
Std prediction: 0.00305


