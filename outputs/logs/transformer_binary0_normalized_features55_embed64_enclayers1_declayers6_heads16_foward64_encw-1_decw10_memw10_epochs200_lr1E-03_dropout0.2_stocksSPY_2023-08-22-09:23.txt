====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 5000, 1]              --
├─Linear: 1-1                                      [1, 5000, 64]             3,584
├─Time2Vec: 1-2                                    [1, 5000, 80]             --
│    └─Linear: 2-1                                 [5000, 16]                80
├─Linear: 1-3                                      [1, 5000, 64]             (recursive)
├─Time2Vec: 1-4                                    [1, 5000, 80]             (recursive)
│    └─Linear: 2-2                                 [5000, 16]                (recursive)
├─Transformer: 1-5                                 [1, 5000, 80]             --
│    └─TransformerEncoder: 2-3                     [1, 5000, 80]             --
│    │    └─ModuleList: 3-1                        --                        36,624
│    │    └─LayerNorm: 3-2                         [1, 5000, 80]             160
│    └─TransformerDecoder: 2-4                     [1, 5000, 80]             --
│    │    └─ModuleList: 3-3                        --                        376,224
│    │    └─LayerNorm: 3-4                         [1, 5000, 80]             160
├─Sequential: 1-6                                  [1, 5000, 1]              --
│    └─Linear: 2-5                                 [1, 5000, 40]             3,240
│    └─Dropout: 2-6                                [1, 5000, 40]             --
│    └─ReLU: 2-7                                   [1, 5000, 40]             --
│    └─Linear: 2-8                                 [1, 5000, 1]              41
├─Identity: 1-7                                    [1, 5000, 1]              --
====================================================================================================
Total params: 420,113
Trainable params: 420,113
Non-trainable params: 0
Total mult-adds (M): 0.88
====================================================================================================
Input size (MB): 2.20
Forward/backward pass size (MB): 106.60
Params size (MB): 0.29
Estimated Total Size (MB): 109.09
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.70046067237854
Epoch 1 / 200, val loss: 0.526354968547821
Epoch 1 / 200, val acc: 0.5637583892617449
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.3045838475227356
Epoch 2 / 200, val loss: 0.22637802362442017
Epoch 2 / 200, val acc: 0.5637583892617449
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.192554771900177
Epoch 3 / 200, val loss: 0.08113601803779602
Epoch 3 / 200, val acc: 0.5570469798657718
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.1786089986562729
Epoch 4 / 200, val loss: 0.03155183792114258
Epoch 4 / 200, val acc: 0.5570469798657718
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.15185046195983887
Epoch 5 / 200, val loss: 0.022476231679320335
Epoch 5 / 200, val acc: 0.48322147651006714
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.12387405335903168
Epoch 6 / 200, val loss: 0.02879359945654869
Epoch 6 / 200, val acc: 0.5033557046979866
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.09832599014043808
Epoch 7 / 200, val loss: 0.04851364716887474
Epoch 7 / 200, val acc: 0.4899328859060403
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.09245696663856506
Epoch 8 / 200, val loss: 0.08732915669679642
Epoch 8 / 200, val acc: 0.4429530201342282
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.0905497595667839
Epoch 9 / 200, val loss: 0.15332826972007751
Epoch 9 / 200, val acc: 0.4429530201342282
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.07321331650018692
Epoch 10 / 200, val loss: 0.2316664755344391
Epoch 10 / 200, val acc: 0.436241610738255
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.061202116310596466
Epoch 11 / 200, val loss: 0.30526143312454224
Epoch 11 / 200, val acc: 0.436241610738255
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.05733126774430275
Epoch 12 / 200, val loss: 0.35777977108955383
Epoch 12 / 200, val acc: 0.436241610738255
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.05545059219002724
Epoch 13 / 200, val loss: 0.3598441183567047
Epoch 13 / 200, val acc: 0.436241610738255
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.05008591711521149
Epoch 14 / 200, val loss: 0.3052133321762085
Epoch 14 / 200, val acc: 0.436241610738255
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.04745960608124733
Epoch 15 / 200, val loss: 0.23535147309303284
Epoch 15 / 200, val acc: 0.436241610738255
Epoch 16 / 200, learning rate: 0.0006
Epoch 16 / 200, train loss: 0.046261925250291824
Epoch 16 / 200, val loss: 0.2154557853937149
Epoch 16 / 200, val acc: 0.436241610738255
Epoch 17 / 200, learning rate: 0.0006
Epoch 17 / 200, train loss: 0.04999038204550743
Epoch 17 / 200, val loss: 0.2390143871307373
Epoch 17 / 200, val acc: 0.436241610738255
Epoch 18 / 200, learning rate: 0.0006
Epoch 18 / 200, train loss: 0.045041147619485855
Epoch 18 / 200, val loss: 0.29484987258911133
Epoch 18 / 200, val acc: 0.436241610738255
Epoch 19 / 200, learning rate: 0.0006
Epoch 19 / 200, train loss: 0.04505423828959465
Epoch 19 / 200, val loss: 0.3705955147743225
Epoch 19 / 200, val acc: 0.436241610738255
Epoch 20 / 200, learning rate: 0.0006
Epoch 20 / 200, train loss: 0.04288100078701973
Epoch 20 / 200, val loss: 0.4548008441925049
Epoch 20 / 200, val acc: 0.436241610738255
Epoch 21 / 200, learning rate: 0.0006
Epoch 21 / 200, train loss: 0.042690299451351166
Epoch 21 / 200, val loss: 0.523707926273346
Epoch 21 / 200, val acc: 0.436241610738255
Epoch 22 / 200, learning rate: 0.0006
Epoch 22 / 200, train loss: 0.04055842384696007
Epoch 22 / 200, val loss: 0.5592364072799683
Epoch 22 / 200, val acc: 0.436241610738255
Epoch 23 / 200, learning rate: 0.0006
Epoch 23 / 200, train loss: 0.0429808646440506
Epoch 23 / 200, val loss: 0.5552762746810913
Epoch 23 / 200, val acc: 0.436241610738255
Epoch 24 / 200, learning rate: 0.0006
Epoch 24 / 200, train loss: 0.0398128516972065
Epoch 24 / 200, val loss: 0.5234769582748413
Epoch 24 / 200, val acc: 0.436241610738255
Epoch 25 / 200, learning rate: 0.0006
Epoch 25 / 200, train loss: 0.04231565445661545
Epoch 25 / 200, val loss: 0.4595487713813782
Epoch 25 / 200, val acc: 0.436241610738255
Epoch 26 / 200, learning rate: 0.0006
Epoch 26 / 200, train loss: 0.037085097283124924
Epoch 26 / 200, val loss: 0.37962406873703003
Epoch 26 / 200, val acc: 0.436241610738255
Epoch 27 / 200, learning rate: 0.00035999999999999997
Epoch 27 / 200, train loss: 0.037630338221788406
Epoch 27 / 200, val loss: 0.30772513151168823
Epoch 27 / 200, val acc: 0.436241610738255
Epoch 28 / 200, learning rate: 0.00035999999999999997
Epoch 28 / 200, train loss: 0.03568147495388985
Epoch 28 / 200, val loss: 0.277622789144516
Epoch 28 / 200, val acc: 0.436241610738255
Epoch 29 / 200, learning rate: 0.00035999999999999997
Epoch 29 / 200, train loss: 0.0376136489212513
Epoch 29 / 200, val loss: 0.2621900141239166
Epoch 29 / 200, val acc: 0.436241610738255
Epoch 30 / 200, learning rate: 0.00035999999999999997
Epoch 30 / 200, train loss: 0.03787073493003845
Epoch 30 / 200, val loss: 0.25957128405570984
Epoch 30 / 200, val acc: 0.436241610738255
Epoch 31 / 200, learning rate: 0.00035999999999999997
Epoch 31 / 200, train loss: 0.035322923213243484
Epoch 31 / 200, val loss: 0.26744019985198975
Epoch 31 / 200, val acc: 0.436241610738255
Epoch 32 / 200, learning rate: 0.00035999999999999997
Epoch 32 / 200, train loss: 0.035502661019563675
Epoch 32 / 200, val loss: 0.2818439304828644
Epoch 32 / 200, val acc: 0.436241610738255
Epoch 33 / 200, learning rate: 0.00035999999999999997
Epoch 33 / 200, train loss: 0.0342399962246418
Epoch 33 / 200, val loss: 0.30072104930877686
Epoch 33 / 200, val acc: 0.436241610738255
Epoch 34 / 200, learning rate: 0.00035999999999999997
Epoch 34 / 200, train loss: 0.03510803356766701
Epoch 34 / 200, val loss: 0.3210643231868744
Epoch 34 / 200, val acc: 0.436241610738255
Epoch 35 / 200, learning rate: 0.00035999999999999997
Epoch 35 / 200, train loss: 0.03473024070262909
Epoch 35 / 200, val loss: 0.33983540534973145
Epoch 35 / 200, val acc: 0.436241610738255
Epoch 36 / 200, learning rate: 0.00035999999999999997
Epoch 36 / 200, train loss: 0.034911010414361954
Epoch 36 / 200, val loss: 0.35175567865371704
Epoch 36 / 200, val acc: 0.436241610738255
Epoch 37 / 200, learning rate: 0.00035999999999999997
Epoch 37 / 200, train loss: 0.036035045981407166
Epoch 37 / 200, val loss: 0.35431215167045593
Epoch 37 / 200, val acc: 0.436241610738255
Epoch 38 / 200, learning rate: 0.00021599999999999996
Epoch 38 / 200, train loss: 0.03305775672197342
Epoch 38 / 200, val loss: 0.3502481281757355
Epoch 38 / 200, val acc: 0.436241610738255
Epoch 39 / 200, learning rate: 0.00021599999999999996
Epoch 39 / 200, train loss: 0.03463155776262283
Epoch 39 / 200, val loss: 0.3453035056591034
Epoch 39 / 200, val acc: 0.436241610738255
Epoch 40 / 200, learning rate: 0.00021599999999999996
Epoch 40 / 200, train loss: 0.03348240256309509
Epoch 40 / 200, val loss: 0.33726629614830017
Epoch 40 / 200, val acc: 0.436241610738255
Epoch 41 / 200, learning rate: 0.00021599999999999996
Epoch 41 / 200, train loss: 0.03373922035098076
Epoch 41 / 200, val loss: 0.3284943997859955
Epoch 41 / 200, val acc: 0.436241610738255
Epoch 42 / 200, learning rate: 0.00021599999999999996
Epoch 42 / 200, train loss: 0.03139296919107437
Epoch 42 / 200, val loss: 0.3179461658000946
Epoch 42 / 200, val acc: 0.436241610738255
Epoch 43 / 200, learning rate: 0.00021599999999999996
Epoch 43 / 200, train loss: 0.032388340681791306
Epoch 43 / 200, val loss: 0.307292640209198
Epoch 43 / 200, val acc: 0.436241610738255
Epoch 44 / 200, learning rate: 0.00021599999999999996
Epoch 44 / 200, train loss: 0.03271842375397682
Epoch 44 / 200, val loss: 0.29985836148262024
Epoch 44 / 200, val acc: 0.436241610738255
Epoch 45 / 200, learning rate: 0.00021599999999999996
Epoch 45 / 200, train loss: 0.033648692071437836
Epoch 45 / 200, val loss: 0.294826477766037
Epoch 45 / 200, val acc: 0.436241610738255
Epoch 46 / 200, learning rate: 0.00021599999999999996
Epoch 46 / 200, train loss: 0.03165344521403313
Epoch 46 / 200, val loss: 0.29196274280548096
Epoch 46 / 200, val acc: 0.436241610738255
Epoch 47 / 200, learning rate: 0.00021599999999999996
Epoch 47 / 200, train loss: 0.03229048103094101
Epoch 47 / 200, val loss: 0.29146260023117065
Epoch 47 / 200, val acc: 0.436241610738255
Epoch 48 / 200, learning rate: 0.00021599999999999996
Epoch 48 / 200, train loss: 0.03294730931520462
Epoch 48 / 200, val loss: 0.2919367253780365
Epoch 48 / 200, val acc: 0.436241610738255
Epoch 49 / 200, learning rate: 0.00012959999999999998
Epoch 49 / 200, train loss: 0.03222694993019104
Epoch 49 / 200, val loss: 0.2946433424949646
Epoch 49 / 200, val acc: 0.436241610738255
Epoch 50 / 200, learning rate: 0.00012959999999999998
Epoch 50 / 200, train loss: 0.03140541911125183
Epoch 50 / 200, val loss: 0.2967110872268677
Epoch 50 / 200, val acc: 0.436241610738255
Epoch 51 / 200, learning rate: 0.00012959999999999998
Epoch 51 / 200, train loss: 0.03416531905531883
Epoch 51 / 200, val loss: 0.29930663108825684
Epoch 51 / 200, val acc: 0.436241610738255
Epoch 52 / 200, learning rate: 0.00012959999999999998
Epoch 52 / 200, train loss: 0.03098669834434986
Epoch 52 / 200, val loss: 0.30267035961151123
Epoch 52 / 200, val acc: 0.436241610738255
Epoch 53 / 200, learning rate: 0.00012959999999999998
Epoch 53 / 200, train loss: 0.03326452523469925
Epoch 53 / 200, val loss: 0.305894136428833
Epoch 53 / 200, val acc: 0.436241610738255
Epoch 54 / 200, learning rate: 0.00012959999999999998
Epoch 54 / 200, train loss: 0.03233954682946205
Epoch 54 / 200, val loss: 0.3090343773365021
Epoch 54 / 200, val acc: 0.436241610738255
Epoch 55 / 200, learning rate: 0.00012959999999999998
Epoch 55 / 200, train loss: 0.0331890694797039
Epoch 55 / 200, val loss: 0.31102657318115234
Epoch 55 / 200, val acc: 0.436241610738255
Epoch 56 / 200, learning rate: 0.00012959999999999998
Epoch 56 / 200, train loss: 0.03102085366845131
Epoch 56 / 200, val loss: 0.3130287230014801
Epoch 56 / 200, val acc: 0.436241610738255
Epoch 57 / 200, learning rate: 0.00012959999999999998
Epoch 57 / 200, train loss: 0.03280540928244591
Epoch 57 / 200, val loss: 0.3136802017688751
Epoch 57 / 200, val acc: 0.436241610738255
Epoch 58 / 200, learning rate: 0.00012959999999999998
Epoch 58 / 200, train loss: 0.031344734132289886
Epoch 58 / 200, val loss: 0.3139188885688782
Epoch 58 / 200, val acc: 0.436241610738255
Epoch 59 / 200, learning rate: 0.00012959999999999998
Epoch 59 / 200, train loss: 0.030315428972244263
Epoch 59 / 200, val loss: 0.3138396143913269
Epoch 59 / 200, val acc: 0.436241610738255
Epoch 60 / 200, learning rate: 7.775999999999999e-05
Epoch 60 / 200, train loss: 0.03213366121053696
Epoch 60 / 200, val loss: 0.3132758140563965
Epoch 60 / 200, val acc: 0.436241610738255
Epoch 61 / 200, learning rate: 7.775999999999999e-05
Epoch 61 / 200, train loss: 0.030382754281163216
Epoch 61 / 200, val loss: 0.3125186860561371
Epoch 61 / 200, val acc: 0.436241610738255
Epoch 62 / 200, learning rate: 7.775999999999999e-05
Epoch 62 / 200, train loss: 0.030238576233386993
Epoch 62 / 200, val loss: 0.3114963471889496
Epoch 62 / 200, val acc: 0.436241610738255
Epoch 63 / 200, learning rate: 7.775999999999999e-05
Epoch 63 / 200, train loss: 0.03255542367696762
Epoch 63 / 200, val loss: 0.3102318346500397
Epoch 63 / 200, val acc: 0.436241610738255
Epoch 64 / 200, learning rate: 7.775999999999999e-05
Epoch 64 / 200, train loss: 0.03080187365412712
Epoch 64 / 200, val loss: 0.30884429812431335
Epoch 64 / 200, val acc: 0.436241610738255
Epoch 65 / 200, learning rate: 7.775999999999999e-05
Epoch 65 / 200, train loss: 0.030216874554753304
Epoch 65 / 200, val loss: 0.3074842393398285
Epoch 65 / 200, val acc: 0.436241610738255
Epoch 66 / 200, learning rate: 7.775999999999999e-05
Epoch 66 / 200, train loss: 0.030667917802929878
Epoch 66 / 200, val loss: 0.3062955439090729
Epoch 66 / 200, val acc: 0.436241610738255
Epoch 67 / 200, learning rate: 7.775999999999999e-05
Epoch 67 / 200, train loss: 0.031546179205179214
Epoch 67 / 200, val loss: 0.30582621693611145
Epoch 67 / 200, val acc: 0.436241610738255
Epoch 68 / 200, learning rate: 7.775999999999999e-05
Epoch 68 / 200, train loss: 0.031777273863554
Epoch 68 / 200, val loss: 0.30646389722824097
Epoch 68 / 200, val acc: 0.436241610738255
Epoch 69 / 200, learning rate: 7.775999999999999e-05
Epoch 69 / 200, train loss: 0.029646165668964386
Epoch 69 / 200, val loss: 0.3074352443218231
Epoch 69 / 200, val acc: 0.436241610738255
Epoch 70 / 200, learning rate: 7.775999999999999e-05
Epoch 70 / 200, train loss: 0.031079251319169998
Epoch 70 / 200, val loss: 0.3079213500022888
Epoch 70 / 200, val acc: 0.436241610738255
Epoch 71 / 200, learning rate: 4.665599999999999e-05
Epoch 71 / 200, train loss: 0.02920391596853733
Epoch 71 / 200, val loss: 0.3086766302585602
Epoch 71 / 200, val acc: 0.436241610738255
Epoch 72 / 200, learning rate: 4.665599999999999e-05
Epoch 72 / 200, train loss: 0.029387829825282097
Epoch 72 / 200, val loss: 0.3086881637573242
Epoch 72 / 200, val acc: 0.436241610738255
Epoch 73 / 200, learning rate: 4.665599999999999e-05
Epoch 73 / 200, train loss: 0.03155510127544403
Epoch 73 / 200, val loss: 0.3084622919559479
Epoch 73 / 200, val acc: 0.436241610738255
Epoch 74 / 200, learning rate: 4.665599999999999e-05
Epoch 74 / 200, train loss: 0.032073166221380234
Epoch 74 / 200, val loss: 0.3081747591495514
Epoch 74 / 200, val acc: 0.436241610738255
Epoch 75 / 200, learning rate: 4.665599999999999e-05
Epoch 75 / 200, train loss: 0.031071742996573448
Epoch 75 / 200, val loss: 0.30775803327560425
Epoch 75 / 200, val acc: 0.436241610738255
Epoch 76 / 200, learning rate: 4.665599999999999e-05
Epoch 76 / 200, train loss: 0.03163332864642143
Epoch 76 / 200, val loss: 0.30789804458618164
Epoch 76 / 200, val acc: 0.436241610738255
Epoch 77 / 200, learning rate: 4.665599999999999e-05
Epoch 77 / 200, train loss: 0.03257078304886818
Epoch 77 / 200, val loss: 0.3082621693611145
Epoch 77 / 200, val acc: 0.436241610738255
Epoch 78 / 200, learning rate: 4.665599999999999e-05
Epoch 78 / 200, train loss: 0.031133199110627174
Epoch 78 / 200, val loss: 0.30892300605773926
Epoch 78 / 200, val acc: 0.436241610738255
Epoch 79 / 200, learning rate: 4.665599999999999e-05
Epoch 79 / 200, train loss: 0.029658596962690353
Epoch 79 / 200, val loss: 0.3101162910461426
Epoch 79 / 200, val acc: 0.436241610738255
Epoch 80 / 200, learning rate: 4.665599999999999e-05
Epoch 80 / 200, train loss: 0.029207628220319748
Epoch 80 / 200, val loss: 0.31150782108306885
Epoch 80 / 200, val acc: 0.436241610738255
Epoch 81 / 200, learning rate: 4.665599999999999e-05
Epoch 81 / 200, train loss: 0.03127459064126015
Epoch 81 / 200, val loss: 0.3127616345882416
Epoch 81 / 200, val acc: 0.436241610738255
Epoch 82 / 200, learning rate: 2.7993599999999992e-05
Epoch 82 / 200, train loss: 0.031714536249637604
Epoch 82 / 200, val loss: 0.31366467475891113
Epoch 82 / 200, val acc: 0.436241610738255
Epoch 83 / 200, learning rate: 2.7993599999999992e-05
Epoch 83 / 200, train loss: 0.03120814450085163
Epoch 83 / 200, val loss: 0.3138783276081085
Epoch 83 / 200, val acc: 0.436241610738255
Epoch 84 / 200, learning rate: 2.7993599999999992e-05
Epoch 84 / 200, train loss: 0.03124123252928257
Epoch 84 / 200, val loss: 0.3141406774520874
Epoch 84 / 200, val acc: 0.436241610738255
Epoch 85 / 200, learning rate: 2.7993599999999992e-05
Epoch 85 / 200, train loss: 0.029152369126677513
Epoch 85 / 200, val loss: 0.31451451778411865
Epoch 85 / 200, val acc: 0.436241610738255
Epoch 86 / 200, learning rate: 2.7993599999999992e-05
Epoch 86 / 200, train loss: 0.03114185854792595
Epoch 86 / 200, val loss: 0.31509706377983093
Epoch 86 / 200, val acc: 0.436241610738255
Epoch 87 / 200, learning rate: 2.7993599999999992e-05
Epoch 87 / 200, train loss: 0.029686493799090385
Epoch 87 / 200, val loss: 0.3155476152896881
Epoch 87 / 200, val acc: 0.436241610738255
Epoch 88 / 200, learning rate: 2.7993599999999992e-05
Epoch 88 / 200, train loss: 0.031521473079919815
Epoch 88 / 200, val loss: 0.3156256377696991
Epoch 88 / 200, val acc: 0.436241610738255
Epoch 89 / 200, learning rate: 2.7993599999999992e-05
Epoch 89 / 200, train loss: 0.03139282763004303
Epoch 89 / 200, val loss: 0.31518885493278503
Epoch 89 / 200, val acc: 0.436241610738255
Epoch 90 / 200, learning rate: 2.7993599999999992e-05
Epoch 90 / 200, train loss: 0.03158271685242653
Epoch 90 / 200, val loss: 0.31452372670173645
Epoch 90 / 200, val acc: 0.436241610738255
Epoch 91 / 200, learning rate: 2.7993599999999992e-05
Epoch 91 / 200, train loss: 0.030604632571339607
Epoch 91 / 200, val loss: 0.31348302960395813
Epoch 91 / 200, val acc: 0.436241610738255
Epoch 92 / 200, learning rate: 2.7993599999999992e-05
Epoch 92 / 200, train loss: 0.03021860308945179
Epoch 92 / 200, val loss: 0.31247708201408386
Epoch 92 / 200, val acc: 0.436241610738255
Epoch 93 / 200, learning rate: 1.6796159999999994e-05
Epoch 93 / 200, train loss: 0.03109399415552616
Epoch 93 / 200, val loss: 0.311348021030426
Epoch 93 / 200, val acc: 0.436241610738255
Epoch 94 / 200, learning rate: 1.6796159999999994e-05
Epoch 94 / 200, train loss: 0.030169567093253136
Epoch 94 / 200, val loss: 0.31063711643218994
Epoch 94 / 200, val acc: 0.436241610738255
Epoch 95 / 200, learning rate: 1.6796159999999994e-05
Epoch 95 / 200, train loss: 0.02903389185667038
Epoch 95 / 200, val loss: 0.30999478697776794
Epoch 95 / 200, val acc: 0.436241610738255
Epoch 96 / 200, learning rate: 1.6796159999999994e-05
Epoch 96 / 200, train loss: 0.030482828617095947
Epoch 96 / 200, val loss: 0.30956026911735535
Epoch 96 / 200, val acc: 0.436241610738255
Epoch 97 / 200, learning rate: 1.6796159999999994e-05
Epoch 97 / 200, train loss: 0.0300906952470541
Epoch 97 / 200, val loss: 0.30916914343833923
Epoch 97 / 200, val acc: 0.436241610738255
Epoch 98 / 200, learning rate: 1.6796159999999994e-05
Epoch 98 / 200, train loss: 0.030948949977755547
Epoch 98 / 200, val loss: 0.30894410610198975
Epoch 98 / 200, val acc: 0.436241610738255
Epoch 99 / 200, learning rate: 1.6796159999999994e-05
Epoch 99 / 200, train loss: 0.029147228226065636
Epoch 99 / 200, val loss: 0.3086465001106262
Epoch 99 / 200, val acc: 0.436241610738255
Epoch 100 / 200, learning rate: 1.6796159999999994e-05
Epoch 100 / 200, train loss: 0.03148099407553673
Epoch 100 / 200, val loss: 0.3084164559841156
Epoch 100 / 200, val acc: 0.436241610738255
Epoch 101 / 200, learning rate: 1.6796159999999994e-05
Epoch 101 / 200, train loss: 0.028304502367973328
Epoch 101 / 200, val loss: 0.30824169516563416
Epoch 101 / 200, val acc: 0.436241610738255
Epoch 102 / 200, learning rate: 1.6796159999999994e-05
Epoch 102 / 200, train loss: 0.029285944998264313
Epoch 102 / 200, val loss: 0.3081668019294739
Epoch 102 / 200, val acc: 0.436241610738255
Epoch 103 / 200, learning rate: 1.6796159999999994e-05
Epoch 103 / 200, train loss: 0.03018408641219139
Epoch 103 / 200, val loss: 0.30819225311279297
Epoch 103 / 200, val acc: 0.436241610738255
Epoch 104 / 200, learning rate: 1.0077695999999996e-05
Epoch 104 / 200, train loss: 0.03044065088033676
Epoch 104 / 200, val loss: 0.30807042121887207
Epoch 104 / 200, val acc: 0.436241610738255
Epoch 105 / 200, learning rate: 1.0077695999999996e-05
Epoch 105 / 200, train loss: 0.03238091245293617
Epoch 105 / 200, val loss: 0.308125764131546
Epoch 105 / 200, val acc: 0.436241610738255
Epoch 106 / 200, learning rate: 1.0077695999999996e-05
Epoch 106 / 200, train loss: 0.030612241476774216
Epoch 106 / 200, val loss: 0.30797725915908813
Epoch 106 / 200, val acc: 0.436241610738255
Epoch 107 / 200, learning rate: 1.0077695999999996e-05
Epoch 107 / 200, train loss: 0.03222694993019104
Epoch 107 / 200, val loss: 0.30786576867103577
Epoch 107 / 200, val acc: 0.436241610738255
Epoch 108 / 200, learning rate: 1.0077695999999996e-05
Epoch 108 / 200, train loss: 0.03312085196375847
Epoch 108 / 200, val loss: 0.3079366683959961
Epoch 108 / 200, val acc: 0.436241610738255
Epoch 109 / 200, learning rate: 1.0077695999999996e-05
Epoch 109 / 200, train loss: 0.02933668904006481
Epoch 109 / 200, val loss: 0.307975709438324
Epoch 109 / 200, val acc: 0.436241610738255
Epoch 110 / 200, learning rate: 1.0077695999999996e-05
Epoch 110 / 200, train loss: 0.030437862500548363
Epoch 110 / 200, val loss: 0.30803972482681274
Epoch 110 / 200, val acc: 0.436241610738255
Epoch 111 / 200, learning rate: 1.0077695999999996e-05
Epoch 111 / 200, train loss: 0.029855558648705482
Epoch 111 / 200, val loss: 0.307955801486969
Epoch 111 / 200, val acc: 0.436241610738255
Epoch 112 / 200, learning rate: 1.0077695999999996e-05
Epoch 112 / 200, train loss: 0.030298955738544464
Epoch 112 / 200, val loss: 0.3079281151294708
Epoch 112 / 200, val acc: 0.436241610738255
Epoch 113 / 200, learning rate: 1.0077695999999996e-05
Epoch 113 / 200, train loss: 0.02970924973487854
Epoch 113 / 200, val loss: 0.30778107047080994
Epoch 113 / 200, val acc: 0.436241610738255
Epoch 114 / 200, learning rate: 1.0077695999999996e-05
Epoch 114 / 200, train loss: 0.02968456596136093
Epoch 114 / 200, val loss: 0.3075793981552124
Epoch 114 / 200, val acc: 0.436241610738255
Epoch 115 / 200, learning rate: 6.046617599999998e-06
Epoch 115 / 200, train loss: 0.030704440549016
Epoch 115 / 200, val loss: 0.30741190910339355
Epoch 115 / 200, val acc: 0.436241610738255
Epoch 116 / 200, learning rate: 6.046617599999998e-06
Epoch 116 / 200, train loss: 0.031520962715148926
Epoch 116 / 200, val loss: 0.30738213658332825
Epoch 116 / 200, val acc: 0.436241610738255
Epoch 117 / 200, learning rate: 6.046617599999998e-06
Epoch 117 / 200, train loss: 0.030516915023326874
Epoch 117 / 200, val loss: 0.30744248628616333
Epoch 117 / 200, val acc: 0.436241610738255
Epoch 118 / 200, learning rate: 6.046617599999998e-06
Epoch 118 / 200, train loss: 0.028471028432250023
Epoch 118 / 200, val loss: 0.30754944682121277
Epoch 118 / 200, val acc: 0.436241610738255
Epoch 119 / 200, learning rate: 6.046617599999998e-06
Epoch 119 / 200, train loss: 0.031011341139674187
Epoch 119 / 200, val loss: 0.30770817399024963
Epoch 119 / 200, val acc: 0.436241610738255
Epoch 120 / 200, learning rate: 6.046617599999998e-06
Epoch 120 / 200, train loss: 0.030875619500875473
Epoch 120 / 200, val loss: 0.30781760811805725
Epoch 120 / 200, val acc: 0.436241610738255
Epoch 121 / 200, learning rate: 6.046617599999998e-06
Epoch 121 / 200, train loss: 0.030375583097338676
Epoch 121 / 200, val loss: 0.3078785240650177
Epoch 121 / 200, val acc: 0.436241610738255
Epoch 122 / 200, learning rate: 6.046617599999998e-06
Epoch 122 / 200, train loss: 0.0295964814722538
Epoch 122 / 200, val loss: 0.30793970823287964
Epoch 122 / 200, val acc: 0.436241610738255
Epoch 123 / 200, learning rate: 6.046617599999998e-06
Epoch 123 / 200, train loss: 0.03097422607243061
Epoch 123 / 200, val loss: 0.3079299032688141
Epoch 123 / 200, val acc: 0.436241610738255
Epoch 124 / 200, learning rate: 6.046617599999998e-06
Epoch 124 / 200, train loss: 0.031059710308909416
Epoch 124 / 200, val loss: 0.3078112304210663
Epoch 124 / 200, val acc: 0.436241610738255
Epoch 125 / 200, learning rate: 6.046617599999998e-06
Epoch 125 / 200, train loss: 0.030633538961410522
Epoch 125 / 200, val loss: 0.3076454699039459
Epoch 125 / 200, val acc: 0.436241610738255
Epoch 126 / 200, learning rate: 3.6279705599999985e-06
Epoch 126 / 200, train loss: 0.031910490244627
Epoch 126 / 200, val loss: 0.30753326416015625
Epoch 126 / 200, val acc: 0.436241610738255
Epoch 127 / 200, learning rate: 3.6279705599999985e-06
Epoch 127 / 200, train loss: 0.03140883892774582
Epoch 127 / 200, val loss: 0.30752208828926086
Epoch 127 / 200, val acc: 0.436241610738255
Epoch 128 / 200, learning rate: 3.6279705599999985e-06
Epoch 128 / 200, train loss: 0.029788602143526077
Epoch 128 / 200, val loss: 0.30748629570007324
Epoch 128 / 200, val acc: 0.436241610738255
Epoch 129 / 200, learning rate: 3.6279705599999985e-06
Epoch 129 / 200, train loss: 0.02905886061489582
Epoch 129 / 200, val loss: 0.3074988126754761
Epoch 129 / 200, val acc: 0.436241610738255
Epoch 130 / 200, learning rate: 3.6279705599999985e-06
Epoch 130 / 200, train loss: 0.03055577166378498
Epoch 130 / 200, val loss: 0.3075281083583832
Epoch 130 / 200, val acc: 0.436241610738255
Epoch 131 / 200, learning rate: 3.6279705599999985e-06
Epoch 131 / 200, train loss: 0.03000088967382908
Epoch 131 / 200, val loss: 0.3075544238090515
Epoch 131 / 200, val acc: 0.436241610738255
Epoch 132 / 200, learning rate: 3.6279705599999985e-06
Epoch 132 / 200, train loss: 0.030410150066018105
Epoch 132 / 200, val loss: 0.3075500428676605
Epoch 132 / 200, val acc: 0.436241610738255
Epoch 133 / 200, learning rate: 3.6279705599999985e-06
Epoch 133 / 200, train loss: 0.028900478035211563
Epoch 133 / 200, val loss: 0.30753710865974426
Epoch 133 / 200, val acc: 0.436241610738255
Epoch 134 / 200, learning rate: 3.6279705599999985e-06
Epoch 134 / 200, train loss: 0.0307733453810215
Epoch 134 / 200, val loss: 0.3075094223022461
Epoch 134 / 200, val acc: 0.436241610738255
Epoch 135 / 200, learning rate: 3.6279705599999985e-06
Epoch 135 / 200, train loss: 0.0291973315179348
Epoch 135 / 200, val loss: 0.30745235085487366
Epoch 135 / 200, val acc: 0.436241610738255
Epoch 136 / 200, learning rate: 3.6279705599999985e-06
Epoch 136 / 200, train loss: 0.029814129695296288
Epoch 136 / 200, val loss: 0.3073886036872864
Epoch 136 / 200, val acc: 0.436241610738255
Epoch 137 / 200, learning rate: 2.176782335999999e-06
Epoch 137 / 200, train loss: 0.03165028989315033
Epoch 137 / 200, val loss: 0.3073175251483917
Epoch 137 / 200, val acc: 0.436241610738255
Epoch 138 / 200, learning rate: 2.176782335999999e-06
Epoch 138 / 200, train loss: 0.03153545781970024
Epoch 138 / 200, val loss: 0.3072994649410248
Epoch 138 / 200, val acc: 0.436241610738255
Epoch 139 / 200, learning rate: 2.176782335999999e-06
Epoch 139 / 200, train loss: 0.028837503865361214
Epoch 139 / 200, val loss: 0.30728083848953247
Epoch 139 / 200, val acc: 0.436241610738255
Epoch 140 / 200, learning rate: 2.176782335999999e-06
Epoch 140 / 200, train loss: 0.030774319544434547
Epoch 140 / 200, val loss: 0.307303249835968
Epoch 140 / 200, val acc: 0.436241610738255
Epoch 141 / 200, learning rate: 2.176782335999999e-06
Epoch 141 / 200, train loss: 0.032873839139938354
Epoch 141 / 200, val loss: 0.30732595920562744
Epoch 141 / 200, val acc: 0.436241610738255
Epoch 142 / 200, learning rate: 2.176782335999999e-06
Epoch 142 / 200, train loss: 0.029556121677160263
Epoch 142 / 200, val loss: 0.3073338270187378
Epoch 142 / 200, val acc: 0.436241610738255
Epoch 143 / 200, learning rate: 2.176782335999999e-06
Epoch 143 / 200, train loss: 0.031549904495477676
Epoch 143 / 200, val loss: 0.3073524534702301
Epoch 143 / 200, val acc: 0.436241610738255
Epoch 144 / 200, learning rate: 2.176782335999999e-06
Epoch 144 / 200, train loss: 0.02836677059531212
Epoch 144 / 200, val loss: 0.3073433041572571
Epoch 144 / 200, val acc: 0.436241610738255
Epoch 145 / 200, learning rate: 2.176782335999999e-06
Epoch 145 / 200, train loss: 0.030830275267362595
Epoch 145 / 200, val loss: 0.30730703473091125
Epoch 145 / 200, val acc: 0.436241610738255
Epoch 146 / 200, learning rate: 2.176782335999999e-06
Epoch 146 / 200, train loss: 0.03042447380721569
Epoch 146 / 200, val loss: 0.30726954340934753
Epoch 146 / 200, val acc: 0.436241610738255
Epoch 147 / 200, learning rate: 2.176782335999999e-06
Epoch 147 / 200, train loss: 0.028853606432676315
Epoch 147 / 200, val loss: 0.30723828077316284
Epoch 147 / 200, val acc: 0.436241610738255
Epoch 148 / 200, learning rate: 1.3060694015999993e-06
Epoch 148 / 200, train loss: 0.029304005205631256
Epoch 148 / 200, val loss: 0.30724796652793884
Epoch 148 / 200, val acc: 0.436241610738255
Epoch 149 / 200, learning rate: 1.3060694015999993e-06
Epoch 149 / 200, train loss: 0.028908761218190193
Epoch 149 / 200, val loss: 0.3072403371334076
Epoch 149 / 200, val acc: 0.436241610738255
Epoch 150 / 200, learning rate: 1.3060694015999993e-06
Epoch 150 / 200, train loss: 0.03029678389430046
Epoch 150 / 200, val loss: 0.30723288655281067
Epoch 150 / 200, val acc: 0.436241610738255
Epoch 151 / 200, learning rate: 1.3060694015999993e-06
Epoch 151 / 200, train loss: 0.03076503984630108
Epoch 151 / 200, val loss: 0.30724263191223145
Epoch 151 / 200, val acc: 0.436241610738255
Epoch 152 / 200, learning rate: 1.3060694015999993e-06
Epoch 152 / 200, train loss: 0.031964316964149475
Epoch 152 / 200, val loss: 0.3072608411312103
Epoch 152 / 200, val acc: 0.436241610738255
Epoch 153 / 200, learning rate: 1.3060694015999993e-06
Epoch 153 / 200, train loss: 0.02799781784415245
Epoch 153 / 200, val loss: 0.30727216601371765
Epoch 153 / 200, val acc: 0.436241610738255
Epoch 154 / 200, learning rate: 1.3060694015999993e-06
Epoch 154 / 200, train loss: 0.030127178877592087
Epoch 154 / 200, val loss: 0.3072831928730011
Epoch 154 / 200, val acc: 0.436241610738255
Epoch 155 / 200, learning rate: 1.3060694015999993e-06
Epoch 155 / 200, train loss: 0.028984135016798973
Epoch 155 / 200, val loss: 0.3072672486305237
Epoch 155 / 200, val acc: 0.436241610738255
Epoch 156 / 200, learning rate: 1.3060694015999993e-06
Epoch 156 / 200, train loss: 0.02982017770409584
Epoch 156 / 200, val loss: 0.3072408139705658
Epoch 156 / 200, val acc: 0.436241610738255
Epoch 157 / 200, learning rate: 1.3060694015999993e-06
Epoch 157 / 200, train loss: 0.031438130885362625
Epoch 157 / 200, val loss: 0.3072080612182617
Epoch 157 / 200, val acc: 0.436241610738255
Epoch 158 / 200, learning rate: 1.3060694015999993e-06
Epoch 158 / 200, train loss: 0.031996969133615494
Epoch 158 / 200, val loss: 0.3071829676628113
Epoch 158 / 200, val acc: 0.436241610738255
Epoch 159 / 200, learning rate: 7.836416409599996e-07
Epoch 159 / 200, train loss: 0.029808402061462402
Epoch 159 / 200, val loss: 0.3071775436401367
Epoch 159 / 200, val acc: 0.436241610738255
Epoch 160 / 200, learning rate: 7.836416409599996e-07
Epoch 160 / 200, train loss: 0.030678309500217438
Epoch 160 / 200, val loss: 0.3071710467338562
Epoch 160 / 200, val acc: 0.436241610738255
Epoch 161 / 200, learning rate: 7.836416409599996e-07
Epoch 161 / 200, train loss: 0.031385648995637894
Epoch 161 / 200, val loss: 0.3071776032447815
Epoch 161 / 200, val acc: 0.436241610738255
Epoch 162 / 200, learning rate: 7.836416409599996e-07
Epoch 162 / 200, train loss: 0.03148180618882179
Epoch 162 / 200, val loss: 0.3071868419647217
Epoch 162 / 200, val acc: 0.436241610738255
Epoch 163 / 200, learning rate: 7.836416409599996e-07
Epoch 163 / 200, train loss: 0.030034061521291733
Epoch 163 / 200, val loss: 0.30719876289367676
Epoch 163 / 200, val acc: 0.436241610738255
Epoch 164 / 200, learning rate: 7.836416409599996e-07
Epoch 164 / 200, train loss: 0.030555032193660736
Epoch 164 / 200, val loss: 0.3072063624858856
Epoch 164 / 200, val acc: 0.436241610738255
Epoch 165 / 200, learning rate: 7.836416409599996e-07
Epoch 165 / 200, train loss: 0.030503930523991585
Epoch 165 / 200, val loss: 0.3072112500667572
Epoch 165 / 200, val acc: 0.436241610738255
Epoch 166 / 200, learning rate: 7.836416409599996e-07
Epoch 166 / 200, train loss: 0.03158434480428696
Epoch 166 / 200, val loss: 0.30720362067222595
Epoch 166 / 200, val acc: 0.436241610738255
Epoch 167 / 200, learning rate: 7.836416409599996e-07
Epoch 167 / 200, train loss: 0.031144089996814728
Epoch 167 / 200, val loss: 0.3072066307067871
Epoch 167 / 200, val acc: 0.436241610738255
Epoch 168 / 200, learning rate: 7.836416409599996e-07
Epoch 168 / 200, train loss: 0.03195108845829964
Epoch 168 / 200, val loss: 0.3071962296962738
Epoch 168 / 200, val acc: 0.436241610738255
Epoch 169 / 200, learning rate: 7.836416409599996e-07
Epoch 169 / 200, train loss: 0.029368707910180092
Epoch 169 / 200, val loss: 0.307184100151062
Epoch 169 / 200, val acc: 0.436241610738255
Epoch 170 / 200, learning rate: 4.7018498457599973e-07
Epoch 170 / 200, train loss: 0.030350418761372566
Epoch 170 / 200, val loss: 0.30716148018836975
Epoch 170 / 200, val acc: 0.436241610738255
Epoch 171 / 200, learning rate: 4.7018498457599973e-07
Epoch 171 / 200, train loss: 0.030876660719513893
Epoch 171 / 200, val loss: 0.30714794993400574
Epoch 171 / 200, val acc: 0.436241610738255
Epoch 172 / 200, learning rate: 4.7018498457599973e-07
Epoch 172 / 200, train loss: 0.03067990206182003
Epoch 172 / 200, val loss: 0.30713751912117004
Epoch 172 / 200, val acc: 0.436241610738255
Epoch 173 / 200, learning rate: 4.7018498457599973e-07
Epoch 173 / 200, train loss: 0.02976779080927372
Epoch 173 / 200, val loss: 0.30712905526161194
Epoch 173 / 200, val acc: 0.436241610738255
Epoch 174 / 200, learning rate: 4.7018498457599973e-07
Epoch 174 / 200, train loss: 0.029776770621538162
Epoch 174 / 200, val loss: 0.3071207106113434
Epoch 174 / 200, val acc: 0.436241610738255
Epoch 175 / 200, learning rate: 4.7018498457599973e-07
Epoch 175 / 200, train loss: 0.02950296178460121
Epoch 175 / 200, val loss: 0.3071155846118927
Epoch 175 / 200, val acc: 0.436241610738255
Epoch 176 / 200, learning rate: 4.7018498457599973e-07
Epoch 176 / 200, train loss: 0.028987720608711243
Epoch 176 / 200, val loss: 0.307107150554657
Epoch 176 / 200, val acc: 0.436241610738255
Epoch 177 / 200, learning rate: 4.7018498457599973e-07
Epoch 177 / 200, train loss: 0.030194919556379318
Epoch 177 / 200, val loss: 0.30710384249687195
Epoch 177 / 200, val acc: 0.436241610738255
Epoch 178 / 200, learning rate: 4.7018498457599973e-07
Epoch 178 / 200, train loss: 0.029994506388902664
Epoch 178 / 200, val loss: 0.307110458612442
Epoch 178 / 200, val acc: 0.436241610738255
Epoch 179 / 200, learning rate: 4.7018498457599973e-07
Epoch 179 / 200, train loss: 0.031464844942092896
Epoch 179 / 200, val loss: 0.30711477994918823
Epoch 179 / 200, val acc: 0.436241610738255
Epoch 180 / 200, learning rate: 4.7018498457599973e-07
Epoch 180 / 200, train loss: 0.03160823881626129
Epoch 180 / 200, val loss: 0.30712032318115234
Epoch 180 / 200, val acc: 0.436241610738255
Epoch 181 / 200, learning rate: 2.821109907455998e-07
Epoch 181 / 200, train loss: 0.03049369901418686
Epoch 181 / 200, val loss: 0.30712735652923584
Epoch 181 / 200, val acc: 0.436241610738255
Epoch 182 / 200, learning rate: 2.821109907455998e-07
Epoch 182 / 200, train loss: 0.029816653579473495
Epoch 182 / 200, val loss: 0.3071305453777313
Epoch 182 / 200, val acc: 0.436241610738255
Epoch 183 / 200, learning rate: 2.821109907455998e-07
Epoch 183 / 200, train loss: 0.031014932319521904
Epoch 183 / 200, val loss: 0.3071366846561432
Epoch 183 / 200, val acc: 0.436241610738255
Epoch 184 / 200, learning rate: 2.821109907455998e-07
Epoch 184 / 200, train loss: 0.029657965525984764
Epoch 184 / 200, val loss: 0.3071417808532715
Epoch 184 / 200, val acc: 0.436241610738255
Epoch 185 / 200, learning rate: 2.821109907455998e-07
Epoch 185 / 200, train loss: 0.0298970527946949
Epoch 185 / 200, val loss: 0.30715107917785645
Epoch 185 / 200, val acc: 0.436241610738255
Epoch 186 / 200, learning rate: 2.821109907455998e-07
Epoch 186 / 200, train loss: 0.028496745973825455
Epoch 186 / 200, val loss: 0.3071599006652832
Epoch 186 / 200, val acc: 0.436241610738255
Epoch 187 / 200, learning rate: 2.821109907455998e-07
Epoch 187 / 200, train loss: 0.02849544771015644
Epoch 187 / 200, val loss: 0.30717238783836365
Epoch 187 / 200, val acc: 0.436241610738255
Epoch 188 / 200, learning rate: 2.821109907455998e-07
Epoch 188 / 200, train loss: 0.030940528959035873
Epoch 188 / 200, val loss: 0.30718448758125305
Epoch 188 / 200, val acc: 0.436241610738255
Epoch 189 / 200, learning rate: 2.821109907455998e-07
Epoch 189 / 200, train loss: 0.028513256460428238
Epoch 189 / 200, val loss: 0.3071958124637604
Epoch 189 / 200, val acc: 0.436241610738255
Epoch 190 / 200, learning rate: 2.821109907455998e-07
Epoch 190 / 200, train loss: 0.030504144728183746
Epoch 190 / 200, val loss: 0.3072086274623871
Epoch 190 / 200, val acc: 0.436241610738255
Epoch 191 / 200, learning rate: 2.821109907455998e-07
Epoch 191 / 200, train loss: 0.029939040541648865
Epoch 191 / 200, val loss: 0.3072251081466675
Epoch 191 / 200, val acc: 0.436241610738255
Epoch 192 / 200, learning rate: 1.6926659444735988e-07
Epoch 192 / 200, train loss: 0.03210264816880226
Epoch 192 / 200, val loss: 0.30724239349365234
Epoch 192 / 200, val acc: 0.436241610738255
Epoch 193 / 200, learning rate: 1.6926659444735988e-07
Epoch 193 / 200, train loss: 0.031571026891469955
Epoch 193 / 200, val loss: 0.3072493076324463
Epoch 193 / 200, val acc: 0.436241610738255
Epoch 194 / 200, learning rate: 1.6926659444735988e-07
Epoch 194 / 200, train loss: 0.030367707833647728
Epoch 194 / 200, val loss: 0.3072551488876343
Epoch 194 / 200, val acc: 0.436241610738255
Epoch 195 / 200, learning rate: 1.6926659444735988e-07
Epoch 195 / 200, train loss: 0.030478578060865402
Epoch 195 / 200, val loss: 0.3072607219219208
Epoch 195 / 200, val acc: 0.436241610738255
Epoch 196 / 200, learning rate: 1.6926659444735988e-07
Epoch 196 / 200, train loss: 0.030548207461833954
Epoch 196 / 200, val loss: 0.3072652220726013
Epoch 196 / 200, val acc: 0.436241610738255
Epoch 197 / 200, learning rate: 1.6926659444735988e-07
Epoch 197 / 200, train loss: 0.03061874955892563
Epoch 197 / 200, val loss: 0.3072699308395386
Epoch 197 / 200, val acc: 0.436241610738255
Epoch 198 / 200, learning rate: 1.6926659444735988e-07
Epoch 198 / 200, train loss: 0.03065536543726921
Epoch 198 / 200, val loss: 0.3072735667228699
Epoch 198 / 200, val acc: 0.436241610738255
Epoch 199 / 200, learning rate: 1.6926659444735988e-07
Epoch 199 / 200, train loss: 0.029800383374094963
Epoch 199 / 200, val loss: 0.3072796165943146
Epoch 199 / 200, val acc: 0.436241610738255
Epoch 200 / 200, learning rate: 1.6926659444735988e-07
Epoch 200 / 200, train loss: 0.032025646418333054
Epoch 200 / 200, val loss: 0.30728450417518616
Epoch 200 / 200, val acc: 0.436241610738255
Training finished

Evaluating best model
Trading strategy for stock SPY:
After 2999 trading days
Binary accuracy: 0.48666
Fraction of long signals: 0.29476
Fraction of short signals: 0.70490
Overall long return: 1.69422
Overall return: 0.01203
Yearly long return: 0.14236
Yearly return: 0.00101
Daily volatility: 0.01083
Max drawdown baseline: 0.16749
Max drawdown: 0.86411
Sharpe ratio: -0.05180
L1 error baseline: 0.01756
L1 error: 0.24736
Average prediction: -0.09225
Std prediction: 1.04509


Trading strategy for stock SPY:
After 150 trading days
Binary accuracy: 0.45638
Fraction of long signals: 0.01333
Fraction of short signals: 0.98667
Overall long return: 0.11226
Overall return: -0.08205
Yearly long return: 0.18860
Yearly return: -0.13784
Daily volatility: 0.00846
Max drawdown baseline: 0.07360
Max drawdown: 0.16424
Sharpe ratio: -0.15361
L1 error baseline: 0.02637
L1 error: 0.30907
Average prediction: 1.33580
Std prediction: 0.00221


