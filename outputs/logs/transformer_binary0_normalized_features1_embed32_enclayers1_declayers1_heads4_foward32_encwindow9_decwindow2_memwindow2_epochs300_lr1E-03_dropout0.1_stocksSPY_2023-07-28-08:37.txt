Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              64
├─Time2Vec: 1-2                                    [1, 100, 36]              --
│    └─Linear: 2-1                                 [100, 4]                  8
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 36]              (recursive)
│    └─Linear: 2-2                                 [100, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 36]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 36]              --
│    │    └─ModuleList: 3-1                        --                        7,844
│    │    └─LayerNorm: 3-2                         [1, 100, 36]              72
│    └─TransformerDecoder: 2-4                     [1, 100, 36]              --
│    │    └─ModuleList: 3-3                        --                        13,244
│    │    └─LayerNorm: 3-4                         [1, 100, 36]              72
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 18]              666
│    └─Dropout: 2-6                                [1, 100, 18]              --
│    └─ReLU: 2-7                                   [1, 100, 18]              --
│    └─Linear: 2-8                                 [1, 100, 1]               19
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 21,989
Trainable params: 21,989
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.29
====================================================================================================
Epoch 1 / 300, learning rate: 0.001
Epoch 1 / 300, train loss: 0.4836011528968811
Epoch 1 / 300, val loss: 6.582182884216309
Epoch 1 / 300, val acc: 0.4699738903394256
Epoch 2 / 300, learning rate: 0.001
Epoch 2 / 300, train loss: 0.4302625060081482
Epoch 2 / 300, val loss: 7.311565399169922
Epoch 2 / 300, val acc: 0.48825065274151436
Epoch 3 / 300, learning rate: 0.001
Epoch 3 / 300, train loss: 0.42507630586624146
Epoch 3 / 300, val loss: 7.642743110656738
Epoch 3 / 300, val acc: 0.5091383812010444
Epoch 4 / 300, learning rate: 0.001
Epoch 4 / 300, train loss: 0.4349111318588257
Epoch 4 / 300, val loss: 7.630075454711914
Epoch 4 / 300, val acc: 0.4908616187989556
Epoch 5 / 300, learning rate: 0.001
Epoch 5 / 300, train loss: 0.4360717833042145
Epoch 5 / 300, val loss: 7.399432182312012
Epoch 5 / 300, val acc: 0.5117493472584856
Epoch 6 / 300, learning rate: 0.001
Epoch 6 / 300, train loss: 0.42356809973716736
Epoch 6 / 300, val loss: 7.110079765319824
Epoch 6 / 300, val acc: 0.4856396866840731
Epoch 7 / 300, learning rate: 0.001
Epoch 7 / 300, train loss: 0.42281243205070496
Epoch 7 / 300, val loss: 6.819600582122803
Epoch 7 / 300, val acc: 0.4804177545691906
Epoch 8 / 300, learning rate: 0.001
Epoch 8 / 300, train loss: 0.4158671796321869
Epoch 8 / 300, val loss: 6.581020355224609
Epoch 8 / 300, val acc: 0.4725848563968668
Epoch 9 / 300, learning rate: 0.001
Epoch 9 / 300, train loss: 0.4190588891506195
Epoch 9 / 300, val loss: 6.4285712242126465
Epoch 9 / 300, val acc: 0.5300261096605744
Epoch 10 / 300, learning rate: 0.001
Epoch 10 / 300, train loss: 0.421176016330719
Epoch 10 / 300, val loss: 6.366728782653809
Epoch 10 / 300, val acc: 0.4856396866840731
Epoch 11 / 300, learning rate: 0.001
Epoch 11 / 300, train loss: 0.4147876501083374
Epoch 11 / 300, val loss: 6.386434078216553
Epoch 11 / 300, val acc: 0.4908616187989556
Epoch 12 / 300, learning rate: 0.001
Epoch 12 / 300, train loss: 0.4195284843444824
Epoch 12 / 300, val loss: 6.464529991149902
Epoch 12 / 300, val acc: 0.5143603133159269
Epoch 13 / 300, learning rate: 0.001
Epoch 13 / 300, train loss: 0.4148196280002594
Epoch 13 / 300, val loss: 6.579490661621094
Epoch 13 / 300, val acc: 0.48825065274151436
Epoch 14 / 300, learning rate: 0.001
Epoch 14 / 300, train loss: 0.41309425234794617
Epoch 14 / 300, val loss: 6.713462829589844
Epoch 14 / 300, val acc: 0.5065274151436031
Epoch 15 / 300, learning rate: 0.001
Epoch 15 / 300, train loss: 0.41118237376213074
Epoch 15 / 300, val loss: 6.844691753387451
Epoch 15 / 300, val acc: 0.4751958224543081
Epoch 16 / 300, learning rate: 0.001
Epoch 16 / 300, train loss: 0.4085647761821747
Epoch 16 / 300, val loss: 6.952273845672607
Epoch 16 / 300, val acc: 0.5091383812010444
Epoch 17 / 300, learning rate: 0.001
Epoch 17 / 300, train loss: 0.4096144735813141
Epoch 17 / 300, val loss: 7.027364730834961
Epoch 17 / 300, val acc: 0.5143603133159269
Epoch 18 / 300, learning rate: 0.001
Epoch 18 / 300, train loss: 0.4118508994579315
Epoch 18 / 300, val loss: 7.061797142028809
Epoch 18 / 300, val acc: 0.5091383812010444
Epoch 19 / 300, learning rate: 0.001
Epoch 19 / 300, train loss: 0.4116988778114319
Epoch 19 / 300, val loss: 7.0580878257751465
Epoch 19 / 300, val acc: 0.5169712793733682
Epoch 20 / 300, learning rate: 0.001
Epoch 20 / 300, train loss: 0.4110547602176666
Epoch 20 / 300, val loss: 7.020800590515137
Epoch 20 / 300, val acc: 0.5091383812010444
Epoch 21 / 300, learning rate: 0.0005
Epoch 21 / 300, train loss: 0.41138261556625366
Epoch 21 / 300, val loss: 6.96108341217041
Epoch 21 / 300, val acc: 0.5091383812010444
Epoch 22 / 300, learning rate: 0.0005
Epoch 22 / 300, train loss: 0.4062022268772125
Epoch 22 / 300, val loss: 6.925561428070068
Epoch 22 / 300, val acc: 0.4934725848563969
Epoch 23 / 300, learning rate: 0.0005
Epoch 23 / 300, train loss: 0.40334418416023254
Epoch 23 / 300, val loss: 6.887965679168701
Epoch 23 / 300, val acc: 0.5013054830287206
Epoch 24 / 300, learning rate: 0.0005
Epoch 24 / 300, train loss: 0.4074355363845825
Epoch 24 / 300, val loss: 6.850669860839844
Epoch 24 / 300, val acc: 0.4856396866840731
Epoch 25 / 300, learning rate: 0.0005
Epoch 25 / 300, train loss: 0.4050467610359192
Epoch 25 / 300, val loss: 6.815423488616943
Epoch 25 / 300, val acc: 0.5065274151436031
Epoch 26 / 300, learning rate: 0.0005
Epoch 26 / 300, train loss: 0.4042690396308899
Epoch 26 / 300, val loss: 6.782323360443115
Epoch 26 / 300, val acc: 0.4804177545691906
Epoch 27 / 300, learning rate: 0.0005
Epoch 27 / 300, train loss: 0.4037257134914398
Epoch 27 / 300, val loss: 6.753716945648193
Epoch 27 / 300, val acc: 0.4960835509138381
Epoch 28 / 300, learning rate: 0.0005
Epoch 28 / 300, train loss: 0.4058838486671448
Epoch 28 / 300, val loss: 6.734235763549805
Epoch 28 / 300, val acc: 0.5065274151436031
Epoch 29 / 300, learning rate: 0.0005
Epoch 29 / 300, train loss: 0.40860581398010254
Epoch 29 / 300, val loss: 6.724313735961914
Epoch 29 / 300, val acc: 0.5195822454308094
Epoch 30 / 300, learning rate: 0.0005
Epoch 30 / 300, train loss: 0.40686923265457153
Epoch 30 / 300, val loss: 6.722775936126709
Epoch 30 / 300, val acc: 0.5091383812010444
Epoch 31 / 300, learning rate: 0.0005
Epoch 31 / 300, train loss: 0.4067171812057495
Epoch 31 / 300, val loss: 6.730138301849365
Epoch 31 / 300, val acc: 0.5091383812010444
Epoch 32 / 300, learning rate: 0.00025
Epoch 32 / 300, train loss: 0.4056868255138397
Epoch 32 / 300, val loss: 6.744654655456543
Epoch 32 / 300, val acc: 0.4830287206266319
Epoch 33 / 300, learning rate: 0.00025
Epoch 33 / 300, train loss: 0.40918150544166565
Epoch 33 / 300, val loss: 6.7545623779296875
Epoch 33 / 300, val acc: 0.4856396866840731
Epoch 34 / 300, learning rate: 0.00025
Epoch 34 / 300, train loss: 0.40631163120269775
Epoch 34 / 300, val loss: 6.7659220695495605
Epoch 34 / 300, val acc: 0.4856396866840731
Epoch 35 / 300, learning rate: 0.00025
Epoch 35 / 300, train loss: 0.40616920590400696
Epoch 35 / 300, val loss: 6.77863073348999
Epoch 35 / 300, val acc: 0.4908616187989556
Epoch 36 / 300, learning rate: 0.00025
Epoch 36 / 300, train loss: 0.4019014239311218
Epoch 36 / 300, val loss: 6.792438507080078
Epoch 36 / 300, val acc: 0.4908616187989556
Epoch 37 / 300, learning rate: 0.00025
Epoch 37 / 300, train loss: 0.4048451781272888
Epoch 37 / 300, val loss: 6.806687831878662
Epoch 37 / 300, val acc: 0.49869451697127937
Epoch 38 / 300, learning rate: 0.00025
Epoch 38 / 300, train loss: 0.4072917699813843
Epoch 38 / 300, val loss: 6.820589065551758
Epoch 38 / 300, val acc: 0.5117493472584856
Epoch 39 / 300, learning rate: 0.00025
Epoch 39 / 300, train loss: 0.40105488896369934
Epoch 39 / 300, val loss: 6.8338541984558105
Epoch 39 / 300, val acc: 0.5143603133159269
Epoch 40 / 300, learning rate: 0.00025
Epoch 40 / 300, train loss: 0.40589332580566406
Epoch 40 / 300, val loss: 6.845394134521484
Epoch 40 / 300, val acc: 0.49869451697127937
Epoch 41 / 300, learning rate: 0.00025
Epoch 41 / 300, train loss: 0.40234747529029846
Epoch 41 / 300, val loss: 6.856244087219238
Epoch 41 / 300, val acc: 0.5091383812010444
Epoch 42 / 300, learning rate: 0.00025
Epoch 42 / 300, train loss: 0.4034874141216278
Epoch 42 / 300, val loss: 6.865839958190918
Epoch 42 / 300, val acc: 0.5039164490861618
Epoch 43 / 300, learning rate: 0.000125
Epoch 43 / 300, train loss: 0.4060277044773102
Epoch 43 / 300, val loss: 6.87204647064209
Epoch 43 / 300, val acc: 0.49869451697127937
Epoch 44 / 300, learning rate: 0.000125
Epoch 44 / 300, train loss: 0.40262049436569214
Epoch 44 / 300, val loss: 6.8740034103393555
Epoch 44 / 300, val acc: 0.49869451697127937
Epoch 45 / 300, learning rate: 0.000125
Epoch 45 / 300, train loss: 0.40769824385643005
Epoch 45 / 300, val loss: 6.874940395355225
Epoch 45 / 300, val acc: 0.5091383812010444
Epoch 46 / 300, learning rate: 0.000125
Epoch 46 / 300, train loss: 0.403896689414978
Epoch 46 / 300, val loss: 6.874671459197998
Epoch 46 / 300, val acc: 0.5013054830287206
Epoch 47 / 300, learning rate: 0.000125
Epoch 47 / 300, train loss: 0.40398162603378296
Epoch 47 / 300, val loss: 6.873106956481934
Epoch 47 / 300, val acc: 0.5013054830287206
Epoch 48 / 300, learning rate: 0.000125
Epoch 48 / 300, train loss: 0.4014250934123993
Epoch 48 / 300, val loss: 6.871091365814209
Epoch 48 / 300, val acc: 0.4960835509138381
Epoch 49 / 300, learning rate: 0.000125
Epoch 49 / 300, train loss: 0.40474262833595276
Epoch 49 / 300, val loss: 6.868089199066162
Epoch 49 / 300, val acc: 0.4960835509138381
Epoch 50 / 300, learning rate: 0.000125
Epoch 50 / 300, train loss: 0.40433815121650696
Epoch 50 / 300, val loss: 6.864869117736816
Epoch 50 / 300, val acc: 0.4908616187989556
Epoch 51 / 300, learning rate: 0.000125
Epoch 51 / 300, train loss: 0.40157121419906616
Epoch 51 / 300, val loss: 6.861236572265625
Epoch 51 / 300, val acc: 0.48825065274151436
Epoch 52 / 300, learning rate: 0.000125
Epoch 52 / 300, train loss: 0.40226447582244873
Epoch 52 / 300, val loss: 6.857222557067871
Epoch 52 / 300, val acc: 0.4856396866840731
Epoch 53 / 300, learning rate: 0.000125
Epoch 53 / 300, train loss: 0.4046354293823242
Epoch 53 / 300, val loss: 6.852620601654053
Epoch 53 / 300, val acc: 0.4830287206266319
Epoch 54 / 300, learning rate: 6.25e-05
Epoch 54 / 300, train loss: 0.4065800905227661
Epoch 54 / 300, val loss: 6.847614288330078
Epoch 54 / 300, val acc: 0.4934725848563969
Epoch 55 / 300, learning rate: 6.25e-05
Epoch 55 / 300, train loss: 0.4034832715988159
Epoch 55 / 300, val loss: 6.845142364501953
Epoch 55 / 300, val acc: 0.48825065274151436
Epoch 56 / 300, learning rate: 6.25e-05
Epoch 56 / 300, train loss: 0.4020852744579315
Epoch 56 / 300, val loss: 6.842736721038818
Epoch 56 / 300, val acc: 0.4908616187989556
Epoch 57 / 300, learning rate: 6.25e-05
Epoch 57 / 300, train loss: 0.4022848606109619
Epoch 57 / 300, val loss: 6.840337753295898
Epoch 57 / 300, val acc: 0.5013054830287206
Epoch 58 / 300, learning rate: 6.25e-05
Epoch 58 / 300, train loss: 0.4008384346961975
Epoch 58 / 300, val loss: 6.838190078735352
Epoch 58 / 300, val acc: 0.49869451697127937
Epoch 59 / 300, learning rate: 6.25e-05
Epoch 59 / 300, train loss: 0.4050399959087372
Epoch 59 / 300, val loss: 6.836066246032715
Epoch 59 / 300, val acc: 0.4934725848563969
Epoch 60 / 300, learning rate: 6.25e-05
Epoch 60 / 300, train loss: 0.4005637764930725
Epoch 60 / 300, val loss: 6.834033012390137
Epoch 60 / 300, val acc: 0.49869451697127937
Epoch 61 / 300, learning rate: 6.25e-05
Epoch 61 / 300, train loss: 0.403666228055954
Epoch 61 / 300, val loss: 6.831954479217529
Epoch 61 / 300, val acc: 0.4830287206266319
Epoch 62 / 300, learning rate: 6.25e-05
Epoch 62 / 300, train loss: 0.40208449959754944
Epoch 62 / 300, val loss: 6.830167770385742
Epoch 62 / 300, val acc: 0.4804177545691906
Epoch 63 / 300, learning rate: 6.25e-05
Epoch 63 / 300, train loss: 0.4067208766937256
Epoch 63 / 300, val loss: 6.828498363494873
Epoch 63 / 300, val acc: 0.47780678851174935
Epoch 64 / 300, learning rate: 6.25e-05
Epoch 64 / 300, train loss: 0.40299054980278015
Epoch 64 / 300, val loss: 6.8267645835876465
Epoch 64 / 300, val acc: 0.4699738903394256
Epoch 65 / 300, learning rate: 3.125e-05
Epoch 65 / 300, train loss: 0.4023154377937317
Epoch 65 / 300, val loss: 6.8253068923950195
Epoch 65 / 300, val acc: 0.4751958224543081
Epoch 66 / 300, learning rate: 3.125e-05
Epoch 66 / 300, train loss: 0.4050867557525635
Epoch 66 / 300, val loss: 6.824597358703613
Epoch 66 / 300, val acc: 0.4856396866840731
Epoch 67 / 300, learning rate: 3.125e-05
Epoch 67 / 300, train loss: 0.4038543105125427
Epoch 67 / 300, val loss: 6.824019432067871
Epoch 67 / 300, val acc: 0.4804177545691906
Epoch 68 / 300, learning rate: 3.125e-05
Epoch 68 / 300, train loss: 0.4019840657711029
Epoch 68 / 300, val loss: 6.8235063552856445
Epoch 68 / 300, val acc: 0.4830287206266319
Epoch 69 / 300, learning rate: 3.125e-05
Epoch 69 / 300, train loss: 0.4010121822357178
Epoch 69 / 300, val loss: 6.823121547698975
Epoch 69 / 300, val acc: 0.4804177545691906
Epoch 70 / 300, learning rate: 3.125e-05
Epoch 70 / 300, train loss: 0.40326574444770813
Epoch 70 / 300, val loss: 6.822927474975586
Epoch 70 / 300, val acc: 0.4725848563968668
Epoch 71 / 300, learning rate: 3.125e-05
Epoch 71 / 300, train loss: 0.4030294120311737
Epoch 71 / 300, val loss: 6.822711944580078
Epoch 71 / 300, val acc: 0.4699738903394256
Epoch 72 / 300, learning rate: 3.125e-05
Epoch 72 / 300, train loss: 0.4038606286048889
Epoch 72 / 300, val loss: 6.822595119476318
Epoch 72 / 300, val acc: 0.4804177545691906
Epoch 73 / 300, learning rate: 3.125e-05
Epoch 73 / 300, train loss: 0.40353500843048096
Epoch 73 / 300, val loss: 6.822501182556152
Epoch 73 / 300, val acc: 0.4830287206266319
Epoch 74 / 300, learning rate: 3.125e-05
Epoch 74 / 300, train loss: 0.40224796533584595
Epoch 74 / 300, val loss: 6.8224101066589355
Epoch 74 / 300, val acc: 0.47780678851174935
Epoch 75 / 300, learning rate: 3.125e-05
Epoch 75 / 300, train loss: 0.4035108983516693
Epoch 75 / 300, val loss: 6.822345733642578
Epoch 75 / 300, val acc: 0.4856396866840731
Epoch 76 / 300, learning rate: 1.5625e-05
Epoch 76 / 300, train loss: 0.40223389863967896
Epoch 76 / 300, val loss: 6.822391510009766
Epoch 76 / 300, val acc: 0.4960835509138381
Epoch 77 / 300, learning rate: 1.5625e-05
Epoch 77 / 300, train loss: 0.4038827121257782
Epoch 77 / 300, val loss: 6.822391510009766
Epoch 77 / 300, val acc: 0.49869451697127937
Epoch 78 / 300, learning rate: 1.5625e-05
Epoch 78 / 300, train loss: 0.4042213559150696
Epoch 78 / 300, val loss: 6.822369575500488
Epoch 78 / 300, val acc: 0.5091383812010444
Epoch 79 / 300, learning rate: 1.5625e-05
Epoch 79 / 300, train loss: 0.40232256054878235
Epoch 79 / 300, val loss: 6.822347640991211
Epoch 79 / 300, val acc: 0.5143603133159269
Epoch 80 / 300, learning rate: 1.5625e-05
Epoch 80 / 300, train loss: 0.40291473269462585
Epoch 80 / 300, val loss: 6.822371482849121
Epoch 80 / 300, val acc: 0.5169712793733682
Epoch 81 / 300, learning rate: 1.5625e-05
Epoch 81 / 300, train loss: 0.4031625986099243
Epoch 81 / 300, val loss: 6.822376251220703
Epoch 81 / 300, val acc: 0.5221932114882507
Epoch 82 / 300, learning rate: 1.5625e-05
Epoch 82 / 300, train loss: 0.4056054353713989
Epoch 82 / 300, val loss: 6.822395324707031
Epoch 82 / 300, val acc: 0.5169712793733682
Epoch 83 / 300, learning rate: 1.5625e-05
Epoch 83 / 300, train loss: 0.40189656615257263
Epoch 83 / 300, val loss: 6.822431564331055
Epoch 83 / 300, val acc: 0.5143603133159269
Epoch 84 / 300, learning rate: 1.5625e-05
Epoch 84 / 300, train loss: 0.4007757008075714
Epoch 84 / 300, val loss: 6.822593688964844
Epoch 84 / 300, val acc: 0.5169712793733682
Epoch 85 / 300, learning rate: 1.5625e-05
Epoch 85 / 300, train loss: 0.4016304612159729
Epoch 85 / 300, val loss: 6.822782516479492
Epoch 85 / 300, val acc: 0.5117493472584856
Epoch 86 / 300, learning rate: 1.5625e-05
Epoch 86 / 300, train loss: 0.4019205570220947
Epoch 86 / 300, val loss: 6.822956085205078
Epoch 86 / 300, val acc: 0.5091383812010444
Epoch 87 / 300, learning rate: 7.8125e-06
Epoch 87 / 300, train loss: 0.4064891040325165
Epoch 87 / 300, val loss: 6.823125839233398
Epoch 87 / 300, val acc: 0.5091383812010444
Epoch 88 / 300, learning rate: 7.8125e-06
Epoch 88 / 300, train loss: 0.4026185870170593
Epoch 88 / 300, val loss: 6.823213577270508
Epoch 88 / 300, val acc: 0.5091383812010444
Epoch 89 / 300, learning rate: 7.8125e-06
Epoch 89 / 300, train loss: 0.4017563462257385
Epoch 89 / 300, val loss: 6.823323726654053
Epoch 89 / 300, val acc: 0.5091383812010444
Epoch 90 / 300, learning rate: 7.8125e-06
Epoch 90 / 300, train loss: 0.4010377526283264
Epoch 90 / 300, val loss: 6.823411464691162
Epoch 90 / 300, val acc: 0.5117493472584856
Epoch 91 / 300, learning rate: 7.8125e-06
Epoch 91 / 300, train loss: 0.4020487666130066
Epoch 91 / 300, val loss: 6.823516845703125
Epoch 91 / 300, val acc: 0.5117493472584856
Epoch 92 / 300, learning rate: 7.8125e-06
Epoch 92 / 300, train loss: 0.3993385434150696
Epoch 92 / 300, val loss: 6.823638439178467
Epoch 92 / 300, val acc: 0.5117493472584856
Epoch 93 / 300, learning rate: 7.8125e-06
Epoch 93 / 300, train loss: 0.4054212272167206
Epoch 93 / 300, val loss: 6.823782920837402
Epoch 93 / 300, val acc: 0.5195822454308094
Epoch 94 / 300, learning rate: 7.8125e-06
Epoch 94 / 300, train loss: 0.40168237686157227
Epoch 94 / 300, val loss: 6.823916435241699
Epoch 94 / 300, val acc: 0.5221932114882507
Epoch 95 / 300, learning rate: 7.8125e-06
Epoch 95 / 300, train loss: 0.40344491600990295
Epoch 95 / 300, val loss: 6.824045181274414
Epoch 95 / 300, val acc: 0.5195822454308094
Epoch 96 / 300, learning rate: 7.8125e-06
Epoch 96 / 300, train loss: 0.4041687846183777
Epoch 96 / 300, val loss: 6.824152946472168
Epoch 96 / 300, val acc: 0.5169712793733682
Epoch 97 / 300, learning rate: 7.8125e-06
Epoch 97 / 300, train loss: 0.4012465178966522
Epoch 97 / 300, val loss: 6.824271202087402
Epoch 97 / 300, val acc: 0.5143603133159269
Epoch 98 / 300, learning rate: 3.90625e-06
Epoch 98 / 300, train loss: 0.4024837613105774
Epoch 98 / 300, val loss: 6.824409484863281
Epoch 98 / 300, val acc: 0.5143603133159269
Epoch 99 / 300, learning rate: 3.90625e-06
Epoch 99 / 300, train loss: 0.401872456073761
Epoch 99 / 300, val loss: 6.824483394622803
Epoch 99 / 300, val acc: 0.5143603133159269
Epoch 100 / 300, learning rate: 3.90625e-06
Epoch 100 / 300, train loss: 0.40297070145606995
Epoch 100 / 300, val loss: 6.824535369873047
Epoch 100 / 300, val acc: 0.5143603133159269
Epoch 101 / 300, learning rate: 3.90625e-06
Epoch 101 / 300, train loss: 0.40266987681388855
Epoch 101 / 300, val loss: 6.8245768547058105
Epoch 101 / 300, val acc: 0.5143603133159269
Epoch 102 / 300, learning rate: 3.90625e-06
Epoch 102 / 300, train loss: 0.40431320667266846
Epoch 102 / 300, val loss: 6.824614524841309
Epoch 102 / 300, val acc: 0.5091383812010444
Epoch 103 / 300, learning rate: 3.90625e-06
Epoch 103 / 300, train loss: 0.40489208698272705
Epoch 103 / 300, val loss: 6.824652671813965
Epoch 103 / 300, val acc: 0.5143603133159269
Epoch 104 / 300, learning rate: 3.90625e-06
Epoch 104 / 300, train loss: 0.4045598804950714
Epoch 104 / 300, val loss: 6.824681758880615
Epoch 104 / 300, val acc: 0.5117493472584856
Epoch 105 / 300, learning rate: 3.90625e-06
Epoch 105 / 300, train loss: 0.4024391174316406
Epoch 105 / 300, val loss: 6.824716567993164
Epoch 105 / 300, val acc: 0.5143603133159269
Epoch 106 / 300, learning rate: 3.90625e-06
Epoch 106 / 300, train loss: 0.4032289683818817
Epoch 106 / 300, val loss: 6.824761867523193
Epoch 106 / 300, val acc: 0.5143603133159269
Epoch 107 / 300, learning rate: 3.90625e-06
Epoch 107 / 300, train loss: 0.40555939078330994
Epoch 107 / 300, val loss: 6.824802398681641
Epoch 107 / 300, val acc: 0.5169712793733682
Epoch 108 / 300, learning rate: 3.90625e-06
Epoch 108 / 300, train loss: 0.4043625295162201
Epoch 108 / 300, val loss: 6.824835777282715
Epoch 108 / 300, val acc: 0.5169712793733682
Epoch 109 / 300, learning rate: 1.953125e-06
Epoch 109 / 300, train loss: 0.4008304476737976
Epoch 109 / 300, val loss: 6.824863433837891
Epoch 109 / 300, val acc: 0.5143603133159269
Epoch 110 / 300, learning rate: 1.953125e-06
Epoch 110 / 300, train loss: 0.40160059928894043
Epoch 110 / 300, val loss: 6.8248701095581055
Epoch 110 / 300, val acc: 0.5117493472584856
Epoch 111 / 300, learning rate: 1.953125e-06
Epoch 111 / 300, train loss: 0.40221694111824036
Epoch 111 / 300, val loss: 6.824885368347168
Epoch 111 / 300, val acc: 0.5143603133159269
Epoch 112 / 300, learning rate: 1.953125e-06
Epoch 112 / 300, train loss: 0.40400901436805725
Epoch 112 / 300, val loss: 6.824891567230225
Epoch 112 / 300, val acc: 0.5117493472584856
Epoch 113 / 300, learning rate: 1.953125e-06
Epoch 113 / 300, train loss: 0.40418967604637146
Epoch 113 / 300, val loss: 6.824898719787598
Epoch 113 / 300, val acc: 0.5143603133159269
Epoch 114 / 300, learning rate: 1.953125e-06
Epoch 114 / 300, train loss: 0.4022389054298401
Epoch 114 / 300, val loss: 6.8249030113220215
Epoch 114 / 300, val acc: 0.5117493472584856
Epoch 115 / 300, learning rate: 1.953125e-06
Epoch 115 / 300, train loss: 0.4026622772216797
Epoch 115 / 300, val loss: 6.82490348815918
Epoch 115 / 300, val acc: 0.5117493472584856
Epoch 116 / 300, learning rate: 1.953125e-06
Epoch 116 / 300, train loss: 0.40351811051368713
Epoch 116 / 300, val loss: 6.824907302856445
Epoch 116 / 300, val acc: 0.5117493472584856
Epoch 117 / 300, learning rate: 1.953125e-06
Epoch 117 / 300, train loss: 0.4021010994911194
Epoch 117 / 300, val loss: 6.824918270111084
Epoch 117 / 300, val acc: 0.5117493472584856
Epoch 118 / 300, learning rate: 1.953125e-06
Epoch 118 / 300, train loss: 0.40343043208122253
Epoch 118 / 300, val loss: 6.8249335289001465
Epoch 118 / 300, val acc: 0.5091383812010444
Epoch 119 / 300, learning rate: 1.953125e-06
Epoch 119 / 300, train loss: 0.4027327299118042
Epoch 119 / 300, val loss: 6.824946403503418
Epoch 119 / 300, val acc: 0.5091383812010444
Epoch 120 / 300, learning rate: 9.765625e-07
Epoch 120 / 300, train loss: 0.40235161781311035
Epoch 120 / 300, val loss: 6.824952602386475
Epoch 120 / 300, val acc: 0.5091383812010444
Epoch 121 / 300, learning rate: 9.765625e-07
Epoch 121 / 300, train loss: 0.40119385719299316
Epoch 121 / 300, val loss: 6.82495641708374
Epoch 121 / 300, val acc: 0.5117493472584856
Epoch 122 / 300, learning rate: 9.765625e-07
Epoch 122 / 300, train loss: 0.3999461829662323
Epoch 122 / 300, val loss: 6.8249616622924805
Epoch 122 / 300, val acc: 0.5091383812010444
Epoch 123 / 300, learning rate: 9.765625e-07
Epoch 123 / 300, train loss: 0.4030715227127075
Epoch 123 / 300, val loss: 6.824965476989746
Epoch 123 / 300, val acc: 0.5091383812010444
Epoch 124 / 300, learning rate: 9.765625e-07
Epoch 124 / 300, train loss: 0.40122735500335693
Epoch 124 / 300, val loss: 6.824970245361328
Epoch 124 / 300, val acc: 0.5091383812010444
Epoch 125 / 300, learning rate: 9.765625e-07
Epoch 125 / 300, train loss: 0.40276938676834106
Epoch 125 / 300, val loss: 6.824976921081543
Epoch 125 / 300, val acc: 0.5091383812010444
Epoch 126 / 300, learning rate: 9.765625e-07
Epoch 126 / 300, train loss: 0.39966556429862976
Epoch 126 / 300, val loss: 6.824989318847656
Epoch 126 / 300, val acc: 0.5117493472584856
Epoch 127 / 300, learning rate: 9.765625e-07
Epoch 127 / 300, train loss: 0.4040287435054779
Epoch 127 / 300, val loss: 6.8249969482421875
Epoch 127 / 300, val acc: 0.5117493472584856
Epoch 128 / 300, learning rate: 9.765625e-07
Epoch 128 / 300, train loss: 0.4039333760738373
Epoch 128 / 300, val loss: 6.825007438659668
Epoch 128 / 300, val acc: 0.5143603133159269
Epoch 129 / 300, learning rate: 9.765625e-07
Epoch 129 / 300, train loss: 0.40283092856407166
Epoch 129 / 300, val loss: 6.82501745223999
Epoch 129 / 300, val acc: 0.5143603133159269
Epoch 130 / 300, learning rate: 9.765625e-07
Epoch 130 / 300, train loss: 0.4025775194168091
Epoch 130 / 300, val loss: 6.825029373168945
Epoch 130 / 300, val acc: 0.5143603133159269
Epoch 131 / 300, learning rate: 4.8828125e-07
Epoch 131 / 300, train loss: 0.4014025032520294
Epoch 131 / 300, val loss: 6.825038909912109
Epoch 131 / 300, val acc: 0.5169712793733682
Epoch 132 / 300, learning rate: 4.8828125e-07
Epoch 132 / 300, train loss: 0.4033069312572479
Epoch 132 / 300, val loss: 6.825042724609375
Epoch 132 / 300, val acc: 0.5143603133159269
Epoch 133 / 300, learning rate: 4.8828125e-07
Epoch 133 / 300, train loss: 0.40221458673477173
Epoch 133 / 300, val loss: 6.825048446655273
Epoch 133 / 300, val acc: 0.5143603133159269
Epoch 134 / 300, learning rate: 4.8828125e-07
Epoch 134 / 300, train loss: 0.4028863310813904
Epoch 134 / 300, val loss: 6.8250555992126465
Epoch 134 / 300, val acc: 0.5143603133159269
Epoch 135 / 300, learning rate: 4.8828125e-07
Epoch 135 / 300, train loss: 0.40252262353897095
Epoch 135 / 300, val loss: 6.8250627517700195
Epoch 135 / 300, val acc: 0.5169712793733682
Epoch 136 / 300, learning rate: 4.8828125e-07
Epoch 136 / 300, train loss: 0.4034191071987152
Epoch 136 / 300, val loss: 6.825069427490234
Epoch 136 / 300, val acc: 0.5169712793733682
Epoch 137 / 300, learning rate: 4.8828125e-07
Epoch 137 / 300, train loss: 0.4034810960292816
Epoch 137 / 300, val loss: 6.825080871582031
Epoch 137 / 300, val acc: 0.5117493472584856
Epoch 138 / 300, learning rate: 4.8828125e-07
Epoch 138 / 300, train loss: 0.403658390045166
Epoch 138 / 300, val loss: 6.825092315673828
Epoch 138 / 300, val acc: 0.5143603133159269
Epoch 139 / 300, learning rate: 4.8828125e-07
Epoch 139 / 300, train loss: 0.4039044678211212
Epoch 139 / 300, val loss: 6.8251051902771
Epoch 139 / 300, val acc: 0.5143603133159269
Epoch 140 / 300, learning rate: 4.8828125e-07
Epoch 140 / 300, train loss: 0.4026913642883301
Epoch 140 / 300, val loss: 6.825115203857422
Epoch 140 / 300, val acc: 0.5169712793733682
Epoch 141 / 300, learning rate: 4.8828125e-07
Epoch 141 / 300, train loss: 0.4015466868877411
Epoch 141 / 300, val loss: 6.825127601623535
Epoch 141 / 300, val acc: 0.5143603133159269
Epoch 142 / 300, learning rate: 2.44140625e-07
Epoch 142 / 300, train loss: 0.4047299921512604
Epoch 142 / 300, val loss: 6.82513952255249
Epoch 142 / 300, val acc: 0.5143603133159269
Epoch 143 / 300, learning rate: 2.44140625e-07
Epoch 143 / 300, train loss: 0.40241873264312744
Epoch 143 / 300, val loss: 6.8251447677612305
Epoch 143 / 300, val acc: 0.5143603133159269
Epoch 144 / 300, learning rate: 2.44140625e-07
Epoch 144 / 300, train loss: 0.4008030295372009
Epoch 144 / 300, val loss: 6.825151443481445
Epoch 144 / 300, val acc: 0.5117493472584856
Epoch 145 / 300, learning rate: 2.44140625e-07
Epoch 145 / 300, train loss: 0.40358874201774597
Epoch 145 / 300, val loss: 6.825157165527344
Epoch 145 / 300, val acc: 0.5117493472584856
Epoch 146 / 300, learning rate: 2.44140625e-07
Epoch 146 / 300, train loss: 0.4035668671131134
Epoch 146 / 300, val loss: 6.825164318084717
Epoch 146 / 300, val acc: 0.5143603133159269
Epoch 147 / 300, learning rate: 2.44140625e-07
Epoch 147 / 300, train loss: 0.40176263451576233
Epoch 147 / 300, val loss: 6.825172424316406
Epoch 147 / 300, val acc: 0.5143603133159269
Epoch 148 / 300, learning rate: 2.44140625e-07
Epoch 148 / 300, train loss: 0.4021334648132324
Epoch 148 / 300, val loss: 6.8251800537109375
Epoch 148 / 300, val acc: 0.5091383812010444
Epoch 149 / 300, learning rate: 2.44140625e-07
Epoch 149 / 300, train loss: 0.40113481879234314
Epoch 149 / 300, val loss: 6.825187683105469
Epoch 149 / 300, val acc: 0.5117493472584856
Epoch 150 / 300, learning rate: 2.44140625e-07
Epoch 150 / 300, train loss: 0.40076056122779846
Epoch 150 / 300, val loss: 6.825196743011475
Epoch 150 / 300, val acc: 0.5117493472584856
Epoch 151 / 300, learning rate: 2.44140625e-07
Epoch 151 / 300, train loss: 0.40136340260505676
Epoch 151 / 300, val loss: 6.825204372406006
Epoch 151 / 300, val acc: 0.5091383812010444
Epoch 152 / 300, learning rate: 2.44140625e-07
Epoch 152 / 300, train loss: 0.4056144654750824
Epoch 152 / 300, val loss: 6.825213432312012
Epoch 152 / 300, val acc: 0.5091383812010444
Epoch 153 / 300, learning rate: 1.220703125e-07
Epoch 153 / 300, train loss: 0.40255963802337646
Epoch 153 / 300, val loss: 6.825220108032227
Epoch 153 / 300, val acc: 0.5065274151436031
Epoch 154 / 300, learning rate: 1.220703125e-07
Epoch 154 / 300, train loss: 0.4040713310241699
Epoch 154 / 300, val loss: 6.825223922729492
Epoch 154 / 300, val acc: 0.5091383812010444
Epoch 155 / 300, learning rate: 1.220703125e-07
Epoch 155 / 300, train loss: 0.4025254547595978
Epoch 155 / 300, val loss: 6.8252272605896
Epoch 155 / 300, val acc: 0.5091383812010444
Epoch 156 / 300, learning rate: 1.220703125e-07
Epoch 156 / 300, train loss: 0.40048661828041077
Epoch 156 / 300, val loss: 6.825231075286865
Epoch 156 / 300, val acc: 0.5117493472584856
Epoch 157 / 300, learning rate: 1.220703125e-07
Epoch 157 / 300, train loss: 0.40418320894241333
Epoch 157 / 300, val loss: 6.825234413146973
Epoch 157 / 300, val acc: 0.5065274151436031
Epoch 158 / 300, learning rate: 1.220703125e-07
Epoch 158 / 300, train loss: 0.4007679224014282
Epoch 158 / 300, val loss: 6.825237274169922
Epoch 158 / 300, val acc: 0.5091383812010444
Epoch 159 / 300, learning rate: 1.220703125e-07
Epoch 159 / 300, train loss: 0.4047987759113312
Epoch 159 / 300, val loss: 6.8252410888671875
Epoch 159 / 300, val acc: 0.5065274151436031
Epoch 160 / 300, learning rate: 1.220703125e-07
Epoch 160 / 300, train loss: 0.4045405685901642
Epoch 160 / 300, val loss: 6.825243949890137
Epoch 160 / 300, val acc: 0.5091383812010444
Epoch 161 / 300, learning rate: 1.220703125e-07
Epoch 161 / 300, train loss: 0.4026559591293335
Epoch 161 / 300, val loss: 6.825244903564453
Epoch 161 / 300, val acc: 0.5065274151436031
Epoch 162 / 300, learning rate: 1.220703125e-07
Epoch 162 / 300, train loss: 0.40259841084480286
Epoch 162 / 300, val loss: 6.825246334075928
Epoch 162 / 300, val acc: 0.5091383812010444
Epoch 163 / 300, learning rate: 1.220703125e-07
Epoch 163 / 300, train loss: 0.40468862652778625
Epoch 163 / 300, val loss: 6.825247764587402
Epoch 163 / 300, val acc: 0.5065274151436031
Epoch 164 / 300, learning rate: 6.103515625e-08
Epoch 164 / 300, train loss: 0.40410861372947693
Epoch 164 / 300, val loss: 6.8252482414245605
Epoch 164 / 300, val acc: 0.5091383812010444
Epoch 165 / 300, learning rate: 6.103515625e-08
Epoch 165 / 300, train loss: 0.4009263515472412
Epoch 165 / 300, val loss: 6.825248718261719
Epoch 165 / 300, val acc: 0.5091383812010444
Epoch 166 / 300, learning rate: 6.103515625e-08
Epoch 166 / 300, train loss: 0.4017712473869324
Epoch 166 / 300, val loss: 6.825250148773193
Epoch 166 / 300, val acc: 0.5091383812010444
Epoch 167 / 300, learning rate: 6.103515625e-08
Epoch 167 / 300, train loss: 0.4010516405105591
Epoch 167 / 300, val loss: 6.825250625610352
Epoch 167 / 300, val acc: 0.5091383812010444
Epoch 168 / 300, learning rate: 6.103515625e-08
Epoch 168 / 300, train loss: 0.4025699198246002
Epoch 168 / 300, val loss: 6.825252056121826
Epoch 168 / 300, val acc: 0.5091383812010444
Epoch 169 / 300, learning rate: 6.103515625e-08
Epoch 169 / 300, train loss: 0.40516865253448486
Epoch 169 / 300, val loss: 6.825252532958984
Epoch 169 / 300, val acc: 0.5091383812010444
Epoch 170 / 300, learning rate: 6.103515625e-08
Epoch 170 / 300, train loss: 0.40085992217063904
Epoch 170 / 300, val loss: 6.825253963470459
Epoch 170 / 300, val acc: 0.5117493472584856
Epoch 171 / 300, learning rate: 6.103515625e-08
Epoch 171 / 300, train loss: 0.4035097658634186
Epoch 171 / 300, val loss: 6.825253963470459
Epoch 171 / 300, val acc: 0.5091383812010444
Epoch 172 / 300, learning rate: 6.103515625e-08
Epoch 172 / 300, train loss: 0.4045020639896393
Epoch 172 / 300, val loss: 6.825255393981934
Epoch 172 / 300, val acc: 0.5091383812010444
Epoch 173 / 300, learning rate: 6.103515625e-08
Epoch 173 / 300, train loss: 0.4027981758117676
Epoch 173 / 300, val loss: 6.825255393981934
Epoch 173 / 300, val acc: 0.5065274151436031
Epoch 174 / 300, learning rate: 6.103515625e-08
Epoch 174 / 300, train loss: 0.40442386269569397
Epoch 174 / 300, val loss: 6.82525634765625
Epoch 174 / 300, val acc: 0.5091383812010444
Epoch 175 / 300, learning rate: 3.0517578125e-08
Epoch 175 / 300, train loss: 0.40267959237098694
Epoch 175 / 300, val loss: 6.82525634765625
Epoch 175 / 300, val acc: 0.5065274151436031
Epoch 176 / 300, learning rate: 3.0517578125e-08
Epoch 176 / 300, train loss: 0.40351706743240356
Epoch 176 / 300, val loss: 6.825257778167725
Epoch 176 / 300, val acc: 0.5091383812010444
Epoch 177 / 300, learning rate: 3.0517578125e-08
Epoch 177 / 300, train loss: 0.40394309163093567
Epoch 177 / 300, val loss: 6.825257778167725
Epoch 177 / 300, val acc: 0.5091383812010444
Epoch 178 / 300, learning rate: 3.0517578125e-08
Epoch 178 / 300, train loss: 0.40256020426750183
Epoch 178 / 300, val loss: 6.825257778167725
Epoch 178 / 300, val acc: 0.5065274151436031
Epoch 179 / 300, learning rate: 3.0517578125e-08
Epoch 179 / 300, train loss: 0.4022766351699829
Epoch 179 / 300, val loss: 6.825257778167725
Epoch 179 / 300, val acc: 0.5091383812010444
Epoch 180 / 300, learning rate: 3.0517578125e-08
Epoch 180 / 300, train loss: 0.3994958996772766
Epoch 180 / 300, val loss: 6.825258255004883
Epoch 180 / 300, val acc: 0.5065274151436031
Epoch 181 / 300, learning rate: 3.0517578125e-08
Epoch 181 / 300, train loss: 0.40314340591430664
Epoch 181 / 300, val loss: 6.825259208679199
Epoch 181 / 300, val acc: 0.5065274151436031
Epoch 182 / 300, learning rate: 3.0517578125e-08
Epoch 182 / 300, train loss: 0.4015083909034729
Epoch 182 / 300, val loss: 6.825259208679199
Epoch 182 / 300, val acc: 0.5091383812010444
Epoch 183 / 300, learning rate: 3.0517578125e-08
Epoch 183 / 300, train loss: 0.40245521068573
Epoch 183 / 300, val loss: 6.825259208679199
Epoch 183 / 300, val acc: 0.5091383812010444
Epoch 184 / 300, learning rate: 3.0517578125e-08
Epoch 184 / 300, train loss: 0.400234192609787
Epoch 184 / 300, val loss: 6.825259208679199
Epoch 184 / 300, val acc: 0.5065274151436031
Epoch 185 / 300, learning rate: 3.0517578125e-08
Epoch 185 / 300, train loss: 0.4014934003353119
Epoch 185 / 300, val loss: 6.825260162353516
Epoch 185 / 300, val acc: 0.5065274151436031
Epoch 186 / 300, learning rate: 1.52587890625e-08
Epoch 186 / 300, train loss: 0.4036271870136261
Epoch 186 / 300, val loss: 6.825260162353516
Epoch 186 / 300, val acc: 0.5091383812010444
Epoch 187 / 300, learning rate: 1.52587890625e-08
Epoch 187 / 300, train loss: 0.403165340423584
Epoch 187 / 300, val loss: 6.825260162353516
Epoch 187 / 300, val acc: 0.5091383812010444
Epoch 188 / 300, learning rate: 1.52587890625e-08
Epoch 188 / 300, train loss: 0.40284964442253113
Epoch 188 / 300, val loss: 6.825260162353516
Epoch 188 / 300, val acc: 0.5091383812010444
Epoch 189 / 300, learning rate: 1.52587890625e-08
Epoch 189 / 300, train loss: 0.40193983912467957
Epoch 189 / 300, val loss: 6.825260162353516
Epoch 189 / 300, val acc: 0.5065274151436031
Epoch 190 / 300, learning rate: 1.52587890625e-08
Epoch 190 / 300, train loss: 0.40323710441589355
Epoch 190 / 300, val loss: 6.825260162353516
Epoch 190 / 300, val acc: 0.5065274151436031
Epoch 191 / 300, learning rate: 1.52587890625e-08
Epoch 191 / 300, train loss: 0.4048202931880951
Epoch 191 / 300, val loss: 6.825260162353516
Epoch 191 / 300, val acc: 0.5091383812010444
Epoch 192 / 300, learning rate: 1.52587890625e-08
Epoch 192 / 300, train loss: 0.4033021032810211
Epoch 192 / 300, val loss: 6.825260162353516
Epoch 192 / 300, val acc: 0.5091383812010444
Epoch 193 / 300, learning rate: 1.52587890625e-08
Epoch 193 / 300, train loss: 0.4038417935371399
Epoch 193 / 300, val loss: 6.825261116027832
Epoch 193 / 300, val acc: 0.5065274151436031
Epoch 194 / 300, learning rate: 1.52587890625e-08
Epoch 194 / 300, train loss: 0.40303415060043335
Epoch 194 / 300, val loss: 6.825261116027832
Epoch 194 / 300, val acc: 0.5065274151436031
Epoch 195 / 300, learning rate: 1.52587890625e-08
Epoch 195 / 300, train loss: 0.4026767313480377
Epoch 195 / 300, val loss: 6.82526159286499
Epoch 195 / 300, val acc: 0.5091383812010444
Epoch 196 / 300, learning rate: 1.52587890625e-08
Epoch 196 / 300, train loss: 0.40371420979499817
Epoch 196 / 300, val loss: 6.82526159286499
Epoch 196 / 300, val acc: 0.5091383812010444
Epoch 197 / 300, learning rate: 1.52587890625e-08
Epoch 197 / 300, train loss: 0.40520066022872925
Epoch 197 / 300, val loss: 6.82526159286499
Epoch 197 / 300, val acc: 0.5091383812010444
Epoch 198 / 300, learning rate: 1.52587890625e-08
Epoch 198 / 300, train loss: 0.40381383895874023
Epoch 198 / 300, val loss: 6.82526159286499
Epoch 198 / 300, val acc: 0.5091383812010444
Epoch 199 / 300, learning rate: 1.52587890625e-08
Epoch 199 / 300, train loss: 0.40155747532844543
Epoch 199 / 300, val loss: 6.82526159286499
Epoch 199 / 300, val acc: 0.5065274151436031
Epoch 200 / 300, learning rate: 1.52587890625e-08
Epoch 200 / 300, train loss: 0.4044833183288574
Epoch 200 / 300, val loss: 6.82526159286499
Epoch 200 / 300, val acc: 0.5065274151436031
Epoch 201 / 300, learning rate: 1.52587890625e-08
Epoch 201 / 300, train loss: 0.40404802560806274
Epoch 201 / 300, val loss: 6.82526159286499
Epoch 201 / 300, val acc: 0.5065274151436031
Epoch 202 / 300, learning rate: 1.52587890625e-08
Epoch 202 / 300, train loss: 0.4043416976928711
Epoch 202 / 300, val loss: 6.82526159286499
Epoch 202 / 300, val acc: 0.5091383812010444
Epoch 203 / 300, learning rate: 1.52587890625e-08
Epoch 203 / 300, train loss: 0.4036271870136261
Epoch 203 / 300, val loss: 6.82526159286499
Epoch 203 / 300, val acc: 0.5091383812010444
Epoch 204 / 300, learning rate: 1.52587890625e-08
Epoch 204 / 300, train loss: 0.40269735455513
Epoch 204 / 300, val loss: 6.82526159286499
Epoch 204 / 300, val acc: 0.5065274151436031
Epoch 205 / 300, learning rate: 1.52587890625e-08
Epoch 205 / 300, train loss: 0.4024559557437897
Epoch 205 / 300, val loss: 6.82526159286499
Epoch 205 / 300, val acc: 0.5065274151436031
Epoch 206 / 300, learning rate: 1.52587890625e-08
Epoch 206 / 300, train loss: 0.40400251746177673
Epoch 206 / 300, val loss: 6.82526159286499
Epoch 206 / 300, val acc: 0.5065274151436031
Epoch 207 / 300, learning rate: 1.52587890625e-08
Epoch 207 / 300, train loss: 0.4029744267463684
Epoch 207 / 300, val loss: 6.82526159286499
Epoch 207 / 300, val acc: 0.5091383812010444
Epoch 208 / 300, learning rate: 1.52587890625e-08
Epoch 208 / 300, train loss: 0.4011061191558838
Epoch 208 / 300, val loss: 6.82526159286499
Epoch 208 / 300, val acc: 0.5091383812010444
Epoch 209 / 300, learning rate: 1.52587890625e-08
Epoch 209 / 300, train loss: 0.40398234128952026
Epoch 209 / 300, val loss: 6.82526159286499
Epoch 209 / 300, val acc: 0.5065274151436031
Epoch 210 / 300, learning rate: 1.52587890625e-08
Epoch 210 / 300, train loss: 0.40211042761802673
Epoch 210 / 300, val loss: 6.82526159286499
Epoch 210 / 300, val acc: 0.5091383812010444
Epoch 211 / 300, learning rate: 1.52587890625e-08
Epoch 211 / 300, train loss: 0.4045478403568268
Epoch 211 / 300, val loss: 6.825262069702148
Epoch 211 / 300, val acc: 0.5091383812010444
Epoch 212 / 300, learning rate: 1.52587890625e-08
Epoch 212 / 300, train loss: 0.4036209285259247
Epoch 212 / 300, val loss: 6.825263023376465
Epoch 212 / 300, val acc: 0.5091383812010444
Epoch 213 / 300, learning rate: 1.52587890625e-08
Epoch 213 / 300, train loss: 0.40535980463027954
Epoch 213 / 300, val loss: 6.825263023376465
Epoch 213 / 300, val acc: 0.5091383812010444
Epoch 214 / 300, learning rate: 1.52587890625e-08
Epoch 214 / 300, train loss: 0.4026358425617218
Epoch 214 / 300, val loss: 6.825263023376465
Epoch 214 / 300, val acc: 0.5091383812010444
Epoch 215 / 300, learning rate: 1.52587890625e-08
Epoch 215 / 300, train loss: 0.4042038321495056
Epoch 215 / 300, val loss: 6.825263023376465
Epoch 215 / 300, val acc: 0.5065274151436031
Epoch 216 / 300, learning rate: 1.52587890625e-08
Epoch 216 / 300, train loss: 0.4047975540161133
Epoch 216 / 300, val loss: 6.825263023376465
Epoch 216 / 300, val acc: 0.5091383812010444
Epoch 217 / 300, learning rate: 1.52587890625e-08
Epoch 217 / 300, train loss: 0.4040943384170532
Epoch 217 / 300, val loss: 6.825263023376465
Epoch 217 / 300, val acc: 0.5091383812010444
Epoch 218 / 300, learning rate: 1.52587890625e-08
Epoch 218 / 300, train loss: 0.40377548336982727
Epoch 218 / 300, val loss: 6.825263023376465
Epoch 218 / 300, val acc: 0.5091383812010444
Epoch 219 / 300, learning rate: 1.52587890625e-08
Epoch 219 / 300, train loss: 0.4020674526691437
Epoch 219 / 300, val loss: 6.825263023376465
Epoch 219 / 300, val acc: 0.5091383812010444
Epoch 220 / 300, learning rate: 1.52587890625e-08
Epoch 220 / 300, train loss: 0.4013769328594208
Epoch 220 / 300, val loss: 6.825263023376465
Epoch 220 / 300, val acc: 0.5091383812010444
Epoch 221 / 300, learning rate: 1.52587890625e-08
Epoch 221 / 300, train loss: 0.4032372236251831
Epoch 221 / 300, val loss: 6.825263023376465
Epoch 221 / 300, val acc: 0.5039164490861618
Epoch 222 / 300, learning rate: 1.52587890625e-08
Epoch 222 / 300, train loss: 0.4033041298389435
Epoch 222 / 300, val loss: 6.825263023376465
Epoch 222 / 300, val acc: 0.5117493472584856
Epoch 223 / 300, learning rate: 1.52587890625e-08
Epoch 223 / 300, train loss: 0.40465760231018066
Epoch 223 / 300, val loss: 6.825263023376465
Epoch 223 / 300, val acc: 0.5065274151436031
Epoch 224 / 300, learning rate: 1.52587890625e-08
Epoch 224 / 300, train loss: 0.4014756679534912
Epoch 224 / 300, val loss: 6.825263500213623
Epoch 224 / 300, val acc: 0.5091383812010444
Epoch 225 / 300, learning rate: 1.52587890625e-08
Epoch 225 / 300, train loss: 0.40395933389663696
Epoch 225 / 300, val loss: 6.825263500213623
Epoch 225 / 300, val acc: 0.5091383812010444
Epoch 226 / 300, learning rate: 1.52587890625e-08
Epoch 226 / 300, train loss: 0.4031854271888733
Epoch 226 / 300, val loss: 6.825263977050781
Epoch 226 / 300, val acc: 0.5091383812010444
Epoch 227 / 300, learning rate: 1.52587890625e-08
Epoch 227 / 300, train loss: 0.4013989269733429
Epoch 227 / 300, val loss: 6.825263977050781
Epoch 227 / 300, val acc: 0.5091383812010444
Epoch 228 / 300, learning rate: 1.52587890625e-08
Epoch 228 / 300, train loss: 0.4037030041217804
Epoch 228 / 300, val loss: 6.825263977050781
Epoch 228 / 300, val acc: 0.5091383812010444
Epoch 229 / 300, learning rate: 1.52587890625e-08
Epoch 229 / 300, train loss: 0.4036555886268616
Epoch 229 / 300, val loss: 6.825263977050781
Epoch 229 / 300, val acc: 0.5091383812010444
Epoch 230 / 300, learning rate: 1.52587890625e-08
Epoch 230 / 300, train loss: 0.40274569392204285
Epoch 230 / 300, val loss: 6.825263977050781
Epoch 230 / 300, val acc: 0.5091383812010444
Epoch 231 / 300, learning rate: 1.52587890625e-08
Epoch 231 / 300, train loss: 0.40287110209465027
Epoch 231 / 300, val loss: 6.825263977050781
Epoch 231 / 300, val acc: 0.5091383812010444
Epoch 232 / 300, learning rate: 1.52587890625e-08
Epoch 232 / 300, train loss: 0.40183550119400024
Epoch 232 / 300, val loss: 6.825265407562256
Epoch 232 / 300, val acc: 0.5091383812010444
Epoch 233 / 300, learning rate: 1.52587890625e-08
Epoch 233 / 300, train loss: 0.40262436866760254
Epoch 233 / 300, val loss: 6.825265407562256
Epoch 233 / 300, val acc: 0.5091383812010444
Epoch 234 / 300, learning rate: 1.52587890625e-08
Epoch 234 / 300, train loss: 0.40291303396224976
Epoch 234 / 300, val loss: 6.825265407562256
Epoch 234 / 300, val acc: 0.5091383812010444
Epoch 235 / 300, learning rate: 1.52587890625e-08
Epoch 235 / 300, train loss: 0.40427735447883606
Epoch 235 / 300, val loss: 6.825265407562256
Epoch 235 / 300, val acc: 0.5065274151436031
Epoch 236 / 300, learning rate: 1.52587890625e-08
Epoch 236 / 300, train loss: 0.4013065695762634
Epoch 236 / 300, val loss: 6.825265407562256
Epoch 236 / 300, val acc: 0.5091383812010444
Epoch 237 / 300, learning rate: 1.52587890625e-08
Epoch 237 / 300, train loss: 0.4036848843097687
Epoch 237 / 300, val loss: 6.825265407562256
Epoch 237 / 300, val acc: 0.5091383812010444
Epoch 238 / 300, learning rate: 1.52587890625e-08
Epoch 238 / 300, train loss: 0.40233826637268066
Epoch 238 / 300, val loss: 6.825265884399414
Epoch 238 / 300, val acc: 0.5091383812010444
Epoch 239 / 300, learning rate: 1.52587890625e-08
Epoch 239 / 300, train loss: 0.40441757440567017
Epoch 239 / 300, val loss: 6.8252668380737305
Epoch 239 / 300, val acc: 0.5091383812010444
Epoch 240 / 300, learning rate: 1.52587890625e-08
Epoch 240 / 300, train loss: 0.40352174639701843
Epoch 240 / 300, val loss: 6.8252668380737305
Epoch 240 / 300, val acc: 0.5091383812010444
Epoch 241 / 300, learning rate: 1.52587890625e-08
Epoch 241 / 300, train loss: 0.4013791084289551
Epoch 241 / 300, val loss: 6.8252668380737305
Epoch 241 / 300, val acc: 0.5091383812010444
Epoch 242 / 300, learning rate: 1.52587890625e-08
Epoch 242 / 300, train loss: 0.40386635065078735
Epoch 242 / 300, val loss: 6.8252668380737305
Epoch 242 / 300, val acc: 0.5091383812010444
Epoch 243 / 300, learning rate: 1.52587890625e-08
Epoch 243 / 300, train loss: 0.4035504162311554
Epoch 243 / 300, val loss: 6.8252668380737305
Epoch 243 / 300, val acc: 0.5091383812010444
Epoch 244 / 300, learning rate: 1.52587890625e-08
Epoch 244 / 300, train loss: 0.40398409962654114
Epoch 244 / 300, val loss: 6.825267314910889
Epoch 244 / 300, val acc: 0.5091383812010444
Epoch 245 / 300, learning rate: 1.52587890625e-08
Epoch 245 / 300, train loss: 0.404448002576828
Epoch 245 / 300, val loss: 6.825267314910889
Epoch 245 / 300, val acc: 0.5065274151436031
Epoch 246 / 300, learning rate: 1.52587890625e-08
Epoch 246 / 300, train loss: 0.4016026258468628
Epoch 246 / 300, val loss: 6.825267791748047
Epoch 246 / 300, val acc: 0.5117493472584856
Epoch 247 / 300, learning rate: 1.52587890625e-08
Epoch 247 / 300, train loss: 0.4025234580039978
Epoch 247 / 300, val loss: 6.825267791748047
Epoch 247 / 300, val acc: 0.5091383812010444
Epoch 248 / 300, learning rate: 1.52587890625e-08
Epoch 248 / 300, train loss: 0.4026845097541809
Epoch 248 / 300, val loss: 6.825267791748047
Epoch 248 / 300, val acc: 0.5091383812010444
Epoch 249 / 300, learning rate: 1.52587890625e-08
Epoch 249 / 300, train loss: 0.4060852825641632
Epoch 249 / 300, val loss: 6.825267791748047
Epoch 249 / 300, val acc: 0.5091383812010444
Epoch 250 / 300, learning rate: 1.52587890625e-08
Epoch 250 / 300, train loss: 0.4040238559246063
Epoch 250 / 300, val loss: 6.825267791748047
Epoch 250 / 300, val acc: 0.5091383812010444
Epoch 251 / 300, learning rate: 1.52587890625e-08
Epoch 251 / 300, train loss: 0.40203985571861267
Epoch 251 / 300, val loss: 6.825267791748047
Epoch 251 / 300, val acc: 0.5091383812010444
Epoch 252 / 300, learning rate: 1.52587890625e-08
Epoch 252 / 300, train loss: 0.4050317108631134
Epoch 252 / 300, val loss: 6.825267791748047
Epoch 252 / 300, val acc: 0.5091383812010444
Epoch 253 / 300, learning rate: 1.52587890625e-08
Epoch 253 / 300, train loss: 0.40384387969970703
Epoch 253 / 300, val loss: 6.825267791748047
Epoch 253 / 300, val acc: 0.5117493472584856
Epoch 254 / 300, learning rate: 1.52587890625e-08
Epoch 254 / 300, train loss: 0.40352171659469604
Epoch 254 / 300, val loss: 6.825267791748047
Epoch 254 / 300, val acc: 0.5091383812010444
Epoch 255 / 300, learning rate: 1.52587890625e-08
Epoch 255 / 300, train loss: 0.40079957246780396
Epoch 255 / 300, val loss: 6.825268745422363
Epoch 255 / 300, val acc: 0.5065274151436031
Epoch 256 / 300, learning rate: 1.52587890625e-08
Epoch 256 / 300, train loss: 0.4020402133464813
Epoch 256 / 300, val loss: 6.825267791748047
Epoch 256 / 300, val acc: 0.5091383812010444
Epoch 257 / 300, learning rate: 1.52587890625e-08
Epoch 257 / 300, train loss: 0.40227845311164856
Epoch 257 / 300, val loss: 6.825268745422363
Epoch 257 / 300, val acc: 0.5091383812010444
Epoch 258 / 300, learning rate: 1.52587890625e-08
Epoch 258 / 300, train loss: 0.4029662609100342
Epoch 258 / 300, val loss: 6.8252692222595215
Epoch 258 / 300, val acc: 0.5091383812010444
Epoch 259 / 300, learning rate: 1.52587890625e-08
Epoch 259 / 300, train loss: 0.403719425201416
Epoch 259 / 300, val loss: 6.825268745422363
Epoch 259 / 300, val acc: 0.5091383812010444
Epoch 260 / 300, learning rate: 1.52587890625e-08
Epoch 260 / 300, train loss: 0.404641330242157
Epoch 260 / 300, val loss: 6.8252692222595215
Epoch 260 / 300, val acc: 0.5091383812010444
Epoch 261 / 300, learning rate: 1.52587890625e-08
Epoch 261 / 300, train loss: 0.4027581512928009
Epoch 261 / 300, val loss: 6.8252692222595215
Epoch 261 / 300, val acc: 0.5091383812010444
Epoch 262 / 300, learning rate: 1.52587890625e-08
Epoch 262 / 300, train loss: 0.4042740762233734
Epoch 262 / 300, val loss: 6.8252692222595215
Epoch 262 / 300, val acc: 0.5091383812010444
Epoch 263 / 300, learning rate: 1.52587890625e-08
Epoch 263 / 300, train loss: 0.40608397126197815
Epoch 263 / 300, val loss: 6.825268745422363
Epoch 263 / 300, val acc: 0.5091383812010444
Epoch 264 / 300, learning rate: 1.52587890625e-08
Epoch 264 / 300, train loss: 0.4061073958873749
Epoch 264 / 300, val loss: 6.8252692222595215
Epoch 264 / 300, val acc: 0.5091383812010444
Epoch 265 / 300, learning rate: 1.52587890625e-08
Epoch 265 / 300, train loss: 0.4028984308242798
Epoch 265 / 300, val loss: 6.825268745422363
Epoch 265 / 300, val acc: 0.5065274151436031
Epoch 266 / 300, learning rate: 1.52587890625e-08
Epoch 266 / 300, train loss: 0.4013238847255707
Epoch 266 / 300, val loss: 6.825268745422363
Epoch 266 / 300, val acc: 0.5091383812010444
Epoch 267 / 300, learning rate: 1.52587890625e-08
Epoch 267 / 300, train loss: 0.4027155637741089
Epoch 267 / 300, val loss: 6.825268745422363
Epoch 267 / 300, val acc: 0.5091383812010444
Epoch 268 / 300, learning rate: 1.52587890625e-08
Epoch 268 / 300, train loss: 0.4056694507598877
Epoch 268 / 300, val loss: 6.8252692222595215
Epoch 268 / 300, val acc: 0.5091383812010444
Epoch 269 / 300, learning rate: 1.52587890625e-08
Epoch 269 / 300, train loss: 0.4045774042606354
Epoch 269 / 300, val loss: 6.825268745422363
Epoch 269 / 300, val acc: 0.5091383812010444
Epoch 270 / 300, learning rate: 1.52587890625e-08
Epoch 270 / 300, train loss: 0.4016555845737457
Epoch 270 / 300, val loss: 6.8252692222595215
Epoch 270 / 300, val acc: 0.5091383812010444
Epoch 271 / 300, learning rate: 1.52587890625e-08
Epoch 271 / 300, train loss: 0.4044252336025238
Epoch 271 / 300, val loss: 6.8252692222595215
Epoch 271 / 300, val acc: 0.5091383812010444
Epoch 272 / 300, learning rate: 1.52587890625e-08
Epoch 272 / 300, train loss: 0.4037996530532837
Epoch 272 / 300, val loss: 6.8252692222595215
Epoch 272 / 300, val acc: 0.5091383812010444
Epoch 273 / 300, learning rate: 1.52587890625e-08
Epoch 273 / 300, train loss: 0.40390557050704956
Epoch 273 / 300, val loss: 6.8252692222595215
Epoch 273 / 300, val acc: 0.5091383812010444
Epoch 274 / 300, learning rate: 1.52587890625e-08
Epoch 274 / 300, train loss: 0.40454429388046265
Epoch 274 / 300, val loss: 6.8252692222595215
Epoch 274 / 300, val acc: 0.5091383812010444
Epoch 275 / 300, learning rate: 1.52587890625e-08
Epoch 275 / 300, train loss: 0.40357446670532227
Epoch 275 / 300, val loss: 6.8252692222595215
Epoch 275 / 300, val acc: 0.5091383812010444
Epoch 276 / 300, learning rate: 1.52587890625e-08
Epoch 276 / 300, train loss: 0.40555453300476074
Epoch 276 / 300, val loss: 6.825268745422363
Epoch 276 / 300, val acc: 0.5091383812010444
Epoch 277 / 300, learning rate: 1.52587890625e-08
Epoch 277 / 300, train loss: 0.4039835035800934
Epoch 277 / 300, val loss: 6.825268745422363
Epoch 277 / 300, val acc: 0.5091383812010444
Epoch 278 / 300, learning rate: 1.52587890625e-08
Epoch 278 / 300, train loss: 0.40334799885749817
Epoch 278 / 300, val loss: 6.825267791748047
Epoch 278 / 300, val acc: 0.5065274151436031
Epoch 279 / 300, learning rate: 1.52587890625e-08
Epoch 279 / 300, train loss: 0.402870774269104
Epoch 279 / 300, val loss: 6.825267791748047
Epoch 279 / 300, val acc: 0.5091383812010444
Epoch 280 / 300, learning rate: 1.52587890625e-08
Epoch 280 / 300, train loss: 0.4035312831401825
Epoch 280 / 300, val loss: 6.825267791748047
Epoch 280 / 300, val acc: 0.5091383812010444
Epoch 281 / 300, learning rate: 1.52587890625e-08
Epoch 281 / 300, train loss: 0.40074893832206726
Epoch 281 / 300, val loss: 6.825267791748047
Epoch 281 / 300, val acc: 0.5091383812010444
Epoch 282 / 300, learning rate: 1.52587890625e-08
Epoch 282 / 300, train loss: 0.40300890803337097
Epoch 282 / 300, val loss: 6.825267791748047
Epoch 282 / 300, val acc: 0.5091383812010444
Epoch 283 / 300, learning rate: 1.52587890625e-08
Epoch 283 / 300, train loss: 0.4031607508659363
Epoch 283 / 300, val loss: 6.825267791748047
Epoch 283 / 300, val acc: 0.5065274151436031
Epoch 284 / 300, learning rate: 1.52587890625e-08
Epoch 284 / 300, train loss: 0.40352609753608704
Epoch 284 / 300, val loss: 6.825267791748047
Epoch 284 / 300, val acc: 0.5091383812010444
Epoch 285 / 300, learning rate: 1.52587890625e-08
Epoch 285 / 300, train loss: 0.40154004096984863
Epoch 285 / 300, val loss: 6.825267791748047
Epoch 285 / 300, val acc: 0.5091383812010444
Epoch 286 / 300, learning rate: 1.52587890625e-08
Epoch 286 / 300, train loss: 0.4029420018196106
Epoch 286 / 300, val loss: 6.825267791748047
Epoch 286 / 300, val acc: 0.5039164490861618
Epoch 287 / 300, learning rate: 1.52587890625e-08
Epoch 287 / 300, train loss: 0.4020898640155792
Epoch 287 / 300, val loss: 6.825267791748047
Epoch 287 / 300, val acc: 0.5091383812010444
Epoch 288 / 300, learning rate: 1.52587890625e-08
Epoch 288 / 300, train loss: 0.4034133553504944
Epoch 288 / 300, val loss: 6.825268745422363
Epoch 288 / 300, val acc: 0.5091383812010444
Epoch 289 / 300, learning rate: 1.52587890625e-08
Epoch 289 / 300, train loss: 0.40327247977256775
Epoch 289 / 300, val loss: 6.825268745422363
Epoch 289 / 300, val acc: 0.5091383812010444
Epoch 290 / 300, learning rate: 1.52587890625e-08
Epoch 290 / 300, train loss: 0.40094152092933655
Epoch 290 / 300, val loss: 6.825268745422363
Epoch 290 / 300, val acc: 0.5065274151436031
Epoch 291 / 300, learning rate: 1.52587890625e-08
Epoch 291 / 300, train loss: 0.4029310643672943
Epoch 291 / 300, val loss: 6.8252692222595215
Epoch 291 / 300, val acc: 0.5091383812010444
Epoch 292 / 300, learning rate: 1.52587890625e-08
Epoch 292 / 300, train loss: 0.40188080072402954
Epoch 292 / 300, val loss: 6.8252692222595215
Epoch 292 / 300, val acc: 0.5065274151436031
Epoch 293 / 300, learning rate: 1.52587890625e-08
Epoch 293 / 300, train loss: 0.40327349305152893
Epoch 293 / 300, val loss: 6.8252692222595215
Epoch 293 / 300, val acc: 0.5091383812010444
Epoch 294 / 300, learning rate: 1.52587890625e-08
Epoch 294 / 300, train loss: 0.402807354927063
Epoch 294 / 300, val loss: 6.8252692222595215
Epoch 294 / 300, val acc: 0.5091383812010444
Epoch 295 / 300, learning rate: 1.52587890625e-08
Epoch 295 / 300, train loss: 0.40476253628730774
Epoch 295 / 300, val loss: 6.8252692222595215
Epoch 295 / 300, val acc: 0.5091383812010444
Epoch 296 / 300, learning rate: 1.52587890625e-08
Epoch 296 / 300, train loss: 0.40274152159690857
Epoch 296 / 300, val loss: 6.8252692222595215
Epoch 296 / 300, val acc: 0.5065274151436031
Epoch 297 / 300, learning rate: 1.52587890625e-08
Epoch 297 / 300, train loss: 0.40522927045822144
Epoch 297 / 300, val loss: 6.8252692222595215
Epoch 297 / 300, val acc: 0.5065274151436031
Epoch 298 / 300, learning rate: 1.52587890625e-08
Epoch 298 / 300, train loss: 0.4021448493003845
Epoch 298 / 300, val loss: 6.8252692222595215
Epoch 298 / 300, val acc: 0.5091383812010444
Epoch 299 / 300, learning rate: 1.52587890625e-08
Epoch 299 / 300, train loss: 0.4037085175514221
Epoch 299 / 300, val loss: 6.8252692222595215
Epoch 299 / 300, val acc: 0.5091383812010444
Epoch 300 / 300, learning rate: 1.52587890625e-08
Epoch 300 / 300, train loss: 0.40346258878707886
Epoch 300 / 300, val loss: 6.8252692222595215
Epoch 300 / 300, val acc: 0.5091383812010444
Training finished

Evaluating best model on test set
Trading strategy for stock SPY:
After 384 trading days
Binary accuracy: 0.50131
Fraction of long signals: 0.47656
Fraction of short signals: 0.52083
Overall long return: 0.03127
Overall return: 0.11845
Yearly long return: 0.02052
Yearly return: 0.07773
Daily volatility: 0.01335
Max drawdown baseline: 0.23197
Max drawdown: 0.21625
Sharpe ratio: 0.01707
L1 error baseline: 2.45427
L1 error: 2.63957
Average prediction: -0.18529
Std prediction: 0.00004
