Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─MyIdentity: 2-3                             [1, 100, 72]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        259,160
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 265,593
Trainable params: 265,593
Non-trainable params: 0
Total mult-adds (M): 0.07
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.61
Params size (MB): 0.22
Estimated Total Size (MB): 1.88
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.7609893679618835
Epoch 1 / 200, val loss: 1.1183512210845947
Epoch 1 / 200, val acc: 0.5100401606425703
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.28727060556411743
Epoch 2 / 200, val loss: 0.8864138722419739
Epoch 2 / 200, val acc: 0.5060240963855421
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.20476536452770233
Epoch 3 / 200, val loss: 0.7527580857276917
Epoch 3 / 200, val acc: 0.5100401606425703
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.1954146772623062
Epoch 4 / 200, val loss: 0.6797661185264587
Epoch 4 / 200, val acc: 0.5060240963855421
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.18454302847385406
Epoch 5 / 200, val loss: 0.6359741687774658
Epoch 5 / 200, val acc: 0.5100401606425703
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.1589811146259308
Epoch 6 / 200, val loss: 0.5910137295722961
Epoch 6 / 200, val acc: 0.5100401606425703
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.13423223793506622
Epoch 7 / 200, val loss: 0.5465354323387146
Epoch 7 / 200, val acc: 0.5020080321285141
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.13064661622047424
Epoch 8 / 200, val loss: 0.4939313232898712
Epoch 8 / 200, val acc: 0.4899598393574297
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.12357790768146515
Epoch 9 / 200, val loss: 0.44464024901390076
Epoch 9 / 200, val acc: 0.4779116465863454
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.11201610416173935
Epoch 10 / 200, val loss: 0.4017176926136017
Epoch 10 / 200, val acc: 0.4939759036144578
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.09819702059030533
Epoch 11 / 200, val loss: 0.36504891514778137
Epoch 11 / 200, val acc: 0.4979919678714859
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.09416959434747696
Epoch 12 / 200, val loss: 0.33342498540878296
Epoch 12 / 200, val acc: 0.5020080321285141
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.09909822046756744
Epoch 13 / 200, val loss: 0.3036194443702698
Epoch 13 / 200, val acc: 0.4899598393574297
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.09273216873407364
Epoch 14 / 200, val loss: 0.27590852975845337
Epoch 14 / 200, val acc: 0.46987951807228917
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.0833604484796524
Epoch 15 / 200, val loss: 0.24856305122375488
Epoch 15 / 200, val acc: 0.4819277108433735
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.07652899622917175
Epoch 16 / 200, val loss: 0.22585096955299377
Epoch 16 / 200, val acc: 0.46987951807228917
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.08236102759838104
Epoch 17 / 200, val loss: 0.21007154881954193
Epoch 17 / 200, val acc: 0.4819277108433735
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.08136073499917984
Epoch 18 / 200, val loss: 0.19806550443172455
Epoch 18 / 200, val acc: 0.4859437751004016
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.07485054433345795
Epoch 19 / 200, val loss: 0.18790845572948456
Epoch 19 / 200, val acc: 0.4899598393574297
Epoch 20 / 200, learning rate: 0.001
Epoch 20 / 200, train loss: 0.07005240768194199
Epoch 20 / 200, val loss: 0.17956116795539856
Epoch 20 / 200, val acc: 0.4859437751004016
Epoch 21 / 200, learning rate: 0.001
Epoch 21 / 200, train loss: 0.07162124663591385
Epoch 21 / 200, val loss: 0.17220847308635712
Epoch 21 / 200, val acc: 0.4979919678714859
Epoch 22 / 200, learning rate: 0.001
Epoch 22 / 200, train loss: 0.07470875233411789
Epoch 22 / 200, val loss: 0.16475199162960052
Epoch 22 / 200, val acc: 0.4899598393574297
Epoch 23 / 200, learning rate: 0.001
Epoch 23 / 200, train loss: 0.07226752489805222
Epoch 23 / 200, val loss: 0.15885385870933533
Epoch 23 / 200, val acc: 0.4899598393574297
Epoch 24 / 200, learning rate: 0.001
Epoch 24 / 200, train loss: 0.06414665281772614
Epoch 24 / 200, val loss: 0.15595608949661255
Epoch 24 / 200, val acc: 0.4979919678714859
Epoch 25 / 200, learning rate: 0.001
Epoch 25 / 200, train loss: 0.0639629065990448
Epoch 25 / 200, val loss: 0.1577344387769699
Epoch 25 / 200, val acc: 0.4979919678714859
Epoch 26 / 200, learning rate: 0.001
Epoch 26 / 200, train loss: 0.06620337814092636
Epoch 26 / 200, val loss: 0.16269883513450623
Epoch 26 / 200, val acc: 0.4819277108433735
Epoch 27 / 200, learning rate: 0.001
Epoch 27 / 200, train loss: 0.06387922912836075
Epoch 27 / 200, val loss: 0.16117185354232788
Epoch 27 / 200, val acc: 0.4819277108433735
Epoch 28 / 200, learning rate: 0.001
Epoch 28 / 200, train loss: 0.059295911341905594
Epoch 28 / 200, val loss: 0.14816880226135254
Epoch 28 / 200, val acc: 0.4939759036144578
Epoch 29 / 200, learning rate: 0.001
Epoch 29 / 200, train loss: 0.05952558293938637
Epoch 29 / 200, val loss: 0.1352338343858719
Epoch 29 / 200, val acc: 0.4939759036144578
Epoch 30 / 200, learning rate: 0.001
Epoch 30 / 200, train loss: 0.05704712122678757
Epoch 30 / 200, val loss: 0.12904757261276245
Epoch 30 / 200, val acc: 0.4939759036144578
Epoch 31 / 200, learning rate: 0.001
Epoch 31 / 200, train loss: 0.0606522373855114
Epoch 31 / 200, val loss: 0.12577037513256073
Epoch 31 / 200, val acc: 0.4899598393574297
Epoch 32 / 200, learning rate: 0.001
Epoch 32 / 200, train loss: 0.05675673484802246
Epoch 32 / 200, val loss: 0.12543079257011414
Epoch 32 / 200, val acc: 0.4979919678714859
Epoch 33 / 200, learning rate: 0.001
Epoch 33 / 200, train loss: 0.056415874511003494
Epoch 33 / 200, val loss: 0.12908150255680084
Epoch 33 / 200, val acc: 0.4939759036144578
Epoch 34 / 200, learning rate: 0.001
Epoch 34 / 200, train loss: 0.0561642087996006
Epoch 34 / 200, val loss: 0.130947545170784
Epoch 34 / 200, val acc: 0.4979919678714859
Epoch 35 / 200, learning rate: 0.001
Epoch 35 / 200, train loss: 0.05493045598268509
Epoch 35 / 200, val loss: 0.12744730710983276
Epoch 35 / 200, val acc: 0.4939759036144578
Epoch 36 / 200, learning rate: 0.001
Epoch 36 / 200, train loss: 0.056934863328933716
Epoch 36 / 200, val loss: 0.11882778257131577
Epoch 36 / 200, val acc: 0.4979919678714859
Epoch 37 / 200, learning rate: 0.001
Epoch 37 / 200, train loss: 0.055025193840265274
Epoch 37 / 200, val loss: 0.11375412344932556
Epoch 37 / 200, val acc: 0.4859437751004016
Epoch 38 / 200, learning rate: 0.001
Epoch 38 / 200, train loss: 0.050998855382204056
Epoch 38 / 200, val loss: 0.11151300370693207
Epoch 38 / 200, val acc: 0.4738955823293173
Epoch 39 / 200, learning rate: 0.001
Epoch 39 / 200, train loss: 0.04999818280339241
Epoch 39 / 200, val loss: 0.11002982407808304
Epoch 39 / 200, val acc: 0.4738955823293173
Epoch 40 / 200, learning rate: 0.001
Epoch 40 / 200, train loss: 0.05193047598004341
Epoch 40 / 200, val loss: 0.10922600328922272
Epoch 40 / 200, val acc: 0.4859437751004016
Epoch 41 / 200, learning rate: 0.001
Epoch 41 / 200, train loss: 0.05070775747299194
Epoch 41 / 200, val loss: 0.10924089699983597
Epoch 41 / 200, val acc: 0.4979919678714859
Epoch 42 / 200, learning rate: 0.001
Epoch 42 / 200, train loss: 0.04834301024675369
Epoch 42 / 200, val loss: 0.10875903069972992
Epoch 42 / 200, val acc: 0.4979919678714859
Epoch 43 / 200, learning rate: 0.001
Epoch 43 / 200, train loss: 0.050071898847818375
Epoch 43 / 200, val loss: 0.10576330125331879
Epoch 43 / 200, val acc: 0.4819277108433735
Epoch 44 / 200, learning rate: 0.001
Epoch 44 / 200, train loss: 0.048785123974084854
Epoch 44 / 200, val loss: 0.10287079215049744
Epoch 44 / 200, val acc: 0.4779116465863454
Epoch 45 / 200, learning rate: 0.001
Epoch 45 / 200, train loss: 0.04879201203584671
Epoch 45 / 200, val loss: 0.10186261683702469
Epoch 45 / 200, val acc: 0.4779116465863454
Epoch 46 / 200, learning rate: 0.001
Epoch 46 / 200, train loss: 0.04682007059454918
Epoch 46 / 200, val loss: 0.10128429532051086
Epoch 46 / 200, val acc: 0.4738955823293173
Epoch 47 / 200, learning rate: 0.001
Epoch 47 / 200, train loss: 0.047325342893600464
Epoch 47 / 200, val loss: 0.1010977253317833
Epoch 47 / 200, val acc: 0.4819277108433735
Epoch 48 / 200, learning rate: 0.001
Epoch 48 / 200, train loss: 0.04705910012125969
Epoch 48 / 200, val loss: 0.10266787558794022
Epoch 48 / 200, val acc: 0.4899598393574297
Epoch 49 / 200, learning rate: 0.001
Epoch 49 / 200, train loss: 0.04462150111794472
Epoch 49 / 200, val loss: 0.10351859033107758
Epoch 49 / 200, val acc: 0.5060240963855421
Epoch 50 / 200, learning rate: 0.001
Epoch 50 / 200, train loss: 0.04688869044184685
Epoch 50 / 200, val loss: 0.1030518114566803
Epoch 50 / 200, val acc: 0.5100401606425703
Epoch 51 / 200, learning rate: 0.001
Epoch 51 / 200, train loss: 0.04525855556130409
Epoch 51 / 200, val loss: 0.10127240419387817
Epoch 51 / 200, val acc: 0.5100401606425703
Epoch 52 / 200, learning rate: 0.001
Epoch 52 / 200, train loss: 0.046346526592969894
Epoch 52 / 200, val loss: 0.09940425306558609
Epoch 52 / 200, val acc: 0.4939759036144578
Epoch 53 / 200, learning rate: 0.001
Epoch 53 / 200, train loss: 0.04572372883558273
Epoch 53 / 200, val loss: 0.098113514482975
Epoch 53 / 200, val acc: 0.4779116465863454
Epoch 54 / 200, learning rate: 0.001
Epoch 54 / 200, train loss: 0.0437784343957901
Epoch 54 / 200, val loss: 0.09815964102745056
Epoch 54 / 200, val acc: 0.4859437751004016
Epoch 55 / 200, learning rate: 0.001
Epoch 55 / 200, train loss: 0.04489661753177643
Epoch 55 / 200, val loss: 0.09875049442052841
Epoch 55 / 200, val acc: 0.4899598393574297
Epoch 56 / 200, learning rate: 0.001
Epoch 56 / 200, train loss: 0.04434783756732941
Epoch 56 / 200, val loss: 0.09954196959733963
Epoch 56 / 200, val acc: 0.5060240963855421
Epoch 57 / 200, learning rate: 0.001
Epoch 57 / 200, train loss: 0.04428577423095703
Epoch 57 / 200, val loss: 0.09911824017763138
Epoch 57 / 200, val acc: 0.5020080321285141
Epoch 58 / 200, learning rate: 0.001
Epoch 58 / 200, train loss: 0.04396678879857063
Epoch 58 / 200, val loss: 0.09701626747846603
Epoch 58 / 200, val acc: 0.4819277108433735
Epoch 59 / 200, learning rate: 0.001
Epoch 59 / 200, train loss: 0.04514114186167717
Epoch 59 / 200, val loss: 0.09549693763256073
Epoch 59 / 200, val acc: 0.46987951807228917
Epoch 60 / 200, learning rate: 0.001
Epoch 60 / 200, train loss: 0.043165288865566254
Epoch 60 / 200, val loss: 0.09538758546113968
Epoch 60 / 200, val acc: 0.4738955823293173
Epoch 61 / 200, learning rate: 0.001
Epoch 61 / 200, train loss: 0.04175305366516113
Epoch 61 / 200, val loss: 0.09653589129447937
Epoch 61 / 200, val acc: 0.4859437751004016
Epoch 62 / 200, learning rate: 0.001
Epoch 62 / 200, train loss: 0.04148140549659729
Epoch 62 / 200, val loss: 0.09908758848905563
Epoch 62 / 200, val acc: 0.4979919678714859
Epoch 63 / 200, learning rate: 0.001
Epoch 63 / 200, train loss: 0.04438728839159012
Epoch 63 / 200, val loss: 0.09932077676057816
Epoch 63 / 200, val acc: 0.4939759036144578
Epoch 64 / 200, learning rate: 0.001
Epoch 64 / 200, train loss: 0.042888544499874115
Epoch 64 / 200, val loss: 0.09609857201576233
Epoch 64 / 200, val acc: 0.4859437751004016
Epoch 65 / 200, learning rate: 0.001
Epoch 65 / 200, train loss: 0.040949542075395584
Epoch 65 / 200, val loss: 0.09423154592514038
Epoch 65 / 200, val acc: 0.4738955823293173
Epoch 66 / 200, learning rate: 0.001
Epoch 66 / 200, train loss: 0.04050062596797943
Epoch 66 / 200, val loss: 0.09412588179111481
Epoch 66 / 200, val acc: 0.4738955823293173
Epoch 67 / 200, learning rate: 0.001
Epoch 67 / 200, train loss: 0.042209990322589874
Epoch 67 / 200, val loss: 0.09541166573762894
Epoch 67 / 200, val acc: 0.4859437751004016
Epoch 68 / 200, learning rate: 0.001
Epoch 68 / 200, train loss: 0.04086777940392494
Epoch 68 / 200, val loss: 0.09788724035024643
Epoch 68 / 200, val acc: 0.4859437751004016
Epoch 69 / 200, learning rate: 0.001
Epoch 69 / 200, train loss: 0.04003685340285301
Epoch 69 / 200, val loss: 0.09892763197422028
Epoch 69 / 200, val acc: 0.4738955823293173
Epoch 70 / 200, learning rate: 0.001
Epoch 70 / 200, train loss: 0.0398826003074646
Epoch 70 / 200, val loss: 0.09800917655229568
Epoch 70 / 200, val acc: 0.4738955823293173
Epoch 71 / 200, learning rate: 0.001
Epoch 71 / 200, train loss: 0.04094626381993294
Epoch 71 / 200, val loss: 0.09723877161741257
Epoch 71 / 200, val acc: 0.4779116465863454
Epoch 72 / 200, learning rate: 0.001
Epoch 72 / 200, train loss: 0.03865937143564224
Epoch 72 / 200, val loss: 0.09638006240129471
Epoch 72 / 200, val acc: 0.4819277108433735
Epoch 73 / 200, learning rate: 0.001
Epoch 73 / 200, train loss: 0.04057634249329567
Epoch 73 / 200, val loss: 0.09632644057273865
Epoch 73 / 200, val acc: 0.4819277108433735
Epoch 74 / 200, learning rate: 0.001
Epoch 74 / 200, train loss: 0.040076036006212234
Epoch 74 / 200, val loss: 0.09780235588550568
Epoch 74 / 200, val acc: 0.4738955823293173
Epoch 75 / 200, learning rate: 0.001
Epoch 75 / 200, train loss: 0.03964428976178169
Epoch 75 / 200, val loss: 0.09902513772249222
Epoch 75 / 200, val acc: 0.4738955823293173
Epoch 76 / 200, learning rate: 0.001
Epoch 76 / 200, train loss: 0.038727208971977234
Epoch 76 / 200, val loss: 0.09892169386148453
Epoch 76 / 200, val acc: 0.4738955823293173
Epoch 77 / 200, learning rate: 0.0005
Epoch 77 / 200, train loss: 0.03786264359951019
Epoch 77 / 200, val loss: 0.09650906920433044
Epoch 77 / 200, val acc: 0.4738955823293173
Epoch 78 / 200, learning rate: 0.0005
Epoch 78 / 200, train loss: 0.03824327513575554
Epoch 78 / 200, val loss: 0.09413065761327744
Epoch 78 / 200, val acc: 0.4819277108433735
Epoch 79 / 200, learning rate: 0.0005
Epoch 79 / 200, train loss: 0.03738541528582573
Epoch 79 / 200, val loss: 0.09259552508592606
Epoch 79 / 200, val acc: 0.4859437751004016
Epoch 80 / 200, learning rate: 0.0005
Epoch 80 / 200, train loss: 0.03900038078427315
Epoch 80 / 200, val loss: 0.09226839244365692
Epoch 80 / 200, val acc: 0.4819277108433735
Epoch 81 / 200, learning rate: 0.0005
Epoch 81 / 200, train loss: 0.038570061326026917
Epoch 81 / 200, val loss: 0.09241803735494614
Epoch 81 / 200, val acc: 0.4819277108433735
Epoch 82 / 200, learning rate: 0.0005
Epoch 82 / 200, train loss: 0.03823966532945633
Epoch 82 / 200, val loss: 0.09344944357872009
Epoch 82 / 200, val acc: 0.4859437751004016
Epoch 83 / 200, learning rate: 0.0005
Epoch 83 / 200, train loss: 0.03775854408740997
Epoch 83 / 200, val loss: 0.0953836739063263
Epoch 83 / 200, val acc: 0.4779116465863454
Epoch 84 / 200, learning rate: 0.0005
Epoch 84 / 200, train loss: 0.0398210808634758
Epoch 84 / 200, val loss: 0.09684799611568451
Epoch 84 / 200, val acc: 0.46987951807228917
Epoch 85 / 200, learning rate: 0.0005
Epoch 85 / 200, train loss: 0.03730853274464607
Epoch 85 / 200, val loss: 0.09669409692287445
Epoch 85 / 200, val acc: 0.46987951807228917
Epoch 86 / 200, learning rate: 0.0005
Epoch 86 / 200, train loss: 0.038115210831165314
Epoch 86 / 200, val loss: 0.09492015838623047
Epoch 86 / 200, val acc: 0.4779116465863454
Epoch 87 / 200, learning rate: 0.0005
Epoch 87 / 200, train loss: 0.03693018853664398
Epoch 87 / 200, val loss: 0.09338687360286713
Epoch 87 / 200, val acc: 0.4819277108433735
Epoch 88 / 200, learning rate: 0.0005
Epoch 88 / 200, train loss: 0.03769997879862785
Epoch 88 / 200, val loss: 0.09277475625276566
Epoch 88 / 200, val acc: 0.4819277108433735
Epoch 89 / 200, learning rate: 0.0005
Epoch 89 / 200, train loss: 0.03711985424160957
Epoch 89 / 200, val loss: 0.09317883849143982
Epoch 89 / 200, val acc: 0.4859437751004016
Epoch 90 / 200, learning rate: 0.0005
Epoch 90 / 200, train loss: 0.03629861772060394
Epoch 90 / 200, val loss: 0.09328240901231766
Epoch 90 / 200, val acc: 0.4819277108433735
Epoch 91 / 200, learning rate: 0.00025
Epoch 91 / 200, train loss: 0.03681264445185661
Epoch 91 / 200, val loss: 0.09360529482364655
Epoch 91 / 200, val acc: 0.4819277108433735
Epoch 92 / 200, learning rate: 0.00025
Epoch 92 / 200, train loss: 0.03663845360279083
Epoch 92 / 200, val loss: 0.09373878687620163
Epoch 92 / 200, val acc: 0.4819277108433735
Epoch 93 / 200, learning rate: 0.00025
Epoch 93 / 200, train loss: 0.038064099848270416
Epoch 93 / 200, val loss: 0.09425098448991776
Epoch 93 / 200, val acc: 0.46987951807228917
Epoch 94 / 200, learning rate: 0.00025
Epoch 94 / 200, train loss: 0.03548609837889671
Epoch 94 / 200, val loss: 0.09498734772205353
Epoch 94 / 200, val acc: 0.4738955823293173
Epoch 95 / 200, learning rate: 0.00025
Epoch 95 / 200, train loss: 0.03636459633708
Epoch 95 / 200, val loss: 0.09516862779855728
Epoch 95 / 200, val acc: 0.4738955823293173
Epoch 96 / 200, learning rate: 0.00025
Epoch 96 / 200, train loss: 0.0365544855594635
Epoch 96 / 200, val loss: 0.09488672018051147
Epoch 96 / 200, val acc: 0.4738955823293173
Epoch 97 / 200, learning rate: 0.00025
Epoch 97 / 200, train loss: 0.036432381719350815
Epoch 97 / 200, val loss: 0.09477156400680542
Epoch 97 / 200, val acc: 0.4738955823293173
Epoch 98 / 200, learning rate: 0.00025
Epoch 98 / 200, train loss: 0.03647790849208832
Epoch 98 / 200, val loss: 0.09495628625154495
Epoch 98 / 200, val acc: 0.4738955823293173
Epoch 99 / 200, learning rate: 0.00025
Epoch 99 / 200, train loss: 0.03674720227718353
Epoch 99 / 200, val loss: 0.09511278569698334
Epoch 99 / 200, val acc: 0.4738955823293173
Epoch 100 / 200, learning rate: 0.00025
Epoch 100 / 200, train loss: 0.03589005395770073
Epoch 100 / 200, val loss: 0.09514785557985306
Epoch 100 / 200, val acc: 0.4738955823293173
Epoch 101 / 200, learning rate: 0.00025
Epoch 101 / 200, train loss: 0.036642152816057205
Epoch 101 / 200, val loss: 0.09498004615306854
Epoch 101 / 200, val acc: 0.4738955823293173
Epoch 102 / 200, learning rate: 0.000125
Epoch 102 / 200, train loss: 0.036808960139751434
Epoch 102 / 200, val loss: 0.09461075812578201
Epoch 102 / 200, val acc: 0.4779116465863454
Epoch 103 / 200, learning rate: 0.000125
Epoch 103 / 200, train loss: 0.03683174028992653
Epoch 103 / 200, val loss: 0.09458640217781067
Epoch 103 / 200, val acc: 0.4779116465863454
Epoch 104 / 200, learning rate: 0.000125
Epoch 104 / 200, train loss: 0.03625950217247009
Epoch 104 / 200, val loss: 0.09460274130105972
Epoch 104 / 200, val acc: 0.4779116465863454
Epoch 105 / 200, learning rate: 0.000125
Epoch 105 / 200, train loss: 0.03733232989907265
Epoch 105 / 200, val loss: 0.09454500675201416
Epoch 105 / 200, val acc: 0.4738955823293173
Epoch 106 / 200, learning rate: 0.000125
Epoch 106 / 200, train loss: 0.03583916649222374
Epoch 106 / 200, val loss: 0.09437218308448792
Epoch 106 / 200, val acc: 0.4738955823293173
Epoch 107 / 200, learning rate: 0.000125
Epoch 107 / 200, train loss: 0.03590685501694679
Epoch 107 / 200, val loss: 0.09421352297067642
Epoch 107 / 200, val acc: 0.4738955823293173
Epoch 108 / 200, learning rate: 0.000125
Epoch 108 / 200, train loss: 0.033971451222896576
Epoch 108 / 200, val loss: 0.09396155178546906
Epoch 108 / 200, val acc: 0.4738955823293173
Epoch 109 / 200, learning rate: 0.000125
Epoch 109 / 200, train loss: 0.035476766526699066
Epoch 109 / 200, val loss: 0.09374630451202393
Epoch 109 / 200, val acc: 0.4738955823293173
Epoch 110 / 200, learning rate: 0.000125
Epoch 110 / 200, train loss: 0.03571733832359314
Epoch 110 / 200, val loss: 0.09344702959060669
Epoch 110 / 200, val acc: 0.4779116465863454
Epoch 111 / 200, learning rate: 0.000125
Epoch 111 / 200, train loss: 0.036717601120471954
Epoch 111 / 200, val loss: 0.09333374351263046
Epoch 111 / 200, val acc: 0.4779116465863454
Epoch 112 / 200, learning rate: 0.000125
Epoch 112 / 200, train loss: 0.035261739045381546
Epoch 112 / 200, val loss: 0.09316866099834442
Epoch 112 / 200, val acc: 0.4819277108433735
Epoch 113 / 200, learning rate: 6.25e-05
Epoch 113 / 200, train loss: 0.0351397879421711
Epoch 113 / 200, val loss: 0.09286339581012726
Epoch 113 / 200, val acc: 0.4859437751004016
Epoch 114 / 200, learning rate: 6.25e-05
Epoch 114 / 200, train loss: 0.036349814385175705
Epoch 114 / 200, val loss: 0.0927518978714943
Epoch 114 / 200, val acc: 0.4819277108433735
Epoch 115 / 200, learning rate: 6.25e-05
Epoch 115 / 200, train loss: 0.036013007164001465
Epoch 115 / 200, val loss: 0.0927591621875763
Epoch 115 / 200, val acc: 0.4859437751004016
Epoch 116 / 200, learning rate: 6.25e-05
Epoch 116 / 200, train loss: 0.03640500456094742
Epoch 116 / 200, val loss: 0.09275545179843903
Epoch 116 / 200, val acc: 0.4859437751004016
Epoch 117 / 200, learning rate: 6.25e-05
Epoch 117 / 200, train loss: 0.03537270426750183
Epoch 117 / 200, val loss: 0.09271491318941116
Epoch 117 / 200, val acc: 0.4859437751004016
Epoch 118 / 200, learning rate: 6.25e-05
Epoch 118 / 200, train loss: 0.03613286092877388
Epoch 118 / 200, val loss: 0.09272973984479904
Epoch 118 / 200, val acc: 0.4859437751004016
Epoch 119 / 200, learning rate: 6.25e-05
Epoch 119 / 200, train loss: 0.03505618870258331
Epoch 119 / 200, val loss: 0.09265728294849396
Epoch 119 / 200, val acc: 0.4859437751004016
Epoch 120 / 200, learning rate: 6.25e-05
Epoch 120 / 200, train loss: 0.0361359529197216
Epoch 120 / 200, val loss: 0.09265187382698059
Epoch 120 / 200, val acc: 0.4859437751004016
Epoch 121 / 200, learning rate: 6.25e-05
Epoch 121 / 200, train loss: 0.035359274595975876
Epoch 121 / 200, val loss: 0.09275875240564346
Epoch 121 / 200, val acc: 0.4819277108433735
Epoch 122 / 200, learning rate: 6.25e-05
Epoch 122 / 200, train loss: 0.03443695604801178
Epoch 122 / 200, val loss: 0.09283588081598282
Epoch 122 / 200, val acc: 0.4819277108433735
Epoch 123 / 200, learning rate: 6.25e-05
Epoch 123 / 200, train loss: 0.03539980202913284
Epoch 123 / 200, val loss: 0.09283580631017685
Epoch 123 / 200, val acc: 0.4819277108433735
Epoch 124 / 200, learning rate: 3.125e-05
Epoch 124 / 200, train loss: 0.03461704030632973
Epoch 124 / 200, val loss: 0.09268224239349365
Epoch 124 / 200, val acc: 0.4819277108433735
Epoch 125 / 200, learning rate: 3.125e-05
Epoch 125 / 200, train loss: 0.03494475036859512
Epoch 125 / 200, val loss: 0.09255602210760117
Epoch 125 / 200, val acc: 0.4859437751004016
Epoch 126 / 200, learning rate: 3.125e-05
Epoch 126 / 200, train loss: 0.036918703466653824
Epoch 126 / 200, val loss: 0.09247071295976639
Epoch 126 / 200, val acc: 0.4819277108433735
Epoch 127 / 200, learning rate: 3.125e-05
Epoch 127 / 200, train loss: 0.036599937826395035
Epoch 127 / 200, val loss: 0.09237957745790482
Epoch 127 / 200, val acc: 0.4819277108433735
Epoch 128 / 200, learning rate: 3.125e-05
Epoch 128 / 200, train loss: 0.03684505075216293
Epoch 128 / 200, val loss: 0.09223287552595139
Epoch 128 / 200, val acc: 0.4859437751004016
Epoch 129 / 200, learning rate: 3.125e-05
Epoch 129 / 200, train loss: 0.0362178198993206
Epoch 129 / 200, val loss: 0.09205944091081619
Epoch 129 / 200, val acc: 0.4859437751004016
Epoch 130 / 200, learning rate: 3.125e-05
Epoch 130 / 200, train loss: 0.036780696362257004
Epoch 130 / 200, val loss: 0.09188436716794968
Epoch 130 / 200, val acc: 0.4859437751004016
Epoch 131 / 200, learning rate: 3.125e-05
Epoch 131 / 200, train loss: 0.03581630438566208
Epoch 131 / 200, val loss: 0.09172914922237396
Epoch 131 / 200, val acc: 0.4859437751004016
Epoch 132 / 200, learning rate: 3.125e-05
Epoch 132 / 200, train loss: 0.03608943894505501
Epoch 132 / 200, val loss: 0.09158960729837418
Epoch 132 / 200, val acc: 0.4859437751004016
Epoch 133 / 200, learning rate: 3.125e-05
Epoch 133 / 200, train loss: 0.0358637236058712
Epoch 133 / 200, val loss: 0.09151078015565872
Epoch 133 / 200, val acc: 0.4859437751004016
Epoch 134 / 200, learning rate: 3.125e-05
Epoch 134 / 200, train loss: 0.035577740520238876
Epoch 134 / 200, val loss: 0.09147869050502777
Epoch 134 / 200, val acc: 0.4859437751004016
Epoch 135 / 200, learning rate: 3.125e-05
Epoch 135 / 200, train loss: 0.03475269302725792
Epoch 135 / 200, val loss: 0.09149329364299774
Epoch 135 / 200, val acc: 0.4859437751004016
Epoch 136 / 200, learning rate: 3.125e-05
Epoch 136 / 200, train loss: 0.03698928654193878
Epoch 136 / 200, val loss: 0.09155740588903427
Epoch 136 / 200, val acc: 0.4859437751004016
Epoch 137 / 200, learning rate: 3.125e-05
Epoch 137 / 200, train loss: 0.03483765199780464
Epoch 137 / 200, val loss: 0.09159863740205765
Epoch 137 / 200, val acc: 0.4859437751004016
Epoch 138 / 200, learning rate: 3.125e-05
Epoch 138 / 200, train loss: 0.03461269289255142
Epoch 138 / 200, val loss: 0.09168533235788345
Epoch 138 / 200, val acc: 0.4859437751004016
Epoch 139 / 200, learning rate: 3.125e-05
Epoch 139 / 200, train loss: 0.03567318990826607
Epoch 139 / 200, val loss: 0.09175955504179001
Epoch 139 / 200, val acc: 0.4859437751004016
Epoch 140 / 200, learning rate: 3.125e-05
Epoch 140 / 200, train loss: 0.03567495942115784
Epoch 140 / 200, val loss: 0.0918552577495575
Epoch 140 / 200, val acc: 0.4859437751004016
Epoch 141 / 200, learning rate: 3.125e-05
Epoch 141 / 200, train loss: 0.0361628383398056
Epoch 141 / 200, val loss: 0.09198306500911713
Epoch 141 / 200, val acc: 0.4859437751004016
Epoch 142 / 200, learning rate: 3.125e-05
Epoch 142 / 200, train loss: 0.035600848495960236
Epoch 142 / 200, val loss: 0.09216348081827164
Epoch 142 / 200, val acc: 0.4819277108433735
Epoch 143 / 200, learning rate: 3.125e-05
Epoch 143 / 200, train loss: 0.036259982734918594
Epoch 143 / 200, val loss: 0.09233883768320084
Epoch 143 / 200, val acc: 0.4819277108433735
Epoch 144 / 200, learning rate: 3.125e-05
Epoch 144 / 200, train loss: 0.035172928124666214
Epoch 144 / 200, val loss: 0.09243034571409225
Epoch 144 / 200, val acc: 0.4819277108433735
Epoch 145 / 200, learning rate: 1.5625e-05
Epoch 145 / 200, train loss: 0.036666300147771835
Epoch 145 / 200, val loss: 0.0925174430012703
Epoch 145 / 200, val acc: 0.4819277108433735
Epoch 146 / 200, learning rate: 1.5625e-05
Epoch 146 / 200, train loss: 0.035677749663591385
Epoch 146 / 200, val loss: 0.09255899488925934
Epoch 146 / 200, val acc: 0.4819277108433735
Epoch 147 / 200, learning rate: 1.5625e-05
Epoch 147 / 200, train loss: 0.03457244858145714
Epoch 147 / 200, val loss: 0.0925823524594307
Epoch 147 / 200, val acc: 0.4779116465863454
Epoch 148 / 200, learning rate: 1.5625e-05
Epoch 148 / 200, train loss: 0.036754757165908813
Epoch 148 / 200, val loss: 0.09259311109781265
Epoch 148 / 200, val acc: 0.4779116465863454
Epoch 149 / 200, learning rate: 1.5625e-05
Epoch 149 / 200, train loss: 0.036628443747758865
Epoch 149 / 200, val loss: 0.09260673820972443
Epoch 149 / 200, val acc: 0.4779116465863454
Epoch 150 / 200, learning rate: 1.5625e-05
Epoch 150 / 200, train loss: 0.037680014967918396
Epoch 150 / 200, val loss: 0.0926201269030571
Epoch 150 / 200, val acc: 0.4819277108433735
Epoch 151 / 200, learning rate: 1.5625e-05
Epoch 151 / 200, train loss: 0.038421615958213806
Epoch 151 / 200, val loss: 0.09265095740556717
Epoch 151 / 200, val acc: 0.4819277108433735
Epoch 152 / 200, learning rate: 1.5625e-05
Epoch 152 / 200, train loss: 0.033627744764089584
Epoch 152 / 200, val loss: 0.0926823765039444
Epoch 152 / 200, val acc: 0.4819277108433735
Epoch 153 / 200, learning rate: 1.5625e-05
Epoch 153 / 200, train loss: 0.0360463447868824
Epoch 153 / 200, val loss: 0.0927031934261322
Epoch 153 / 200, val acc: 0.4779116465863454
Epoch 154 / 200, learning rate: 1.5625e-05
Epoch 154 / 200, train loss: 0.036716002970933914
Epoch 154 / 200, val loss: 0.09270036965608597
Epoch 154 / 200, val acc: 0.4779116465863454
Epoch 155 / 200, learning rate: 1.5625e-05
Epoch 155 / 200, train loss: 0.03464183211326599
Epoch 155 / 200, val loss: 0.09268976747989655
Epoch 155 / 200, val acc: 0.4779116465863454
Epoch 156 / 200, learning rate: 7.8125e-06
Epoch 156 / 200, train loss: 0.03642963990569115
Epoch 156 / 200, val loss: 0.09267416596412659
Epoch 156 / 200, val acc: 0.4779116465863454
Epoch 157 / 200, learning rate: 7.8125e-06
Epoch 157 / 200, train loss: 0.035252299159765244
Epoch 157 / 200, val loss: 0.09265583008527756
Epoch 157 / 200, val acc: 0.4779116465863454
Epoch 158 / 200, learning rate: 7.8125e-06
Epoch 158 / 200, train loss: 0.03578783944249153
Epoch 158 / 200, val loss: 0.09264611452817917
Epoch 158 / 200, val acc: 0.4779116465863454
Epoch 159 / 200, learning rate: 7.8125e-06
Epoch 159 / 200, train loss: 0.0360213965177536
Epoch 159 / 200, val loss: 0.0926235020160675
Epoch 159 / 200, val acc: 0.4779116465863454
Epoch 160 / 200, learning rate: 7.8125e-06
Epoch 160 / 200, train loss: 0.035935577005147934
Epoch 160 / 200, val loss: 0.09260980039834976
Epoch 160 / 200, val acc: 0.4779116465863454
Epoch 161 / 200, learning rate: 7.8125e-06
Epoch 161 / 200, train loss: 0.03672243282198906
Epoch 161 / 200, val loss: 0.09259237349033356
Epoch 161 / 200, val acc: 0.4819277108433735
Epoch 162 / 200, learning rate: 7.8125e-06
Epoch 162 / 200, train loss: 0.03596140071749687
Epoch 162 / 200, val loss: 0.09257905930280685
Epoch 162 / 200, val acc: 0.4819277108433735
Epoch 163 / 200, learning rate: 7.8125e-06
Epoch 163 / 200, train loss: 0.03553533926606178
Epoch 163 / 200, val loss: 0.09255155920982361
Epoch 163 / 200, val acc: 0.4819277108433735
Epoch 164 / 200, learning rate: 7.8125e-06
Epoch 164 / 200, train loss: 0.03537087142467499
Epoch 164 / 200, val loss: 0.09251604229211807
Epoch 164 / 200, val acc: 0.4819277108433735
Epoch 165 / 200, learning rate: 7.8125e-06
Epoch 165 / 200, train loss: 0.03524770215153694
Epoch 165 / 200, val loss: 0.09246630221605301
Epoch 165 / 200, val acc: 0.4859437751004016
Epoch 166 / 200, learning rate: 7.8125e-06
Epoch 166 / 200, train loss: 0.03520065173506737
Epoch 166 / 200, val loss: 0.0924268588423729
Epoch 166 / 200, val acc: 0.4859437751004016
Epoch 167 / 200, learning rate: 3.90625e-06
Epoch 167 / 200, train loss: 0.035161666572093964
Epoch 167 / 200, val loss: 0.09239105880260468
Epoch 167 / 200, val acc: 0.4859437751004016
Epoch 168 / 200, learning rate: 3.90625e-06
Epoch 168 / 200, train loss: 0.03462998569011688
Epoch 168 / 200, val loss: 0.09237068891525269
Epoch 168 / 200, val acc: 0.4859437751004016
Epoch 169 / 200, learning rate: 3.90625e-06
Epoch 169 / 200, train loss: 0.03505393862724304
Epoch 169 / 200, val loss: 0.09235214442014694
Epoch 169 / 200, val acc: 0.4859437751004016
Epoch 170 / 200, learning rate: 3.90625e-06
Epoch 170 / 200, train loss: 0.03592503443360329
Epoch 170 / 200, val loss: 0.09233320504426956
Epoch 170 / 200, val acc: 0.4859437751004016
Epoch 171 / 200, learning rate: 3.90625e-06
Epoch 171 / 200, train loss: 0.03531409427523613
Epoch 171 / 200, val loss: 0.09231884032487869
Epoch 171 / 200, val acc: 0.4859437751004016
Epoch 172 / 200, learning rate: 3.90625e-06
Epoch 172 / 200, train loss: 0.03685508668422699
Epoch 172 / 200, val loss: 0.09230898320674896
Epoch 172 / 200, val acc: 0.4859437751004016
Epoch 173 / 200, learning rate: 3.90625e-06
Epoch 173 / 200, train loss: 0.03657477721571922
Epoch 173 / 200, val loss: 0.09229094535112381
Epoch 173 / 200, val acc: 0.4859437751004016
Epoch 174 / 200, learning rate: 3.90625e-06
Epoch 174 / 200, train loss: 0.03676841780543327
Epoch 174 / 200, val loss: 0.09226750582456589
Epoch 174 / 200, val acc: 0.4859437751004016
Epoch 175 / 200, learning rate: 3.90625e-06
Epoch 175 / 200, train loss: 0.03403729200363159
Epoch 175 / 200, val loss: 0.09224981814622879
Epoch 175 / 200, val acc: 0.4859437751004016
Epoch 176 / 200, learning rate: 3.90625e-06
Epoch 176 / 200, train loss: 0.03566204756498337
Epoch 176 / 200, val loss: 0.09223326295614243
Epoch 176 / 200, val acc: 0.4859437751004016
Epoch 177 / 200, learning rate: 3.90625e-06
Epoch 177 / 200, train loss: 0.03587173670530319
Epoch 177 / 200, val loss: 0.09221766889095306
Epoch 177 / 200, val acc: 0.4859437751004016
Epoch 178 / 200, learning rate: 1.953125e-06
Epoch 178 / 200, train loss: 0.03771662712097168
Epoch 178 / 200, val loss: 0.09220634400844574
Epoch 178 / 200, val acc: 0.4859437751004016
Epoch 179 / 200, learning rate: 1.953125e-06
Epoch 179 / 200, train loss: 0.03505181521177292
Epoch 179 / 200, val loss: 0.09220166504383087
Epoch 179 / 200, val acc: 0.4859437751004016
Epoch 180 / 200, learning rate: 1.953125e-06
Epoch 180 / 200, train loss: 0.03542300686240196
Epoch 180 / 200, val loss: 0.09220041334629059
Epoch 180 / 200, val acc: 0.4859437751004016
Epoch 181 / 200, learning rate: 1.953125e-06
Epoch 181 / 200, train loss: 0.03530470281839371
Epoch 181 / 200, val loss: 0.09219690412282944
Epoch 181 / 200, val acc: 0.4859437751004016
Epoch 182 / 200, learning rate: 1.953125e-06
Epoch 182 / 200, train loss: 0.034525275230407715
Epoch 182 / 200, val loss: 0.09219208359718323
Epoch 182 / 200, val acc: 0.4859437751004016
Epoch 183 / 200, learning rate: 1.953125e-06
Epoch 183 / 200, train loss: 0.03659111633896828
Epoch 183 / 200, val loss: 0.09219484031200409
Epoch 183 / 200, val acc: 0.4859437751004016
Epoch 184 / 200, learning rate: 1.953125e-06
Epoch 184 / 200, train loss: 0.035384006798267365
Epoch 184 / 200, val loss: 0.09219368547201157
Epoch 184 / 200, val acc: 0.4859437751004016
Epoch 185 / 200, learning rate: 1.953125e-06
Epoch 185 / 200, train loss: 0.035268448293209076
Epoch 185 / 200, val loss: 0.09219695627689362
Epoch 185 / 200, val acc: 0.4859437751004016
Epoch 186 / 200, learning rate: 1.953125e-06
Epoch 186 / 200, train loss: 0.035803209990262985
Epoch 186 / 200, val loss: 0.09220267832279205
Epoch 186 / 200, val acc: 0.4859437751004016
Epoch 187 / 200, learning rate: 1.953125e-06
Epoch 187 / 200, train loss: 0.0357946902513504
Epoch 187 / 200, val loss: 0.09221260994672775
Epoch 187 / 200, val acc: 0.4859437751004016
Epoch 188 / 200, learning rate: 1.953125e-06
Epoch 188 / 200, train loss: 0.036252327263355255
Epoch 188 / 200, val loss: 0.0922262892127037
Epoch 188 / 200, val acc: 0.4859437751004016
Epoch 189 / 200, learning rate: 9.765625e-07
Epoch 189 / 200, train loss: 0.036300983279943466
Epoch 189 / 200, val loss: 0.0922391265630722
Epoch 189 / 200, val acc: 0.4859437751004016
Epoch 190 / 200, learning rate: 9.765625e-07
Epoch 190 / 200, train loss: 0.03577636182308197
Epoch 190 / 200, val loss: 0.09224406629800797
Epoch 190 / 200, val acc: 0.4859437751004016
Epoch 191 / 200, learning rate: 9.765625e-07
Epoch 191 / 200, train loss: 0.03675185889005661
Epoch 191 / 200, val loss: 0.09224875271320343
Epoch 191 / 200, val acc: 0.4859437751004016
Epoch 192 / 200, learning rate: 9.765625e-07
Epoch 192 / 200, train loss: 0.035892553627491
Epoch 192 / 200, val loss: 0.09225073456764221
Epoch 192 / 200, val acc: 0.4859437751004016
Epoch 193 / 200, learning rate: 9.765625e-07
Epoch 193 / 200, train loss: 0.035546015948057175
Epoch 193 / 200, val loss: 0.09225106984376907
Epoch 193 / 200, val acc: 0.4859437751004016
Epoch 194 / 200, learning rate: 9.765625e-07
Epoch 194 / 200, train loss: 0.03558630496263504
Epoch 194 / 200, val loss: 0.0922515019774437
Epoch 194 / 200, val acc: 0.4859437751004016
Epoch 195 / 200, learning rate: 9.765625e-07
Epoch 195 / 200, train loss: 0.0369560569524765
Epoch 195 / 200, val loss: 0.09225229173898697
Epoch 195 / 200, val acc: 0.4859437751004016
Epoch 196 / 200, learning rate: 9.765625e-07
Epoch 196 / 200, train loss: 0.03496693819761276
Epoch 196 / 200, val loss: 0.09225285053253174
Epoch 196 / 200, val acc: 0.4859437751004016
Epoch 197 / 200, learning rate: 9.765625e-07
Epoch 197 / 200, train loss: 0.03456771373748779
Epoch 197 / 200, val loss: 0.09225208312273026
Epoch 197 / 200, val acc: 0.4859437751004016
Epoch 198 / 200, learning rate: 9.765625e-07
Epoch 198 / 200, train loss: 0.035453516989946365
Epoch 198 / 200, val loss: 0.0922522321343422
Epoch 198 / 200, val acc: 0.4859437751004016
Epoch 199 / 200, learning rate: 9.765625e-07
Epoch 199 / 200, train loss: 0.03660732880234718
Epoch 199 / 200, val loss: 0.09224817156791687
Epoch 199 / 200, val acc: 0.4859437751004016
Epoch 200 / 200, learning rate: 4.8828125e-07
Epoch 200 / 200, train loss: 0.03655049577355385
Epoch 200 / 200, val loss: 0.09224405884742737
Epoch 200 / 200, val acc: 0.4859437751004016
Training finished

Evaluating best model
Trading strategy for stock MBGAF:
After 4999 trading days
Binary accuracy: 0.50820
Fraction of long signals: 0.55511
Fraction of short signals: 0.44489
Overall long return: 2.62889
Overall return: 2.47528
Yearly long return: 0.13252
Yearly return: 0.12478
Daily volatility: 0.02290
Max drawdown baseline: 0.59456
Max drawdown: 0.36819
Sharpe ratio: -0.00134
L1 error baseline: 0.83500
L1 error: 0.10321
Average prediction: 0.00683
Std prediction: 0.96912


Trading strategy for stock MBGAF:
After 250 trading days
Binary accuracy: 0.52610
Fraction of long signals: 0.72000
Fraction of short signals: 0.28000
Overall long return: 0.43435
Overall return: 0.17210
Yearly long return: 0.43782
Yearly return: 0.17347
Daily volatility: 0.01938
Max drawdown baseline: 0.19036
Max drawdown: 0.35359
Sharpe ratio: -0.05399
L1 error baseline: 1.39734
L1 error: 0.13111
Average prediction: 1.35698
Std prediction: 0.65461


