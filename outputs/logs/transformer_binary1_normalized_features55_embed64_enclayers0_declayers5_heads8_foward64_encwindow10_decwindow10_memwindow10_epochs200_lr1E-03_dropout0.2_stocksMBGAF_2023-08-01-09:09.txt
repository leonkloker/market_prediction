Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─MyIdentity: 2-3                             [1, 100, 72]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        259,160
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Sigmoid: 1-7                                     [1, 100, 1]               --
====================================================================================================
Total params: 265,593
Trainable params: 265,593
Non-trainable params: 0
Total mult-adds (M): 0.07
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.61
Params size (MB): 0.22
Estimated Total Size (MB): 1.88
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.7203935980796814
Epoch 1 / 200, val loss: 0.6934364438056946
Epoch 1 / 200, val acc: 0.52
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.6970868706703186
Epoch 2 / 200, val loss: 0.6950209140777588
Epoch 2 / 200, val acc: 0.504
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.6971046924591064
Epoch 3 / 200, val loss: 0.6959400773048401
Epoch 3 / 200, val acc: 0.504
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.6951552629470825
Epoch 4 / 200, val loss: 0.6935436129570007
Epoch 4 / 200, val acc: 0.524
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.6966855525970459
Epoch 5 / 200, val loss: 0.6927950978279114
Epoch 5 / 200, val acc: 0.508
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.6952531337738037
Epoch 6 / 200, val loss: 0.6943277716636658
Epoch 6 / 200, val acc: 0.512
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.6954893469810486
Epoch 7 / 200, val loss: 0.6949973106384277
Epoch 7 / 200, val acc: 0.496
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.6940129399299622
Epoch 8 / 200, val loss: 0.6943876147270203
Epoch 8 / 200, val acc: 0.496
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.6950010061264038
Epoch 9 / 200, val loss: 0.693755567073822
Epoch 9 / 200, val acc: 0.496
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.6919901371002197
Epoch 10 / 200, val loss: 0.6934874653816223
Epoch 10 / 200, val acc: 0.496
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.6928117275238037
Epoch 11 / 200, val loss: 0.6933620572090149
Epoch 11 / 200, val acc: 0.464
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.6924282908439636
Epoch 12 / 200, val loss: 0.6933178901672363
Epoch 12 / 200, val acc: 0.5
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.6931145191192627
Epoch 13 / 200, val loss: 0.6933538317680359
Epoch 13 / 200, val acc: 0.504
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.6926215291023254
Epoch 14 / 200, val loss: 0.6935148239135742
Epoch 14 / 200, val acc: 0.504
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.6926869750022888
Epoch 15 / 200, val loss: 0.6934990286827087
Epoch 15 / 200, val acc: 0.504
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.692226231098175
Epoch 16 / 200, val loss: 0.6934542655944824
Epoch 16 / 200, val acc: 0.504
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.6929439902305603
Epoch 17 / 200, val loss: 0.6934740543365479
Epoch 17 / 200, val acc: 0.504
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.69261634349823
Epoch 18 / 200, val loss: 0.6934688091278076
Epoch 18 / 200, val acc: 0.504
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.6923840045928955
Epoch 19 / 200, val loss: 0.6934516429901123
Epoch 19 / 200, val acc: 0.504
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.6925171613693237
Epoch 20 / 200, val loss: 0.6934357285499573
Epoch 20 / 200, val acc: 0.5
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.6921006441116333
Epoch 21 / 200, val loss: 0.6934151649475098
Epoch 21 / 200, val acc: 0.492
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.6921308040618896
Epoch 22 / 200, val loss: 0.6934055685997009
Epoch 22 / 200, val acc: 0.488
Epoch 23 / 200, learning rate: 0.0005
Epoch 23 / 200, train loss: 0.6925467252731323
Epoch 23 / 200, val loss: 0.6933855414390564
Epoch 23 / 200, val acc: 0.488
Epoch 24 / 200, learning rate: 0.0005
Epoch 24 / 200, train loss: 0.69286048412323
Epoch 24 / 200, val loss: 0.6933804154396057
Epoch 24 / 200, val acc: 0.488
Epoch 25 / 200, learning rate: 0.0005
Epoch 25 / 200, train loss: 0.6923454999923706
Epoch 25 / 200, val loss: 0.693406343460083
Epoch 25 / 200, val acc: 0.488
Epoch 26 / 200, learning rate: 0.0005
Epoch 26 / 200, train loss: 0.6923778653144836
Epoch 26 / 200, val loss: 0.6934570670127869
Epoch 26 / 200, val acc: 0.492
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.6926621794700623
Epoch 27 / 200, val loss: 0.6934289336204529
Epoch 27 / 200, val acc: 0.488
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.6929119229316711
Epoch 28 / 200, val loss: 0.6934194564819336
Epoch 28 / 200, val acc: 0.492
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.6920671463012695
Epoch 29 / 200, val loss: 0.6934170722961426
Epoch 29 / 200, val acc: 0.476
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.6927589774131775
Epoch 30 / 200, val loss: 0.6934048533439636
Epoch 30 / 200, val acc: 0.464
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.6922169923782349
Epoch 31 / 200, val loss: 0.6933791041374207
Epoch 31 / 200, val acc: 0.452
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.6925851702690125
Epoch 32 / 200, val loss: 0.6933360695838928
Epoch 32 / 200, val acc: 0.452
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.6921166777610779
Epoch 33 / 200, val loss: 0.6932969093322754
Epoch 33 / 200, val acc: 0.464
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.6924212574958801
Epoch 34 / 200, val loss: 0.6932529807090759
Epoch 34 / 200, val acc: 0.512
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.6925184726715088
Epoch 35 / 200, val loss: 0.6932288408279419
Epoch 35 / 200, val acc: 0.52
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.6920267343521118
Epoch 36 / 200, val loss: 0.6932076215744019
Epoch 36 / 200, val acc: 0.536
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.6925822496414185
Epoch 37 / 200, val loss: 0.6932103037834167
Epoch 37 / 200, val acc: 0.532
Epoch 38 / 200, learning rate: 0.000125
Epoch 38 / 200, train loss: 0.6922473907470703
Epoch 38 / 200, val loss: 0.6932135820388794
Epoch 38 / 200, val acc: 0.532
Epoch 39 / 200, learning rate: 0.000125
Epoch 39 / 200, train loss: 0.6920835375785828
Epoch 39 / 200, val loss: 0.6932108402252197
Epoch 39 / 200, val acc: 0.532
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.6934406161308289
Epoch 40 / 200, val loss: 0.6932116150856018
Epoch 40 / 200, val acc: 0.528
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.6920797824859619
Epoch 41 / 200, val loss: 0.693212628364563
Epoch 41 / 200, val acc: 0.532
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.6915796995162964
Epoch 42 / 200, val loss: 0.6932122111320496
Epoch 42 / 200, val acc: 0.532
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.6924084424972534
Epoch 43 / 200, val loss: 0.6932138800621033
Epoch 43 / 200, val acc: 0.528
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.692070722579956
Epoch 44 / 200, val loss: 0.6932154893875122
Epoch 44 / 200, val acc: 0.528
Epoch 45 / 200, learning rate: 0.000125
Epoch 45 / 200, train loss: 0.6928026080131531
Epoch 45 / 200, val loss: 0.6932147741317749
Epoch 45 / 200, val acc: 0.52
Epoch 46 / 200, learning rate: 0.000125
Epoch 46 / 200, train loss: 0.692781388759613
Epoch 46 / 200, val loss: 0.6932144165039062
Epoch 46 / 200, val acc: 0.512
Epoch 47 / 200, learning rate: 0.000125
Epoch 47 / 200, train loss: 0.6920078992843628
Epoch 47 / 200, val loss: 0.6932158470153809
Epoch 47 / 200, val acc: 0.532
Epoch 48 / 200, learning rate: 0.000125
Epoch 48 / 200, train loss: 0.6921773552894592
Epoch 48 / 200, val loss: 0.6932161450386047
Epoch 48 / 200, val acc: 0.528
Epoch 49 / 200, learning rate: 6.25e-05
Epoch 49 / 200, train loss: 0.6922218799591064
Epoch 49 / 200, val loss: 0.6932159066200256
Epoch 49 / 200, val acc: 0.532
Epoch 50 / 200, learning rate: 6.25e-05
Epoch 50 / 200, train loss: 0.692757248878479
Epoch 50 / 200, val loss: 0.693215548992157
Epoch 50 / 200, val acc: 0.532
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.6919512152671814
Epoch 51 / 200, val loss: 0.6932147741317749
Epoch 51 / 200, val acc: 0.532
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.691472589969635
Epoch 52 / 200, val loss: 0.6932136416435242
Epoch 52 / 200, val acc: 0.532
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.6918977499008179
Epoch 53 / 200, val loss: 0.6932110786437988
Epoch 53 / 200, val acc: 0.532
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.6929382085800171
Epoch 54 / 200, val loss: 0.6932101845741272
Epoch 54 / 200, val acc: 0.536
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.6920270323753357
Epoch 55 / 200, val loss: 0.6932111978530884
Epoch 55 / 200, val acc: 0.548
Epoch 56 / 200, learning rate: 6.25e-05
Epoch 56 / 200, train loss: 0.6918102502822876
Epoch 56 / 200, val loss: 0.6932124495506287
Epoch 56 / 200, val acc: 0.54
Epoch 57 / 200, learning rate: 6.25e-05
Epoch 57 / 200, train loss: 0.691818356513977
Epoch 57 / 200, val loss: 0.6932144165039062
Epoch 57 / 200, val acc: 0.536
Epoch 58 / 200, learning rate: 6.25e-05
Epoch 58 / 200, train loss: 0.6919301748275757
Epoch 58 / 200, val loss: 0.6932149529457092
Epoch 58 / 200, val acc: 0.54
Epoch 59 / 200, learning rate: 6.25e-05
Epoch 59 / 200, train loss: 0.6923080682754517
Epoch 59 / 200, val loss: 0.6932143568992615
Epoch 59 / 200, val acc: 0.544
Epoch 60 / 200, learning rate: 3.125e-05
Epoch 60 / 200, train loss: 0.6918262839317322
Epoch 60 / 200, val loss: 0.693213701248169
Epoch 60 / 200, val acc: 0.528
Epoch 61 / 200, learning rate: 3.125e-05
Epoch 61 / 200, train loss: 0.6910989880561829
Epoch 61 / 200, val loss: 0.6932130455970764
Epoch 61 / 200, val acc: 0.532
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.6920160055160522
Epoch 62 / 200, val loss: 0.6932123303413391
Epoch 62 / 200, val acc: 0.528
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.6923174858093262
Epoch 63 / 200, val loss: 0.6932113170623779
Epoch 63 / 200, val acc: 0.528
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.6922599673271179
Epoch 64 / 200, val loss: 0.6932104825973511
Epoch 64 / 200, val acc: 0.528
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.6919000148773193
Epoch 65 / 200, val loss: 0.6932098269462585
Epoch 65 / 200, val acc: 0.528
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.6922484040260315
Epoch 66 / 200, val loss: 0.6932095289230347
Epoch 66 / 200, val acc: 0.524
Epoch 67 / 200, learning rate: 3.125e-05
Epoch 67 / 200, train loss: 0.6918020844459534
Epoch 67 / 200, val loss: 0.6932096481323242
Epoch 67 / 200, val acc: 0.52
Epoch 68 / 200, learning rate: 3.125e-05
Epoch 68 / 200, train loss: 0.6925090551376343
Epoch 68 / 200, val loss: 0.6932094097137451
Epoch 68 / 200, val acc: 0.52
Epoch 69 / 200, learning rate: 3.125e-05
Epoch 69 / 200, train loss: 0.6931021809577942
Epoch 69 / 200, val loss: 0.6932092905044556
Epoch 69 / 200, val acc: 0.52
Epoch 70 / 200, learning rate: 3.125e-05
Epoch 70 / 200, train loss: 0.6920670866966248
Epoch 70 / 200, val loss: 0.6932088732719421
Epoch 70 / 200, val acc: 0.52
Epoch 71 / 200, learning rate: 1.5625e-05
Epoch 71 / 200, train loss: 0.6922010779380798
Epoch 71 / 200, val loss: 0.6932085156440735
Epoch 71 / 200, val acc: 0.512
Epoch 72 / 200, learning rate: 1.5625e-05
Epoch 72 / 200, train loss: 0.6916628479957581
Epoch 72 / 200, val loss: 0.6932082772254944
Epoch 72 / 200, val acc: 0.512
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.6925352811813354
Epoch 73 / 200, val loss: 0.6932081580162048
Epoch 73 / 200, val acc: 0.512
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.6917261481285095
Epoch 74 / 200, val loss: 0.6932081580162048
Epoch 74 / 200, val acc: 0.516
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.6913533806800842
Epoch 75 / 200, val loss: 0.6932079195976257
Epoch 75 / 200, val acc: 0.508
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.6926479339599609
Epoch 76 / 200, val loss: 0.6932075619697571
Epoch 76 / 200, val acc: 0.504
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.6925879716873169
Epoch 77 / 200, val loss: 0.6932070255279541
Epoch 77 / 200, val acc: 0.508
Epoch 78 / 200, learning rate: 1.5625e-05
Epoch 78 / 200, train loss: 0.6919373869895935
Epoch 78 / 200, val loss: 0.6932064294815063
Epoch 78 / 200, val acc: 0.508
Epoch 79 / 200, learning rate: 1.5625e-05
Epoch 79 / 200, train loss: 0.6923539638519287
Epoch 79 / 200, val loss: 0.6932059526443481
Epoch 79 / 200, val acc: 0.504
Epoch 80 / 200, learning rate: 1.5625e-05
Epoch 80 / 200, train loss: 0.6926206350326538
Epoch 80 / 200, val loss: 0.6932053565979004
Epoch 80 / 200, val acc: 0.504
Epoch 81 / 200, learning rate: 1.5625e-05
Epoch 81 / 200, train loss: 0.6920278072357178
Epoch 81 / 200, val loss: 0.6932045817375183
Epoch 81 / 200, val acc: 0.5
Epoch 82 / 200, learning rate: 7.8125e-06
Epoch 82 / 200, train loss: 0.693040668964386
Epoch 82 / 200, val loss: 0.693203866481781
Epoch 82 / 200, val acc: 0.508
Epoch 83 / 200, learning rate: 7.8125e-06
Epoch 83 / 200, train loss: 0.6921164393424988
Epoch 83 / 200, val loss: 0.6932036280632019
Epoch 83 / 200, val acc: 0.512
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.6922116875648499
Epoch 84 / 200, val loss: 0.6932033896446228
Epoch 84 / 200, val acc: 0.512
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.6924146413803101
Epoch 85 / 200, val loss: 0.6932031512260437
Epoch 85 / 200, val acc: 0.512
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.6926007270812988
Epoch 86 / 200, val loss: 0.6932029128074646
Epoch 86 / 200, val acc: 0.512
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.6917882561683655
Epoch 87 / 200, val loss: 0.6932026743888855
Epoch 87 / 200, val acc: 0.512
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.6914120316505432
Epoch 88 / 200, val loss: 0.6932024359703064
Epoch 88 / 200, val acc: 0.508
Epoch 89 / 200, learning rate: 7.8125e-06
Epoch 89 / 200, train loss: 0.6923617124557495
Epoch 89 / 200, val loss: 0.6932021975517273
Epoch 89 / 200, val acc: 0.508
Epoch 90 / 200, learning rate: 7.8125e-06
Epoch 90 / 200, train loss: 0.69205242395401
Epoch 90 / 200, val loss: 0.6932019591331482
Epoch 90 / 200, val acc: 0.508
Epoch 91 / 200, learning rate: 7.8125e-06
Epoch 91 / 200, train loss: 0.6932493448257446
Epoch 91 / 200, val loss: 0.6932018399238586
Epoch 91 / 200, val acc: 0.512
Epoch 92 / 200, learning rate: 7.8125e-06
Epoch 92 / 200, train loss: 0.6923961043357849
Epoch 92 / 200, val loss: 0.6932015419006348
Epoch 92 / 200, val acc: 0.508
Epoch 93 / 200, learning rate: 3.90625e-06
Epoch 93 / 200, train loss: 0.6921724081039429
Epoch 93 / 200, val loss: 0.6932010650634766
Epoch 93 / 200, val acc: 0.508
Epoch 94 / 200, learning rate: 3.90625e-06
Epoch 94 / 200, train loss: 0.6917889714241028
Epoch 94 / 200, val loss: 0.6932007670402527
Epoch 94 / 200, val acc: 0.508
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.692148745059967
Epoch 95 / 200, val loss: 0.6932004690170288
Epoch 95 / 200, val acc: 0.504
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.6924443244934082
Epoch 96 / 200, val loss: 0.693200409412384
Epoch 96 / 200, val acc: 0.504
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.6924946308135986
Epoch 97 / 200, val loss: 0.6932002902030945
Epoch 97 / 200, val acc: 0.504
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.6921722292900085
Epoch 98 / 200, val loss: 0.6932001113891602
Epoch 98 / 200, val acc: 0.504
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.6917727589607239
Epoch 99 / 200, val loss: 0.693199872970581
Epoch 99 / 200, val acc: 0.5
Epoch 100 / 200, learning rate: 3.90625e-06
Epoch 100 / 200, train loss: 0.6923770308494568
Epoch 100 / 200, val loss: 0.693199634552002
Epoch 100 / 200, val acc: 0.496
Epoch 101 / 200, learning rate: 3.90625e-06
Epoch 101 / 200, train loss: 0.6918672919273376
Epoch 101 / 200, val loss: 0.6931994557380676
Epoch 101 / 200, val acc: 0.496
Epoch 102 / 200, learning rate: 3.90625e-06
Epoch 102 / 200, train loss: 0.692181408405304
Epoch 102 / 200, val loss: 0.6931993365287781
Epoch 102 / 200, val acc: 0.496
Epoch 103 / 200, learning rate: 3.90625e-06
Epoch 103 / 200, train loss: 0.6925414800643921
Epoch 103 / 200, val loss: 0.6931991577148438
Epoch 103 / 200, val acc: 0.496
Epoch 104 / 200, learning rate: 1.953125e-06
Epoch 104 / 200, train loss: 0.6915302872657776
Epoch 104 / 200, val loss: 0.693199098110199
Epoch 104 / 200, val acc: 0.496
Epoch 105 / 200, learning rate: 1.953125e-06
Epoch 105 / 200, train loss: 0.6928410530090332
Epoch 105 / 200, val loss: 0.6931989789009094
Epoch 105 / 200, val acc: 0.496
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.6926692724227905
Epoch 106 / 200, val loss: 0.6931989789009094
Epoch 106 / 200, val acc: 0.492
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.6918018460273743
Epoch 107 / 200, val loss: 0.693199098110199
Epoch 107 / 200, val acc: 0.488
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.6930230259895325
Epoch 108 / 200, val loss: 0.693199098110199
Epoch 108 / 200, val acc: 0.488
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.6921890377998352
Epoch 109 / 200, val loss: 0.6931989789009094
Epoch 109 / 200, val acc: 0.488
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.6927804946899414
Epoch 110 / 200, val loss: 0.6931988596916199
Epoch 110 / 200, val acc: 0.492
Epoch 111 / 200, learning rate: 1.953125e-06
Epoch 111 / 200, train loss: 0.6922604441642761
Epoch 111 / 200, val loss: 0.6931988596916199
Epoch 111 / 200, val acc: 0.496
Epoch 112 / 200, learning rate: 1.953125e-06
Epoch 112 / 200, train loss: 0.691778838634491
Epoch 112 / 200, val loss: 0.6931988596916199
Epoch 112 / 200, val acc: 0.496
Epoch 113 / 200, learning rate: 1.953125e-06
Epoch 113 / 200, train loss: 0.6918778419494629
Epoch 113 / 200, val loss: 0.6931988000869751
Epoch 113 / 200, val acc: 0.492
Epoch 114 / 200, learning rate: 1.953125e-06
Epoch 114 / 200, train loss: 0.6924965977668762
Epoch 114 / 200, val loss: 0.6931988000869751
Epoch 114 / 200, val acc: 0.496
Epoch 115 / 200, learning rate: 9.765625e-07
Epoch 115 / 200, train loss: 0.6918262243270874
Epoch 115 / 200, val loss: 0.6931988596916199
Epoch 115 / 200, val acc: 0.492
Epoch 116 / 200, learning rate: 9.765625e-07
Epoch 116 / 200, train loss: 0.6923227310180664
Epoch 116 / 200, val loss: 0.6931988000869751
Epoch 116 / 200, val acc: 0.492
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.6920837163925171
Epoch 117 / 200, val loss: 0.6931988000869751
Epoch 117 / 200, val acc: 0.492
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.692699134349823
Epoch 118 / 200, val loss: 0.6931987404823303
Epoch 118 / 200, val acc: 0.492
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.6915452480316162
Epoch 119 / 200, val loss: 0.6931987404823303
Epoch 119 / 200, val acc: 0.492
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.6909713745117188
Epoch 120 / 200, val loss: 0.6931987404823303
Epoch 120 / 200, val acc: 0.492
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.6918671131134033
Epoch 121 / 200, val loss: 0.6931986808776855
Epoch 121 / 200, val acc: 0.492
Epoch 122 / 200, learning rate: 9.765625e-07
Epoch 122 / 200, train loss: 0.6917290091514587
Epoch 122 / 200, val loss: 0.6931986212730408
Epoch 122 / 200, val acc: 0.496
Epoch 123 / 200, learning rate: 9.765625e-07
Epoch 123 / 200, train loss: 0.6922361254692078
Epoch 123 / 200, val loss: 0.6931986212730408
Epoch 123 / 200, val acc: 0.496
Epoch 124 / 200, learning rate: 9.765625e-07
Epoch 124 / 200, train loss: 0.6929029822349548
Epoch 124 / 200, val loss: 0.6931986212730408
Epoch 124 / 200, val acc: 0.496
Epoch 125 / 200, learning rate: 9.765625e-07
Epoch 125 / 200, train loss: 0.692251980304718
Epoch 125 / 200, val loss: 0.6931986212730408
Epoch 125 / 200, val acc: 0.496
Epoch 126 / 200, learning rate: 4.8828125e-07
Epoch 126 / 200, train loss: 0.691631555557251
Epoch 126 / 200, val loss: 0.6931986212730408
Epoch 126 / 200, val acc: 0.496
Epoch 127 / 200, learning rate: 4.8828125e-07
Epoch 127 / 200, train loss: 0.6919626593589783
Epoch 127 / 200, val loss: 0.6931986212730408
Epoch 127 / 200, val acc: 0.496
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.6921245455741882
Epoch 128 / 200, val loss: 0.6931986212730408
Epoch 128 / 200, val acc: 0.496
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.6921151280403137
Epoch 129 / 200, val loss: 0.6931986212730408
Epoch 129 / 200, val acc: 0.496
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.6921957731246948
Epoch 130 / 200, val loss: 0.6931986212730408
Epoch 130 / 200, val acc: 0.496
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.691717267036438
Epoch 131 / 200, val loss: 0.6931985020637512
Epoch 131 / 200, val acc: 0.496
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.6922169327735901
Epoch 132 / 200, val loss: 0.6931985020637512
Epoch 132 / 200, val acc: 0.492
Epoch 133 / 200, learning rate: 4.8828125e-07
Epoch 133 / 200, train loss: 0.6915671825408936
Epoch 133 / 200, val loss: 0.6931985020637512
Epoch 133 / 200, val acc: 0.492
Epoch 134 / 200, learning rate: 4.8828125e-07
Epoch 134 / 200, train loss: 0.6919586658477783
Epoch 134 / 200, val loss: 0.6931985020637512
Epoch 134 / 200, val acc: 0.492
Epoch 135 / 200, learning rate: 4.8828125e-07
Epoch 135 / 200, train loss: 0.6926484704017639
Epoch 135 / 200, val loss: 0.693198561668396
Epoch 135 / 200, val acc: 0.492
Epoch 136 / 200, learning rate: 4.8828125e-07
Epoch 136 / 200, train loss: 0.6927099823951721
Epoch 136 / 200, val loss: 0.693198561668396
Epoch 136 / 200, val acc: 0.492
Epoch 137 / 200, learning rate: 2.44140625e-07
Epoch 137 / 200, train loss: 0.692566990852356
Epoch 137 / 200, val loss: 0.693198561668396
Epoch 137 / 200, val acc: 0.492
Epoch 138 / 200, learning rate: 2.44140625e-07
Epoch 138 / 200, train loss: 0.6926308870315552
Epoch 138 / 200, val loss: 0.6931985020637512
Epoch 138 / 200, val acc: 0.492
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.6922550201416016
Epoch 139 / 200, val loss: 0.6931985020637512
Epoch 139 / 200, val acc: 0.492
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.6931125521659851
Epoch 140 / 200, val loss: 0.6931985020637512
Epoch 140 / 200, val acc: 0.492
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.6921188235282898
Epoch 141 / 200, val loss: 0.6931985020637512
Epoch 141 / 200, val acc: 0.492
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.6916583180427551
Epoch 142 / 200, val loss: 0.693198561668396
Epoch 142 / 200, val acc: 0.492
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.6918756365776062
Epoch 143 / 200, val loss: 0.693198561668396
Epoch 143 / 200, val acc: 0.492
Epoch 144 / 200, learning rate: 2.44140625e-07
Epoch 144 / 200, train loss: 0.6927006244659424
Epoch 144 / 200, val loss: 0.693198561668396
Epoch 144 / 200, val acc: 0.492
Epoch 145 / 200, learning rate: 2.44140625e-07
Epoch 145 / 200, train loss: 0.6924380660057068
Epoch 145 / 200, val loss: 0.693198561668396
Epoch 145 / 200, val acc: 0.492
Epoch 146 / 200, learning rate: 2.44140625e-07
Epoch 146 / 200, train loss: 0.6920580863952637
Epoch 146 / 200, val loss: 0.693198561668396
Epoch 146 / 200, val acc: 0.496
Epoch 147 / 200, learning rate: 2.44140625e-07
Epoch 147 / 200, train loss: 0.6922273635864258
Epoch 147 / 200, val loss: 0.6931986212730408
Epoch 147 / 200, val acc: 0.496
Epoch 148 / 200, learning rate: 1.220703125e-07
Epoch 148 / 200, train loss: 0.6924912929534912
Epoch 148 / 200, val loss: 0.6931986212730408
Epoch 148 / 200, val acc: 0.496
Epoch 149 / 200, learning rate: 1.220703125e-07
Epoch 149 / 200, train loss: 0.6917149424552917
Epoch 149 / 200, val loss: 0.6931986212730408
Epoch 149 / 200, val acc: 0.496
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.6917402148246765
Epoch 150 / 200, val loss: 0.6931986212730408
Epoch 150 / 200, val acc: 0.496
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.6918165683746338
Epoch 151 / 200, val loss: 0.6931986212730408
Epoch 151 / 200, val acc: 0.496
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.6928011178970337
Epoch 152 / 200, val loss: 0.6931986212730408
Epoch 152 / 200, val acc: 0.496
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.692701518535614
Epoch 153 / 200, val loss: 0.6931986212730408
Epoch 153 / 200, val acc: 0.496
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.6928920745849609
Epoch 154 / 200, val loss: 0.6931986212730408
Epoch 154 / 200, val acc: 0.496
Epoch 155 / 200, learning rate: 1.220703125e-07
Epoch 155 / 200, train loss: 0.6926001906394958
Epoch 155 / 200, val loss: 0.6931986212730408
Epoch 155 / 200, val acc: 0.496
Epoch 156 / 200, learning rate: 1.220703125e-07
Epoch 156 / 200, train loss: 0.6920924782752991
Epoch 156 / 200, val loss: 0.6931986212730408
Epoch 156 / 200, val acc: 0.496
Epoch 157 / 200, learning rate: 1.220703125e-07
Epoch 157 / 200, train loss: 0.6929552555084229
Epoch 157 / 200, val loss: 0.693198561668396
Epoch 157 / 200, val acc: 0.496
Epoch 158 / 200, learning rate: 1.220703125e-07
Epoch 158 / 200, train loss: 0.6911165714263916
Epoch 158 / 200, val loss: 0.693198561668396
Epoch 158 / 200, val acc: 0.496
Epoch 159 / 200, learning rate: 1e-07
Epoch 159 / 200, train loss: 0.6922816038131714
Epoch 159 / 200, val loss: 0.6931985020637512
Epoch 159 / 200, val acc: 0.496
Epoch 160 / 200, learning rate: 1e-07
Epoch 160 / 200, train loss: 0.6926601529121399
Epoch 160 / 200, val loss: 0.693198561668396
Epoch 160 / 200, val acc: 0.496
Epoch 161 / 200, learning rate: 1e-07
Epoch 161 / 200, train loss: 0.6912898421287537
Epoch 161 / 200, val loss: 0.693198561668396
Epoch 161 / 200, val acc: 0.496
Epoch 162 / 200, learning rate: 1e-07
Epoch 162 / 200, train loss: 0.6915649771690369
Epoch 162 / 200, val loss: 0.6931985020637512
Epoch 162 / 200, val acc: 0.496
Epoch 163 / 200, learning rate: 1e-07
Epoch 163 / 200, train loss: 0.6924991607666016
Epoch 163 / 200, val loss: 0.6931985020637512
Epoch 163 / 200, val acc: 0.496
Epoch 164 / 200, learning rate: 1e-07
Epoch 164 / 200, train loss: 0.692486584186554
Epoch 164 / 200, val loss: 0.6931985020637512
Epoch 164 / 200, val acc: 0.496
Epoch 165 / 200, learning rate: 1e-07
Epoch 165 / 200, train loss: 0.6923494935035706
Epoch 165 / 200, val loss: 0.693198561668396
Epoch 165 / 200, val acc: 0.496
Epoch 166 / 200, learning rate: 1e-07
Epoch 166 / 200, train loss: 0.692179262638092
Epoch 166 / 200, val loss: 0.693198561668396
Epoch 166 / 200, val acc: 0.496
Epoch 167 / 200, learning rate: 1e-07
Epoch 167 / 200, train loss: 0.6927027106285095
Epoch 167 / 200, val loss: 0.693198561668396
Epoch 167 / 200, val acc: 0.496
Epoch 168 / 200, learning rate: 1e-07
Epoch 168 / 200, train loss: 0.6917726993560791
Epoch 168 / 200, val loss: 0.693198561668396
Epoch 168 / 200, val acc: 0.496
Epoch 169 / 200, learning rate: 1e-07
Epoch 169 / 200, train loss: 0.6923098564147949
Epoch 169 / 200, val loss: 0.693198561668396
Epoch 169 / 200, val acc: 0.496
Epoch 170 / 200, learning rate: 1e-07
Epoch 170 / 200, train loss: 0.6916211247444153
Epoch 170 / 200, val loss: 0.693198561668396
Epoch 170 / 200, val acc: 0.496
Epoch 171 / 200, learning rate: 1e-07
Epoch 171 / 200, train loss: 0.6924217343330383
Epoch 171 / 200, val loss: 0.6931985020637512
Epoch 171 / 200, val acc: 0.496
Epoch 172 / 200, learning rate: 1e-07
Epoch 172 / 200, train loss: 0.6918234825134277
Epoch 172 / 200, val loss: 0.693198561668396
Epoch 172 / 200, val acc: 0.496
Epoch 173 / 200, learning rate: 1e-07
Epoch 173 / 200, train loss: 0.6924217939376831
Epoch 173 / 200, val loss: 0.6931985020637512
Epoch 173 / 200, val acc: 0.492
Epoch 174 / 200, learning rate: 1e-07
Epoch 174 / 200, train loss: 0.6928285956382751
Epoch 174 / 200, val loss: 0.6931985020637512
Epoch 174 / 200, val acc: 0.492
Epoch 175 / 200, learning rate: 1e-07
Epoch 175 / 200, train loss: 0.6926957368850708
Epoch 175 / 200, val loss: 0.6931985020637512
Epoch 175 / 200, val acc: 0.496
Epoch 176 / 200, learning rate: 1e-07
Epoch 176 / 200, train loss: 0.6924331188201904
Epoch 176 / 200, val loss: 0.6931985020637512
Epoch 176 / 200, val acc: 0.496
Epoch 177 / 200, learning rate: 1e-07
Epoch 177 / 200, train loss: 0.6924871206283569
Epoch 177 / 200, val loss: 0.6931985020637512
Epoch 177 / 200, val acc: 0.496
Epoch 178 / 200, learning rate: 1e-07
Epoch 178 / 200, train loss: 0.6930428743362427
Epoch 178 / 200, val loss: 0.693198561668396
Epoch 178 / 200, val acc: 0.496
Epoch 179 / 200, learning rate: 1e-07
Epoch 179 / 200, train loss: 0.6911724209785461
Epoch 179 / 200, val loss: 0.693198561668396
Epoch 179 / 200, val acc: 0.496
Epoch 180 / 200, learning rate: 1e-07
Epoch 180 / 200, train loss: 0.6921871900558472
Epoch 180 / 200, val loss: 0.6931985020637512
Epoch 180 / 200, val acc: 0.496
Epoch 181 / 200, learning rate: 1e-07
Epoch 181 / 200, train loss: 0.6925326585769653
Epoch 181 / 200, val loss: 0.693198561668396
Epoch 181 / 200, val acc: 0.496
Epoch 182 / 200, learning rate: 1e-07
Epoch 182 / 200, train loss: 0.691596508026123
Epoch 182 / 200, val loss: 0.693198561668396
Epoch 182 / 200, val acc: 0.496
Epoch 183 / 200, learning rate: 1e-07
Epoch 183 / 200, train loss: 0.6926902532577515
Epoch 183 / 200, val loss: 0.6931986212730408
Epoch 183 / 200, val acc: 0.496
Epoch 184 / 200, learning rate: 1e-07
Epoch 184 / 200, train loss: 0.6921268701553345
Epoch 184 / 200, val loss: 0.693198561668396
Epoch 184 / 200, val acc: 0.496
Epoch 185 / 200, learning rate: 1e-07
Epoch 185 / 200, train loss: 0.6919947266578674
Epoch 185 / 200, val loss: 0.6931986212730408
Epoch 185 / 200, val acc: 0.496
Epoch 186 / 200, learning rate: 1e-07
Epoch 186 / 200, train loss: 0.6924362182617188
Epoch 186 / 200, val loss: 0.6931986212730408
Epoch 186 / 200, val acc: 0.496
Epoch 187 / 200, learning rate: 1e-07
Epoch 187 / 200, train loss: 0.6925209760665894
Epoch 187 / 200, val loss: 0.6931986212730408
Epoch 187 / 200, val acc: 0.496
Epoch 188 / 200, learning rate: 1e-07
Epoch 188 / 200, train loss: 0.6926708221435547
Epoch 188 / 200, val loss: 0.693198561668396
Epoch 188 / 200, val acc: 0.492
Epoch 189 / 200, learning rate: 1e-07
Epoch 189 / 200, train loss: 0.6919239163398743
Epoch 189 / 200, val loss: 0.6931986212730408
Epoch 189 / 200, val acc: 0.492
Epoch 190 / 200, learning rate: 1e-07
Epoch 190 / 200, train loss: 0.6920495629310608
Epoch 190 / 200, val loss: 0.6931986212730408
Epoch 190 / 200, val acc: 0.492
Epoch 191 / 200, learning rate: 1e-07
Epoch 191 / 200, train loss: 0.6928195357322693
Epoch 191 / 200, val loss: 0.6931986212730408
Epoch 191 / 200, val acc: 0.492
Epoch 192 / 200, learning rate: 1e-07
Epoch 192 / 200, train loss: 0.692587673664093
Epoch 192 / 200, val loss: 0.6931986212730408
Epoch 192 / 200, val acc: 0.492
Epoch 193 / 200, learning rate: 1e-07
Epoch 193 / 200, train loss: 0.6920261979103088
Epoch 193 / 200, val loss: 0.6931986212730408
Epoch 193 / 200, val acc: 0.492
Epoch 194 / 200, learning rate: 1e-07
Epoch 194 / 200, train loss: 0.6919963955879211
Epoch 194 / 200, val loss: 0.6931986212730408
Epoch 194 / 200, val acc: 0.492
Epoch 195 / 200, learning rate: 1e-07
Epoch 195 / 200, train loss: 0.6919305324554443
Epoch 195 / 200, val loss: 0.6931986212730408
Epoch 195 / 200, val acc: 0.492
Epoch 196 / 200, learning rate: 1e-07
Epoch 196 / 200, train loss: 0.6920658946037292
Epoch 196 / 200, val loss: 0.6931986212730408
Epoch 196 / 200, val acc: 0.492
Epoch 197 / 200, learning rate: 1e-07
Epoch 197 / 200, train loss: 0.6921805143356323
Epoch 197 / 200, val loss: 0.6931986212730408
Epoch 197 / 200, val acc: 0.492
Epoch 198 / 200, learning rate: 1e-07
Epoch 198 / 200, train loss: 0.6916115283966064
Epoch 198 / 200, val loss: 0.6931986212730408
Epoch 198 / 200, val acc: 0.492
Epoch 199 / 200, learning rate: 1e-07
Epoch 199 / 200, train loss: 0.692541241645813
Epoch 199 / 200, val loss: 0.6931986212730408
Epoch 199 / 200, val acc: 0.492
Epoch 200 / 200, learning rate: 1e-07
Epoch 200 / 200, train loss: 0.6920254826545715
Epoch 200 / 200, val loss: 0.6931986212730408
Epoch 200 / 200, val acc: 0.492
Training finished

Evaluating best model
Trading strategy for stock MBGAF:
After 4999 trading days
Binary accuracy: 0.51390
Fraction of long signals: 0.92599
Fraction of short signals: 0.07401
Overall long return: 110.18614
Overall return: 94.79899
Yearly long return: 5.55449
Yearly return: 4.77882
Daily volatility: 0.21373
Max drawdown baseline: 0.19067
Max drawdown: 0.05816
Sharpe ratio: -0.01438
Average prediction: 0.51896
Std prediction: 0.01426


Trading strategy for stock MBGAF:
After 250 trading days
Binary accuracy: 0.50400
Fraction of long signals: 0.56000
Fraction of short signals: 0.44000
Overall long return: 5.83651
Overall return: 1.06118
Yearly long return: 5.88320
Yearly return: 1.06967
Daily volatility: 0.22121
Max drawdown baseline: 0.19067
Max drawdown: 0.61644
Sharpe ratio: -0.08627
Average prediction: 0.50608
Std prediction: 0.01766


