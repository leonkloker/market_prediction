Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              384
├─Time2Vec: 1-2                                    [1, 100, 36]              --
│    └─Linear: 2-1                                 [100, 4]                  8
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 36]              (recursive)
│    └─Linear: 2-2                                 [100, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 36]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 36]              --
│    │    └─ModuleList: 3-1                        --                        23,532
│    │    └─LayerNorm: 3-2                         [1, 100, 36]              72
│    └─TransformerDecoder: 2-4                     [1, 100, 36]              --
│    │    └─ModuleList: 3-3                        --                        39,732
│    │    └─LayerNorm: 3-4                         [1, 100, 36]              72
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 18]              666
│    └─Dropout: 2-6                                [1, 100, 18]              --
│    └─ReLU: 2-7                                   [1, 100, 18]              --
│    └─Linear: 2-8                                 [1, 100, 1]               19
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 64,485
Trainable params: 64,485
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.55
Params size (MB): 0.04
Estimated Total Size (MB): 0.60
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.6935976147651672
Epoch 1 / 200, val loss: 7.181105613708496
Epoch 1 / 200, val acc: 0.4804177545691906
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.4735719859600067
Epoch 2 / 200, val loss: 8.907066345214844
Epoch 2 / 200, val acc: 0.4856396866840731
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.47741013765335083
Epoch 3 / 200, val loss: 8.186729431152344
Epoch 3 / 200, val acc: 0.5352480417754569
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.4602394104003906
Epoch 4 / 200, val loss: 7.424315452575684
Epoch 4 / 200, val acc: 0.4908616187989556
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.43039700388908386
Epoch 5 / 200, val loss: 6.770013332366943
Epoch 5 / 200, val acc: 0.4751958224543081
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.4256213903427124
Epoch 6 / 200, val loss: 6.357202053070068
Epoch 6 / 200, val acc: 0.5091383812010444
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.4310634136199951
Epoch 7 / 200, val loss: 6.221595287322998
Epoch 7 / 200, val acc: 0.5404699738903395
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.4276055693626404
Epoch 8 / 200, val loss: 6.279287338256836
Epoch 8 / 200, val acc: 0.566579634464752
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.42370182275772095
Epoch 9 / 200, val loss: 6.434075355529785
Epoch 9 / 200, val acc: 0.5378590078328982
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.4197593331336975
Epoch 10 / 200, val loss: 6.631922721862793
Epoch 10 / 200, val acc: 0.5195822454308094
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.41528430581092834
Epoch 11 / 200, val loss: 6.805387020111084
Epoch 11 / 200, val acc: 0.5248041775456919
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.41340574622154236
Epoch 12 / 200, val loss: 6.96280574798584
Epoch 12 / 200, val acc: 0.4804177545691906
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.4157298803329468
Epoch 13 / 200, val loss: 7.064689636230469
Epoch 13 / 200, val acc: 0.5274151436031331
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.41519585251808167
Epoch 14 / 200, val loss: 7.103054046630859
Epoch 14 / 200, val acc: 0.46475195822454307
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.4114689230918884
Epoch 15 / 200, val loss: 7.083470821380615
Epoch 15 / 200, val acc: 0.45691906005221933
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.416390985250473
Epoch 16 / 200, val loss: 7.01534366607666
Epoch 16 / 200, val acc: 0.5065274151436031
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.4108210802078247
Epoch 17 / 200, val loss: 6.916238307952881
Epoch 17 / 200, val acc: 0.5430809399477807
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.41090139746665955
Epoch 18 / 200, val loss: 6.807376861572266
Epoch 18 / 200, val acc: 0.5535248041775457
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.40817317366600037
Epoch 19 / 200, val loss: 6.753381729125977
Epoch 19 / 200, val acc: 0.556135770234987
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.4097808003425598
Epoch 20 / 200, val loss: 6.702050685882568
Epoch 20 / 200, val acc: 0.5404699738903395
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.40842869877815247
Epoch 21 / 200, val loss: 6.648148536682129
Epoch 21 / 200, val acc: 0.4908616187989556
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.40848293900489807
Epoch 22 / 200, val loss: 6.612227439880371
Epoch 22 / 200, val acc: 0.5013054830287206
Epoch 23 / 200, learning rate: 0.0005
Epoch 23 / 200, train loss: 0.40719130635261536
Epoch 23 / 200, val loss: 6.593694686889648
Epoch 23 / 200, val acc: 0.5404699738903395
Epoch 24 / 200, learning rate: 0.0005
Epoch 24 / 200, train loss: 0.40895962715148926
Epoch 24 / 200, val loss: 6.582381248474121
Epoch 24 / 200, val acc: 0.5039164490861618
Epoch 25 / 200, learning rate: 0.0005
Epoch 25 / 200, train loss: 0.4099355638027191
Epoch 25 / 200, val loss: 6.577481746673584
Epoch 25 / 200, val acc: 0.5039164490861618
Epoch 26 / 200, learning rate: 0.0005
Epoch 26 / 200, train loss: 0.4090976119041443
Epoch 26 / 200, val loss: 6.579221248626709
Epoch 26 / 200, val acc: 0.5143603133159269
Epoch 27 / 200, learning rate: 0.0005
Epoch 27 / 200, train loss: 0.4081823229789734
Epoch 27 / 200, val loss: 6.587047100067139
Epoch 27 / 200, val acc: 0.4934725848563969
Epoch 28 / 200, learning rate: 0.0005
Epoch 28 / 200, train loss: 0.4085298478603363
Epoch 28 / 200, val loss: 6.604279518127441
Epoch 28 / 200, val acc: 0.577023498694517
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.4074263572692871
Epoch 29 / 200, val loss: 6.628941535949707
Epoch 29 / 200, val acc: 0.5613577023498695
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.40830111503601074
Epoch 30 / 200, val loss: 6.644261360168457
Epoch 30 / 200, val acc: 0.5613577023498695
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.4049180746078491
Epoch 31 / 200, val loss: 6.660453796386719
Epoch 31 / 200, val acc: 0.5430809399477807
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.4094851016998291
Epoch 32 / 200, val loss: 6.677325248718262
Epoch 32 / 200, val acc: 0.5404699738903395
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.4064442813396454
Epoch 33 / 200, val loss: 6.695123195648193
Epoch 33 / 200, val acc: 0.556135770234987
Epoch 34 / 200, learning rate: 0.00025
Epoch 34 / 200, train loss: 0.4096566438674927
Epoch 34 / 200, val loss: 6.7114996910095215
Epoch 34 / 200, val acc: 0.5378590078328982
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.4057123064994812
Epoch 35 / 200, val loss: 6.727741241455078
Epoch 35 / 200, val acc: 0.556135770234987
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.4082596004009247
Epoch 36 / 200, val loss: 6.742586135864258
Epoch 36 / 200, val acc: 0.5718015665796344
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.4070392847061157
Epoch 37 / 200, val loss: 6.756032466888428
Epoch 37 / 200, val acc: 0.5221932114882507
Epoch 38 / 200, learning rate: 0.00025
Epoch 38 / 200, train loss: 0.40887847542762756
Epoch 38 / 200, val loss: 6.767837047576904
Epoch 38 / 200, val acc: 0.4934725848563969
Epoch 39 / 200, learning rate: 0.00025
Epoch 39 / 200, train loss: 0.40800032019615173
Epoch 39 / 200, val loss: 6.776822566986084
Epoch 39 / 200, val acc: 0.47780678851174935
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.40697649121284485
Epoch 40 / 200, val loss: 6.783729076385498
Epoch 40 / 200, val acc: 0.46475195822454307
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.40576815605163574
Epoch 41 / 200, val loss: 6.786216735839844
Epoch 41 / 200, val acc: 0.46736292428198434
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.405913382768631
Epoch 42 / 200, val loss: 6.788121700286865
Epoch 42 / 200, val acc: 0.46475195822454307
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.40848904848098755
Epoch 43 / 200, val loss: 6.789328575134277
Epoch 43 / 200, val acc: 0.4751958224543081
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.4061405062675476
Epoch 44 / 200, val loss: 6.789811611175537
Epoch 44 / 200, val acc: 0.4699738903394256
Epoch 45 / 200, learning rate: 0.000125
Epoch 45 / 200, train loss: 0.4084542989730835
Epoch 45 / 200, val loss: 6.789783477783203
Epoch 45 / 200, val acc: 0.4699738903394256
Epoch 46 / 200, learning rate: 0.000125
Epoch 46 / 200, train loss: 0.4091931879520416
Epoch 46 / 200, val loss: 6.787911891937256
Epoch 46 / 200, val acc: 0.46475195822454307
Epoch 47 / 200, learning rate: 0.000125
Epoch 47 / 200, train loss: 0.40586063265800476
Epoch 47 / 200, val loss: 6.7858123779296875
Epoch 47 / 200, val acc: 0.46475195822454307
Epoch 48 / 200, learning rate: 0.000125
Epoch 48 / 200, train loss: 0.40615278482437134
Epoch 48 / 200, val loss: 6.783389091491699
Epoch 48 / 200, val acc: 0.4490861618798956
Epoch 49 / 200, learning rate: 0.000125
Epoch 49 / 200, train loss: 0.4052656590938568
Epoch 49 / 200, val loss: 6.781152725219727
Epoch 49 / 200, val acc: 0.47780678851174935
Epoch 50 / 200, learning rate: 0.000125
Epoch 50 / 200, train loss: 0.40884461998939514
Epoch 50 / 200, val loss: 6.77891731262207
Epoch 50 / 200, val acc: 0.47780678851174935
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.407509982585907
Epoch 51 / 200, val loss: 6.77681303024292
Epoch 51 / 200, val acc: 0.4699738903394256
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.407875120639801
Epoch 52 / 200, val loss: 6.775865077972412
Epoch 52 / 200, val acc: 0.4725848563968668
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.40867671370506287
Epoch 53 / 200, val loss: 6.774545192718506
Epoch 53 / 200, val acc: 0.4725848563968668
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.4070090353488922
Epoch 54 / 200, val loss: 6.773041725158691
Epoch 54 / 200, val acc: 0.4699738903394256
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.4066888689994812
Epoch 55 / 200, val loss: 6.771491050720215
Epoch 55 / 200, val acc: 0.46736292428198434
Epoch 56 / 200, learning rate: 6.25e-05
Epoch 56 / 200, train loss: 0.4107312262058258
Epoch 56 / 200, val loss: 6.769504070281982
Epoch 56 / 200, val acc: 0.4621409921671018
Epoch 57 / 200, learning rate: 6.25e-05
Epoch 57 / 200, train loss: 0.40635597705841064
Epoch 57 / 200, val loss: 6.767810821533203
Epoch 57 / 200, val acc: 0.46736292428198434
Epoch 58 / 200, learning rate: 6.25e-05
Epoch 58 / 200, train loss: 0.40909650921821594
Epoch 58 / 200, val loss: 6.765866756439209
Epoch 58 / 200, val acc: 0.4699738903394256
Epoch 59 / 200, learning rate: 6.25e-05
Epoch 59 / 200, train loss: 0.40798017382621765
Epoch 59 / 200, val loss: 6.763942241668701
Epoch 59 / 200, val acc: 0.46475195822454307
Epoch 60 / 200, learning rate: 6.25e-05
Epoch 60 / 200, train loss: 0.40785083174705505
Epoch 60 / 200, val loss: 6.761796474456787
Epoch 60 / 200, val acc: 0.4699738903394256
Epoch 61 / 200, learning rate: 6.25e-05
Epoch 61 / 200, train loss: 0.4101512134075165
Epoch 61 / 200, val loss: 6.759633541107178
Epoch 61 / 200, val acc: 0.4751958224543081
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.4066354036331177
Epoch 62 / 200, val loss: 6.757708549499512
Epoch 62 / 200, val acc: 0.4699738903394256
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.4062737822532654
Epoch 63 / 200, val loss: 6.756829261779785
Epoch 63 / 200, val acc: 0.4699738903394256
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.4082231819629669
Epoch 64 / 200, val loss: 6.755985260009766
Epoch 64 / 200, val acc: 0.46736292428198434
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.4092003107070923
Epoch 65 / 200, val loss: 6.755176067352295
Epoch 65 / 200, val acc: 0.4725848563968668
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.40724655985832214
Epoch 66 / 200, val loss: 6.754463195800781
Epoch 66 / 200, val acc: 0.4699738903394256
Epoch 67 / 200, learning rate: 3.125e-05
Epoch 67 / 200, train loss: 0.40792542695999146
Epoch 67 / 200, val loss: 6.753800868988037
Epoch 67 / 200, val acc: 0.47780678851174935
Epoch 68 / 200, learning rate: 3.125e-05
Epoch 68 / 200, train loss: 0.4082418978214264
Epoch 68 / 200, val loss: 6.753121852874756
Epoch 68 / 200, val acc: 0.4830287206266319
Epoch 69 / 200, learning rate: 3.125e-05
Epoch 69 / 200, train loss: 0.4049891531467438
Epoch 69 / 200, val loss: 6.752593994140625
Epoch 69 / 200, val acc: 0.4934725848563969
Epoch 70 / 200, learning rate: 3.125e-05
Epoch 70 / 200, train loss: 0.4071168601512909
Epoch 70 / 200, val loss: 6.752010345458984
Epoch 70 / 200, val acc: 0.5065274151436031
Epoch 71 / 200, learning rate: 3.125e-05
Epoch 71 / 200, train loss: 0.40616804361343384
Epoch 71 / 200, val loss: 6.751668453216553
Epoch 71 / 200, val acc: 0.4960835509138381
Epoch 72 / 200, learning rate: 3.125e-05
Epoch 72 / 200, train loss: 0.40530654788017273
Epoch 72 / 200, val loss: 6.751472473144531
Epoch 72 / 200, val acc: 0.4908616187989556
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.4075458347797394
Epoch 73 / 200, val loss: 6.751378059387207
Epoch 73 / 200, val acc: 0.4830287206266319
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.4076082110404968
Epoch 74 / 200, val loss: 6.751365661621094
Epoch 74 / 200, val acc: 0.4934725848563969
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.4062992334365845
Epoch 75 / 200, val loss: 6.751391410827637
Epoch 75 / 200, val acc: 0.47780678851174935
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.40555986762046814
Epoch 76 / 200, val loss: 6.751486778259277
Epoch 76 / 200, val acc: 0.4830287206266319
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.4066982567310333
Epoch 77 / 200, val loss: 6.75156307220459
Epoch 77 / 200, val acc: 0.4856396866840731
Epoch 78 / 200, learning rate: 1.5625e-05
Epoch 78 / 200, train loss: 0.40882912278175354
Epoch 78 / 200, val loss: 6.751656532287598
Epoch 78 / 200, val acc: 0.4830287206266319
Epoch 79 / 200, learning rate: 1.5625e-05
Epoch 79 / 200, train loss: 0.4064769446849823
Epoch 79 / 200, val loss: 6.751750469207764
Epoch 79 / 200, val acc: 0.48825065274151436
Epoch 80 / 200, learning rate: 1.5625e-05
Epoch 80 / 200, train loss: 0.40677332878112793
Epoch 80 / 200, val loss: 6.751842498779297
Epoch 80 / 200, val acc: 0.4908616187989556
Epoch 81 / 200, learning rate: 1.5625e-05
Epoch 81 / 200, train loss: 0.4065309464931488
Epoch 81 / 200, val loss: 6.751970291137695
Epoch 81 / 200, val acc: 0.4908616187989556
Epoch 82 / 200, learning rate: 1.5625e-05
Epoch 82 / 200, train loss: 0.4073013663291931
Epoch 82 / 200, val loss: 6.752106666564941
Epoch 82 / 200, val acc: 0.4934725848563969
Epoch 83 / 200, learning rate: 1.5625e-05
Epoch 83 / 200, train loss: 0.4077798128128052
Epoch 83 / 200, val loss: 6.752184867858887
Epoch 83 / 200, val acc: 0.4960835509138381
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.4067426025867462
Epoch 84 / 200, val loss: 6.752322196960449
Epoch 84 / 200, val acc: 0.4908616187989556
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.40614762902259827
Epoch 85 / 200, val loss: 6.7524566650390625
Epoch 85 / 200, val acc: 0.4908616187989556
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.4071807265281677
Epoch 86 / 200, val loss: 6.752583980560303
Epoch 86 / 200, val acc: 0.48825065274151436
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.4078409671783447
Epoch 87 / 200, val loss: 6.752685546875
Epoch 87 / 200, val acc: 0.4830287206266319
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.40510907769203186
Epoch 88 / 200, val loss: 6.75281286239624
Epoch 88 / 200, val acc: 0.48825065274151436
Epoch 89 / 200, learning rate: 7.8125e-06
Epoch 89 / 200, train loss: 0.4068424701690674
Epoch 89 / 200, val loss: 6.7529191970825195
Epoch 89 / 200, val acc: 0.4908616187989556
Epoch 90 / 200, learning rate: 7.8125e-06
Epoch 90 / 200, train loss: 0.4062402546405792
Epoch 90 / 200, val loss: 6.7530059814453125
Epoch 90 / 200, val acc: 0.4830287206266319
Epoch 91 / 200, learning rate: 7.8125e-06
Epoch 91 / 200, train loss: 0.40702491998672485
Epoch 91 / 200, val loss: 6.75308895111084
Epoch 91 / 200, val acc: 0.4856396866840731
Epoch 92 / 200, learning rate: 7.8125e-06
Epoch 92 / 200, train loss: 0.4070468842983246
Epoch 92 / 200, val loss: 6.753207683563232
Epoch 92 / 200, val acc: 0.4856396866840731
Epoch 93 / 200, learning rate: 7.8125e-06
Epoch 93 / 200, train loss: 0.4078098237514496
Epoch 93 / 200, val loss: 6.75327205657959
Epoch 93 / 200, val acc: 0.4856396866840731
Epoch 94 / 200, learning rate: 7.8125e-06
Epoch 94 / 200, train loss: 0.40576204657554626
Epoch 94 / 200, val loss: 6.753314971923828
Epoch 94 / 200, val acc: 0.4804177545691906
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.40764352679252625
Epoch 95 / 200, val loss: 6.753305435180664
Epoch 95 / 200, val acc: 0.4856396866840731
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.4082043766975403
Epoch 96 / 200, val loss: 6.75328254699707
Epoch 96 / 200, val acc: 0.48825065274151436
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.4039859473705292
Epoch 97 / 200, val loss: 6.7532782554626465
Epoch 97 / 200, val acc: 0.47780678851174935
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.40461936593055725
Epoch 98 / 200, val loss: 6.753293514251709
Epoch 98 / 200, val acc: 0.4908616187989556
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.406787246465683
Epoch 99 / 200, val loss: 6.753303050994873
Epoch 99 / 200, val acc: 0.48825065274151436
Epoch 100 / 200, learning rate: 3.90625e-06
Epoch 100 / 200, train loss: 0.4080089330673218
Epoch 100 / 200, val loss: 6.753296852111816
Epoch 100 / 200, val acc: 0.4908616187989556
Epoch 101 / 200, learning rate: 3.90625e-06
Epoch 101 / 200, train loss: 0.40822502970695496
Epoch 101 / 200, val loss: 6.753291130065918
Epoch 101 / 200, val acc: 0.4856396866840731
Epoch 102 / 200, learning rate: 3.90625e-06
Epoch 102 / 200, train loss: 0.4078187942504883
Epoch 102 / 200, val loss: 6.753316879272461
Epoch 102 / 200, val acc: 0.4960835509138381
Epoch 103 / 200, learning rate: 3.90625e-06
Epoch 103 / 200, train loss: 0.40943583846092224
Epoch 103 / 200, val loss: 6.753354549407959
Epoch 103 / 200, val acc: 0.48825065274151436
Epoch 104 / 200, learning rate: 3.90625e-06
Epoch 104 / 200, train loss: 0.40826642513275146
Epoch 104 / 200, val loss: 6.753378868103027
Epoch 104 / 200, val acc: 0.4856396866840731
Epoch 105 / 200, learning rate: 3.90625e-06
Epoch 105 / 200, train loss: 0.406366765499115
Epoch 105 / 200, val loss: 6.753415584564209
Epoch 105 / 200, val acc: 0.4856396866840731
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.4072687029838562
Epoch 106 / 200, val loss: 6.753440856933594
Epoch 106 / 200, val acc: 0.48825065274151436
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.40621984004974365
Epoch 107 / 200, val loss: 6.753458023071289
Epoch 107 / 200, val acc: 0.4856396866840731
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.40620994567871094
Epoch 108 / 200, val loss: 6.753466606140137
Epoch 108 / 200, val acc: 0.4804177545691906
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.4069612920284271
Epoch 109 / 200, val loss: 6.753474235534668
Epoch 109 / 200, val acc: 0.4804177545691906
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.40685153007507324
Epoch 110 / 200, val loss: 6.753476619720459
Epoch 110 / 200, val acc: 0.4934725848563969
Epoch 111 / 200, learning rate: 1.953125e-06
Epoch 111 / 200, train loss: 0.40420347452163696
Epoch 111 / 200, val loss: 6.753493309020996
Epoch 111 / 200, val acc: 0.4804177545691906
Epoch 112 / 200, learning rate: 1.953125e-06
Epoch 112 / 200, train loss: 0.4058801233768463
Epoch 112 / 200, val loss: 6.7535200119018555
Epoch 112 / 200, val acc: 0.4830287206266319
Epoch 113 / 200, learning rate: 1.953125e-06
Epoch 113 / 200, train loss: 0.4050411581993103
Epoch 113 / 200, val loss: 6.753551483154297
Epoch 113 / 200, val acc: 0.48825065274151436
Epoch 114 / 200, learning rate: 1.953125e-06
Epoch 114 / 200, train loss: 0.40731772780418396
Epoch 114 / 200, val loss: 6.75357723236084
Epoch 114 / 200, val acc: 0.48825065274151436
Epoch 115 / 200, learning rate: 1.953125e-06
Epoch 115 / 200, train loss: 0.41067469120025635
Epoch 115 / 200, val loss: 6.753600120544434
Epoch 115 / 200, val acc: 0.4804177545691906
Epoch 116 / 200, learning rate: 1.953125e-06
Epoch 116 / 200, train loss: 0.40619978308677673
Epoch 116 / 200, val loss: 6.753636360168457
Epoch 116 / 200, val acc: 0.4830287206266319
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.40571898221969604
Epoch 117 / 200, val loss: 6.753687858581543
Epoch 117 / 200, val acc: 0.4908616187989556
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.4059212803840637
Epoch 118 / 200, val loss: 6.753713607788086
Epoch 118 / 200, val acc: 0.4856396866840731
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.40565428137779236
Epoch 119 / 200, val loss: 6.753734588623047
Epoch 119 / 200, val acc: 0.47780678851174935
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.4073511064052582
Epoch 120 / 200, val loss: 6.753754615783691
Epoch 120 / 200, val acc: 0.4830287206266319
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.4084283709526062
Epoch 121 / 200, val loss: 6.753764629364014
Epoch 121 / 200, val acc: 0.48825065274151436
Epoch 122 / 200, learning rate: 9.765625e-07
Epoch 122 / 200, train loss: 0.4047422707080841
Epoch 122 / 200, val loss: 6.753776550292969
Epoch 122 / 200, val acc: 0.4830287206266319
Epoch 123 / 200, learning rate: 9.765625e-07
Epoch 123 / 200, train loss: 0.4065265953540802
Epoch 123 / 200, val loss: 6.75378942489624
Epoch 123 / 200, val acc: 0.4908616187989556
Epoch 124 / 200, learning rate: 9.765625e-07
Epoch 124 / 200, train loss: 0.4074128568172455
Epoch 124 / 200, val loss: 6.753800392150879
Epoch 124 / 200, val acc: 0.4908616187989556
Epoch 125 / 200, learning rate: 9.765625e-07
Epoch 125 / 200, train loss: 0.41070041060447693
Epoch 125 / 200, val loss: 6.753810882568359
Epoch 125 / 200, val acc: 0.4908616187989556
Epoch 126 / 200, learning rate: 9.765625e-07
Epoch 126 / 200, train loss: 0.4054720997810364
Epoch 126 / 200, val loss: 6.753819942474365
Epoch 126 / 200, val acc: 0.4934725848563969
Epoch 127 / 200, learning rate: 9.765625e-07
Epoch 127 / 200, train loss: 0.4067057967185974
Epoch 127 / 200, val loss: 6.7538275718688965
Epoch 127 / 200, val acc: 0.4908616187989556
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.40690016746520996
Epoch 128 / 200, val loss: 6.753836631774902
Epoch 128 / 200, val acc: 0.49869451697127937
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.40743955969810486
Epoch 129 / 200, val loss: 6.753840446472168
Epoch 129 / 200, val acc: 0.4934725848563969
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.4083544909954071
Epoch 130 / 200, val loss: 6.753842353820801
Epoch 130 / 200, val acc: 0.4960835509138381
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.4109337329864502
Epoch 131 / 200, val loss: 6.753841400146484
Epoch 131 / 200, val acc: 0.4960835509138381
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.4061111807823181
Epoch 132 / 200, val loss: 6.753842830657959
Epoch 132 / 200, val acc: 0.4934725848563969
Epoch 133 / 200, learning rate: 4.8828125e-07
Epoch 133 / 200, train loss: 0.40595054626464844
Epoch 133 / 200, val loss: 6.753849029541016
Epoch 133 / 200, val acc: 0.49869451697127937
Epoch 134 / 200, learning rate: 4.8828125e-07
Epoch 134 / 200, train loss: 0.40661391615867615
Epoch 134 / 200, val loss: 6.753859519958496
Epoch 134 / 200, val acc: 0.4934725848563969
Epoch 135 / 200, learning rate: 4.8828125e-07
Epoch 135 / 200, train loss: 0.4053623080253601
Epoch 135 / 200, val loss: 6.753871917724609
Epoch 135 / 200, val acc: 0.4908616187989556
Epoch 136 / 200, learning rate: 4.8828125e-07
Epoch 136 / 200, train loss: 0.4062664210796356
Epoch 136 / 200, val loss: 6.753887176513672
Epoch 136 / 200, val acc: 0.4908616187989556
Epoch 137 / 200, learning rate: 4.8828125e-07
Epoch 137 / 200, train loss: 0.40885797142982483
Epoch 137 / 200, val loss: 6.753898620605469
Epoch 137 / 200, val acc: 0.48825065274151436
Epoch 138 / 200, learning rate: 4.8828125e-07
Epoch 138 / 200, train loss: 0.40988749265670776
Epoch 138 / 200, val loss: 6.753904342651367
Epoch 138 / 200, val acc: 0.4960835509138381
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.4057096540927887
Epoch 139 / 200, val loss: 6.753913879394531
Epoch 139 / 200, val acc: 0.4934725848563969
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.40903013944625854
Epoch 140 / 200, val loss: 6.753917694091797
Epoch 140 / 200, val acc: 0.4934725848563969
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.40617382526397705
Epoch 141 / 200, val loss: 6.7539215087890625
Epoch 141 / 200, val acc: 0.4908616187989556
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.4087847173213959
Epoch 142 / 200, val loss: 6.753924369812012
Epoch 142 / 200, val acc: 0.4934725848563969
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.40598148107528687
Epoch 143 / 200, val loss: 6.753925323486328
Epoch 143 / 200, val acc: 0.4960835509138381
Epoch 144 / 200, learning rate: 2.44140625e-07
Epoch 144 / 200, train loss: 0.4058995544910431
Epoch 144 / 200, val loss: 6.7539286613464355
Epoch 144 / 200, val acc: 0.4960835509138381
Epoch 145 / 200, learning rate: 2.44140625e-07
Epoch 145 / 200, train loss: 0.40811625123023987
Epoch 145 / 200, val loss: 6.753931999206543
Epoch 145 / 200, val acc: 0.4960835509138381
Epoch 146 / 200, learning rate: 2.44140625e-07
Epoch 146 / 200, train loss: 0.40765076875686646
Epoch 146 / 200, val loss: 6.753935813903809
Epoch 146 / 200, val acc: 0.4960835509138381
Epoch 147 / 200, learning rate: 2.44140625e-07
Epoch 147 / 200, train loss: 0.40951934456825256
Epoch 147 / 200, val loss: 6.753936290740967
Epoch 147 / 200, val acc: 0.4960835509138381
Epoch 148 / 200, learning rate: 2.44140625e-07
Epoch 148 / 200, train loss: 0.40651172399520874
Epoch 148 / 200, val loss: 6.753936290740967
Epoch 148 / 200, val acc: 0.4908616187989556
Epoch 149 / 200, learning rate: 2.44140625e-07
Epoch 149 / 200, train loss: 0.4088086783885956
Epoch 149 / 200, val loss: 6.753935813903809
Epoch 149 / 200, val acc: 0.4934725848563969
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.40473005175590515
Epoch 150 / 200, val loss: 6.753934860229492
Epoch 150 / 200, val acc: 0.4908616187989556
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.40598031878471375
Epoch 151 / 200, val loss: 6.753934383392334
Epoch 151 / 200, val acc: 0.4960835509138381
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.4075160026550293
Epoch 152 / 200, val loss: 6.753933906555176
Epoch 152 / 200, val acc: 0.4934725848563969
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.4063485562801361
Epoch 153 / 200, val loss: 6.753932952880859
Epoch 153 / 200, val acc: 0.4934725848563969
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.40541988611221313
Epoch 154 / 200, val loss: 6.753932476043701
Epoch 154 / 200, val acc: 0.4908616187989556
Epoch 155 / 200, learning rate: 1.220703125e-07
Epoch 155 / 200, train loss: 0.4074416160583496
Epoch 155 / 200, val loss: 6.753931999206543
Epoch 155 / 200, val acc: 0.4934725848563969
Epoch 156 / 200, learning rate: 1.220703125e-07
Epoch 156 / 200, train loss: 0.4098735451698303
Epoch 156 / 200, val loss: 6.753930568695068
Epoch 156 / 200, val acc: 0.4934725848563969
Epoch 157 / 200, learning rate: 1.220703125e-07
Epoch 157 / 200, train loss: 0.40686190128326416
Epoch 157 / 200, val loss: 6.753929138183594
Epoch 157 / 200, val acc: 0.4934725848563969
Epoch 158 / 200, learning rate: 1.220703125e-07
Epoch 158 / 200, train loss: 0.40544360876083374
Epoch 158 / 200, val loss: 6.753929138183594
Epoch 158 / 200, val acc: 0.4934725848563969
Epoch 159 / 200, learning rate: 1.220703125e-07
Epoch 159 / 200, train loss: 0.4064309895038605
Epoch 159 / 200, val loss: 6.753929138183594
Epoch 159 / 200, val acc: 0.48825065274151436
Epoch 160 / 200, learning rate: 1.220703125e-07
Epoch 160 / 200, train loss: 0.4052017033100128
Epoch 160 / 200, val loss: 6.7539286613464355
Epoch 160 / 200, val acc: 0.4934725848563969
Epoch 161 / 200, learning rate: 6.103515625e-08
Epoch 161 / 200, train loss: 0.40621209144592285
Epoch 161 / 200, val loss: 6.7539286613464355
Epoch 161 / 200, val acc: 0.4934725848563969
Epoch 162 / 200, learning rate: 6.103515625e-08
Epoch 162 / 200, train loss: 0.4059313237667084
Epoch 162 / 200, val loss: 6.753929138183594
Epoch 162 / 200, val acc: 0.4908616187989556
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.409926176071167
Epoch 163 / 200, val loss: 6.75393009185791
Epoch 163 / 200, val acc: 0.4856396866840731
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.4063028395175934
Epoch 164 / 200, val loss: 6.753930568695068
Epoch 164 / 200, val acc: 0.4960835509138381
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.40533602237701416
Epoch 165 / 200, val loss: 6.753931045532227
Epoch 165 / 200, val acc: 0.4934725848563969
Epoch 166 / 200, learning rate: 6.103515625e-08
Epoch 166 / 200, train loss: 0.40720218420028687
Epoch 166 / 200, val loss: 6.753931999206543
Epoch 166 / 200, val acc: 0.4934725848563969
Epoch 167 / 200, learning rate: 6.103515625e-08
Epoch 167 / 200, train loss: 0.4058021903038025
Epoch 167 / 200, val loss: 6.753932952880859
Epoch 167 / 200, val acc: 0.4908616187989556
Epoch 168 / 200, learning rate: 6.103515625e-08
Epoch 168 / 200, train loss: 0.40403008460998535
Epoch 168 / 200, val loss: 6.753932952880859
Epoch 168 / 200, val acc: 0.4934725848563969
Epoch 169 / 200, learning rate: 6.103515625e-08
Epoch 169 / 200, train loss: 0.40800341963768005
Epoch 169 / 200, val loss: 6.753933906555176
Epoch 169 / 200, val acc: 0.4934725848563969
Epoch 170 / 200, learning rate: 6.103515625e-08
Epoch 170 / 200, train loss: 0.40644583106040955
Epoch 170 / 200, val loss: 6.753933906555176
Epoch 170 / 200, val acc: 0.4934725848563969
Epoch 171 / 200, learning rate: 6.103515625e-08
Epoch 171 / 200, train loss: 0.40762266516685486
Epoch 171 / 200, val loss: 6.753934383392334
Epoch 171 / 200, val acc: 0.4934725848563969
Epoch 172 / 200, learning rate: 3.0517578125e-08
Epoch 172 / 200, train loss: 0.40780335664749146
Epoch 172 / 200, val loss: 6.753934383392334
Epoch 172 / 200, val acc: 0.4908616187989556
Epoch 173 / 200, learning rate: 3.0517578125e-08
Epoch 173 / 200, train loss: 0.4073057472705841
Epoch 173 / 200, val loss: 6.753934860229492
Epoch 173 / 200, val acc: 0.4934725848563969
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.4078333079814911
Epoch 174 / 200, val loss: 6.753934860229492
Epoch 174 / 200, val acc: 0.5013054830287206
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.4077918827533722
Epoch 175 / 200, val loss: 6.753934860229492
Epoch 175 / 200, val acc: 0.4908616187989556
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.40395355224609375
Epoch 176 / 200, val loss: 6.753934860229492
Epoch 176 / 200, val acc: 0.4856396866840731
Epoch 177 / 200, learning rate: 3.0517578125e-08
Epoch 177 / 200, train loss: 0.40724891424179077
Epoch 177 / 200, val loss: 6.753934860229492
Epoch 177 / 200, val acc: 0.4908616187989556
Epoch 178 / 200, learning rate: 3.0517578125e-08
Epoch 178 / 200, train loss: 0.40541863441467285
Epoch 178 / 200, val loss: 6.753935813903809
Epoch 178 / 200, val acc: 0.4908616187989556
Epoch 179 / 200, learning rate: 3.0517578125e-08
Epoch 179 / 200, train loss: 0.40756192803382874
Epoch 179 / 200, val loss: 6.753935813903809
Epoch 179 / 200, val acc: 0.48825065274151436
Epoch 180 / 200, learning rate: 3.0517578125e-08
Epoch 180 / 200, train loss: 0.4064897298812866
Epoch 180 / 200, val loss: 6.753935813903809
Epoch 180 / 200, val acc: 0.48825065274151436
Epoch 181 / 200, learning rate: 3.0517578125e-08
Epoch 181 / 200, train loss: 0.40752312541007996
Epoch 181 / 200, val loss: 6.753935813903809
Epoch 181 / 200, val acc: 0.4934725848563969
Epoch 182 / 200, learning rate: 3.0517578125e-08
Epoch 182 / 200, train loss: 0.40745681524276733
Epoch 182 / 200, val loss: 6.753935813903809
Epoch 182 / 200, val acc: 0.4960835509138381
Epoch 183 / 200, learning rate: 1.52587890625e-08
Epoch 183 / 200, train loss: 0.407287061214447
Epoch 183 / 200, val loss: 6.753935813903809
Epoch 183 / 200, val acc: 0.4960835509138381
Epoch 184 / 200, learning rate: 1.52587890625e-08
Epoch 184 / 200, train loss: 0.40665262937545776
Epoch 184 / 200, val loss: 6.753935813903809
Epoch 184 / 200, val acc: 0.4908616187989556
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.40752142667770386
Epoch 185 / 200, val loss: 6.753935813903809
Epoch 185 / 200, val acc: 0.4934725848563969
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.40577220916748047
Epoch 186 / 200, val loss: 6.753935813903809
Epoch 186 / 200, val acc: 0.4908616187989556
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.4092719852924347
Epoch 187 / 200, val loss: 6.753935813903809
Epoch 187 / 200, val acc: 0.49869451697127937
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.40711382031440735
Epoch 188 / 200, val loss: 6.753935813903809
Epoch 188 / 200, val acc: 0.4934725848563969
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.40785902738571167
Epoch 189 / 200, val loss: 6.753935813903809
Epoch 189 / 200, val acc: 0.4960835509138381
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.40540027618408203
Epoch 190 / 200, val loss: 6.753935813903809
Epoch 190 / 200, val acc: 0.48825065274151436
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.4071292579174042
Epoch 191 / 200, val loss: 6.753936290740967
Epoch 191 / 200, val acc: 0.4934725848563969
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.40918564796447754
Epoch 192 / 200, val loss: 6.753936290740967
Epoch 192 / 200, val acc: 0.4908616187989556
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.405670166015625
Epoch 193 / 200, val loss: 6.753936290740967
Epoch 193 / 200, val acc: 0.4934725848563969
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.4089958667755127
Epoch 194 / 200, val loss: 6.753936290740967
Epoch 194 / 200, val acc: 0.4960835509138381
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.405568927526474
Epoch 195 / 200, val loss: 6.753936767578125
Epoch 195 / 200, val acc: 0.4908616187989556
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.40608105063438416
Epoch 196 / 200, val loss: 6.753936767578125
Epoch 196 / 200, val acc: 0.4960835509138381
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.4061702787876129
Epoch 197 / 200, val loss: 6.753936767578125
Epoch 197 / 200, val acc: 0.4908616187989556
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.4058954417705536
Epoch 198 / 200, val loss: 6.753936767578125
Epoch 198 / 200, val acc: 0.48825065274151436
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.4088478088378906
Epoch 199 / 200, val loss: 6.753937721252441
Epoch 199 / 200, val acc: 0.4908616187989556
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.40841078758239746
Epoch 200 / 200, val loss: 6.7539381980896
Epoch 200 / 200, val acc: 0.4908616187989556
Training finished

Evaluating best model on entire dataset
Trading strategy for stock SPY:
After 7679 trading days
Binary accuracy: 0.50716
Fraction of long signals: 0.51192
Fraction of short signals: 0.48756
Overall long return: 3.44117
Overall return: 0.62948
Yearly long return: 0.11293
Yearly return: 0.02066
Daily volatility: 0.01188
Max drawdown baseline: 0.25668
Max drawdown: 0.48260
Sharpe ratio: -0.03082
L1 error baseline: 0.78804
L1 error: 0.73685
Average prediction: -0.15393
Std prediction: 0.01028
