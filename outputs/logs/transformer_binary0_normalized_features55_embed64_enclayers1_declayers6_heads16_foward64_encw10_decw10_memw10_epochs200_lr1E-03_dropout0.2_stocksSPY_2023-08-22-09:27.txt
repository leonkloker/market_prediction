====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 5000, 1]              --
├─Linear: 1-1                                      [1, 5000, 64]             3,584
├─Time2Vec: 1-2                                    [1, 5000, 80]             --
│    └─Linear: 2-1                                 [5000, 16]                80
├─Linear: 1-3                                      [1, 5000, 64]             (recursive)
├─Time2Vec: 1-4                                    [1, 5000, 80]             (recursive)
│    └─Linear: 2-2                                 [5000, 16]                (recursive)
├─Transformer: 1-5                                 [1, 5000, 80]             --
│    └─TransformerEncoder: 2-3                     [1, 5000, 80]             --
│    │    └─ModuleList: 3-1                        --                        36,624
│    │    └─LayerNorm: 3-2                         [1, 5000, 80]             160
│    └─TransformerDecoder: 2-4                     [1, 5000, 80]             --
│    │    └─ModuleList: 3-3                        --                        376,224
│    │    └─LayerNorm: 3-4                         [1, 5000, 80]             160
├─Sequential: 1-6                                  [1, 5000, 1]              --
│    └─Linear: 2-5                                 [1, 5000, 40]             3,240
│    └─Dropout: 2-6                                [1, 5000, 40]             --
│    └─ReLU: 2-7                                   [1, 5000, 40]             --
│    └─Linear: 2-8                                 [1, 5000, 1]              41
├─Identity: 1-7                                    [1, 5000, 1]              --
====================================================================================================
Total params: 420,113
Trainable params: 420,113
Non-trainable params: 0
Total mult-adds (M): 0.88
====================================================================================================
Input size (MB): 2.20
Forward/backward pass size (MB): 106.60
Params size (MB): 0.29
Estimated Total Size (MB): 109.09
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.7592055797576904
Epoch 1 / 200, val loss: 0.07165896147489548
Epoch 1 / 200, val acc: 0.5704697986577181
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.26033324003219604
Epoch 2 / 200, val loss: 0.06012742593884468
Epoch 2 / 200, val acc: 0.47651006711409394
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.13907559216022491
Epoch 3 / 200, val loss: 0.1752595156431198
Epoch 3 / 200, val acc: 0.436241610738255
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.15681958198547363
Epoch 4 / 200, val loss: 0.21418528258800507
Epoch 4 / 200, val acc: 0.436241610738255
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.1333896368741989
Epoch 5 / 200, val loss: 0.14047464728355408
Epoch 5 / 200, val acc: 0.436241610738255
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.10312903672456741
Epoch 6 / 200, val loss: 0.05182798579335213
Epoch 6 / 200, val acc: 0.5033557046979866
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.09760415554046631
Epoch 7 / 200, val loss: 0.031119659543037415
Epoch 7 / 200, val acc: 0.5033557046979866
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.10779869556427002
Epoch 8 / 200, val loss: 0.06901485472917557
Epoch 8 / 200, val acc: 0.4563758389261745
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.08852680027484894
Epoch 9 / 200, val loss: 0.19948865473270416
Epoch 9 / 200, val acc: 0.436241610738255
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.07284516841173172
Epoch 10 / 200, val loss: 0.35186469554901123
Epoch 10 / 200, val acc: 0.436241610738255
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.0668841227889061
Epoch 11 / 200, val loss: 0.4444640278816223
Epoch 11 / 200, val acc: 0.436241610738255
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.06713969260454178
Epoch 12 / 200, val loss: 0.4470541477203369
Epoch 12 / 200, val acc: 0.436241610738255
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.061130087822675705
Epoch 13 / 200, val loss: 0.3827979564666748
Epoch 13 / 200, val acc: 0.436241610738255
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.057770196348428726
Epoch 14 / 200, val loss: 0.27103883028030396
Epoch 14 / 200, val acc: 0.436241610738255
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.05578238144516945
Epoch 15 / 200, val loss: 0.16154378652572632
Epoch 15 / 200, val acc: 0.436241610738255
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.05459681525826454
Epoch 16 / 200, val loss: 0.09731319546699524
Epoch 16 / 200, val acc: 0.42953020134228187
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.05523725599050522
Epoch 17 / 200, val loss: 0.08071950823068619
Epoch 17 / 200, val acc: 0.4563758389261745
Epoch 18 / 200, learning rate: 0.0006
Epoch 18 / 200, train loss: 0.05488089472055435
Epoch 18 / 200, val loss: 0.09688623994588852
Epoch 18 / 200, val acc: 0.42953020134228187
Epoch 19 / 200, learning rate: 0.0006
Epoch 19 / 200, train loss: 0.05140342190861702
Epoch 19 / 200, val loss: 0.1318703442811966
Epoch 19 / 200, val acc: 0.436241610738255
Epoch 20 / 200, learning rate: 0.0006
Epoch 20 / 200, train loss: 0.04694368690252304
Epoch 20 / 200, val loss: 0.18671979010105133
Epoch 20 / 200, val acc: 0.436241610738255
Epoch 21 / 200, learning rate: 0.0006
Epoch 21 / 200, train loss: 0.04586334899067879
Epoch 21 / 200, val loss: 0.25149860978126526
Epoch 21 / 200, val acc: 0.436241610738255
Epoch 22 / 200, learning rate: 0.0006
Epoch 22 / 200, train loss: 0.04516427963972092
Epoch 22 / 200, val loss: 0.3058859705924988
Epoch 22 / 200, val acc: 0.436241610738255
Epoch 23 / 200, learning rate: 0.0006
Epoch 23 / 200, train loss: 0.04768773168325424
Epoch 23 / 200, val loss: 0.3352031409740448
Epoch 23 / 200, val acc: 0.436241610738255
Epoch 24 / 200, learning rate: 0.0006
Epoch 24 / 200, train loss: 0.0440058559179306
Epoch 24 / 200, val loss: 0.33832621574401855
Epoch 24 / 200, val acc: 0.436241610738255
Epoch 25 / 200, learning rate: 0.0006
Epoch 25 / 200, train loss: 0.04217313975095749
Epoch 25 / 200, val loss: 0.3209766149520874
Epoch 25 / 200, val acc: 0.436241610738255
Epoch 26 / 200, learning rate: 0.0006
Epoch 26 / 200, train loss: 0.046581678092479706
Epoch 26 / 200, val loss: 0.28863513469696045
Epoch 26 / 200, val acc: 0.436241610738255
Epoch 27 / 200, learning rate: 0.0006
Epoch 27 / 200, train loss: 0.04611045867204666
Epoch 27 / 200, val loss: 0.24536962807178497
Epoch 27 / 200, val acc: 0.436241610738255
Epoch 28 / 200, learning rate: 0.0006
Epoch 28 / 200, train loss: 0.04142753779888153
Epoch 28 / 200, val loss: 0.203058123588562
Epoch 28 / 200, val acc: 0.436241610738255
Epoch 29 / 200, learning rate: 0.00035999999999999997
Epoch 29 / 200, train loss: 0.04266609251499176
Epoch 29 / 200, val loss: 0.1674228012561798
Epoch 29 / 200, val acc: 0.436241610738255
Epoch 30 / 200, learning rate: 0.00035999999999999997
Epoch 30 / 200, train loss: 0.04157634824514389
Epoch 30 / 200, val loss: 0.15135329961776733
Epoch 30 / 200, val acc: 0.436241610738255
Epoch 31 / 200, learning rate: 0.00035999999999999997
Epoch 31 / 200, train loss: 0.04023877531290054
Epoch 31 / 200, val loss: 0.1398376226425171
Epoch 31 / 200, val acc: 0.436241610738255
Epoch 32 / 200, learning rate: 0.00035999999999999997
Epoch 32 / 200, train loss: 0.03833836317062378
Epoch 32 / 200, val loss: 0.13489583134651184
Epoch 32 / 200, val acc: 0.436241610738255
Epoch 33 / 200, learning rate: 0.00035999999999999997
Epoch 33 / 200, train loss: 0.0376083180308342
Epoch 33 / 200, val loss: 0.13608594238758087
Epoch 33 / 200, val acc: 0.436241610738255
Epoch 34 / 200, learning rate: 0.00035999999999999997
Epoch 34 / 200, train loss: 0.03862537816166878
Epoch 34 / 200, val loss: 0.14192083477973938
Epoch 34 / 200, val acc: 0.436241610738255
Epoch 35 / 200, learning rate: 0.00035999999999999997
Epoch 35 / 200, train loss: 0.03995707631111145
Epoch 35 / 200, val loss: 0.15520323812961578
Epoch 35 / 200, val acc: 0.436241610738255
Epoch 36 / 200, learning rate: 0.00035999999999999997
Epoch 36 / 200, train loss: 0.037647929042577744
Epoch 36 / 200, val loss: 0.17311109602451324
Epoch 36 / 200, val acc: 0.436241610738255
Epoch 37 / 200, learning rate: 0.00035999999999999997
Epoch 37 / 200, train loss: 0.038410693407058716
Epoch 37 / 200, val loss: 0.1899866759777069
Epoch 37 / 200, val acc: 0.436241610738255
Epoch 38 / 200, learning rate: 0.00035999999999999997
Epoch 38 / 200, train loss: 0.0381571426987648
Epoch 38 / 200, val loss: 0.20724833011627197
Epoch 38 / 200, val acc: 0.436241610738255
Epoch 39 / 200, learning rate: 0.00035999999999999997
Epoch 39 / 200, train loss: 0.039877429604530334
Epoch 39 / 200, val loss: 0.2213970422744751
Epoch 39 / 200, val acc: 0.436241610738255
Epoch 40 / 200, learning rate: 0.00021599999999999996
Epoch 40 / 200, train loss: 0.035733722150325775
Epoch 40 / 200, val loss: 0.22751061618328094
Epoch 40 / 200, val acc: 0.436241610738255
Epoch 41 / 200, learning rate: 0.00021599999999999996
Epoch 41 / 200, train loss: 0.03858526796102524
Epoch 41 / 200, val loss: 0.22542348504066467
Epoch 41 / 200, val acc: 0.436241610738255
Epoch 42 / 200, learning rate: 0.00021599999999999996
Epoch 42 / 200, train loss: 0.03913470357656479
Epoch 42 / 200, val loss: 0.22035400569438934
Epoch 42 / 200, val acc: 0.436241610738255
Epoch 43 / 200, learning rate: 0.00021599999999999996
Epoch 43 / 200, train loss: 0.03798941522836685
Epoch 43 / 200, val loss: 0.2120371311903
Epoch 43 / 200, val acc: 0.436241610738255
Epoch 44 / 200, learning rate: 0.00021599999999999996
Epoch 44 / 200, train loss: 0.03595506399869919
Epoch 44 / 200, val loss: 0.20068520307540894
Epoch 44 / 200, val acc: 0.436241610738255
Epoch 45 / 200, learning rate: 0.00021599999999999996
Epoch 45 / 200, train loss: 0.034586891531944275
Epoch 45 / 200, val loss: 0.18838921189308167
Epoch 45 / 200, val acc: 0.436241610738255
Epoch 46 / 200, learning rate: 0.00021599999999999996
Epoch 46 / 200, train loss: 0.03582015261054039
Epoch 46 / 200, val loss: 0.1770275980234146
Epoch 46 / 200, val acc: 0.436241610738255
Epoch 47 / 200, learning rate: 0.00021599999999999996
Epoch 47 / 200, train loss: 0.036601897329092026
Epoch 47 / 200, val loss: 0.1665136218070984
Epoch 47 / 200, val acc: 0.436241610738255
Epoch 48 / 200, learning rate: 0.00021599999999999996
Epoch 48 / 200, train loss: 0.03461484983563423
Epoch 48 / 200, val loss: 0.15901024639606476
Epoch 48 / 200, val acc: 0.436241610738255
Epoch 49 / 200, learning rate: 0.00021599999999999996
Epoch 49 / 200, train loss: 0.03437916561961174
Epoch 49 / 200, val loss: 0.153096005320549
Epoch 49 / 200, val acc: 0.436241610738255
Epoch 50 / 200, learning rate: 0.00021599999999999996
Epoch 50 / 200, train loss: 0.034738775342702866
Epoch 50 / 200, val loss: 0.14967501163482666
Epoch 50 / 200, val acc: 0.436241610738255
Epoch 51 / 200, learning rate: 0.00012959999999999998
Epoch 51 / 200, train loss: 0.03595748916268349
Epoch 51 / 200, val loss: 0.1497003734111786
Epoch 51 / 200, val acc: 0.436241610738255
Epoch 52 / 200, learning rate: 0.00012959999999999998
Epoch 52 / 200, train loss: 0.034800782799720764
Epoch 52 / 200, val loss: 0.15153422951698303
Epoch 52 / 200, val acc: 0.436241610738255
Epoch 53 / 200, learning rate: 0.00012959999999999998
Epoch 53 / 200, train loss: 0.037674758583307266
Epoch 53 / 200, val loss: 0.15450787544250488
Epoch 53 / 200, val acc: 0.436241610738255
Epoch 54 / 200, learning rate: 0.00012959999999999998
Epoch 54 / 200, train loss: 0.03463287651538849
Epoch 54 / 200, val loss: 0.15855659544467926
Epoch 54 / 200, val acc: 0.436241610738255
Epoch 55 / 200, learning rate: 0.00012959999999999998
Epoch 55 / 200, train loss: 0.036276087164878845
Epoch 55 / 200, val loss: 0.1623041331768036
Epoch 55 / 200, val acc: 0.436241610738255
Epoch 56 / 200, learning rate: 0.00012959999999999998
Epoch 56 / 200, train loss: 0.03321268782019615
Epoch 56 / 200, val loss: 0.16630767285823822
Epoch 56 / 200, val acc: 0.436241610738255
Epoch 57 / 200, learning rate: 0.00012959999999999998
Epoch 57 / 200, train loss: 0.036185767501592636
Epoch 57 / 200, val loss: 0.1706719994544983
Epoch 57 / 200, val acc: 0.436241610738255
Epoch 58 / 200, learning rate: 0.00012959999999999998
Epoch 58 / 200, train loss: 0.03302307054400444
Epoch 58 / 200, val loss: 0.17480944097042084
Epoch 58 / 200, val acc: 0.436241610738255
Epoch 59 / 200, learning rate: 0.00012959999999999998
Epoch 59 / 200, train loss: 0.034417036920785904
Epoch 59 / 200, val loss: 0.17941221594810486
Epoch 59 / 200, val acc: 0.436241610738255
Epoch 60 / 200, learning rate: 0.00012959999999999998
Epoch 60 / 200, train loss: 0.03362744674086571
Epoch 60 / 200, val loss: 0.18467731773853302
Epoch 60 / 200, val acc: 0.436241610738255
Epoch 61 / 200, learning rate: 0.00012959999999999998
Epoch 61 / 200, train loss: 0.03354956954717636
Epoch 61 / 200, val loss: 0.1892235428094864
Epoch 61 / 200, val acc: 0.436241610738255
Epoch 62 / 200, learning rate: 7.775999999999999e-05
Epoch 62 / 200, train loss: 0.03458598628640175
Epoch 62 / 200, val loss: 0.19373831152915955
Epoch 62 / 200, val acc: 0.436241610738255
Epoch 63 / 200, learning rate: 7.775999999999999e-05
Epoch 63 / 200, train loss: 0.035613786429166794
Epoch 63 / 200, val loss: 0.19542823731899261
Epoch 63 / 200, val acc: 0.436241610738255
Epoch 64 / 200, learning rate: 7.775999999999999e-05
Epoch 64 / 200, train loss: 0.0347064808011055
Epoch 64 / 200, val loss: 0.1967797577381134
Epoch 64 / 200, val acc: 0.436241610738255
Epoch 65 / 200, learning rate: 7.775999999999999e-05
Epoch 65 / 200, train loss: 0.03455549478530884
Epoch 65 / 200, val loss: 0.19794686138629913
Epoch 65 / 200, val acc: 0.436241610738255
Epoch 66 / 200, learning rate: 7.775999999999999e-05
Epoch 66 / 200, train loss: 0.03462865948677063
Epoch 66 / 200, val loss: 0.1983836144208908
Epoch 66 / 200, val acc: 0.436241610738255
Epoch 67 / 200, learning rate: 7.775999999999999e-05
Epoch 67 / 200, train loss: 0.033036552369594574
Epoch 67 / 200, val loss: 0.1987941861152649
Epoch 67 / 200, val acc: 0.436241610738255
Epoch 68 / 200, learning rate: 7.775999999999999e-05
Epoch 68 / 200, train loss: 0.03507143631577492
Epoch 68 / 200, val loss: 0.19806770980358124
Epoch 68 / 200, val acc: 0.436241610738255
Epoch 69 / 200, learning rate: 7.775999999999999e-05
Epoch 69 / 200, train loss: 0.035272516310214996
Epoch 69 / 200, val loss: 0.19594551622867584
Epoch 69 / 200, val acc: 0.436241610738255
Epoch 70 / 200, learning rate: 7.775999999999999e-05
Epoch 70 / 200, train loss: 0.03345390409231186
Epoch 70 / 200, val loss: 0.1926325261592865
Epoch 70 / 200, val acc: 0.436241610738255
Epoch 71 / 200, learning rate: 7.775999999999999e-05
Epoch 71 / 200, train loss: 0.03398437798023224
Epoch 71 / 200, val loss: 0.18877176940441132
Epoch 71 / 200, val acc: 0.436241610738255
Epoch 72 / 200, learning rate: 7.775999999999999e-05
Epoch 72 / 200, train loss: 0.03281140699982643
Epoch 72 / 200, val loss: 0.1845352053642273
Epoch 72 / 200, val acc: 0.436241610738255
Epoch 73 / 200, learning rate: 4.665599999999999e-05
Epoch 73 / 200, train loss: 0.03204667195677757
Epoch 73 / 200, val loss: 0.18040810525417328
Epoch 73 / 200, val acc: 0.436241610738255
Epoch 74 / 200, learning rate: 4.665599999999999e-05
Epoch 74 / 200, train loss: 0.035443078726530075
Epoch 74 / 200, val loss: 0.17827802896499634
Epoch 74 / 200, val acc: 0.436241610738255
Epoch 75 / 200, learning rate: 4.665599999999999e-05
Epoch 75 / 200, train loss: 0.03369811549782753
Epoch 75 / 200, val loss: 0.17611293494701385
Epoch 75 / 200, val acc: 0.436241610738255
Epoch 76 / 200, learning rate: 4.665599999999999e-05
Epoch 76 / 200, train loss: 0.0343560166656971
Epoch 76 / 200, val loss: 0.17415070533752441
Epoch 76 / 200, val acc: 0.436241610738255
Epoch 77 / 200, learning rate: 4.665599999999999e-05
Epoch 77 / 200, train loss: 0.033167023211717606
Epoch 77 / 200, val loss: 0.17223797738552094
Epoch 77 / 200, val acc: 0.436241610738255
Epoch 78 / 200, learning rate: 4.665599999999999e-05
Epoch 78 / 200, train loss: 0.03361489996314049
Epoch 78 / 200, val loss: 0.17076869308948517
Epoch 78 / 200, val acc: 0.436241610738255
Epoch 79 / 200, learning rate: 4.665599999999999e-05
Epoch 79 / 200, train loss: 0.03296620771288872
Epoch 79 / 200, val loss: 0.16955864429473877
Epoch 79 / 200, val acc: 0.436241610738255
Epoch 80 / 200, learning rate: 4.665599999999999e-05
Epoch 80 / 200, train loss: 0.035029880702495575
Epoch 80 / 200, val loss: 0.16885128617286682
Epoch 80 / 200, val acc: 0.436241610738255
Epoch 81 / 200, learning rate: 4.665599999999999e-05
Epoch 81 / 200, train loss: 0.033726174384355545
Epoch 81 / 200, val loss: 0.16859307885169983
Epoch 81 / 200, val acc: 0.436241610738255
Epoch 82 / 200, learning rate: 4.665599999999999e-05
Epoch 82 / 200, train loss: 0.033958204090595245
Epoch 82 / 200, val loss: 0.16887280344963074
Epoch 82 / 200, val acc: 0.436241610738255
Epoch 83 / 200, learning rate: 4.665599999999999e-05
Epoch 83 / 200, train loss: 0.033087022602558136
Epoch 83 / 200, val loss: 0.16943396627902985
Epoch 83 / 200, val acc: 0.436241610738255
Epoch 84 / 200, learning rate: 2.7993599999999992e-05
Epoch 84 / 200, train loss: 0.032013293355703354
Epoch 84 / 200, val loss: 0.17007049918174744
Epoch 84 / 200, val acc: 0.436241610738255
Epoch 85 / 200, learning rate: 2.7993599999999992e-05
Epoch 85 / 200, train loss: 0.03129143267869949
Epoch 85 / 200, val loss: 0.17028000950813293
Epoch 85 / 200, val acc: 0.436241610738255
Epoch 86 / 200, learning rate: 2.7993599999999992e-05
Epoch 86 / 200, train loss: 0.03460467606782913
Epoch 86 / 200, val loss: 0.17040593922138214
Epoch 86 / 200, val acc: 0.436241610738255
Epoch 87 / 200, learning rate: 2.7993599999999992e-05
Epoch 87 / 200, train loss: 0.033246226608753204
Epoch 87 / 200, val loss: 0.1707727611064911
Epoch 87 / 200, val acc: 0.436241610738255
Epoch 88 / 200, learning rate: 2.7993599999999992e-05
Epoch 88 / 200, train loss: 0.03377753868699074
Epoch 88 / 200, val loss: 0.17103686928749084
Epoch 88 / 200, val acc: 0.436241610738255
Epoch 89 / 200, learning rate: 2.7993599999999992e-05
Epoch 89 / 200, train loss: 0.03416431322693825
Epoch 89 / 200, val loss: 0.17156973481178284
Epoch 89 / 200, val acc: 0.436241610738255
Epoch 90 / 200, learning rate: 2.7993599999999992e-05
Epoch 90 / 200, train loss: 0.03352377563714981
Epoch 90 / 200, val loss: 0.17221954464912415
Epoch 90 / 200, val acc: 0.436241610738255
Epoch 91 / 200, learning rate: 2.7993599999999992e-05
Epoch 91 / 200, train loss: 0.032003168016672134
Epoch 91 / 200, val loss: 0.1725749522447586
Epoch 91 / 200, val acc: 0.436241610738255
Epoch 92 / 200, learning rate: 2.7993599999999992e-05
Epoch 92 / 200, train loss: 0.03466474637389183
Epoch 92 / 200, val loss: 0.17330607771873474
Epoch 92 / 200, val acc: 0.436241610738255
Epoch 93 / 200, learning rate: 2.7993599999999992e-05
Epoch 93 / 200, train loss: 0.03138399124145508
Epoch 93 / 200, val loss: 0.1739177107810974
Epoch 93 / 200, val acc: 0.436241610738255
Epoch 94 / 200, learning rate: 2.7993599999999992e-05
Epoch 94 / 200, train loss: 0.03481016308069229
Epoch 94 / 200, val loss: 0.17419345676898956
Epoch 94 / 200, val acc: 0.436241610738255
Epoch 95 / 200, learning rate: 1.6796159999999994e-05
Epoch 95 / 200, train loss: 0.03232862055301666
Epoch 95 / 200, val loss: 0.17422015964984894
Epoch 95 / 200, val acc: 0.436241610738255
Epoch 96 / 200, learning rate: 1.6796159999999994e-05
Epoch 96 / 200, train loss: 0.033615704625844955
Epoch 96 / 200, val loss: 0.17429517209529877
Epoch 96 / 200, val acc: 0.436241610738255
Epoch 97 / 200, learning rate: 1.6796159999999994e-05
Epoch 97 / 200, train loss: 0.03303268924355507
Epoch 97 / 200, val loss: 0.17429125308990479
Epoch 97 / 200, val acc: 0.436241610738255
Epoch 98 / 200, learning rate: 1.6796159999999994e-05
Epoch 98 / 200, train loss: 0.03067464381456375
Epoch 98 / 200, val loss: 0.17424531280994415
Epoch 98 / 200, val acc: 0.436241610738255
Epoch 99 / 200, learning rate: 1.6796159999999994e-05
Epoch 99 / 200, train loss: 0.03244846686720848
Epoch 99 / 200, val loss: 0.17421437799930573
Epoch 99 / 200, val acc: 0.436241610738255
Epoch 100 / 200, learning rate: 1.6796159999999994e-05
Epoch 100 / 200, train loss: 0.03394898772239685
Epoch 100 / 200, val loss: 0.17413735389709473
Epoch 100 / 200, val acc: 0.436241610738255
Epoch 101 / 200, learning rate: 1.6796159999999994e-05
Epoch 101 / 200, train loss: 0.0339428186416626
Epoch 101 / 200, val loss: 0.17406630516052246
Epoch 101 / 200, val acc: 0.436241610738255
Epoch 102 / 200, learning rate: 1.6796159999999994e-05
Epoch 102 / 200, train loss: 0.03624521940946579
Epoch 102 / 200, val loss: 0.17393934726715088
Epoch 102 / 200, val acc: 0.436241610738255
Epoch 103 / 200, learning rate: 1.6796159999999994e-05
Epoch 103 / 200, train loss: 0.03314155340194702
Epoch 103 / 200, val loss: 0.1739015430212021
Epoch 103 / 200, val acc: 0.436241610738255
Epoch 104 / 200, learning rate: 1.6796159999999994e-05
Epoch 104 / 200, train loss: 0.033490609377622604
Epoch 104 / 200, val loss: 0.1740262359380722
Epoch 104 / 200, val acc: 0.436241610738255
Epoch 105 / 200, learning rate: 1.6796159999999994e-05
Epoch 105 / 200, train loss: 0.034582361578941345
Epoch 105 / 200, val loss: 0.17408525943756104
Epoch 105 / 200, val acc: 0.436241610738255
Epoch 106 / 200, learning rate: 1.0077695999999996e-05
Epoch 106 / 200, train loss: 0.034064050763845444
Epoch 106 / 200, val loss: 0.17407859861850739
Epoch 106 / 200, val acc: 0.436241610738255
Epoch 107 / 200, learning rate: 1.0077695999999996e-05
Epoch 107 / 200, train loss: 0.03386198729276657
Epoch 107 / 200, val loss: 0.17421849071979523
Epoch 107 / 200, val acc: 0.436241610738255
Epoch 108 / 200, learning rate: 1.0077695999999996e-05
Epoch 108 / 200, train loss: 0.03406991809606552
Epoch 108 / 200, val loss: 0.17428621649742126
Epoch 108 / 200, val acc: 0.436241610738255
Epoch 109 / 200, learning rate: 1.0077695999999996e-05
Epoch 109 / 200, train loss: 0.03147289529442787
Epoch 109 / 200, val loss: 0.17425879836082458
Epoch 109 / 200, val acc: 0.436241610738255
Epoch 110 / 200, learning rate: 1.0077695999999996e-05
Epoch 110 / 200, train loss: 0.0330597385764122
Epoch 110 / 200, val loss: 0.17430713772773743
Epoch 110 / 200, val acc: 0.436241610738255
Epoch 111 / 200, learning rate: 1.0077695999999996e-05
Epoch 111 / 200, train loss: 0.03328636661171913
Epoch 111 / 200, val loss: 0.17441870272159576
Epoch 111 / 200, val acc: 0.436241610738255
Epoch 112 / 200, learning rate: 1.0077695999999996e-05
Epoch 112 / 200, train loss: 0.033938344568014145
Epoch 112 / 200, val loss: 0.17446556687355042
Epoch 112 / 200, val acc: 0.436241610738255
Epoch 113 / 200, learning rate: 1.0077695999999996e-05
Epoch 113 / 200, train loss: 0.03192136436700821
Epoch 113 / 200, val loss: 0.17455103993415833
Epoch 113 / 200, val acc: 0.436241610738255
Epoch 114 / 200, learning rate: 1.0077695999999996e-05
Epoch 114 / 200, train loss: 0.03419964015483856
Epoch 114 / 200, val loss: 0.17456640303134918
Epoch 114 / 200, val acc: 0.436241610738255
Epoch 115 / 200, learning rate: 1.0077695999999996e-05
Epoch 115 / 200, train loss: 0.033467188477516174
Epoch 115 / 200, val loss: 0.17453642189502716
Epoch 115 / 200, val acc: 0.436241610738255
Epoch 116 / 200, learning rate: 1.0077695999999996e-05
Epoch 116 / 200, train loss: 0.034438129514455795
Epoch 116 / 200, val loss: 0.1745283305644989
Epoch 116 / 200, val acc: 0.436241610738255
Epoch 117 / 200, learning rate: 6.046617599999998e-06
Epoch 117 / 200, train loss: 0.03303567320108414
Epoch 117 / 200, val loss: 0.17445145547389984
Epoch 117 / 200, val acc: 0.436241610738255
Epoch 118 / 200, learning rate: 6.046617599999998e-06
Epoch 118 / 200, train loss: 0.031176123768091202
Epoch 118 / 200, val loss: 0.17445166409015656
Epoch 118 / 200, val acc: 0.436241610738255
Epoch 119 / 200, learning rate: 6.046617599999998e-06
Epoch 119 / 200, train loss: 0.033044490963220596
Epoch 119 / 200, val loss: 0.17438697814941406
Epoch 119 / 200, val acc: 0.436241610738255
Epoch 120 / 200, learning rate: 6.046617599999998e-06
Epoch 120 / 200, train loss: 0.03452768549323082
Epoch 120 / 200, val loss: 0.1742977499961853
Epoch 120 / 200, val acc: 0.436241610738255
Epoch 121 / 200, learning rate: 6.046617599999998e-06
Epoch 121 / 200, train loss: 0.03166089206933975
Epoch 121 / 200, val loss: 0.17422902584075928
Epoch 121 / 200, val acc: 0.436241610738255
Epoch 122 / 200, learning rate: 6.046617599999998e-06
Epoch 122 / 200, train loss: 0.033030666410923004
Epoch 122 / 200, val loss: 0.17424409091472626
Epoch 122 / 200, val acc: 0.436241610738255
Epoch 123 / 200, learning rate: 6.046617599999998e-06
Epoch 123 / 200, train loss: 0.032983485609292984
Epoch 123 / 200, val loss: 0.17435269057750702
Epoch 123 / 200, val acc: 0.436241610738255
Epoch 124 / 200, learning rate: 6.046617599999998e-06
Epoch 124 / 200, train loss: 0.0329754464328289
Epoch 124 / 200, val loss: 0.17448043823242188
Epoch 124 / 200, val acc: 0.436241610738255
Epoch 125 / 200, learning rate: 6.046617599999998e-06
Epoch 125 / 200, train loss: 0.031846825033426285
Epoch 125 / 200, val loss: 0.1745852380990982
Epoch 125 / 200, val acc: 0.436241610738255
Epoch 126 / 200, learning rate: 6.046617599999998e-06
Epoch 126 / 200, train loss: 0.03409932181239128
Epoch 126 / 200, val loss: 0.1746518313884735
Epoch 126 / 200, val acc: 0.436241610738255
Epoch 127 / 200, learning rate: 6.046617599999998e-06
Epoch 127 / 200, train loss: 0.03315077722072601
Epoch 127 / 200, val loss: 0.17475225031375885
Epoch 127 / 200, val acc: 0.436241610738255
Epoch 128 / 200, learning rate: 3.6279705599999985e-06
Epoch 128 / 200, train loss: 0.035204991698265076
Epoch 128 / 200, val loss: 0.1748691350221634
Epoch 128 / 200, val acc: 0.436241610738255
Epoch 129 / 200, learning rate: 3.6279705599999985e-06
Epoch 129 / 200, train loss: 0.032508254051208496
Epoch 129 / 200, val loss: 0.17498919367790222
Epoch 129 / 200, val acc: 0.436241610738255
Epoch 130 / 200, learning rate: 3.6279705599999985e-06
Epoch 130 / 200, train loss: 0.034782543778419495
Epoch 130 / 200, val loss: 0.17510199546813965
Epoch 130 / 200, val acc: 0.436241610738255
Epoch 131 / 200, learning rate: 3.6279705599999985e-06
Epoch 131 / 200, train loss: 0.03409285098314285
Epoch 131 / 200, val loss: 0.17515043914318085
Epoch 131 / 200, val acc: 0.436241610738255
Epoch 132 / 200, learning rate: 3.6279705599999985e-06
Epoch 132 / 200, train loss: 0.03488563746213913
Epoch 132 / 200, val loss: 0.17523980140686035
Epoch 132 / 200, val acc: 0.436241610738255
Epoch 133 / 200, learning rate: 3.6279705599999985e-06
Epoch 133 / 200, train loss: 0.033665549010038376
Epoch 133 / 200, val loss: 0.17532016336917877
Epoch 133 / 200, val acc: 0.436241610738255
Epoch 134 / 200, learning rate: 3.6279705599999985e-06
Epoch 134 / 200, train loss: 0.03491887450218201
Epoch 134 / 200, val loss: 0.17538027465343475
Epoch 134 / 200, val acc: 0.436241610738255
Epoch 135 / 200, learning rate: 3.6279705599999985e-06
Epoch 135 / 200, train loss: 0.031898386776447296
Epoch 135 / 200, val loss: 0.17545361816883087
Epoch 135 / 200, val acc: 0.436241610738255
Epoch 136 / 200, learning rate: 3.6279705599999985e-06
Epoch 136 / 200, train loss: 0.032424990087747574
Epoch 136 / 200, val loss: 0.1755227893590927
Epoch 136 / 200, val acc: 0.436241610738255
Epoch 137 / 200, learning rate: 3.6279705599999985e-06
Epoch 137 / 200, train loss: 0.031990550458431244
Epoch 137 / 200, val loss: 0.17560897767543793
Epoch 137 / 200, val acc: 0.436241610738255
Epoch 138 / 200, learning rate: 3.6279705599999985e-06
Epoch 138 / 200, train loss: 0.03236907720565796
Epoch 138 / 200, val loss: 0.1756640374660492
Epoch 138 / 200, val acc: 0.436241610738255
Epoch 139 / 200, learning rate: 2.176782335999999e-06
Epoch 139 / 200, train loss: 0.031877100467681885
Epoch 139 / 200, val loss: 0.1757342666387558
Epoch 139 / 200, val acc: 0.436241610738255
Epoch 140 / 200, learning rate: 2.176782335999999e-06
Epoch 140 / 200, train loss: 0.034092504531145096
Epoch 140 / 200, val loss: 0.17574724555015564
Epoch 140 / 200, val acc: 0.436241610738255
Epoch 141 / 200, learning rate: 2.176782335999999e-06
Epoch 141 / 200, train loss: 0.032606855034828186
Epoch 141 / 200, val loss: 0.17575043439865112
Epoch 141 / 200, val acc: 0.436241610738255
Epoch 142 / 200, learning rate: 2.176782335999999e-06
Epoch 142 / 200, train loss: 0.03263116255402565
Epoch 142 / 200, val loss: 0.175752192735672
Epoch 142 / 200, val acc: 0.436241610738255
Epoch 143 / 200, learning rate: 2.176782335999999e-06
Epoch 143 / 200, train loss: 0.03519666939973831
Epoch 143 / 200, val loss: 0.17573194205760956
Epoch 143 / 200, val acc: 0.436241610738255
Epoch 144 / 200, learning rate: 2.176782335999999e-06
Epoch 144 / 200, train loss: 0.03483849763870239
Epoch 144 / 200, val loss: 0.17567335069179535
Epoch 144 / 200, val acc: 0.436241610738255
Epoch 145 / 200, learning rate: 2.176782335999999e-06
Epoch 145 / 200, train loss: 0.03215617313981056
Epoch 145 / 200, val loss: 0.1756325215101242
Epoch 145 / 200, val acc: 0.436241610738255
Epoch 146 / 200, learning rate: 2.176782335999999e-06
Epoch 146 / 200, train loss: 0.03486888110637665
Epoch 146 / 200, val loss: 0.17556758224964142
Epoch 146 / 200, val acc: 0.436241610738255
Epoch 147 / 200, learning rate: 2.176782335999999e-06
Epoch 147 / 200, train loss: 0.03332589194178581
Epoch 147 / 200, val loss: 0.17551031708717346
Epoch 147 / 200, val acc: 0.436241610738255
Epoch 148 / 200, learning rate: 2.176782335999999e-06
Epoch 148 / 200, train loss: 0.033972885459661484
Epoch 148 / 200, val loss: 0.1754530817270279
Epoch 148 / 200, val acc: 0.436241610738255
Epoch 149 / 200, learning rate: 2.176782335999999e-06
Epoch 149 / 200, train loss: 0.033286966383457184
Epoch 149 / 200, val loss: 0.1753809154033661
Epoch 149 / 200, val acc: 0.436241610738255
Epoch 150 / 200, learning rate: 1.3060694015999993e-06
Epoch 150 / 200, train loss: 0.03380654379725456
Epoch 150 / 200, val loss: 0.17531491816043854
Epoch 150 / 200, val acc: 0.436241610738255
Epoch 151 / 200, learning rate: 1.3060694015999993e-06
Epoch 151 / 200, train loss: 0.03325103968381882
Epoch 151 / 200, val loss: 0.17526176571846008
Epoch 151 / 200, val acc: 0.436241610738255
Epoch 152 / 200, learning rate: 1.3060694015999993e-06
Epoch 152 / 200, train loss: 0.03239063546061516
Epoch 152 / 200, val loss: 0.17521800100803375
Epoch 152 / 200, val acc: 0.436241610738255
Epoch 153 / 200, learning rate: 1.3060694015999993e-06
Epoch 153 / 200, train loss: 0.03330204263329506
Epoch 153 / 200, val loss: 0.1751798838376999
Epoch 153 / 200, val acc: 0.436241610738255
Epoch 154 / 200, learning rate: 1.3060694015999993e-06
Epoch 154 / 200, train loss: 0.0327027291059494
Epoch 154 / 200, val loss: 0.17515242099761963
Epoch 154 / 200, val acc: 0.436241610738255
Epoch 155 / 200, learning rate: 1.3060694015999993e-06
Epoch 155 / 200, train loss: 0.03175234794616699
Epoch 155 / 200, val loss: 0.17512892186641693
Epoch 155 / 200, val acc: 0.436241610738255
Epoch 156 / 200, learning rate: 1.3060694015999993e-06
Epoch 156 / 200, train loss: 0.032999586313962936
Epoch 156 / 200, val loss: 0.1751096099615097
Epoch 156 / 200, val acc: 0.436241610738255
Epoch 157 / 200, learning rate: 1.3060694015999993e-06
Epoch 157 / 200, train loss: 0.03343671187758446
Epoch 157 / 200, val loss: 0.17509818077087402
Epoch 157 / 200, val acc: 0.436241610738255
Epoch 158 / 200, learning rate: 1.3060694015999993e-06
Epoch 158 / 200, train loss: 0.03088662400841713
Epoch 158 / 200, val loss: 0.17508290708065033
Epoch 158 / 200, val acc: 0.436241610738255
Epoch 159 / 200, learning rate: 1.3060694015999993e-06
Epoch 159 / 200, train loss: 0.035061877220869064
Epoch 159 / 200, val loss: 0.175085186958313
Epoch 159 / 200, val acc: 0.436241610738255
Epoch 160 / 200, learning rate: 1.3060694015999993e-06
Epoch 160 / 200, train loss: 0.03367368504405022
Epoch 160 / 200, val loss: 0.1750953644514084
Epoch 160 / 200, val acc: 0.436241610738255
Epoch 161 / 200, learning rate: 7.836416409599996e-07
Epoch 161 / 200, train loss: 0.03100156970322132
Epoch 161 / 200, val loss: 0.1751013845205307
Epoch 161 / 200, val acc: 0.436241610738255
Epoch 162 / 200, learning rate: 7.836416409599996e-07
Epoch 162 / 200, train loss: 0.03486498445272446
Epoch 162 / 200, val loss: 0.17510896921157837
Epoch 162 / 200, val acc: 0.436241610738255
Epoch 163 / 200, learning rate: 7.836416409599996e-07
Epoch 163 / 200, train loss: 0.03378188610076904
Epoch 163 / 200, val loss: 0.17512720823287964
Epoch 163 / 200, val acc: 0.436241610738255
Epoch 164 / 200, learning rate: 7.836416409599996e-07
Epoch 164 / 200, train loss: 0.03408898040652275
Epoch 164 / 200, val loss: 0.1751382201910019
Epoch 164 / 200, val acc: 0.436241610738255
Epoch 165 / 200, learning rate: 7.836416409599996e-07
Epoch 165 / 200, train loss: 0.03322409838438034
Epoch 165 / 200, val loss: 0.1751471310853958
Epoch 165 / 200, val acc: 0.436241610738255
Epoch 166 / 200, learning rate: 7.836416409599996e-07
Epoch 166 / 200, train loss: 0.03312529996037483
Epoch 166 / 200, val loss: 0.17516718804836273
Epoch 166 / 200, val acc: 0.436241610738255
Epoch 167 / 200, learning rate: 7.836416409599996e-07
Epoch 167 / 200, train loss: 0.0319925881922245
Epoch 167 / 200, val loss: 0.17518876492977142
Epoch 167 / 200, val acc: 0.436241610738255
Epoch 168 / 200, learning rate: 7.836416409599996e-07
Epoch 168 / 200, train loss: 0.03319503366947174
Epoch 168 / 200, val loss: 0.17520946264266968
Epoch 168 / 200, val acc: 0.436241610738255
Epoch 169 / 200, learning rate: 7.836416409599996e-07
Epoch 169 / 200, train loss: 0.033290546387434006
Epoch 169 / 200, val loss: 0.1752321720123291
Epoch 169 / 200, val acc: 0.436241610738255
Epoch 170 / 200, learning rate: 7.836416409599996e-07
Epoch 170 / 200, train loss: 0.033829011023044586
Epoch 170 / 200, val loss: 0.1752469688653946
Epoch 170 / 200, val acc: 0.436241610738255
Epoch 171 / 200, learning rate: 7.836416409599996e-07
Epoch 171 / 200, train loss: 0.033134348690509796
Epoch 171 / 200, val loss: 0.17526628077030182
Epoch 171 / 200, val acc: 0.436241610738255
Epoch 172 / 200, learning rate: 4.7018498457599973e-07
Epoch 172 / 200, train loss: 0.030959730967879295
Epoch 172 / 200, val loss: 0.1752823442220688
Epoch 172 / 200, val acc: 0.436241610738255
Epoch 173 / 200, learning rate: 4.7018498457599973e-07
Epoch 173 / 200, train loss: 0.0319652333855629
Epoch 173 / 200, val loss: 0.17529019713401794
Epoch 173 / 200, val acc: 0.436241610738255
Epoch 174 / 200, learning rate: 4.7018498457599973e-07
Epoch 174 / 200, train loss: 0.034609805792570114
Epoch 174 / 200, val loss: 0.17529863119125366
Epoch 174 / 200, val acc: 0.436241610738255
Epoch 175 / 200, learning rate: 4.7018498457599973e-07
Epoch 175 / 200, train loss: 0.03352874889969826
Epoch 175 / 200, val loss: 0.17531117796897888
Epoch 175 / 200, val acc: 0.436241610738255
Epoch 176 / 200, learning rate: 4.7018498457599973e-07
Epoch 176 / 200, train loss: 0.033438537269830704
Epoch 176 / 200, val loss: 0.1753249317407608
Epoch 176 / 200, val acc: 0.436241610738255
Epoch 177 / 200, learning rate: 4.7018498457599973e-07
Epoch 177 / 200, train loss: 0.032136220484972
Epoch 177 / 200, val loss: 0.1753377765417099
Epoch 177 / 200, val acc: 0.436241610738255
Epoch 178 / 200, learning rate: 4.7018498457599973e-07
Epoch 178 / 200, train loss: 0.032224055379629135
Epoch 178 / 200, val loss: 0.17535123229026794
Epoch 178 / 200, val acc: 0.436241610738255
Epoch 179 / 200, learning rate: 4.7018498457599973e-07
Epoch 179 / 200, train loss: 0.03466029092669487
Epoch 179 / 200, val loss: 0.17536191642284393
Epoch 179 / 200, val acc: 0.436241610738255
Epoch 180 / 200, learning rate: 4.7018498457599973e-07
Epoch 180 / 200, train loss: 0.034662604331970215
Epoch 180 / 200, val loss: 0.17537282407283783
Epoch 180 / 200, val acc: 0.436241610738255
Epoch 181 / 200, learning rate: 4.7018498457599973e-07
Epoch 181 / 200, train loss: 0.03326203674077988
Epoch 181 / 200, val loss: 0.175377756357193
Epoch 181 / 200, val acc: 0.436241610738255
Epoch 182 / 200, learning rate: 4.7018498457599973e-07
Epoch 182 / 200, train loss: 0.03482898697257042
Epoch 182 / 200, val loss: 0.17537574470043182
Epoch 182 / 200, val acc: 0.436241610738255
Epoch 183 / 200, learning rate: 2.821109907455998e-07
Epoch 183 / 200, train loss: 0.03222525119781494
Epoch 183 / 200, val loss: 0.17537173628807068
Epoch 183 / 200, val acc: 0.436241610738255
Epoch 184 / 200, learning rate: 2.821109907455998e-07
Epoch 184 / 200, train loss: 0.033573348075151443
Epoch 184 / 200, val loss: 0.17536810040473938
Epoch 184 / 200, val acc: 0.436241610738255
Epoch 185 / 200, learning rate: 2.821109907455998e-07
Epoch 185 / 200, train loss: 0.03232589736580849
Epoch 185 / 200, val loss: 0.1753663867712021
Epoch 185 / 200, val acc: 0.436241610738255
Epoch 186 / 200, learning rate: 2.821109907455998e-07
Epoch 186 / 200, train loss: 0.03321744501590729
Epoch 186 / 200, val loss: 0.17536410689353943
Epoch 186 / 200, val acc: 0.436241610738255
Epoch 187 / 200, learning rate: 2.821109907455998e-07
Epoch 187 / 200, train loss: 0.03327920660376549
Epoch 187 / 200, val loss: 0.1753627210855484
Epoch 187 / 200, val acc: 0.436241610738255
Epoch 188 / 200, learning rate: 2.821109907455998e-07
Epoch 188 / 200, train loss: 0.03349360078573227
Epoch 188 / 200, val loss: 0.17535880208015442
Epoch 188 / 200, val acc: 0.436241610738255
Epoch 189 / 200, learning rate: 2.821109907455998e-07
Epoch 189 / 200, train loss: 0.031833115965127945
Epoch 189 / 200, val loss: 0.17535634338855743
Epoch 189 / 200, val acc: 0.436241610738255
Epoch 190 / 200, learning rate: 2.821109907455998e-07
Epoch 190 / 200, train loss: 0.032869454473257065
Epoch 190 / 200, val loss: 0.17535652220249176
Epoch 190 / 200, val acc: 0.436241610738255
Epoch 191 / 200, learning rate: 2.821109907455998e-07
Epoch 191 / 200, train loss: 0.03193078190088272
Epoch 191 / 200, val loss: 0.17535126209259033
Epoch 191 / 200, val acc: 0.436241610738255
Epoch 192 / 200, learning rate: 2.821109907455998e-07
Epoch 192 / 200, train loss: 0.033415280282497406
Epoch 192 / 200, val loss: 0.1753455400466919
Epoch 192 / 200, val acc: 0.436241610738255
Epoch 193 / 200, learning rate: 2.821109907455998e-07
Epoch 193 / 200, train loss: 0.034432657063007355
Epoch 193 / 200, val loss: 0.1753379851579666
Epoch 193 / 200, val acc: 0.436241610738255
Epoch 194 / 200, learning rate: 1.6926659444735988e-07
Epoch 194 / 200, train loss: 0.033884547650814056
Epoch 194 / 200, val loss: 0.17533494532108307
Epoch 194 / 200, val acc: 0.436241610738255
Epoch 195 / 200, learning rate: 1.6926659444735988e-07
Epoch 195 / 200, train loss: 0.03367066755890846
Epoch 195 / 200, val loss: 0.1753338724374771
Epoch 195 / 200, val acc: 0.436241610738255
Epoch 196 / 200, learning rate: 1.6926659444735988e-07
Epoch 196 / 200, train loss: 0.03335435688495636
Epoch 196 / 200, val loss: 0.17533166706562042
Epoch 196 / 200, val acc: 0.436241610738255
Epoch 197 / 200, learning rate: 1.6926659444735988e-07
Epoch 197 / 200, train loss: 0.034845586866140366
Epoch 197 / 200, val loss: 0.1753309667110443
Epoch 197 / 200, val acc: 0.436241610738255
Epoch 198 / 200, learning rate: 1.6926659444735988e-07
Epoch 198 / 200, train loss: 0.032142266631126404
Epoch 198 / 200, val loss: 0.17533069849014282
Epoch 198 / 200, val acc: 0.436241610738255
Epoch 199 / 200, learning rate: 1.6926659444735988e-07
Epoch 199 / 200, train loss: 0.034401532262563705
Epoch 199 / 200, val loss: 0.17533160746097565
Epoch 199 / 200, val acc: 0.436241610738255
Epoch 200 / 200, learning rate: 1.6926659444735988e-07
Epoch 200 / 200, train loss: 0.032225351780653
Epoch 200 / 200, val loss: 0.17533430457115173
Epoch 200 / 200, val acc: 0.436241610738255
Training finished

Evaluating best model
Trading strategy for stock SPY:
After 2999 trading days
Binary accuracy: 0.47565
Fraction of long signals: 0.22774
Fraction of short signals: 0.77192
Overall long return: 1.69422
Overall return: -0.38014
Yearly long return: 0.14236
Yearly return: -0.03194
Daily volatility: 0.01083
Max drawdown baseline: 0.16749
Max drawdown: 1.02139
Sharpe ratio: -0.06388
L1 error baseline: 0.01756
L1 error: 0.15126
Average prediction: -0.09585
Std prediction: 0.96830


Trading strategy for stock SPY:
After 150 trading days
Binary accuracy: 0.51007
Fraction of long signals: 0.36667
Fraction of short signals: 0.63333
Overall long return: 0.11226
Overall return: 0.09022
Yearly long return: 0.18860
Yearly return: 0.15157
Daily volatility: 0.00845
Max drawdown baseline: 0.07360
Max drawdown: 0.09662
Sharpe ratio: -0.01690
L1 error baseline: 0.02637
L1 error: 0.15248
Average prediction: 1.56113
Std prediction: 0.02851


