Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─MyIdentity: 2-3                             [1, 100, 72]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        155,496
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 161,929
Trainable params: 161,929
Non-trainable params: 0
Total mult-adds (M): 0.05
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.05
Params size (MB): 0.14
Estimated Total Size (MB): 1.23
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.8476287126541138
Epoch 1 / 200, val loss: 3.555917739868164
Epoch 1 / 200, val acc: 0.5
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.568446159362793
Epoch 2 / 200, val loss: 2.048211097717285
Epoch 2 / 200, val acc: 0.5
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.3925993740558624
Epoch 3 / 200, val loss: 1.2839547395706177
Epoch 3 / 200, val acc: 0.5
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.2990579605102539
Epoch 4 / 200, val loss: 0.9317269921302795
Epoch 4 / 200, val acc: 0.5121951219512195
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.24480359256267548
Epoch 5 / 200, val loss: 0.7081469893455505
Epoch 5 / 200, val acc: 0.5060975609756098
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.21088077127933502
Epoch 6 / 200, val loss: 0.5469533801078796
Epoch 6 / 200, val acc: 0.4817073170731707
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.17978139221668243
Epoch 7 / 200, val loss: 0.4315388798713684
Epoch 7 / 200, val acc: 0.4878048780487805
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.16390272974967957
Epoch 8 / 200, val loss: 0.3473012149333954
Epoch 8 / 200, val acc: 0.524390243902439
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.1411714255809784
Epoch 9 / 200, val loss: 0.2858361005783081
Epoch 9 / 200, val acc: 0.5487804878048781
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.12464219331741333
Epoch 10 / 200, val loss: 0.24257200956344604
Epoch 10 / 200, val acc: 0.5304878048780488
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.10620325058698654
Epoch 11 / 200, val loss: 0.21427519619464874
Epoch 11 / 200, val acc: 0.5365853658536586
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.10530880838632584
Epoch 12 / 200, val loss: 0.19851794838905334
Epoch 12 / 200, val acc: 0.5548780487804879
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.10434815287590027
Epoch 13 / 200, val loss: 0.19288413226604462
Epoch 13 / 200, val acc: 0.524390243902439
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.09888046234846115
Epoch 14 / 200, val loss: 0.1952015608549118
Epoch 14 / 200, val acc: 0.5182926829268293
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.09268641471862793
Epoch 15 / 200, val loss: 0.2033807933330536
Epoch 15 / 200, val acc: 0.5121951219512195
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.08639070391654968
Epoch 16 / 200, val loss: 0.2143496423959732
Epoch 16 / 200, val acc: 0.5060975609756098
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.08131150901317596
Epoch 17 / 200, val loss: 0.22515951097011566
Epoch 17 / 200, val acc: 0.5304878048780488
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.08392421901226044
Epoch 18 / 200, val loss: 0.23282571136951447
Epoch 18 / 200, val acc: 0.524390243902439
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.0778244361281395
Epoch 19 / 200, val loss: 0.23638859391212463
Epoch 19 / 200, val acc: 0.524390243902439
Epoch 20 / 200, learning rate: 0.001
Epoch 20 / 200, train loss: 0.0736926943063736
Epoch 20 / 200, val loss: 0.23657147586345673
Epoch 20 / 200, val acc: 0.5304878048780488
Epoch 21 / 200, learning rate: 0.001
Epoch 21 / 200, train loss: 0.07484714686870575
Epoch 21 / 200, val loss: 0.23614251613616943
Epoch 21 / 200, val acc: 0.5365853658536586
Epoch 22 / 200, learning rate: 0.001
Epoch 22 / 200, train loss: 0.06662310659885406
Epoch 22 / 200, val loss: 0.23386019468307495
Epoch 22 / 200, val acc: 0.5365853658536586
Epoch 23 / 200, learning rate: 0.001
Epoch 23 / 200, train loss: 0.06872201710939407
Epoch 23 / 200, val loss: 0.23612940311431885
Epoch 23 / 200, val acc: 0.5304878048780488
Epoch 24 / 200, learning rate: 0.0005
Epoch 24 / 200, train loss: 0.06796371936798096
Epoch 24 / 200, val loss: 0.24196591973304749
Epoch 24 / 200, val acc: 0.5182926829268293
Epoch 25 / 200, learning rate: 0.0005
Epoch 25 / 200, train loss: 0.07007885724306107
Epoch 25 / 200, val loss: 0.24716004729270935
Epoch 25 / 200, val acc: 0.5182926829268293
Epoch 26 / 200, learning rate: 0.0005
Epoch 26 / 200, train loss: 0.06357691437005997
Epoch 26 / 200, val loss: 0.25183019042015076
Epoch 26 / 200, val acc: 0.524390243902439
Epoch 27 / 200, learning rate: 0.0005
Epoch 27 / 200, train loss: 0.0660194531083107
Epoch 27 / 200, val loss: 0.2506585121154785
Epoch 27 / 200, val acc: 0.5304878048780488
Epoch 28 / 200, learning rate: 0.0005
Epoch 28 / 200, train loss: 0.06501034647226334
Epoch 28 / 200, val loss: 0.24703994393348694
Epoch 28 / 200, val acc: 0.5304878048780488
Epoch 29 / 200, learning rate: 0.0005
Epoch 29 / 200, train loss: 0.06080331653356552
Epoch 29 / 200, val loss: 0.24163194000720978
Epoch 29 / 200, val acc: 0.5304878048780488
Epoch 30 / 200, learning rate: 0.0005
Epoch 30 / 200, train loss: 0.06369863450527191
Epoch 30 / 200, val loss: 0.2350476235151291
Epoch 30 / 200, val acc: 0.5304878048780488
Epoch 31 / 200, learning rate: 0.0005
Epoch 31 / 200, train loss: 0.06307199597358704
Epoch 31 / 200, val loss: 0.228666290640831
Epoch 31 / 200, val acc: 0.5182926829268293
Epoch 32 / 200, learning rate: 0.0005
Epoch 32 / 200, train loss: 0.05745222792029381
Epoch 32 / 200, val loss: 0.22414541244506836
Epoch 32 / 200, val acc: 0.5182926829268293
Epoch 33 / 200, learning rate: 0.0005
Epoch 33 / 200, train loss: 0.06200546398758888
Epoch 33 / 200, val loss: 0.21814808249473572
Epoch 33 / 200, val acc: 0.5121951219512195
Epoch 34 / 200, learning rate: 0.0005
Epoch 34 / 200, train loss: 0.060322996228933334
Epoch 34 / 200, val loss: 0.21155089139938354
Epoch 34 / 200, val acc: 0.5121951219512195
Epoch 35 / 200, learning rate: 0.00025
Epoch 35 / 200, train loss: 0.060540053993463516
Epoch 35 / 200, val loss: 0.20664840936660767
Epoch 35 / 200, val acc: 0.5121951219512195
Epoch 36 / 200, learning rate: 0.00025
Epoch 36 / 200, train loss: 0.06627341359853745
Epoch 36 / 200, val loss: 0.20660099387168884
Epoch 36 / 200, val acc: 0.5121951219512195
Epoch 37 / 200, learning rate: 0.00025
Epoch 37 / 200, train loss: 0.05880017578601837
Epoch 37 / 200, val loss: 0.2063002735376358
Epoch 37 / 200, val acc: 0.5182926829268293
Epoch 38 / 200, learning rate: 0.00025
Epoch 38 / 200, train loss: 0.059034574776887894
Epoch 38 / 200, val loss: 0.2064189314842224
Epoch 38 / 200, val acc: 0.524390243902439
Epoch 39 / 200, learning rate: 0.00025
Epoch 39 / 200, train loss: 0.058988798409700394
Epoch 39 / 200, val loss: 0.2063077986240387
Epoch 39 / 200, val acc: 0.524390243902439
Epoch 40 / 200, learning rate: 0.00025
Epoch 40 / 200, train loss: 0.06065782532095909
Epoch 40 / 200, val loss: 0.2064809501171112
Epoch 40 / 200, val acc: 0.524390243902439
Epoch 41 / 200, learning rate: 0.00025
Epoch 41 / 200, train loss: 0.062290336936712265
Epoch 41 / 200, val loss: 0.20461073517799377
Epoch 41 / 200, val acc: 0.5304878048780488
Epoch 42 / 200, learning rate: 0.00025
Epoch 42 / 200, train loss: 0.05833003297448158
Epoch 42 / 200, val loss: 0.20126841962337494
Epoch 42 / 200, val acc: 0.5304878048780488
Epoch 43 / 200, learning rate: 0.00025
Epoch 43 / 200, train loss: 0.05786215513944626
Epoch 43 / 200, val loss: 0.19769984483718872
Epoch 43 / 200, val acc: 0.524390243902439
Epoch 44 / 200, learning rate: 0.00025
Epoch 44 / 200, train loss: 0.06151995062828064
Epoch 44 / 200, val loss: 0.19495351612567902
Epoch 44 / 200, val acc: 0.524390243902439
Epoch 45 / 200, learning rate: 0.00025
Epoch 45 / 200, train loss: 0.058759499341249466
Epoch 45 / 200, val loss: 0.19172126054763794
Epoch 45 / 200, val acc: 0.5182926829268293
Epoch 46 / 200, learning rate: 0.00025
Epoch 46 / 200, train loss: 0.05749523267149925
Epoch 46 / 200, val loss: 0.18962639570236206
Epoch 46 / 200, val acc: 0.5182926829268293
Epoch 47 / 200, learning rate: 0.00025
Epoch 47 / 200, train loss: 0.05676799640059471
Epoch 47 / 200, val loss: 0.18756608664989471
Epoch 47 / 200, val acc: 0.5182926829268293
Epoch 48 / 200, learning rate: 0.00025
Epoch 48 / 200, train loss: 0.05591577664017677
Epoch 48 / 200, val loss: 0.18835794925689697
Epoch 48 / 200, val acc: 0.524390243902439
Epoch 49 / 200, learning rate: 0.00025
Epoch 49 / 200, train loss: 0.061003632843494415
Epoch 49 / 200, val loss: 0.18999455869197845
Epoch 49 / 200, val acc: 0.524390243902439
Epoch 50 / 200, learning rate: 0.00025
Epoch 50 / 200, train loss: 0.05946369469165802
Epoch 50 / 200, val loss: 0.19262921810150146
Epoch 50 / 200, val acc: 0.5365853658536586
Epoch 51 / 200, learning rate: 0.00025
Epoch 51 / 200, train loss: 0.05238572508096695
Epoch 51 / 200, val loss: 0.1928543746471405
Epoch 51 / 200, val acc: 0.5365853658536586
Epoch 52 / 200, learning rate: 0.00025
Epoch 52 / 200, train loss: 0.0536876916885376
Epoch 52 / 200, val loss: 0.19263401627540588
Epoch 52 / 200, val acc: 0.5365853658536586
Epoch 53 / 200, learning rate: 0.00025
Epoch 53 / 200, train loss: 0.053219251334667206
Epoch 53 / 200, val loss: 0.1889370083808899
Epoch 53 / 200, val acc: 0.5365853658536586
Epoch 54 / 200, learning rate: 0.00025
Epoch 54 / 200, train loss: 0.05537845566868782
Epoch 54 / 200, val loss: 0.18601594865322113
Epoch 54 / 200, val acc: 0.5365853658536586
Epoch 55 / 200, learning rate: 0.00025
Epoch 55 / 200, train loss: 0.05472571402788162
Epoch 55 / 200, val loss: 0.18312549591064453
Epoch 55 / 200, val acc: 0.5365853658536586
Epoch 56 / 200, learning rate: 0.00025
Epoch 56 / 200, train loss: 0.05237039923667908
Epoch 56 / 200, val loss: 0.1790485829114914
Epoch 56 / 200, val acc: 0.5365853658536586
Epoch 57 / 200, learning rate: 0.00025
Epoch 57 / 200, train loss: 0.05246706306934357
Epoch 57 / 200, val loss: 0.1740657240152359
Epoch 57 / 200, val acc: 0.5304878048780488
Epoch 58 / 200, learning rate: 0.00025
Epoch 58 / 200, train loss: 0.05216262862086296
Epoch 58 / 200, val loss: 0.17078301310539246
Epoch 58 / 200, val acc: 0.5365853658536586
Epoch 59 / 200, learning rate: 0.00025
Epoch 59 / 200, train loss: 0.05036291852593422
Epoch 59 / 200, val loss: 0.16935192048549652
Epoch 59 / 200, val acc: 0.5365853658536586
Epoch 60 / 200, learning rate: 0.00025
Epoch 60 / 200, train loss: 0.05188721790909767
Epoch 60 / 200, val loss: 0.16730454564094543
Epoch 60 / 200, val acc: 0.5365853658536586
Epoch 61 / 200, learning rate: 0.00025
Epoch 61 / 200, train loss: 0.05339011922478676
Epoch 61 / 200, val loss: 0.16704139113426208
Epoch 61 / 200, val acc: 0.5426829268292683
Epoch 62 / 200, learning rate: 0.00025
Epoch 62 / 200, train loss: 0.051207367330789566
Epoch 62 / 200, val loss: 0.1666382998228073
Epoch 62 / 200, val acc: 0.5426829268292683
Epoch 63 / 200, learning rate: 0.00025
Epoch 63 / 200, train loss: 0.048434559255838394
Epoch 63 / 200, val loss: 0.16371361911296844
Epoch 63 / 200, val acc: 0.5426829268292683
Epoch 64 / 200, learning rate: 0.00025
Epoch 64 / 200, train loss: 0.05578412860631943
Epoch 64 / 200, val loss: 0.1637352555990219
Epoch 64 / 200, val acc: 0.5426829268292683
Epoch 65 / 200, learning rate: 0.00025
Epoch 65 / 200, train loss: 0.05558864027261734
Epoch 65 / 200, val loss: 0.16384916007518768
Epoch 65 / 200, val acc: 0.5426829268292683
Epoch 66 / 200, learning rate: 0.00025
Epoch 66 / 200, train loss: 0.05126965790987015
Epoch 66 / 200, val loss: 0.16575199365615845
Epoch 66 / 200, val acc: 0.5426829268292683
Epoch 67 / 200, learning rate: 0.00025
Epoch 67 / 200, train loss: 0.0490371473133564
Epoch 67 / 200, val loss: 0.16769729554653168
Epoch 67 / 200, val acc: 0.5365853658536586
Epoch 68 / 200, learning rate: 0.00025
Epoch 68 / 200, train loss: 0.0524628572165966
Epoch 68 / 200, val loss: 0.16586516797542572
Epoch 68 / 200, val acc: 0.5365853658536586
Epoch 69 / 200, learning rate: 0.00025
Epoch 69 / 200, train loss: 0.0532284714281559
Epoch 69 / 200, val loss: 0.16408343613147736
Epoch 69 / 200, val acc: 0.5365853658536586
Epoch 70 / 200, learning rate: 0.00025
Epoch 70 / 200, train loss: 0.04893197864294052
Epoch 70 / 200, val loss: 0.1633446216583252
Epoch 70 / 200, val acc: 0.5426829268292683
Epoch 71 / 200, learning rate: 0.00025
Epoch 71 / 200, train loss: 0.048937372863292694
Epoch 71 / 200, val loss: 0.16241075098514557
Epoch 71 / 200, val acc: 0.5365853658536586
Epoch 72 / 200, learning rate: 0.00025
Epoch 72 / 200, train loss: 0.048763956874608994
Epoch 72 / 200, val loss: 0.1618662029504776
Epoch 72 / 200, val acc: 0.5365853658536586
Epoch 73 / 200, learning rate: 0.00025
Epoch 73 / 200, train loss: 0.04911196604371071
Epoch 73 / 200, val loss: 0.1616583615541458
Epoch 73 / 200, val acc: 0.5365853658536586
Epoch 74 / 200, learning rate: 0.00025
Epoch 74 / 200, train loss: 0.04894673451781273
Epoch 74 / 200, val loss: 0.15982474386692047
Epoch 74 / 200, val acc: 0.5365853658536586
Epoch 75 / 200, learning rate: 0.00025
Epoch 75 / 200, train loss: 0.05810043215751648
Epoch 75 / 200, val loss: 0.1538558155298233
Epoch 75 / 200, val acc: 0.5365853658536586
Epoch 76 / 200, learning rate: 0.00025
Epoch 76 / 200, train loss: 0.04911801591515541
Epoch 76 / 200, val loss: 0.14866845309734344
Epoch 76 / 200, val acc: 0.5365853658536586
Epoch 77 / 200, learning rate: 0.00025
Epoch 77 / 200, train loss: 0.048944324254989624
Epoch 77 / 200, val loss: 0.14239776134490967
Epoch 77 / 200, val acc: 0.5365853658536586
Epoch 78 / 200, learning rate: 0.00025
Epoch 78 / 200, train loss: 0.0433293879032135
Epoch 78 / 200, val loss: 0.13856257498264313
Epoch 78 / 200, val acc: 0.5365853658536586
Epoch 79 / 200, learning rate: 0.00025
Epoch 79 / 200, train loss: 0.04749658331274986
Epoch 79 / 200, val loss: 0.13587136566638947
Epoch 79 / 200, val acc: 0.5365853658536586
Epoch 80 / 200, learning rate: 0.00025
Epoch 80 / 200, train loss: 0.04664359241724014
Epoch 80 / 200, val loss: 0.13362766802310944
Epoch 80 / 200, val acc: 0.5365853658536586
Epoch 81 / 200, learning rate: 0.00025
Epoch 81 / 200, train loss: 0.03990767523646355
Epoch 81 / 200, val loss: 0.1323629915714264
Epoch 81 / 200, val acc: 0.5365853658536586
Epoch 82 / 200, learning rate: 0.00025
Epoch 82 / 200, train loss: 0.0465613454580307
Epoch 82 / 200, val loss: 0.13101954758167267
Epoch 82 / 200, val acc: 0.5365853658536586
Epoch 83 / 200, learning rate: 0.00025
Epoch 83 / 200, train loss: 0.04900243133306503
Epoch 83 / 200, val loss: 0.1305643618106842
Epoch 83 / 200, val acc: 0.5304878048780488
Epoch 84 / 200, learning rate: 0.00025
Epoch 84 / 200, train loss: 0.044705238193273544
Epoch 84 / 200, val loss: 0.13098719716072083
Epoch 84 / 200, val acc: 0.5365853658536586
Epoch 85 / 200, learning rate: 0.00025
Epoch 85 / 200, train loss: 0.04306838661432266
Epoch 85 / 200, val loss: 0.13554517924785614
Epoch 85 / 200, val acc: 0.5365853658536586
Epoch 86 / 200, learning rate: 0.00025
Epoch 86 / 200, train loss: 0.044277895241975784
Epoch 86 / 200, val loss: 0.13989582657814026
Epoch 86 / 200, val acc: 0.5304878048780488
Epoch 87 / 200, learning rate: 0.00025
Epoch 87 / 200, train loss: 0.049608584493398666
Epoch 87 / 200, val loss: 0.14062762260437012
Epoch 87 / 200, val acc: 0.5304878048780488
Epoch 88 / 200, learning rate: 0.00025
Epoch 88 / 200, train loss: 0.04826800897717476
Epoch 88 / 200, val loss: 0.14085614681243896
Epoch 88 / 200, val acc: 0.5304878048780488
Epoch 89 / 200, learning rate: 0.00025
Epoch 89 / 200, train loss: 0.04723624512553215
Epoch 89 / 200, val loss: 0.13734616339206696
Epoch 89 / 200, val acc: 0.5304878048780488
Epoch 90 / 200, learning rate: 0.00025
Epoch 90 / 200, train loss: 0.048222366720438004
Epoch 90 / 200, val loss: 0.1298052817583084
Epoch 90 / 200, val acc: 0.524390243902439
Epoch 91 / 200, learning rate: 0.00025
Epoch 91 / 200, train loss: 0.044996920973062515
Epoch 91 / 200, val loss: 0.12115242332220078
Epoch 91 / 200, val acc: 0.5304878048780488
Epoch 92 / 200, learning rate: 0.00025
Epoch 92 / 200, train loss: 0.046225856989622116
Epoch 92 / 200, val loss: 0.11403258144855499
Epoch 92 / 200, val acc: 0.524390243902439
Epoch 93 / 200, learning rate: 0.00025
Epoch 93 / 200, train loss: 0.044472355395555496
Epoch 93 / 200, val loss: 0.1124514490365982
Epoch 93 / 200, val acc: 0.5182926829268293
Epoch 94 / 200, learning rate: 0.00025
Epoch 94 / 200, train loss: 0.0529852993786335
Epoch 94 / 200, val loss: 0.11516093462705612
Epoch 94 / 200, val acc: 0.5304878048780488
Epoch 95 / 200, learning rate: 0.00025
Epoch 95 / 200, train loss: 0.0450826995074749
Epoch 95 / 200, val loss: 0.1184605062007904
Epoch 95 / 200, val acc: 0.5304878048780488
Epoch 96 / 200, learning rate: 0.00025
Epoch 96 / 200, train loss: 0.04487823694944382
Epoch 96 / 200, val loss: 0.11931191384792328
Epoch 96 / 200, val acc: 0.524390243902439
Epoch 97 / 200, learning rate: 0.00025
Epoch 97 / 200, train loss: 0.04441846162080765
Epoch 97 / 200, val loss: 0.11979686468839645
Epoch 97 / 200, val acc: 0.5304878048780488
Epoch 98 / 200, learning rate: 0.00025
Epoch 98 / 200, train loss: 0.04113425686955452
Epoch 98 / 200, val loss: 0.11564421653747559
Epoch 98 / 200, val acc: 0.5304878048780488
Epoch 99 / 200, learning rate: 0.00025
Epoch 99 / 200, train loss: 0.047379981726408005
Epoch 99 / 200, val loss: 0.11080934852361679
Epoch 99 / 200, val acc: 0.524390243902439
Epoch 100 / 200, learning rate: 0.00025
Epoch 100 / 200, train loss: 0.04374860227108002
Epoch 100 / 200, val loss: 0.1108589619398117
Epoch 100 / 200, val acc: 0.524390243902439
Epoch 101 / 200, learning rate: 0.00025
Epoch 101 / 200, train loss: 0.044074784964323044
Epoch 101 / 200, val loss: 0.10923314839601517
Epoch 101 / 200, val acc: 0.5182926829268293
Epoch 102 / 200, learning rate: 0.00025
Epoch 102 / 200, train loss: 0.041463371366262436
Epoch 102 / 200, val loss: 0.1112947016954422
Epoch 102 / 200, val acc: 0.5304878048780488
Epoch 103 / 200, learning rate: 0.00025
Epoch 103 / 200, train loss: 0.038714759051799774
Epoch 103 / 200, val loss: 0.11272389441728592
Epoch 103 / 200, val acc: 0.5304878048780488
Epoch 104 / 200, learning rate: 0.00025
Epoch 104 / 200, train loss: 0.038923490792512894
Epoch 104 / 200, val loss: 0.11141140013933182
Epoch 104 / 200, val acc: 0.5304878048780488
Epoch 105 / 200, learning rate: 0.00025
Epoch 105 / 200, train loss: 0.042379580438137054
Epoch 105 / 200, val loss: 0.11180990934371948
Epoch 105 / 200, val acc: 0.5365853658536586
Epoch 106 / 200, learning rate: 0.00025
Epoch 106 / 200, train loss: 0.04387237876653671
Epoch 106 / 200, val loss: 0.10735059529542923
Epoch 106 / 200, val acc: 0.5182926829268293
Epoch 107 / 200, learning rate: 0.00025
Epoch 107 / 200, train loss: 0.047083139419555664
Epoch 107 / 200, val loss: 0.09827618300914764
Epoch 107 / 200, val acc: 0.5060975609756098
Epoch 108 / 200, learning rate: 0.00025
Epoch 108 / 200, train loss: 0.04249326512217522
Epoch 108 / 200, val loss: 0.09281741082668304
Epoch 108 / 200, val acc: 0.5121951219512195
Epoch 109 / 200, learning rate: 0.00025
Epoch 109 / 200, train loss: 0.042024143040180206
Epoch 109 / 200, val loss: 0.09398821741342545
Epoch 109 / 200, val acc: 0.5121951219512195
Epoch 110 / 200, learning rate: 0.00025
Epoch 110 / 200, train loss: 0.04273616522550583
Epoch 110 / 200, val loss: 0.09786644577980042
Epoch 110 / 200, val acc: 0.5182926829268293
Epoch 111 / 200, learning rate: 0.00025
Epoch 111 / 200, train loss: 0.0424659438431263
Epoch 111 / 200, val loss: 0.10130662471055984
Epoch 111 / 200, val acc: 0.524390243902439
Epoch 112 / 200, learning rate: 0.00025
Epoch 112 / 200, train loss: 0.04096789285540581
Epoch 112 / 200, val loss: 0.10270611941814423
Epoch 112 / 200, val acc: 0.5182926829268293
Epoch 113 / 200, learning rate: 0.00025
Epoch 113 / 200, train loss: 0.044142987579107285
Epoch 113 / 200, val loss: 0.10161525756120682
Epoch 113 / 200, val acc: 0.5182926829268293
Epoch 114 / 200, learning rate: 0.00025
Epoch 114 / 200, train loss: 0.03882717713713646
Epoch 114 / 200, val loss: 0.10118648409843445
Epoch 114 / 200, val acc: 0.5304878048780488
Epoch 115 / 200, learning rate: 0.00025
Epoch 115 / 200, train loss: 0.04537544399499893
Epoch 115 / 200, val loss: 0.10070126503705978
Epoch 115 / 200, val acc: 0.5304878048780488
Epoch 116 / 200, learning rate: 0.00025
Epoch 116 / 200, train loss: 0.04377084970474243
Epoch 116 / 200, val loss: 0.10085326433181763
Epoch 116 / 200, val acc: 0.5304878048780488
Epoch 117 / 200, learning rate: 0.00025
Epoch 117 / 200, train loss: 0.04470483586192131
Epoch 117 / 200, val loss: 0.10025712847709656
Epoch 117 / 200, val acc: 0.524390243902439
Epoch 118 / 200, learning rate: 0.00025
Epoch 118 / 200, train loss: 0.03726574778556824
Epoch 118 / 200, val loss: 0.09582585841417313
Epoch 118 / 200, val acc: 0.5182926829268293
Epoch 119 / 200, learning rate: 0.00025
Epoch 119 / 200, train loss: 0.038901399821043015
Epoch 119 / 200, val loss: 0.0923522338271141
Epoch 119 / 200, val acc: 0.5121951219512195
Epoch 120 / 200, learning rate: 0.00025
Epoch 120 / 200, train loss: 0.03751913458108902
Epoch 120 / 200, val loss: 0.09032994508743286
Epoch 120 / 200, val acc: 0.5121951219512195
Epoch 121 / 200, learning rate: 0.00025
Epoch 121 / 200, train loss: 0.040357429534196854
Epoch 121 / 200, val loss: 0.08940090984106064
Epoch 121 / 200, val acc: 0.5121951219512195
Epoch 122 / 200, learning rate: 0.00025
Epoch 122 / 200, train loss: 0.04266808554530144
Epoch 122 / 200, val loss: 0.0915953665971756
Epoch 122 / 200, val acc: 0.5121951219512195
Epoch 123 / 200, learning rate: 0.00025
Epoch 123 / 200, train loss: 0.03949851915240288
Epoch 123 / 200, val loss: 0.09885275363922119
Epoch 123 / 200, val acc: 0.5182926829268293
Epoch 124 / 200, learning rate: 0.00025
Epoch 124 / 200, train loss: 0.034080155193805695
Epoch 124 / 200, val loss: 0.10669319331645966
Epoch 124 / 200, val acc: 0.524390243902439
Epoch 125 / 200, learning rate: 0.00025
Epoch 125 / 200, train loss: 0.04124017804861069
Epoch 125 / 200, val loss: 0.10938068479299545
Epoch 125 / 200, val acc: 0.5182926829268293
Epoch 126 / 200, learning rate: 0.00025
Epoch 126 / 200, train loss: 0.04414571076631546
Epoch 126 / 200, val loss: 0.10917653888463974
Epoch 126 / 200, val acc: 0.5182926829268293
Epoch 127 / 200, learning rate: 0.00025
Epoch 127 / 200, train loss: 0.040137879550457
Epoch 127 / 200, val loss: 0.10335776209831238
Epoch 127 / 200, val acc: 0.5182926829268293
Epoch 128 / 200, learning rate: 0.00025
Epoch 128 / 200, train loss: 0.0393829271197319
Epoch 128 / 200, val loss: 0.09879938513040543
Epoch 128 / 200, val acc: 0.5182926829268293
Epoch 129 / 200, learning rate: 0.00025
Epoch 129 / 200, train loss: 0.037349652498960495
Epoch 129 / 200, val loss: 0.09804119914770126
Epoch 129 / 200, val acc: 0.5121951219512195
Epoch 130 / 200, learning rate: 0.00025
Epoch 130 / 200, train loss: 0.04256347939372063
Epoch 130 / 200, val loss: 0.10006743669509888
Epoch 130 / 200, val acc: 0.5060975609756098
Epoch 131 / 200, learning rate: 0.00025
Epoch 131 / 200, train loss: 0.042913250625133514
Epoch 131 / 200, val loss: 0.098985955119133
Epoch 131 / 200, val acc: 0.5060975609756098
Epoch 132 / 200, learning rate: 0.000125
Epoch 132 / 200, train loss: 0.04137329012155533
Epoch 132 / 200, val loss: 0.09701285511255264
Epoch 132 / 200, val acc: 0.5060975609756098
Epoch 133 / 200, learning rate: 0.000125
Epoch 133 / 200, train loss: 0.035500358790159225
Epoch 133 / 200, val loss: 0.09757784008979797
Epoch 133 / 200, val acc: 0.5060975609756098
Epoch 134 / 200, learning rate: 0.000125
Epoch 134 / 200, train loss: 0.04154864698648453
Epoch 134 / 200, val loss: 0.09896419942378998
Epoch 134 / 200, val acc: 0.5060975609756098
Epoch 135 / 200, learning rate: 0.000125
Epoch 135 / 200, train loss: 0.04264509305357933
Epoch 135 / 200, val loss: 0.1022898405790329
Epoch 135 / 200, val acc: 0.5060975609756098
Epoch 136 / 200, learning rate: 0.000125
Epoch 136 / 200, train loss: 0.04553026333451271
Epoch 136 / 200, val loss: 0.10329892486333847
Epoch 136 / 200, val acc: 0.5060975609756098
Epoch 137 / 200, learning rate: 0.000125
Epoch 137 / 200, train loss: 0.03959516063332558
Epoch 137 / 200, val loss: 0.10140898078680038
Epoch 137 / 200, val acc: 0.5060975609756098
Epoch 138 / 200, learning rate: 0.000125
Epoch 138 / 200, train loss: 0.03889438137412071
Epoch 138 / 200, val loss: 0.09621317684650421
Epoch 138 / 200, val acc: 0.5060975609756098
Epoch 139 / 200, learning rate: 0.000125
Epoch 139 / 200, train loss: 0.03529759496450424
Epoch 139 / 200, val loss: 0.0920163094997406
Epoch 139 / 200, val acc: 0.5121951219512195
Epoch 140 / 200, learning rate: 0.000125
Epoch 140 / 200, train loss: 0.03989020735025406
Epoch 140 / 200, val loss: 0.08700878173112869
Epoch 140 / 200, val acc: 0.5182926829268293
Epoch 141 / 200, learning rate: 0.000125
Epoch 141 / 200, train loss: 0.03786960616707802
Epoch 141 / 200, val loss: 0.08203928172588348
Epoch 141 / 200, val acc: 0.5426829268292683
Epoch 142 / 200, learning rate: 0.000125
Epoch 142 / 200, train loss: 0.035881299525499344
Epoch 142 / 200, val loss: 0.07808822393417358
Epoch 142 / 200, val acc: 0.5487804878048781
Epoch 143 / 200, learning rate: 0.000125
Epoch 143 / 200, train loss: 0.03867986425757408
Epoch 143 / 200, val loss: 0.07585807144641876
Epoch 143 / 200, val acc: 0.5548780487804879
Epoch 144 / 200, learning rate: 0.000125
Epoch 144 / 200, train loss: 0.03799785301089287
Epoch 144 / 200, val loss: 0.07661998271942139
Epoch 144 / 200, val acc: 0.5487804878048781
Epoch 145 / 200, learning rate: 0.000125
Epoch 145 / 200, train loss: 0.03361452743411064
Epoch 145 / 200, val loss: 0.08051130920648575
Epoch 145 / 200, val acc: 0.5609756097560976
Epoch 146 / 200, learning rate: 0.000125
Epoch 146 / 200, train loss: 0.0399911105632782
Epoch 146 / 200, val loss: 0.08559668809175491
Epoch 146 / 200, val acc: 0.5182926829268293
Epoch 147 / 200, learning rate: 0.000125
Epoch 147 / 200, train loss: 0.040785305202007294
Epoch 147 / 200, val loss: 0.09122949093580246
Epoch 147 / 200, val acc: 0.5
Epoch 148 / 200, learning rate: 0.000125
Epoch 148 / 200, train loss: 0.03974439576268196
Epoch 148 / 200, val loss: 0.09896188974380493
Epoch 148 / 200, val acc: 0.5121951219512195
Epoch 149 / 200, learning rate: 0.000125
Epoch 149 / 200, train loss: 0.035748545080423355
Epoch 149 / 200, val loss: 0.10512475669384003
Epoch 149 / 200, val acc: 0.5
Epoch 150 / 200, learning rate: 0.000125
Epoch 150 / 200, train loss: 0.03466889634728432
Epoch 150 / 200, val loss: 0.11267586797475815
Epoch 150 / 200, val acc: 0.5
Epoch 151 / 200, learning rate: 0.000125
Epoch 151 / 200, train loss: 0.03761781379580498
Epoch 151 / 200, val loss: 0.11601148545742035
Epoch 151 / 200, val acc: 0.5
Epoch 152 / 200, learning rate: 0.000125
Epoch 152 / 200, train loss: 0.03754708915948868
Epoch 152 / 200, val loss: 0.11126047372817993
Epoch 152 / 200, val acc: 0.5
Epoch 153 / 200, learning rate: 0.000125
Epoch 153 / 200, train loss: 0.038424812257289886
Epoch 153 / 200, val loss: 0.10440851747989655
Epoch 153 / 200, val acc: 0.5
Epoch 154 / 200, learning rate: 6.25e-05
Epoch 154 / 200, train loss: 0.037315066903829575
Epoch 154 / 200, val loss: 0.09596860408782959
Epoch 154 / 200, val acc: 0.5060975609756098
Epoch 155 / 200, learning rate: 6.25e-05
Epoch 155 / 200, train loss: 0.0407048836350441
Epoch 155 / 200, val loss: 0.09167575091123581
Epoch 155 / 200, val acc: 0.5
Epoch 156 / 200, learning rate: 6.25e-05
Epoch 156 / 200, train loss: 0.04034525901079178
Epoch 156 / 200, val loss: 0.0875951498746872
Epoch 156 / 200, val acc: 0.5121951219512195
Epoch 157 / 200, learning rate: 6.25e-05
Epoch 157 / 200, train loss: 0.03694736585021019
Epoch 157 / 200, val loss: 0.08495493233203888
Epoch 157 / 200, val acc: 0.524390243902439
Epoch 158 / 200, learning rate: 6.25e-05
Epoch 158 / 200, train loss: 0.037204135209321976
Epoch 158 / 200, val loss: 0.08331139385700226
Epoch 158 / 200, val acc: 0.5365853658536586
Epoch 159 / 200, learning rate: 6.25e-05
Epoch 159 / 200, train loss: 0.03677695617079735
Epoch 159 / 200, val loss: 0.08253378421068192
Epoch 159 / 200, val acc: 0.5365853658536586
Epoch 160 / 200, learning rate: 6.25e-05
Epoch 160 / 200, train loss: 0.04308462142944336
Epoch 160 / 200, val loss: 0.08179052919149399
Epoch 160 / 200, val acc: 0.5426829268292683
Epoch 161 / 200, learning rate: 6.25e-05
Epoch 161 / 200, train loss: 0.03458486124873161
Epoch 161 / 200, val loss: 0.08086654543876648
Epoch 161 / 200, val acc: 0.5487804878048781
Epoch 162 / 200, learning rate: 6.25e-05
Epoch 162 / 200, train loss: 0.03520386293530464
Epoch 162 / 200, val loss: 0.08019542694091797
Epoch 162 / 200, val acc: 0.5609756097560976
Epoch 163 / 200, learning rate: 6.25e-05
Epoch 163 / 200, train loss: 0.03605908155441284
Epoch 163 / 200, val loss: 0.07950012385845184
Epoch 163 / 200, val acc: 0.5609756097560976
Epoch 164 / 200, learning rate: 6.25e-05
Epoch 164 / 200, train loss: 0.034146156162023544
Epoch 164 / 200, val loss: 0.07991787791252136
Epoch 164 / 200, val acc: 0.5609756097560976
Epoch 165 / 200, learning rate: 3.125e-05
Epoch 165 / 200, train loss: 0.03755456209182739
Epoch 165 / 200, val loss: 0.08140221238136292
Epoch 165 / 200, val acc: 0.5487804878048781
Epoch 166 / 200, learning rate: 3.125e-05
Epoch 166 / 200, train loss: 0.03752443566918373
Epoch 166 / 200, val loss: 0.08232277631759644
Epoch 166 / 200, val acc: 0.5304878048780488
Epoch 167 / 200, learning rate: 3.125e-05
Epoch 167 / 200, train loss: 0.04152139648795128
Epoch 167 / 200, val loss: 0.08371888846158981
Epoch 167 / 200, val acc: 0.524390243902439
Epoch 168 / 200, learning rate: 3.125e-05
Epoch 168 / 200, train loss: 0.03574572876095772
Epoch 168 / 200, val loss: 0.08536761999130249
Epoch 168 / 200, val acc: 0.5182926829268293
Epoch 169 / 200, learning rate: 3.125e-05
Epoch 169 / 200, train loss: 0.03586447611451149
Epoch 169 / 200, val loss: 0.08762316405773163
Epoch 169 / 200, val acc: 0.5
Epoch 170 / 200, learning rate: 3.125e-05
Epoch 170 / 200, train loss: 0.035218462347984314
Epoch 170 / 200, val loss: 0.08953890949487686
Epoch 170 / 200, val acc: 0.49390243902439024
Epoch 171 / 200, learning rate: 3.125e-05
Epoch 171 / 200, train loss: 0.04250870272517204
Epoch 171 / 200, val loss: 0.09132218360900879
Epoch 171 / 200, val acc: 0.5060975609756098
Epoch 172 / 200, learning rate: 3.125e-05
Epoch 172 / 200, train loss: 0.03667474910616875
Epoch 172 / 200, val loss: 0.09335576742887497
Epoch 172 / 200, val acc: 0.5060975609756098
Epoch 173 / 200, learning rate: 3.125e-05
Epoch 173 / 200, train loss: 0.03937065228819847
Epoch 173 / 200, val loss: 0.09524013102054596
Epoch 173 / 200, val acc: 0.5060975609756098
Epoch 174 / 200, learning rate: 3.125e-05
Epoch 174 / 200, train loss: 0.03446953743696213
Epoch 174 / 200, val loss: 0.09636515378952026
Epoch 174 / 200, val acc: 0.5060975609756098
Epoch 175 / 200, learning rate: 3.125e-05
Epoch 175 / 200, train loss: 0.03642776980996132
Epoch 175 / 200, val loss: 0.09696674346923828
Epoch 175 / 200, val acc: 0.5121951219512195
Epoch 176 / 200, learning rate: 1.5625e-05
Epoch 176 / 200, train loss: 0.03655112162232399
Epoch 176 / 200, val loss: 0.09718985855579376
Epoch 176 / 200, val acc: 0.5121951219512195
Epoch 177 / 200, learning rate: 1.5625e-05
Epoch 177 / 200, train loss: 0.03711549937725067
Epoch 177 / 200, val loss: 0.09679082781076431
Epoch 177 / 200, val acc: 0.5060975609756098
Epoch 178 / 200, learning rate: 1.5625e-05
Epoch 178 / 200, train loss: 0.0368049181997776
Epoch 178 / 200, val loss: 0.09599531441926956
Epoch 178 / 200, val acc: 0.5060975609756098
Epoch 179 / 200, learning rate: 1.5625e-05
Epoch 179 / 200, train loss: 0.03661679849028587
Epoch 179 / 200, val loss: 0.09492775797843933
Epoch 179 / 200, val acc: 0.5060975609756098
Epoch 180 / 200, learning rate: 1.5625e-05
Epoch 180 / 200, train loss: 0.03953108936548233
Epoch 180 / 200, val loss: 0.09361926466226578
Epoch 180 / 200, val acc: 0.5060975609756098
Epoch 181 / 200, learning rate: 1.5625e-05
Epoch 181 / 200, train loss: 0.037681229412555695
Epoch 181 / 200, val loss: 0.09229296445846558
Epoch 181 / 200, val acc: 0.5060975609756098
Epoch 182 / 200, learning rate: 1.5625e-05
Epoch 182 / 200, train loss: 0.036268897354602814
Epoch 182 / 200, val loss: 0.09131594002246857
Epoch 182 / 200, val acc: 0.5
Epoch 183 / 200, learning rate: 1.5625e-05
Epoch 183 / 200, train loss: 0.03838971629738808
Epoch 183 / 200, val loss: 0.09055706113576889
Epoch 183 / 200, val acc: 0.5
Epoch 184 / 200, learning rate: 1.5625e-05
Epoch 184 / 200, train loss: 0.03444936126470566
Epoch 184 / 200, val loss: 0.08959469944238663
Epoch 184 / 200, val acc: 0.5
Epoch 185 / 200, learning rate: 1.5625e-05
Epoch 185 / 200, train loss: 0.03484801948070526
Epoch 185 / 200, val loss: 0.08877752721309662
Epoch 185 / 200, val acc: 0.49390243902439024
Epoch 186 / 200, learning rate: 1.5625e-05
Epoch 186 / 200, train loss: 0.03422166779637337
Epoch 186 / 200, val loss: 0.08801914006471634
Epoch 186 / 200, val acc: 0.5
Epoch 187 / 200, learning rate: 7.8125e-06
Epoch 187 / 200, train loss: 0.037171926349401474
Epoch 187 / 200, val loss: 0.08745848387479782
Epoch 187 / 200, val acc: 0.5121951219512195
Epoch 188 / 200, learning rate: 7.8125e-06
Epoch 188 / 200, train loss: 0.04039258882403374
Epoch 188 / 200, val loss: 0.08722908794879913
Epoch 188 / 200, val acc: 0.5121951219512195
Epoch 189 / 200, learning rate: 7.8125e-06
Epoch 189 / 200, train loss: 0.04295625537633896
Epoch 189 / 200, val loss: 0.08704885840415955
Epoch 189 / 200, val acc: 0.5121951219512195
Epoch 190 / 200, learning rate: 7.8125e-06
Epoch 190 / 200, train loss: 0.034697502851486206
Epoch 190 / 200, val loss: 0.0869845598936081
Epoch 190 / 200, val acc: 0.5121951219512195
Epoch 191 / 200, learning rate: 7.8125e-06
Epoch 191 / 200, train loss: 0.035749804228544235
Epoch 191 / 200, val loss: 0.08697036653757095
Epoch 191 / 200, val acc: 0.5121951219512195
Epoch 192 / 200, learning rate: 7.8125e-06
Epoch 192 / 200, train loss: 0.037427425384521484
Epoch 192 / 200, val loss: 0.0869249626994133
Epoch 192 / 200, val acc: 0.5121951219512195
Epoch 193 / 200, learning rate: 7.8125e-06
Epoch 193 / 200, train loss: 0.04114242270588875
Epoch 193 / 200, val loss: 0.08696897327899933
Epoch 193 / 200, val acc: 0.5121951219512195
Epoch 194 / 200, learning rate: 7.8125e-06
Epoch 194 / 200, train loss: 0.03777690231800079
Epoch 194 / 200, val loss: 0.08704671263694763
Epoch 194 / 200, val acc: 0.5121951219512195
Epoch 195 / 200, learning rate: 7.8125e-06
Epoch 195 / 200, train loss: 0.03654635325074196
Epoch 195 / 200, val loss: 0.08715519309043884
Epoch 195 / 200, val acc: 0.5121951219512195
Epoch 196 / 200, learning rate: 7.8125e-06
Epoch 196 / 200, train loss: 0.03403519466519356
Epoch 196 / 200, val loss: 0.08737548440694809
Epoch 196 / 200, val acc: 0.5121951219512195
Epoch 197 / 200, learning rate: 7.8125e-06
Epoch 197 / 200, train loss: 0.037540826946496964
Epoch 197 / 200, val loss: 0.08752121031284332
Epoch 197 / 200, val acc: 0.5121951219512195
Epoch 198 / 200, learning rate: 3.90625e-06
Epoch 198 / 200, train loss: 0.035508982837200165
Epoch 198 / 200, val loss: 0.08781087398529053
Epoch 198 / 200, val acc: 0.5060975609756098
Epoch 199 / 200, learning rate: 3.90625e-06
Epoch 199 / 200, train loss: 0.03453296795487404
Epoch 199 / 200, val loss: 0.08794905990362167
Epoch 199 / 200, val acc: 0.5060975609756098
Epoch 200 / 200, learning rate: 3.90625e-06
Epoch 200 / 200, train loss: 0.03573429211974144
Epoch 200 / 200, val loss: 0.08813599497079849
Epoch 200 / 200, val acc: 0.5060975609756098
Training finished

Evaluating best model
Trading strategy for stock TSLA:
After 3294 trading days
Binary accuracy: 0.49803
Fraction of long signals: 0.20219
Fraction of short signals: 0.79751
Overall long return: 7.24165
Overall return: -2.25739
Yearly long return: 0.55401
Yearly return: -0.17270
Daily volatility: 0.03609
Max drawdown baseline: 0.13098
Max drawdown: 2.50138
Sharpe ratio: -0.07991
L1 error baseline: 0.79460
L1 error: 0.06910
Average prediction: -0.03409
Std prediction: 0.98296


Trading strategy for stock TSLA:
After 165 trading days
Binary accuracy: 0.42683
Fraction of long signals: 0.37576
Fraction of short signals: 0.62424
Overall long return: 0.42742
Overall return: -0.72459
Yearly long return: 0.65278
Yearly return: -1.10665
Daily volatility: 0.03878
Max drawdown baseline: 0.55750
Max drawdown: 0.84405
Sharpe ratio: -0.18071
L1 error baseline: 1.31066
L1 error: 0.18121
Average prediction: 1.26217
Std prediction: 0.38944


