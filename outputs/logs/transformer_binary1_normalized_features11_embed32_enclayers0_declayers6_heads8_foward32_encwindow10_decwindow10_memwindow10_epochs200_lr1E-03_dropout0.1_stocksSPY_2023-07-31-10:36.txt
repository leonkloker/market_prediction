Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              384
├─Time2Vec: 1-2                                    [1, 100, 40]              --
│    └─Linear: 2-1                                 [100, 8]                  16
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 40]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 40]              --
│    └─MyIdentity: 2-3                             [1, 100, 40]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 40]              --
│    │    └─ModuleList: 3-1                        --                        95,952
│    │    └─LayerNorm: 3-2                         [1, 100, 40]              80
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 20]              820
│    └─Dropout: 2-6                                [1, 100, 20]              --
│    └─ReLU: 2-7                                   [1, 100, 20]              --
│    └─Linear: 2-8                                 [1, 100, 1]               21
├─Sigmoid: 1-7                                     [1, 100, 1]               --
====================================================================================================
Total params: 97,273
Trainable params: 97,273
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.03
Params size (MB): 0.07
Estimated Total Size (MB): 1.12
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.6998104453086853
Epoch 1 / 200, val loss: 0.6927140355110168
Epoch 1 / 200, val acc: 0.7590361445783133
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.691807746887207
Epoch 2 / 200, val loss: 0.6944600939750671
Epoch 2 / 200, val acc: 0.7590361445783133
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.6892372965812683
Epoch 3 / 200, val loss: 0.6987102031707764
Epoch 3 / 200, val acc: 0.7590361445783133
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.688547670841217
Epoch 4 / 200, val loss: 0.7014559507369995
Epoch 4 / 200, val acc: 0.7590361445783133
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.6908940672874451
Epoch 5 / 200, val loss: 0.7025169134140015
Epoch 5 / 200, val acc: 0.7590361445783133
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.691559374332428
Epoch 6 / 200, val loss: 0.7018187642097473
Epoch 6 / 200, val acc: 0.7590361445783133
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.689318060874939
Epoch 7 / 200, val loss: 0.6999189853668213
Epoch 7 / 200, val acc: 0.7590361445783133
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.6889967322349548
Epoch 8 / 200, val loss: 0.6979415416717529
Epoch 8 / 200, val acc: 0.7590361445783133
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.6889017224311829
Epoch 9 / 200, val loss: 0.6963403224945068
Epoch 9 / 200, val acc: 0.7590361445783133
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.6869812607765198
Epoch 10 / 200, val loss: 0.695309579372406
Epoch 10 / 200, val acc: 0.7590361445783133
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.688065767288208
Epoch 11 / 200, val loss: 0.694523811340332
Epoch 11 / 200, val acc: 0.7590361445783133
Epoch 12 / 200, learning rate: 0.0005
Epoch 12 / 200, train loss: 0.6876710057258606
Epoch 12 / 200, val loss: 0.6939769387245178
Epoch 12 / 200, val acc: 0.7590361445783133
Epoch 13 / 200, learning rate: 0.0005
Epoch 13 / 200, train loss: 0.6878294348716736
Epoch 13 / 200, val loss: 0.6938216686248779
Epoch 13 / 200, val acc: 0.7590361445783133
Epoch 14 / 200, learning rate: 0.0005
Epoch 14 / 200, train loss: 0.6873492002487183
Epoch 14 / 200, val loss: 0.6937564015388489
Epoch 14 / 200, val acc: 0.7590361445783133
Epoch 15 / 200, learning rate: 0.0005
Epoch 15 / 200, train loss: 0.6882138848304749
Epoch 15 / 200, val loss: 0.6937399506568909
Epoch 15 / 200, val acc: 0.7590361445783133
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.6871251463890076
Epoch 16 / 200, val loss: 0.6937594413757324
Epoch 16 / 200, val acc: 0.7590361445783133
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.6883533000946045
Epoch 17 / 200, val loss: 0.693818986415863
Epoch 17 / 200, val acc: 0.7590361445783133
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.6878649592399597
Epoch 18 / 200, val loss: 0.6939069628715515
Epoch 18 / 200, val acc: 0.7590361445783133
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.6885787844657898
Epoch 19 / 200, val loss: 0.6940222382545471
Epoch 19 / 200, val acc: 0.7590361445783133
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.6884118914604187
Epoch 20 / 200, val loss: 0.694158136844635
Epoch 20 / 200, val acc: 0.7590361445783133
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.6882350444793701
Epoch 21 / 200, val loss: 0.6943131685256958
Epoch 21 / 200, val acc: 0.7590361445783133
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.6875
Epoch 22 / 200, val loss: 0.6944780349731445
Epoch 22 / 200, val acc: 0.7590361445783133
Epoch 23 / 200, learning rate: 0.00025
Epoch 23 / 200, train loss: 0.6876704692840576
Epoch 23 / 200, val loss: 0.694659948348999
Epoch 23 / 200, val acc: 0.7590361445783133
Epoch 24 / 200, learning rate: 0.00025
Epoch 24 / 200, train loss: 0.6867796778678894
Epoch 24 / 200, val loss: 0.6947476863861084
Epoch 24 / 200, val acc: 0.7590361445783133
Epoch 25 / 200, learning rate: 0.00025
Epoch 25 / 200, train loss: 0.6882104873657227
Epoch 25 / 200, val loss: 0.6948401927947998
Epoch 25 / 200, val acc: 0.7590361445783133
Epoch 26 / 200, learning rate: 0.00025
Epoch 26 / 200, train loss: 0.6874895095825195
Epoch 26 / 200, val loss: 0.6949381828308105
Epoch 26 / 200, val acc: 0.7590361445783133
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.6882968544960022
Epoch 27 / 200, val loss: 0.6950353384017944
Epoch 27 / 200, val acc: 0.7590361445783133
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.6877281665802002
Epoch 28 / 200, val loss: 0.6951295137405396
Epoch 28 / 200, val acc: 0.7590361445783133
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.6874600052833557
Epoch 29 / 200, val loss: 0.6952176690101624
Epoch 29 / 200, val acc: 0.7590361445783133
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.6869267821311951
Epoch 30 / 200, val loss: 0.6952947378158569
Epoch 30 / 200, val acc: 0.7590361445783133
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.6879726648330688
Epoch 31 / 200, val loss: 0.6953529119491577
Epoch 31 / 200, val acc: 0.7590361445783133
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.688513994216919
Epoch 32 / 200, val loss: 0.6954017877578735
Epoch 32 / 200, val acc: 0.7590361445783133
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.686968207359314
Epoch 33 / 200, val loss: 0.6954503655433655
Epoch 33 / 200, val acc: 0.7590361445783133
Epoch 34 / 200, learning rate: 0.000125
Epoch 34 / 200, train loss: 0.6877217888832092
Epoch 34 / 200, val loss: 0.6954784393310547
Epoch 34 / 200, val acc: 0.7590361445783133
Epoch 35 / 200, learning rate: 0.000125
Epoch 35 / 200, train loss: 0.6873575448989868
Epoch 35 / 200, val loss: 0.6954900026321411
Epoch 35 / 200, val acc: 0.7590361445783133
Epoch 36 / 200, learning rate: 0.000125
Epoch 36 / 200, train loss: 0.6878031492233276
Epoch 36 / 200, val loss: 0.6954968571662903
Epoch 36 / 200, val acc: 0.7590361445783133
Epoch 37 / 200, learning rate: 0.000125
Epoch 37 / 200, train loss: 0.6869952082633972
Epoch 37 / 200, val loss: 0.695503830909729
Epoch 37 / 200, val acc: 0.7590361445783133
Epoch 38 / 200, learning rate: 0.000125
Epoch 38 / 200, train loss: 0.6874502897262573
Epoch 38 / 200, val loss: 0.6955087184906006
Epoch 38 / 200, val acc: 0.7590361445783133
Epoch 39 / 200, learning rate: 0.000125
Epoch 39 / 200, train loss: 0.687179684638977
Epoch 39 / 200, val loss: 0.6955123543739319
Epoch 39 / 200, val acc: 0.7590361445783133
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.6880733370780945
Epoch 40 / 200, val loss: 0.6955116391181946
Epoch 40 / 200, val acc: 0.7590361445783133
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.6876127123832703
Epoch 41 / 200, val loss: 0.6955135464668274
Epoch 41 / 200, val acc: 0.7590361445783133
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.6878348588943481
Epoch 42 / 200, val loss: 0.6955097913742065
Epoch 42 / 200, val acc: 0.7590361445783133
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.6880735754966736
Epoch 43 / 200, val loss: 0.6955063939094543
Epoch 43 / 200, val acc: 0.7590361445783133
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.6874968409538269
Epoch 44 / 200, val loss: 0.6955024600028992
Epoch 44 / 200, val acc: 0.7590361445783133
Epoch 45 / 200, learning rate: 6.25e-05
Epoch 45 / 200, train loss: 0.6876568794250488
Epoch 45 / 200, val loss: 0.6954953670501709
Epoch 45 / 200, val acc: 0.7590361445783133
Epoch 46 / 200, learning rate: 6.25e-05
Epoch 46 / 200, train loss: 0.687385618686676
Epoch 46 / 200, val loss: 0.6954895257949829
Epoch 46 / 200, val acc: 0.7590361445783133
Epoch 47 / 200, learning rate: 6.25e-05
Epoch 47 / 200, train loss: 0.6872407793998718
Epoch 47 / 200, val loss: 0.6954841017723083
Epoch 47 / 200, val acc: 0.7590361445783133
Epoch 48 / 200, learning rate: 6.25e-05
Epoch 48 / 200, train loss: 0.6875461339950562
Epoch 48 / 200, val loss: 0.6954787373542786
Epoch 48 / 200, val acc: 0.7590361445783133
Epoch 49 / 200, learning rate: 6.25e-05
Epoch 49 / 200, train loss: 0.6871607303619385
Epoch 49 / 200, val loss: 0.6954724192619324
Epoch 49 / 200, val acc: 0.7590361445783133
Epoch 50 / 200, learning rate: 6.25e-05
Epoch 50 / 200, train loss: 0.6881511211395264
Epoch 50 / 200, val loss: 0.6954636573791504
Epoch 50 / 200, val acc: 0.7590361445783133
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.6884064674377441
Epoch 51 / 200, val loss: 0.6954535245895386
Epoch 51 / 200, val acc: 0.7590361445783133
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.6870955228805542
Epoch 52 / 200, val loss: 0.6954423785209656
Epoch 52 / 200, val acc: 0.7590361445783133
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.6876486539840698
Epoch 53 / 200, val loss: 0.6954284906387329
Epoch 53 / 200, val acc: 0.7590361445783133
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.6871489882469177
Epoch 54 / 200, val loss: 0.695414662361145
Epoch 54 / 200, val acc: 0.7590361445783133
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.6874167919158936
Epoch 55 / 200, val loss: 0.695399820804596
Epoch 55 / 200, val acc: 0.7590361445783133
Epoch 56 / 200, learning rate: 3.125e-05
Epoch 56 / 200, train loss: 0.6877268552780151
Epoch 56 / 200, val loss: 0.6953842639923096
Epoch 56 / 200, val acc: 0.7590361445783133
Epoch 57 / 200, learning rate: 3.125e-05
Epoch 57 / 200, train loss: 0.6877628564834595
Epoch 57 / 200, val loss: 0.6953766942024231
Epoch 57 / 200, val acc: 0.7590361445783133
Epoch 58 / 200, learning rate: 3.125e-05
Epoch 58 / 200, train loss: 0.6873851418495178
Epoch 58 / 200, val loss: 0.6953694224357605
Epoch 58 / 200, val acc: 0.7590361445783133
Epoch 59 / 200, learning rate: 3.125e-05
Epoch 59 / 200, train loss: 0.6872902512550354
Epoch 59 / 200, val loss: 0.6953607797622681
Epoch 59 / 200, val acc: 0.7590361445783133
Epoch 60 / 200, learning rate: 3.125e-05
Epoch 60 / 200, train loss: 0.6880211234092712
Epoch 60 / 200, val loss: 0.6953525543212891
Epoch 60 / 200, val acc: 0.7590361445783133
Epoch 61 / 200, learning rate: 3.125e-05
Epoch 61 / 200, train loss: 0.6874058246612549
Epoch 61 / 200, val loss: 0.6953446269035339
Epoch 61 / 200, val acc: 0.7590361445783133
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.6871424913406372
Epoch 62 / 200, val loss: 0.6953380703926086
Epoch 62 / 200, val acc: 0.7590361445783133
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.6874173283576965
Epoch 63 / 200, val loss: 0.6953328251838684
Epoch 63 / 200, val acc: 0.7590361445783133
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.6875855922698975
Epoch 64 / 200, val loss: 0.6953275203704834
Epoch 64 / 200, val acc: 0.7590361445783133
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.688266396522522
Epoch 65 / 200, val loss: 0.6953220367431641
Epoch 65 / 200, val acc: 0.7590361445783133
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.6868326663970947
Epoch 66 / 200, val loss: 0.6953167915344238
Epoch 66 / 200, val acc: 0.7590361445783133
Epoch 67 / 200, learning rate: 1.5625e-05
Epoch 67 / 200, train loss: 0.6877875328063965
Epoch 67 / 200, val loss: 0.6953111290931702
Epoch 67 / 200, val acc: 0.7590361445783133
Epoch 68 / 200, learning rate: 1.5625e-05
Epoch 68 / 200, train loss: 0.6881168484687805
Epoch 68 / 200, val loss: 0.6953083872795105
Epoch 68 / 200, val acc: 0.7590361445783133
Epoch 69 / 200, learning rate: 1.5625e-05
Epoch 69 / 200, train loss: 0.6869511604309082
Epoch 69 / 200, val loss: 0.6953056454658508
Epoch 69 / 200, val acc: 0.7590361445783133
Epoch 70 / 200, learning rate: 1.5625e-05
Epoch 70 / 200, train loss: 0.6868053078651428
Epoch 70 / 200, val loss: 0.6953028440475464
Epoch 70 / 200, val acc: 0.7590361445783133
Epoch 71 / 200, learning rate: 1.5625e-05
Epoch 71 / 200, train loss: 0.6871607303619385
Epoch 71 / 200, val loss: 0.6952999830245972
Epoch 71 / 200, val acc: 0.7590361445783133
Epoch 72 / 200, learning rate: 1.5625e-05
Epoch 72 / 200, train loss: 0.6877357959747314
Epoch 72 / 200, val loss: 0.6952975392341614
Epoch 72 / 200, val acc: 0.7590361445783133
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.6880795359611511
Epoch 73 / 200, val loss: 0.6952948570251465
Epoch 73 / 200, val acc: 0.7590361445783133
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.6874171495437622
Epoch 74 / 200, val loss: 0.6952922940254211
Epoch 74 / 200, val acc: 0.7590361445783133
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.6874333024024963
Epoch 75 / 200, val loss: 0.6952903270721436
Epoch 75 / 200, val acc: 0.7590361445783133
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.687933623790741
Epoch 76 / 200, val loss: 0.6952882409095764
Epoch 76 / 200, val acc: 0.7590361445783133
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.6868535280227661
Epoch 77 / 200, val loss: 0.6952862739562988
Epoch 77 / 200, val acc: 0.7590361445783133
Epoch 78 / 200, learning rate: 7.8125e-06
Epoch 78 / 200, train loss: 0.686799168586731
Epoch 78 / 200, val loss: 0.6952846050262451
Epoch 78 / 200, val acc: 0.7590361445783133
Epoch 79 / 200, learning rate: 7.8125e-06
Epoch 79 / 200, train loss: 0.6873416900634766
Epoch 79 / 200, val loss: 0.6952839493751526
Epoch 79 / 200, val acc: 0.7590361445783133
Epoch 80 / 200, learning rate: 7.8125e-06
Epoch 80 / 200, train loss: 0.6876587271690369
Epoch 80 / 200, val loss: 0.6952831149101257
Epoch 80 / 200, val acc: 0.7590361445783133
Epoch 81 / 200, learning rate: 7.8125e-06
Epoch 81 / 200, train loss: 0.6876236200332642
Epoch 81 / 200, val loss: 0.6952821612358093
Epoch 81 / 200, val acc: 0.7590361445783133
Epoch 82 / 200, learning rate: 7.8125e-06
Epoch 82 / 200, train loss: 0.6870899796485901
Epoch 82 / 200, val loss: 0.6952811479568481
Epoch 82 / 200, val acc: 0.7590361445783133
Epoch 83 / 200, learning rate: 7.8125e-06
Epoch 83 / 200, train loss: 0.6863201260566711
Epoch 83 / 200, val loss: 0.695280134677887
Epoch 83 / 200, val acc: 0.7590361445783133
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.6866276264190674
Epoch 84 / 200, val loss: 0.6952797174453735
Epoch 84 / 200, val acc: 0.7590361445783133
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.6879656910896301
Epoch 85 / 200, val loss: 0.6952788829803467
Epoch 85 / 200, val acc: 0.7590361445783133
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.6878635883331299
Epoch 86 / 200, val loss: 0.6952781677246094
Epoch 86 / 200, val acc: 0.7590361445783133
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.6879723072052002
Epoch 87 / 200, val loss: 0.6952773928642273
Epoch 87 / 200, val acc: 0.7590361445783133
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.687557578086853
Epoch 88 / 200, val loss: 0.6952762603759766
Epoch 88 / 200, val acc: 0.7590361445783133
Epoch 89 / 200, learning rate: 3.90625e-06
Epoch 89 / 200, train loss: 0.6875662207603455
Epoch 89 / 200, val loss: 0.695275068283081
Epoch 89 / 200, val acc: 0.7590361445783133
Epoch 90 / 200, learning rate: 3.90625e-06
Epoch 90 / 200, train loss: 0.6877660751342773
Epoch 90 / 200, val loss: 0.6952745318412781
Epoch 90 / 200, val acc: 0.7590361445783133
Epoch 91 / 200, learning rate: 3.90625e-06
Epoch 91 / 200, train loss: 0.6868876218795776
Epoch 91 / 200, val loss: 0.6952740550041199
Epoch 91 / 200, val acc: 0.7590361445783133
Epoch 92 / 200, learning rate: 3.90625e-06
Epoch 92 / 200, train loss: 0.6865910887718201
Epoch 92 / 200, val loss: 0.6952736973762512
Epoch 92 / 200, val acc: 0.7590361445783133
Epoch 93 / 200, learning rate: 3.90625e-06
Epoch 93 / 200, train loss: 0.6869285106658936
Epoch 93 / 200, val loss: 0.6952733993530273
Epoch 93 / 200, val acc: 0.7590361445783133
Epoch 94 / 200, learning rate: 3.90625e-06
Epoch 94 / 200, train loss: 0.6877670288085938
Epoch 94 / 200, val loss: 0.6952729821205139
Epoch 94 / 200, val acc: 0.7590361445783133
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.687572717666626
Epoch 95 / 200, val loss: 0.6952726244926453
Epoch 95 / 200, val acc: 0.7590361445783133
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.6871191263198853
Epoch 96 / 200, val loss: 0.6952721476554871
Epoch 96 / 200, val acc: 0.7590361445783133
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.6886687278747559
Epoch 97 / 200, val loss: 0.6952716112136841
Epoch 97 / 200, val acc: 0.7590361445783133
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.6878745555877686
Epoch 98 / 200, val loss: 0.6952712535858154
Epoch 98 / 200, val acc: 0.7590361445783133
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.6880407929420471
Epoch 99 / 200, val loss: 0.695270836353302
Epoch 99 / 200, val acc: 0.7590361445783133
Epoch 100 / 200, learning rate: 1.953125e-06
Epoch 100 / 200, train loss: 0.6874304413795471
Epoch 100 / 200, val loss: 0.6952704191207886
Epoch 100 / 200, val acc: 0.7590361445783133
Epoch 101 / 200, learning rate: 1.953125e-06
Epoch 101 / 200, train loss: 0.687950849533081
Epoch 101 / 200, val loss: 0.6952702403068542
Epoch 101 / 200, val acc: 0.7590361445783133
Epoch 102 / 200, learning rate: 1.953125e-06
Epoch 102 / 200, train loss: 0.6872628331184387
Epoch 102 / 200, val loss: 0.6952700614929199
Epoch 102 / 200, val acc: 0.7590361445783133
Epoch 103 / 200, learning rate: 1.953125e-06
Epoch 103 / 200, train loss: 0.6879619359970093
Epoch 103 / 200, val loss: 0.6952698826789856
Epoch 103 / 200, val acc: 0.7590361445783133
Epoch 104 / 200, learning rate: 1.953125e-06
Epoch 104 / 200, train loss: 0.6877170205116272
Epoch 104 / 200, val loss: 0.6952695846557617
Epoch 104 / 200, val acc: 0.7590361445783133
Epoch 105 / 200, learning rate: 1.953125e-06
Epoch 105 / 200, train loss: 0.6874544024467468
Epoch 105 / 200, val loss: 0.6952694654464722
Epoch 105 / 200, val acc: 0.7590361445783133
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.6867753267288208
Epoch 106 / 200, val loss: 0.6952692270278931
Epoch 106 / 200, val acc: 0.7590361445783133
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.6875080466270447
Epoch 107 / 200, val loss: 0.6952689290046692
Epoch 107 / 200, val acc: 0.7590361445783133
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.6866522431373596
Epoch 108 / 200, val loss: 0.6952688097953796
Epoch 108 / 200, val acc: 0.7590361445783133
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.688374936580658
Epoch 109 / 200, val loss: 0.6952685713768005
Epoch 109 / 200, val acc: 0.7590361445783133
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.6869246959686279
Epoch 110 / 200, val loss: 0.6952683329582214
Epoch 110 / 200, val acc: 0.7590361445783133
Epoch 111 / 200, learning rate: 9.765625e-07
Epoch 111 / 200, train loss: 0.6883624196052551
Epoch 111 / 200, val loss: 0.6952680945396423
Epoch 111 / 200, val acc: 0.7590361445783133
Epoch 112 / 200, learning rate: 9.765625e-07
Epoch 112 / 200, train loss: 0.6879119277000427
Epoch 112 / 200, val loss: 0.6952680349349976
Epoch 112 / 200, val acc: 0.7590361445783133
Epoch 113 / 200, learning rate: 9.765625e-07
Epoch 113 / 200, train loss: 0.6867568492889404
Epoch 113 / 200, val loss: 0.6952679753303528
Epoch 113 / 200, val acc: 0.7590361445783133
Epoch 114 / 200, learning rate: 9.765625e-07
Epoch 114 / 200, train loss: 0.6877115368843079
Epoch 114 / 200, val loss: 0.695267915725708
Epoch 114 / 200, val acc: 0.7590361445783133
Epoch 115 / 200, learning rate: 9.765625e-07
Epoch 115 / 200, train loss: 0.6867527365684509
Epoch 115 / 200, val loss: 0.6952677369117737
Epoch 115 / 200, val acc: 0.7590361445783133
Epoch 116 / 200, learning rate: 9.765625e-07
Epoch 116 / 200, train loss: 0.6872382760047913
Epoch 116 / 200, val loss: 0.6952676773071289
Epoch 116 / 200, val acc: 0.7590361445783133
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.6868043541908264
Epoch 117 / 200, val loss: 0.6952675580978394
Epoch 117 / 200, val acc: 0.7590361445783133
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.6876354217529297
Epoch 118 / 200, val loss: 0.695267379283905
Epoch 118 / 200, val acc: 0.7590361445783133
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.6866850256919861
Epoch 119 / 200, val loss: 0.6952672600746155
Epoch 119 / 200, val acc: 0.7590361445783133
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.6877627968788147
Epoch 120 / 200, val loss: 0.6952671408653259
Epoch 120 / 200, val acc: 0.7590361445783133
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.6874551177024841
Epoch 121 / 200, val loss: 0.6952670216560364
Epoch 121 / 200, val acc: 0.7590361445783133
Epoch 122 / 200, learning rate: 4.8828125e-07
Epoch 122 / 200, train loss: 0.687576174736023
Epoch 122 / 200, val loss: 0.6952669024467468
Epoch 122 / 200, val acc: 0.7590361445783133
Epoch 123 / 200, learning rate: 4.8828125e-07
Epoch 123 / 200, train loss: 0.6880332231521606
Epoch 123 / 200, val loss: 0.6952667236328125
Epoch 123 / 200, val acc: 0.7590361445783133
Epoch 124 / 200, learning rate: 4.8828125e-07
Epoch 124 / 200, train loss: 0.687485933303833
Epoch 124 / 200, val loss: 0.6952666640281677
Epoch 124 / 200, val acc: 0.7590361445783133
Epoch 125 / 200, learning rate: 4.8828125e-07
Epoch 125 / 200, train loss: 0.6867526769638062
Epoch 125 / 200, val loss: 0.6952664852142334
Epoch 125 / 200, val acc: 0.7590361445783133
Epoch 126 / 200, learning rate: 4.8828125e-07
Epoch 126 / 200, train loss: 0.6870541572570801
Epoch 126 / 200, val loss: 0.6952664852142334
Epoch 126 / 200, val acc: 0.7590361445783133
Epoch 127 / 200, learning rate: 4.8828125e-07
Epoch 127 / 200, train loss: 0.6870594620704651
Epoch 127 / 200, val loss: 0.6952663660049438
Epoch 127 / 200, val acc: 0.7590361445783133
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.6877978444099426
Epoch 128 / 200, val loss: 0.6952663064002991
Epoch 128 / 200, val acc: 0.7590361445783133
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.687140941619873
Epoch 129 / 200, val loss: 0.6952662467956543
Epoch 129 / 200, val acc: 0.7590361445783133
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.6878654956817627
Epoch 130 / 200, val loss: 0.6952661871910095
Epoch 130 / 200, val acc: 0.7590361445783133
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.6873946189880371
Epoch 131 / 200, val loss: 0.6952661275863647
Epoch 131 / 200, val acc: 0.7590361445783133
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.6875322461128235
Epoch 132 / 200, val loss: 0.69526606798172
Epoch 132 / 200, val acc: 0.7590361445783133
Epoch 133 / 200, learning rate: 2.44140625e-07
Epoch 133 / 200, train loss: 0.6871869564056396
Epoch 133 / 200, val loss: 0.6952660083770752
Epoch 133 / 200, val acc: 0.7590361445783133
Epoch 134 / 200, learning rate: 2.44140625e-07
Epoch 134 / 200, train loss: 0.6878429055213928
Epoch 134 / 200, val loss: 0.6952660083770752
Epoch 134 / 200, val acc: 0.7590361445783133
Epoch 135 / 200, learning rate: 2.44140625e-07
Epoch 135 / 200, train loss: 0.6885301470756531
Epoch 135 / 200, val loss: 0.6952660083770752
Epoch 135 / 200, val acc: 0.7590361445783133
Epoch 136 / 200, learning rate: 2.44140625e-07
Epoch 136 / 200, train loss: 0.6871127486228943
Epoch 136 / 200, val loss: 0.6952660083770752
Epoch 136 / 200, val acc: 0.7590361445783133
Epoch 137 / 200, learning rate: 2.44140625e-07
Epoch 137 / 200, train loss: 0.6879615187644958
Epoch 137 / 200, val loss: 0.6952660083770752
Epoch 137 / 200, val acc: 0.7590361445783133
Epoch 138 / 200, learning rate: 2.44140625e-07
Epoch 138 / 200, train loss: 0.6879425048828125
Epoch 138 / 200, val loss: 0.6952660083770752
Epoch 138 / 200, val acc: 0.7590361445783133
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.6885042190551758
Epoch 139 / 200, val loss: 0.6952660083770752
Epoch 139 / 200, val acc: 0.7590361445783133
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.6874364018440247
Epoch 140 / 200, val loss: 0.6952660083770752
Epoch 140 / 200, val acc: 0.7590361445783133
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.6869882345199585
Epoch 141 / 200, val loss: 0.6952660083770752
Epoch 141 / 200, val acc: 0.7590361445783133
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.6869609355926514
Epoch 142 / 200, val loss: 0.6952660083770752
Epoch 142 / 200, val acc: 0.7590361445783133
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.6870542764663696
Epoch 143 / 200, val loss: 0.6952660083770752
Epoch 143 / 200, val acc: 0.7590361445783133
Epoch 144 / 200, learning rate: 1.220703125e-07
Epoch 144 / 200, train loss: 0.6874535083770752
Epoch 144 / 200, val loss: 0.6952660083770752
Epoch 144 / 200, val acc: 0.7590361445783133
Epoch 145 / 200, learning rate: 1.220703125e-07
Epoch 145 / 200, train loss: 0.6874382495880127
Epoch 145 / 200, val loss: 0.6952660083770752
Epoch 145 / 200, val acc: 0.7590361445783133
Epoch 146 / 200, learning rate: 1.220703125e-07
Epoch 146 / 200, train loss: 0.6878992319107056
Epoch 146 / 200, val loss: 0.6952660083770752
Epoch 146 / 200, val acc: 0.7590361445783133
Epoch 147 / 200, learning rate: 1.220703125e-07
Epoch 147 / 200, train loss: 0.6873157620429993
Epoch 147 / 200, val loss: 0.6952659487724304
Epoch 147 / 200, val acc: 0.7590361445783133
Epoch 148 / 200, learning rate: 1.220703125e-07
Epoch 148 / 200, train loss: 0.6868066191673279
Epoch 148 / 200, val loss: 0.6952659487724304
Epoch 148 / 200, val acc: 0.7590361445783133
Epoch 149 / 200, learning rate: 1.220703125e-07
Epoch 149 / 200, train loss: 0.6875734925270081
Epoch 149 / 200, val loss: 0.6952659487724304
Epoch 149 / 200, val acc: 0.7590361445783133
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.6880421042442322
Epoch 150 / 200, val loss: 0.6952659487724304
Epoch 150 / 200, val acc: 0.7590361445783133
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.6877551078796387
Epoch 151 / 200, val loss: 0.6952659487724304
Epoch 151 / 200, val acc: 0.7590361445783133
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.6871469020843506
Epoch 152 / 200, val loss: 0.6952659487724304
Epoch 152 / 200, val acc: 0.7590361445783133
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.6878759264945984
Epoch 153 / 200, val loss: 0.6952658891677856
Epoch 153 / 200, val acc: 0.7590361445783133
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.686601459980011
Epoch 154 / 200, val loss: 0.6952658891677856
Epoch 154 / 200, val acc: 0.7590361445783133
Epoch 155 / 200, learning rate: 6.103515625e-08
Epoch 155 / 200, train loss: 0.6880159378051758
Epoch 155 / 200, val loss: 0.6952658891677856
Epoch 155 / 200, val acc: 0.7590361445783133
Epoch 156 / 200, learning rate: 6.103515625e-08
Epoch 156 / 200, train loss: 0.6878690719604492
Epoch 156 / 200, val loss: 0.6952658891677856
Epoch 156 / 200, val acc: 0.7590361445783133
Epoch 157 / 200, learning rate: 6.103515625e-08
Epoch 157 / 200, train loss: 0.687029242515564
Epoch 157 / 200, val loss: 0.6952658891677856
Epoch 157 / 200, val acc: 0.7590361445783133
Epoch 158 / 200, learning rate: 6.103515625e-08
Epoch 158 / 200, train loss: 0.6868935227394104
Epoch 158 / 200, val loss: 0.6952658891677856
Epoch 158 / 200, val acc: 0.7590361445783133
Epoch 159 / 200, learning rate: 6.103515625e-08
Epoch 159 / 200, train loss: 0.6870704889297485
Epoch 159 / 200, val loss: 0.6952658891677856
Epoch 159 / 200, val acc: 0.7590361445783133
Epoch 160 / 200, learning rate: 6.103515625e-08
Epoch 160 / 200, train loss: 0.687938928604126
Epoch 160 / 200, val loss: 0.6952658891677856
Epoch 160 / 200, val acc: 0.7590361445783133
Epoch 161 / 200, learning rate: 6.103515625e-08
Epoch 161 / 200, train loss: 0.6876872777938843
Epoch 161 / 200, val loss: 0.6952658891677856
Epoch 161 / 200, val acc: 0.7590361445783133
Epoch 162 / 200, learning rate: 6.103515625e-08
Epoch 162 / 200, train loss: 0.6860877275466919
Epoch 162 / 200, val loss: 0.6952658891677856
Epoch 162 / 200, val acc: 0.7590361445783133
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.6873837113380432
Epoch 163 / 200, val loss: 0.6952658891677856
Epoch 163 / 200, val acc: 0.7590361445783133
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.6873738169670105
Epoch 164 / 200, val loss: 0.6952658891677856
Epoch 164 / 200, val acc: 0.7590361445783133
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.6869200468063354
Epoch 165 / 200, val loss: 0.6952658891677856
Epoch 165 / 200, val acc: 0.7590361445783133
Epoch 166 / 200, learning rate: 3.0517578125e-08
Epoch 166 / 200, train loss: 0.6871271729469299
Epoch 166 / 200, val loss: 0.6952658891677856
Epoch 166 / 200, val acc: 0.7590361445783133
Epoch 167 / 200, learning rate: 3.0517578125e-08
Epoch 167 / 200, train loss: 0.6869262456893921
Epoch 167 / 200, val loss: 0.6952658891677856
Epoch 167 / 200, val acc: 0.7590361445783133
Epoch 168 / 200, learning rate: 3.0517578125e-08
Epoch 168 / 200, train loss: 0.6879904866218567
Epoch 168 / 200, val loss: 0.6952658891677856
Epoch 168 / 200, val acc: 0.7590361445783133
Epoch 169 / 200, learning rate: 3.0517578125e-08
Epoch 169 / 200, train loss: 0.6876434683799744
Epoch 169 / 200, val loss: 0.6952658891677856
Epoch 169 / 200, val acc: 0.7590361445783133
Epoch 170 / 200, learning rate: 3.0517578125e-08
Epoch 170 / 200, train loss: 0.687673807144165
Epoch 170 / 200, val loss: 0.6952658891677856
Epoch 170 / 200, val acc: 0.7590361445783133
Epoch 171 / 200, learning rate: 3.0517578125e-08
Epoch 171 / 200, train loss: 0.6869843602180481
Epoch 171 / 200, val loss: 0.6952658891677856
Epoch 171 / 200, val acc: 0.7590361445783133
Epoch 172 / 200, learning rate: 3.0517578125e-08
Epoch 172 / 200, train loss: 0.6878185868263245
Epoch 172 / 200, val loss: 0.6952658891677856
Epoch 172 / 200, val acc: 0.7590361445783133
Epoch 173 / 200, learning rate: 3.0517578125e-08
Epoch 173 / 200, train loss: 0.6879478096961975
Epoch 173 / 200, val loss: 0.6952658891677856
Epoch 173 / 200, val acc: 0.7590361445783133
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.6878734827041626
Epoch 174 / 200, val loss: 0.6952658891677856
Epoch 174 / 200, val acc: 0.7590361445783133
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.6868216395378113
Epoch 175 / 200, val loss: 0.6952658891677856
Epoch 175 / 200, val acc: 0.7590361445783133
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.6869126558303833
Epoch 176 / 200, val loss: 0.6952658891677856
Epoch 176 / 200, val acc: 0.7590361445783133
Epoch 177 / 200, learning rate: 1.52587890625e-08
Epoch 177 / 200, train loss: 0.6876176595687866
Epoch 177 / 200, val loss: 0.6952658891677856
Epoch 177 / 200, val acc: 0.7590361445783133
Epoch 178 / 200, learning rate: 1.52587890625e-08
Epoch 178 / 200, train loss: 0.6874300837516785
Epoch 178 / 200, val loss: 0.6952658891677856
Epoch 178 / 200, val acc: 0.7590361445783133
Epoch 179 / 200, learning rate: 1.52587890625e-08
Epoch 179 / 200, train loss: 0.6873335838317871
Epoch 179 / 200, val loss: 0.6952658891677856
Epoch 179 / 200, val acc: 0.7590361445783133
Epoch 180 / 200, learning rate: 1.52587890625e-08
Epoch 180 / 200, train loss: 0.6881179809570312
Epoch 180 / 200, val loss: 0.6952658891677856
Epoch 180 / 200, val acc: 0.7590361445783133
Epoch 181 / 200, learning rate: 1.52587890625e-08
Epoch 181 / 200, train loss: 0.6878551244735718
Epoch 181 / 200, val loss: 0.6952658891677856
Epoch 181 / 200, val acc: 0.7590361445783133
Epoch 182 / 200, learning rate: 1.52587890625e-08
Epoch 182 / 200, train loss: 0.6872228980064392
Epoch 182 / 200, val loss: 0.6952658891677856
Epoch 182 / 200, val acc: 0.7590361445783133
Epoch 183 / 200, learning rate: 1.52587890625e-08
Epoch 183 / 200, train loss: 0.6869269609451294
Epoch 183 / 200, val loss: 0.6952658891677856
Epoch 183 / 200, val acc: 0.7590361445783133
Epoch 184 / 200, learning rate: 1.52587890625e-08
Epoch 184 / 200, train loss: 0.6878094673156738
Epoch 184 / 200, val loss: 0.6952658891677856
Epoch 184 / 200, val acc: 0.7590361445783133
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.6874672174453735
Epoch 185 / 200, val loss: 0.6952658891677856
Epoch 185 / 200, val acc: 0.7590361445783133
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.6880164742469788
Epoch 186 / 200, val loss: 0.6952658891677856
Epoch 186 / 200, val acc: 0.7590361445783133
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.6872333288192749
Epoch 187 / 200, val loss: 0.6952658891677856
Epoch 187 / 200, val acc: 0.7590361445783133
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.6881096959114075
Epoch 188 / 200, val loss: 0.6952658891677856
Epoch 188 / 200, val acc: 0.7590361445783133
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.6871933937072754
Epoch 189 / 200, val loss: 0.6952658891677856
Epoch 189 / 200, val acc: 0.7590361445783133
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.6867773532867432
Epoch 190 / 200, val loss: 0.6952658891677856
Epoch 190 / 200, val acc: 0.7590361445783133
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.6875437498092651
Epoch 191 / 200, val loss: 0.6952658891677856
Epoch 191 / 200, val acc: 0.7590361445783133
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.6886841654777527
Epoch 192 / 200, val loss: 0.6952658891677856
Epoch 192 / 200, val acc: 0.7590361445783133
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.688564658164978
Epoch 193 / 200, val loss: 0.6952658891677856
Epoch 193 / 200, val acc: 0.7590361445783133
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.6872023940086365
Epoch 194 / 200, val loss: 0.6952658891677856
Epoch 194 / 200, val acc: 0.7590361445783133
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.6870056390762329
Epoch 195 / 200, val loss: 0.6952658891677856
Epoch 195 / 200, val acc: 0.7590361445783133
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.6875604391098022
Epoch 196 / 200, val loss: 0.6952658891677856
Epoch 196 / 200, val acc: 0.7590361445783133
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.688106119632721
Epoch 197 / 200, val loss: 0.6952658891677856
Epoch 197 / 200, val acc: 0.7590361445783133
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.6871964931488037
Epoch 198 / 200, val loss: 0.6952658891677856
Epoch 198 / 200, val acc: 0.7590361445783133
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.6869770884513855
Epoch 199 / 200, val loss: 0.6952658891677856
Epoch 199 / 200, val acc: 0.7590361445783133
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.6873905658721924
Epoch 200 / 200, val loss: 0.6952658891677856
Epoch 200 / 200, val acc: 0.7590361445783133
Training finished

Evaluating best model on entire dataset

Evaluating best model on test dataset
999 trading days
Binary accuracy: 0.74610
Fraction of long signals: 1.00000
Fraction of short signals: 0.00000
Overall long return: 293.96109
Overall return: 293.96109
Yearly long return: 14.81860
Yearly return: 14.81860
Daily volatility: 0.35719
Max drawdown baseline: 0.23537
Max drawdown: 0.23537
Sharpe ratio: 0.00003
Average prediction: 0.51293
Std prediction: 0.01032
Trading strategy for stock SPY:
After 250 trading days
Binary accuracy: 0.74297
Fraction of long signals: 1.00000
Fraction of short signals: 0.00000
Overall long return: 15.18537
Overall return: 15.18537
Yearly long return: 15.30686
Yearly return: 15.30686
Daily volatility: 0.35831
Max drawdown baseline: 0.23537
Max drawdown: 0.23537
Sharpe ratio: 0.00068
Average prediction: 0.51003
Std prediction: 0.00006
