Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 200, 1]               --
├─Linear: 1-1                                      [1, 200, 64]              384
├─Time2Vec: 1-2                                    [1, 200, 68]              --
│    └─Linear: 2-1                                 [200, 4]                  8
├─Linear: 1-3                                      [1, 200, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 200, 68]              (recursive)
│    └─Linear: 2-2                                 [200, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 200, 68]              --
│    └─TransformerEncoder: 2-3                     [1, 200, 68]              --
│    │    └─ModuleList: 3-1                        --                        55,752
│    │    └─LayerNorm: 3-2                         [1, 200, 68]              136
│    └─TransformerDecoder: 2-4                     [1, 200, 68]              --
│    │    └─ModuleList: 3-3                        --                        93,560
│    │    └─LayerNorm: 3-4                         [1, 200, 68]              136
├─Sequential: 1-6                                  [1, 200, 1]               --
│    └─Linear: 2-5                                 [1, 200, 34]              2,346
│    └─Dropout: 2-6                                [1, 200, 34]              --
│    └─ReLU: 2-7                                   [1, 200, 34]              --
│    └─Linear: 2-8                                 [1, 200, 1]               35
├─Identity: 1-7                                    [1, 200, 1]               --
====================================================================================================
Total params: 152,357
Trainable params: 152,357
Non-trainable params: 0
Total mult-adds (M): 0.03
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.57
Params size (MB): 0.09
Estimated Total Size (MB): 1.66
====================================================================================================
Epoch 1 / 300, train loss: 0.4840570390224457
Epoch 1 / 300, val loss: 0.9258024096488953
Epoch 1 / 300, val acc: 0.0
Epoch 2 / 300, train loss: 0.20025582611560822
Epoch 2 / 300, val loss: 1.4699827432632446
Epoch 2 / 300, val acc: 0.0
Epoch 3 / 300, train loss: 0.24040286242961884
Epoch 3 / 300, val loss: 1.2382540702819824
Epoch 3 / 300, val acc: 0.0
Epoch 4 / 300, train loss: 0.20577184855937958
Epoch 4 / 300, val loss: 0.9884796142578125
Epoch 4 / 300, val acc: 0.0
Epoch 5 / 300, train loss: 0.18981824815273285
Epoch 5 / 300, val loss: 0.7216701507568359
Epoch 5 / 300, val acc: 0.0
Epoch 6 / 300, train loss: 0.1941222846508026
Epoch 6 / 300, val loss: 0.6578546762466431
Epoch 6 / 300, val acc: 0.0
Epoch 7 / 300, train loss: 0.19790641963481903
Epoch 7 / 300, val loss: 0.7140613794326782
Epoch 7 / 300, val acc: 0.0
Epoch 8 / 300, train loss: 0.19116751849651337
Epoch 8 / 300, val loss: 0.8257331848144531
Epoch 8 / 300, val acc: 0.0
Epoch 9 / 300, train loss: 0.1798526793718338
Epoch 9 / 300, val loss: 0.9471285343170166
Epoch 9 / 300, val acc: 0.0
Epoch 10 / 300, train loss: 0.17798590660095215
Epoch 10 / 300, val loss: 1.035728096961975
Epoch 10 / 300, val acc: 0.0
Epoch 11 / 300, train loss: 0.17896339297294617
Epoch 11 / 300, val loss: 1.0720312595367432
Epoch 11 / 300, val acc: 0.0
Epoch 12 / 300, train loss: 0.1820540428161621
Epoch 12 / 300, val loss: 1.0600731372833252
Epoch 12 / 300, val acc: 0.0
Epoch 13 / 300, train loss: 0.17991222441196442
Epoch 13 / 300, val loss: 0.9951630234718323
Epoch 13 / 300, val acc: 0.0
Epoch 14 / 300, train loss: 0.17214302718639374
Epoch 14 / 300, val loss: 0.9141950607299805
Epoch 14 / 300, val acc: 0.0
Epoch 15 / 300, train loss: 0.16763530671596527
Epoch 15 / 300, val loss: 0.8346770405769348
Epoch 15 / 300, val acc: 0.0
Epoch 16 / 300, train loss: 0.167541041970253
Epoch 16 / 300, val loss: 0.7716259956359863
Epoch 16 / 300, val acc: 0.0
Epoch 17 / 300, train loss: 0.16359466314315796
Epoch 17 / 300, val loss: 0.7355796098709106
Epoch 17 / 300, val acc: 0.0
Epoch 18 / 300, train loss: 0.16129887104034424
Epoch 18 / 300, val loss: 0.7321674823760986
Epoch 18 / 300, val acc: 0.0
Epoch 19 / 300, train loss: 0.15967004001140594
Epoch 19 / 300, val loss: 0.7428164482116699
Epoch 19 / 300, val acc: 0.0
Epoch 20 / 300, train loss: 0.15389083325862885
Epoch 20 / 300, val loss: 0.7669952511787415
Epoch 20 / 300, val acc: 0.0
Epoch 21 / 300, train loss: 0.14701712131500244
Epoch 21 / 300, val loss: 0.8133235573768616
Epoch 21 / 300, val acc: 0.0
Epoch 22 / 300, train loss: 0.14558185636997223
Epoch 22 / 300, val loss: 0.810620129108429
Epoch 22 / 300, val acc: 0.0
Epoch 23 / 300, train loss: 0.1403762698173523
Epoch 23 / 300, val loss: 0.8150624632835388
Epoch 23 / 300, val acc: 0.0
Epoch 24 / 300, train loss: 0.13471975922584534
Epoch 24 / 300, val loss: 0.815943717956543
Epoch 24 / 300, val acc: 0.0
Epoch 25 / 300, train loss: 0.13129106163978577
Epoch 25 / 300, val loss: 0.797343909740448
Epoch 25 / 300, val acc: 0.0
Epoch 26 / 300, train loss: 0.12601594626903534
Epoch 26 / 300, val loss: 0.760085940361023
Epoch 26 / 300, val acc: 0.0
Epoch 27 / 300, train loss: 0.12151196599006653
Epoch 27 / 300, val loss: 0.7129660248756409
Epoch 27 / 300, val acc: 0.0
Epoch 28 / 300, train loss: 0.11267580091953278
Epoch 28 / 300, val loss: 0.6586748957633972
Epoch 28 / 300, val acc: 0.0
Epoch 29 / 300, train loss: 0.10714386403560638
Epoch 29 / 300, val loss: 0.632530689239502
Epoch 29 / 300, val acc: 0.0
Epoch 30 / 300, train loss: 0.10316599905490875
Epoch 30 / 300, val loss: 0.6094188094139099
Epoch 30 / 300, val acc: 0.0
Epoch 31 / 300, train loss: 0.10064239799976349
Epoch 31 / 300, val loss: 0.5887888073921204
Epoch 31 / 300, val acc: 0.0
Epoch 32 / 300, train loss: 0.09715215861797333
Epoch 32 / 300, val loss: 0.5736144185066223
Epoch 32 / 300, val acc: 0.0
Epoch 33 / 300, train loss: 0.093622125685215
Epoch 33 / 300, val loss: 0.5686743855476379
Epoch 33 / 300, val acc: 0.0
Epoch 34 / 300, train loss: 0.09141723066568375
Epoch 34 / 300, val loss: 0.5690881013870239
Epoch 34 / 300, val acc: 0.0
Epoch 35 / 300, train loss: 0.08883979916572571
Epoch 35 / 300, val loss: 0.567058265209198
Epoch 35 / 300, val acc: 0.0
Epoch 36 / 300, train loss: 0.08553063124418259
Epoch 36 / 300, val loss: 0.545598030090332
Epoch 36 / 300, val acc: 0.0
Epoch 37 / 300, train loss: 0.08362893015146255
Epoch 37 / 300, val loss: 0.5207931995391846
Epoch 37 / 300, val acc: 0.0
Epoch 38 / 300, train loss: 0.08231104910373688
Epoch 38 / 300, val loss: 0.48419174551963806
Epoch 38 / 300, val acc: 0.0
Epoch 39 / 300, train loss: 0.08087079226970673
Epoch 39 / 300, val loss: 0.4461815059185028
Epoch 39 / 300, val acc: 0.0
Epoch 40 / 300, train loss: 0.07862503826618195
Epoch 40 / 300, val loss: 0.4286457598209381
Epoch 40 / 300, val acc: 0.0
Epoch 41 / 300, train loss: 0.07716038823127747
Epoch 41 / 300, val loss: 0.4227069616317749
Epoch 41 / 300, val acc: 0.0
Epoch 42 / 300, train loss: 0.07772094011306763
Epoch 42 / 300, val loss: 0.4356037676334381
Epoch 42 / 300, val acc: 0.0
Epoch 43 / 300, train loss: 0.07634202390909195
Epoch 43 / 300, val loss: 0.45157667994499207
Epoch 43 / 300, val acc: 0.0
Epoch 44 / 300, train loss: 0.07672154158353806
Epoch 44 / 300, val loss: 0.441520094871521
Epoch 44 / 300, val acc: 0.0
Epoch 45 / 300, train loss: 0.07644496858119965
Epoch 45 / 300, val loss: 0.41312310099601746
Epoch 45 / 300, val acc: 0.0
Epoch 46 / 300, train loss: 0.0738164409995079
Epoch 46 / 300, val loss: 0.38759031891822815
Epoch 46 / 300, val acc: 0.0
Epoch 47 / 300, train loss: 0.07289733737707138
Epoch 47 / 300, val loss: 0.39348411560058594
Epoch 47 / 300, val acc: 0.0
Epoch 48 / 300, train loss: 0.07306148111820221
Epoch 48 / 300, val loss: 0.43628448247909546
Epoch 48 / 300, val acc: 0.0
Epoch 49 / 300, train loss: 0.07086938619613647
Epoch 49 / 300, val loss: 0.521037220954895
Epoch 49 / 300, val acc: 0.0
Epoch 50 / 300, train loss: 0.07196516543626785
Epoch 50 / 300, val loss: 0.5065081715583801
Epoch 50 / 300, val acc: 0.0
Epoch 51 / 300, train loss: 0.06999198347330093
Epoch 51 / 300, val loss: 0.4741305708885193
Epoch 51 / 300, val acc: 0.0
Epoch 52 / 300, train loss: 0.06842083483934402
Epoch 52 / 300, val loss: 0.41002291440963745
Epoch 52 / 300, val acc: 0.0
Epoch 53 / 300, train loss: 0.0684795081615448
Epoch 53 / 300, val loss: 0.4076322019100189
Epoch 53 / 300, val acc: 0.0
Epoch 54 / 300, train loss: 0.06757554411888123
Epoch 54 / 300, val loss: 0.4478486478328705
Epoch 54 / 300, val acc: 0.0
Epoch 55 / 300, train loss: 0.06733770668506622
Epoch 55 / 300, val loss: 0.5293023586273193
Epoch 55 / 300, val acc: 0.0
Epoch 56 / 300, train loss: 0.06604230403900146
Epoch 56 / 300, val loss: 0.5520251393318176
Epoch 56 / 300, val acc: 0.0
Epoch 57 / 300, train loss: 0.06756339967250824
Epoch 57 / 300, val loss: 0.4719482660293579
Epoch 57 / 300, val acc: 0.0
Epoch 58 / 300, train loss: 0.06489469856023788
Epoch 58 / 300, val loss: 0.4360182285308838
Epoch 58 / 300, val acc: 0.0
Epoch 59 / 300, train loss: 0.0651811882853508
Epoch 59 / 300, val loss: 0.4348507821559906
Epoch 59 / 300, val acc: 0.0
Epoch 60 / 300, train loss: 0.06476878374814987
Epoch 60 / 300, val loss: 0.44193142652511597
Epoch 60 / 300, val acc: 0.0
Epoch 61 / 300, train loss: 0.06428565829992294
Epoch 61 / 300, val loss: 0.46354854106903076
Epoch 61 / 300, val acc: 0.0
Epoch 62 / 300, train loss: 0.06381465494632721
Epoch 62 / 300, val loss: 0.4958643913269043
Epoch 62 / 300, val acc: 0.0
Epoch 63 / 300, train loss: 0.0631740540266037
Epoch 63 / 300, val loss: 0.5262461304664612
Epoch 63 / 300, val acc: 0.0
Epoch 64 / 300, train loss: 0.06285333633422852
Epoch 64 / 300, val loss: 0.5325587391853333
Epoch 64 / 300, val acc: 0.0
Epoch 65 / 300, train loss: 0.06234821677207947
Epoch 65 / 300, val loss: 0.5134032368659973
Epoch 65 / 300, val acc: 0.0
Epoch 66 / 300, train loss: 0.06241357699036598
Epoch 66 / 300, val loss: 0.48976513743400574
Epoch 66 / 300, val acc: 0.0
Epoch 67 / 300, train loss: 0.06063506752252579
Epoch 67 / 300, val loss: 0.47172224521636963
Epoch 67 / 300, val acc: 0.0
Epoch 68 / 300, train loss: 0.062422994524240494
Epoch 68 / 300, val loss: 0.47390425205230713
Epoch 68 / 300, val acc: 0.0
Epoch 69 / 300, train loss: 0.06066080182790756
Epoch 69 / 300, val loss: 0.48561155796051025
Epoch 69 / 300, val acc: 0.0
Epoch 70 / 300, train loss: 0.06097977235913277
Epoch 70 / 300, val loss: 0.4954228103160858
Epoch 70 / 300, val acc: 0.0
Epoch 71 / 300, train loss: 0.06123223900794983
Epoch 71 / 300, val loss: 0.5145387649536133
Epoch 71 / 300, val acc: 0.0
Epoch 72 / 300, train loss: 0.06089116632938385
Epoch 72 / 300, val loss: 0.507604718208313
Epoch 72 / 300, val acc: 0.0
Epoch 73 / 300, train loss: 0.06052224338054657
Epoch 73 / 300, val loss: 0.4980292022228241
Epoch 73 / 300, val acc: 0.0
Epoch 74 / 300, train loss: 0.059982653707265854
Epoch 74 / 300, val loss: 0.47951215505599976
Epoch 74 / 300, val acc: 0.0
Epoch 75 / 300, train loss: 0.05981319025158882
Epoch 75 / 300, val loss: 0.4675309956073761
Epoch 75 / 300, val acc: 0.0
Epoch 76 / 300, train loss: 0.06114843487739563
Epoch 76 / 300, val loss: 0.4681250751018524
Epoch 76 / 300, val acc: 0.0
Epoch 77 / 300, train loss: 0.05974972993135452
Epoch 77 / 300, val loss: 0.4772580862045288
Epoch 77 / 300, val acc: 0.0
Epoch 78 / 300, train loss: 0.05898316577076912
Epoch 78 / 300, val loss: 0.48409098386764526
Epoch 78 / 300, val acc: 0.0
Epoch 79 / 300, train loss: 0.05990250036120415
Epoch 79 / 300, val loss: 0.47759556770324707
Epoch 79 / 300, val acc: 0.0
Epoch 80 / 300, train loss: 0.059683553874492645
Epoch 80 / 300, val loss: 0.47642073035240173
Epoch 80 / 300, val acc: 0.0
Epoch 81 / 300, train loss: 0.059431008994579315
Epoch 81 / 300, val loss: 0.47731268405914307
Epoch 81 / 300, val acc: 0.0
Epoch 82 / 300, train loss: 0.0591353103518486
Epoch 82 / 300, val loss: 0.4732784628868103
Epoch 82 / 300, val acc: 0.0
Epoch 83 / 300, train loss: 0.05953171104192734
Epoch 83 / 300, val loss: 0.47357693314552307
Epoch 83 / 300, val acc: 0.0
Epoch 84 / 300, train loss: 0.05981607362627983
Epoch 84 / 300, val loss: 0.47613775730133057
Epoch 84 / 300, val acc: 0.0
Epoch 85 / 300, train loss: 0.058682408183813095
Epoch 85 / 300, val loss: 0.4860227406024933
Epoch 85 / 300, val acc: 0.0
Epoch 86 / 300, train loss: 0.0586136169731617
Epoch 86 / 300, val loss: 0.49557146430015564
Epoch 86 / 300, val acc: 0.0
Epoch 87 / 300, train loss: 0.05886460095643997
Epoch 87 / 300, val loss: 0.5034911632537842
Epoch 87 / 300, val acc: 0.0
Epoch 88 / 300, train loss: 0.05810621380805969
Epoch 88 / 300, val loss: 0.5113214254379272
Epoch 88 / 300, val acc: 0.0
Epoch 89 / 300, train loss: 0.0582953542470932
Epoch 89 / 300, val loss: 0.5149909853935242
Epoch 89 / 300, val acc: 0.0
Epoch 90 / 300, train loss: 0.0573432594537735
Epoch 90 / 300, val loss: 0.5083861351013184
Epoch 90 / 300, val acc: 0.0
Epoch 91 / 300, train loss: 0.059216875582933426
Epoch 91 / 300, val loss: 0.5031108856201172
Epoch 91 / 300, val acc: 0.0
