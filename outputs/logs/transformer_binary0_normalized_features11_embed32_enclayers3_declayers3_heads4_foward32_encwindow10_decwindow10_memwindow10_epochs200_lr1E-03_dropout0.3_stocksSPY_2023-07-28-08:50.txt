Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              384
├─Time2Vec: 1-2                                    [1, 100, 36]              --
│    └─Linear: 2-1                                 [100, 4]                  8
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 36]              (recursive)
│    └─Linear: 2-2                                 [100, 4]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 36]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 36]              --
│    │    └─ModuleList: 3-1                        --                        23,532
│    │    └─LayerNorm: 3-2                         [1, 100, 36]              72
│    └─TransformerDecoder: 2-4                     [1, 100, 36]              --
│    │    └─ModuleList: 3-3                        --                        39,732
│    │    └─LayerNorm: 3-4                         [1, 100, 36]              72
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 18]              666
│    └─Dropout: 2-6                                [1, 100, 18]              --
│    └─ReLU: 2-7                                   [1, 100, 18]              --
│    └─Linear: 2-8                                 [1, 100, 1]               19
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 64,485
Trainable params: 64,485
Non-trainable params: 0
Total mult-adds (M): 0.01
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.55
Params size (MB): 0.04
Estimated Total Size (MB): 0.60
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.6829507350921631
Epoch 1 / 200, val loss: 6.38785457611084
Epoch 1 / 200, val acc: 0.4804177545691906
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.5063375234603882
Epoch 2 / 200, val loss: 6.797778129577637
Epoch 2 / 200, val acc: 0.4751958224543081
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.4447483420372009
Epoch 3 / 200, val loss: 7.062856197357178
Epoch 3 / 200, val acc: 0.4856396866840731
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.4308495819568634
Epoch 4 / 200, val loss: 7.327651023864746
Epoch 4 / 200, val acc: 0.4725848563968668
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.43296924233436584
Epoch 5 / 200, val loss: 7.3234100341796875
Epoch 5 / 200, val acc: 0.4908616187989556
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.43597865104675293
Epoch 6 / 200, val loss: 7.1797308921813965
Epoch 6 / 200, val acc: 0.4621409921671018
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.4280926585197449
Epoch 7 / 200, val loss: 7.047479152679443
Epoch 7 / 200, val acc: 0.5248041775456919
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.4239943325519562
Epoch 8 / 200, val loss: 6.888938903808594
Epoch 8 / 200, val acc: 0.49869451697127937
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.4187139868736267
Epoch 9 / 200, val loss: 6.745359420776367
Epoch 9 / 200, val acc: 0.4908616187989556
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.4183007776737213
Epoch 10 / 200, val loss: 6.630632400512695
Epoch 10 / 200, val acc: 0.5404699738903395
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.4196167588233948
Epoch 11 / 200, val loss: 6.549039840698242
Epoch 11 / 200, val acc: 0.4856396866840731
Epoch 12 / 200, learning rate: 0.0005
Epoch 12 / 200, train loss: 0.4173242449760437
Epoch 12 / 200, val loss: 6.502902507781982
Epoch 12 / 200, val acc: 0.4804177545691906
Epoch 13 / 200, learning rate: 0.0005
Epoch 13 / 200, train loss: 0.415357381105423
Epoch 13 / 200, val loss: 6.496211051940918
Epoch 13 / 200, val acc: 0.46475195822454307
Epoch 14 / 200, learning rate: 0.0005
Epoch 14 / 200, train loss: 0.41667842864990234
Epoch 14 / 200, val loss: 6.500539302825928
Epoch 14 / 200, val acc: 0.5143603133159269
Epoch 15 / 200, learning rate: 0.0005
Epoch 15 / 200, train loss: 0.41798681020736694
Epoch 15 / 200, val loss: 6.515081405639648
Epoch 15 / 200, val acc: 0.5091383812010444
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.4115249514579773
Epoch 16 / 200, val loss: 6.537168025970459
Epoch 16 / 200, val acc: 0.5013054830287206
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.4141685962677002
Epoch 17 / 200, val loss: 6.567103385925293
Epoch 17 / 200, val acc: 0.5378590078328982
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.4141858220100403
Epoch 18 / 200, val loss: 6.602102279663086
Epoch 18 / 200, val acc: 0.5352480417754569
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.4161874055862427
Epoch 19 / 200, val loss: 6.639350414276123
Epoch 19 / 200, val acc: 0.4934725848563969
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.4178423583507538
Epoch 20 / 200, val loss: 6.6749396324157715
Epoch 20 / 200, val acc: 0.4830287206266319
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.41760605573654175
Epoch 21 / 200, val loss: 6.709583282470703
Epoch 21 / 200, val acc: 0.4908616187989556
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.41602450609207153
Epoch 22 / 200, val loss: 6.741048812866211
Epoch 22 / 200, val acc: 0.46475195822454307
Epoch 23 / 200, learning rate: 0.00025
Epoch 23 / 200, train loss: 0.4149266481399536
Epoch 23 / 200, val loss: 6.770133018493652
Epoch 23 / 200, val acc: 0.44386422976501305
Epoch 24 / 200, learning rate: 0.00025
Epoch 24 / 200, train loss: 0.4156123101711273
Epoch 24 / 200, val loss: 6.782449245452881
Epoch 24 / 200, val acc: 0.45691906005221933
Epoch 25 / 200, learning rate: 0.00025
Epoch 25 / 200, train loss: 0.41505900025367737
Epoch 25 / 200, val loss: 6.791774749755859
Epoch 25 / 200, val acc: 0.45691906005221933
Epoch 26 / 200, learning rate: 0.00025
Epoch 26 / 200, train loss: 0.4136793911457062
Epoch 26 / 200, val loss: 6.798943519592285
Epoch 26 / 200, val acc: 0.4830287206266319
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.4139755964279175
Epoch 27 / 200, val loss: 6.804366111755371
Epoch 27 / 200, val acc: 0.4751958224543081
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.41517969965934753
Epoch 28 / 200, val loss: 6.807511329650879
Epoch 28 / 200, val acc: 0.48825065274151436
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.41367197036743164
Epoch 29 / 200, val loss: 6.808551788330078
Epoch 29 / 200, val acc: 0.5065274151436031
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.41265669465065
Epoch 30 / 200, val loss: 6.807867050170898
Epoch 30 / 200, val acc: 0.4908616187989556
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.4152810275554657
Epoch 31 / 200, val loss: 6.80528450012207
Epoch 31 / 200, val acc: 0.49869451697127937
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.4159381687641144
Epoch 32 / 200, val loss: 6.801833152770996
Epoch 32 / 200, val acc: 0.49869451697127937
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.41394397616386414
Epoch 33 / 200, val loss: 6.79718017578125
Epoch 33 / 200, val acc: 0.5013054830287206
Epoch 34 / 200, learning rate: 0.000125
Epoch 34 / 200, train loss: 0.4163672626018524
Epoch 34 / 200, val loss: 6.791039943695068
Epoch 34 / 200, val acc: 0.5039164490861618
Epoch 35 / 200, learning rate: 0.000125
Epoch 35 / 200, train loss: 0.41511988639831543
Epoch 35 / 200, val loss: 6.787994384765625
Epoch 35 / 200, val acc: 0.5013054830287206
Epoch 36 / 200, learning rate: 0.000125
Epoch 36 / 200, train loss: 0.41310596466064453
Epoch 36 / 200, val loss: 6.784510612487793
Epoch 36 / 200, val acc: 0.5091383812010444
Epoch 37 / 200, learning rate: 0.000125
Epoch 37 / 200, train loss: 0.40925145149230957
Epoch 37 / 200, val loss: 6.781148433685303
Epoch 37 / 200, val acc: 0.5065274151436031
Epoch 38 / 200, learning rate: 0.000125
Epoch 38 / 200, train loss: 0.40997782349586487
Epoch 38 / 200, val loss: 6.777818202972412
Epoch 38 / 200, val acc: 0.5039164490861618
Epoch 39 / 200, learning rate: 0.000125
Epoch 39 / 200, train loss: 0.41522908210754395
Epoch 39 / 200, val loss: 6.774443626403809
Epoch 39 / 200, val acc: 0.5065274151436031
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.41309911012649536
Epoch 40 / 200, val loss: 6.770806789398193
Epoch 40 / 200, val acc: 0.5065274151436031
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.41112110018730164
Epoch 41 / 200, val loss: 6.767727851867676
Epoch 41 / 200, val acc: 0.4960835509138381
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.4138762652873993
Epoch 42 / 200, val loss: 6.764388084411621
Epoch 42 / 200, val acc: 0.4934725848563969
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.4132874310016632
Epoch 43 / 200, val loss: 6.761112213134766
Epoch 43 / 200, val acc: 0.48825065274151436
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.4126680791378021
Epoch 44 / 200, val loss: 6.758155822753906
Epoch 44 / 200, val acc: 0.4934725848563969
Epoch 45 / 200, learning rate: 6.25e-05
Epoch 45 / 200, train loss: 0.4133077561855316
Epoch 45 / 200, val loss: 6.755846977233887
Epoch 45 / 200, val acc: 0.49869451697127937
Epoch 46 / 200, learning rate: 6.25e-05
Epoch 46 / 200, train loss: 0.41174882650375366
Epoch 46 / 200, val loss: 6.754949569702148
Epoch 46 / 200, val acc: 0.5039164490861618
Epoch 47 / 200, learning rate: 6.25e-05
Epoch 47 / 200, train loss: 0.41314977407455444
Epoch 47 / 200, val loss: 6.7542853355407715
Epoch 47 / 200, val acc: 0.5065274151436031
Epoch 48 / 200, learning rate: 6.25e-05
Epoch 48 / 200, train loss: 0.4103317856788635
Epoch 48 / 200, val loss: 6.7539286613464355
Epoch 48 / 200, val acc: 0.5143603133159269
Epoch 49 / 200, learning rate: 6.25e-05
Epoch 49 / 200, train loss: 0.41082191467285156
Epoch 49 / 200, val loss: 6.753951072692871
Epoch 49 / 200, val acc: 0.5195822454308094
Epoch 50 / 200, learning rate: 6.25e-05
Epoch 50 / 200, train loss: 0.4087126851081848
Epoch 50 / 200, val loss: 6.753983497619629
Epoch 50 / 200, val acc: 0.5169712793733682
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.4134365916252136
Epoch 51 / 200, val loss: 6.754157066345215
Epoch 51 / 200, val acc: 0.5221932114882507
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.4132739305496216
Epoch 52 / 200, val loss: 6.754482269287109
Epoch 52 / 200, val acc: 0.5221932114882507
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.4148326516151428
Epoch 53 / 200, val loss: 6.754763603210449
Epoch 53 / 200, val acc: 0.5117493472584856
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.41252896189689636
Epoch 54 / 200, val loss: 6.755012512207031
Epoch 54 / 200, val acc: 0.5143603133159269
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.41247037053108215
Epoch 55 / 200, val loss: 6.7553839683532715
Epoch 55 / 200, val acc: 0.5143603133159269
Epoch 56 / 200, learning rate: 3.125e-05
Epoch 56 / 200, train loss: 0.4123496413230896
Epoch 56 / 200, val loss: 6.755870819091797
Epoch 56 / 200, val acc: 0.49869451697127937
Epoch 57 / 200, learning rate: 3.125e-05
Epoch 57 / 200, train loss: 0.41012170910835266
Epoch 57 / 200, val loss: 6.756106376647949
Epoch 57 / 200, val acc: 0.4960835509138381
Epoch 58 / 200, learning rate: 3.125e-05
Epoch 58 / 200, train loss: 0.4143693745136261
Epoch 58 / 200, val loss: 6.756215572357178
Epoch 58 / 200, val acc: 0.4934725848563969
Epoch 59 / 200, learning rate: 3.125e-05
Epoch 59 / 200, train loss: 0.4144880771636963
Epoch 59 / 200, val loss: 6.75629186630249
Epoch 59 / 200, val acc: 0.5091383812010444
Epoch 60 / 200, learning rate: 3.125e-05
Epoch 60 / 200, train loss: 0.4130397140979767
Epoch 60 / 200, val loss: 6.756255149841309
Epoch 60 / 200, val acc: 0.5143603133159269
Epoch 61 / 200, learning rate: 3.125e-05
Epoch 61 / 200, train loss: 0.4134269058704376
Epoch 61 / 200, val loss: 6.756139278411865
Epoch 61 / 200, val acc: 0.5117493472584856
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.4154561460018158
Epoch 62 / 200, val loss: 6.756014823913574
Epoch 62 / 200, val acc: 0.5195822454308094
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.413430392742157
Epoch 63 / 200, val loss: 6.755937099456787
Epoch 63 / 200, val acc: 0.5169712793733682
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.4114413559436798
Epoch 64 / 200, val loss: 6.755797863006592
Epoch 64 / 200, val acc: 0.5169712793733682
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.4119536578655243
Epoch 65 / 200, val loss: 6.755618572235107
Epoch 65 / 200, val acc: 0.5065274151436031
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.4099341332912445
Epoch 66 / 200, val loss: 6.755608558654785
Epoch 66 / 200, val acc: 0.5091383812010444
Epoch 67 / 200, learning rate: 1.5625e-05
Epoch 67 / 200, train loss: 0.4124404191970825
Epoch 67 / 200, val loss: 6.755525588989258
Epoch 67 / 200, val acc: 0.5065274151436031
Epoch 68 / 200, learning rate: 1.5625e-05
Epoch 68 / 200, train loss: 0.41153454780578613
Epoch 68 / 200, val loss: 6.755492210388184
Epoch 68 / 200, val acc: 0.5065274151436031
Epoch 69 / 200, learning rate: 1.5625e-05
Epoch 69 / 200, train loss: 0.41145339608192444
Epoch 69 / 200, val loss: 6.755507469177246
Epoch 69 / 200, val acc: 0.5117493472584856
Epoch 70 / 200, learning rate: 1.5625e-05
Epoch 70 / 200, train loss: 0.41177260875701904
Epoch 70 / 200, val loss: 6.7555341720581055
Epoch 70 / 200, val acc: 0.5169712793733682
Epoch 71 / 200, learning rate: 1.5625e-05
Epoch 71 / 200, train loss: 0.4093310534954071
Epoch 71 / 200, val loss: 6.755575180053711
Epoch 71 / 200, val acc: 0.5195822454308094
Epoch 72 / 200, learning rate: 1.5625e-05
Epoch 72 / 200, train loss: 0.41164344549179077
Epoch 72 / 200, val loss: 6.755671977996826
Epoch 72 / 200, val acc: 0.5195822454308094
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.41414889693260193
Epoch 73 / 200, val loss: 6.755746364593506
Epoch 73 / 200, val acc: 0.5169712793733682
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.4105655550956726
Epoch 74 / 200, val loss: 6.755786895751953
Epoch 74 / 200, val acc: 0.5143603133159269
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.4173693358898163
Epoch 75 / 200, val loss: 6.755731105804443
Epoch 75 / 200, val acc: 0.5143603133159269
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.41088494658470154
Epoch 76 / 200, val loss: 6.755744934082031
Epoch 76 / 200, val acc: 0.5221932114882507
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.41146671772003174
Epoch 77 / 200, val loss: 6.755821228027344
Epoch 77 / 200, val acc: 0.5195822454308094
Epoch 78 / 200, learning rate: 7.8125e-06
Epoch 78 / 200, train loss: 0.41384559869766235
Epoch 78 / 200, val loss: 6.755887031555176
Epoch 78 / 200, val acc: 0.5169712793733682
Epoch 79 / 200, learning rate: 7.8125e-06
Epoch 79 / 200, train loss: 0.4138253331184387
Epoch 79 / 200, val loss: 6.755895137786865
Epoch 79 / 200, val acc: 0.5169712793733682
Epoch 80 / 200, learning rate: 7.8125e-06
Epoch 80 / 200, train loss: 0.4088901877403259
Epoch 80 / 200, val loss: 6.755914211273193
Epoch 80 / 200, val acc: 0.5143603133159269
Epoch 81 / 200, learning rate: 7.8125e-06
Epoch 81 / 200, train loss: 0.41274479031562805
Epoch 81 / 200, val loss: 6.75592041015625
Epoch 81 / 200, val acc: 0.5143603133159269
Epoch 82 / 200, learning rate: 7.8125e-06
Epoch 82 / 200, train loss: 0.412413090467453
Epoch 82 / 200, val loss: 6.755938529968262
Epoch 82 / 200, val acc: 0.5169712793733682
Epoch 83 / 200, learning rate: 7.8125e-06
Epoch 83 / 200, train loss: 0.4111717939376831
Epoch 83 / 200, val loss: 6.756003379821777
Epoch 83 / 200, val acc: 0.5195822454308094
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.40939080715179443
Epoch 84 / 200, val loss: 6.756072044372559
Epoch 84 / 200, val acc: 0.5195822454308094
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.41306427121162415
Epoch 85 / 200, val loss: 6.756141662597656
Epoch 85 / 200, val acc: 0.5143603133159269
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.4117538332939148
Epoch 86 / 200, val loss: 6.756211757659912
Epoch 86 / 200, val acc: 0.5143603133159269
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.41467276215553284
Epoch 87 / 200, val loss: 6.756275177001953
Epoch 87 / 200, val acc: 0.5117493472584856
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.4134448170661926
Epoch 88 / 200, val loss: 6.756337642669678
Epoch 88 / 200, val acc: 0.5117493472584856
Epoch 89 / 200, learning rate: 3.90625e-06
Epoch 89 / 200, train loss: 0.4128100275993347
Epoch 89 / 200, val loss: 6.75641393661499
Epoch 89 / 200, val acc: 0.5117493472584856
Epoch 90 / 200, learning rate: 3.90625e-06
Epoch 90 / 200, train loss: 0.41231778264045715
Epoch 90 / 200, val loss: 6.756436824798584
Epoch 90 / 200, val acc: 0.5091383812010444
Epoch 91 / 200, learning rate: 3.90625e-06
Epoch 91 / 200, train loss: 0.4084922671318054
Epoch 91 / 200, val loss: 6.756487846374512
Epoch 91 / 200, val acc: 0.5117493472584856
Epoch 92 / 200, learning rate: 3.90625e-06
Epoch 92 / 200, train loss: 0.41236135363578796
Epoch 92 / 200, val loss: 6.756533622741699
Epoch 92 / 200, val acc: 0.5091383812010444
Epoch 93 / 200, learning rate: 3.90625e-06
Epoch 93 / 200, train loss: 0.41239380836486816
Epoch 93 / 200, val loss: 6.756594657897949
Epoch 93 / 200, val acc: 0.5117493472584856
Epoch 94 / 200, learning rate: 3.90625e-06
Epoch 94 / 200, train loss: 0.4139306843280792
Epoch 94 / 200, val loss: 6.756646633148193
Epoch 94 / 200, val acc: 0.5117493472584856
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.4140767455101013
Epoch 95 / 200, val loss: 6.756699562072754
Epoch 95 / 200, val acc: 0.5143603133159269
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.4091281294822693
Epoch 96 / 200, val loss: 6.756758689880371
Epoch 96 / 200, val acc: 0.5143603133159269
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.4111803472042084
Epoch 97 / 200, val loss: 6.756812572479248
Epoch 97 / 200, val acc: 0.5195822454308094
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.41155028343200684
Epoch 98 / 200, val loss: 6.75687313079834
Epoch 98 / 200, val acc: 0.5169712793733682
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.4141516387462616
Epoch 99 / 200, val loss: 6.756930351257324
Epoch 99 / 200, val acc: 0.5117493472584856
Epoch 100 / 200, learning rate: 1.953125e-06
Epoch 100 / 200, train loss: 0.4125362038612366
Epoch 100 / 200, val loss: 6.7569899559021
Epoch 100 / 200, val acc: 0.5143603133159269
Epoch 101 / 200, learning rate: 1.953125e-06
Epoch 101 / 200, train loss: 0.4127226173877716
Epoch 101 / 200, val loss: 6.757017135620117
Epoch 101 / 200, val acc: 0.5143603133159269
Epoch 102 / 200, learning rate: 1.953125e-06
Epoch 102 / 200, train loss: 0.41256818175315857
Epoch 102 / 200, val loss: 6.757040023803711
Epoch 102 / 200, val acc: 0.5117493472584856
Epoch 103 / 200, learning rate: 1.953125e-06
Epoch 103 / 200, train loss: 0.41548916697502136
Epoch 103 / 200, val loss: 6.757052421569824
Epoch 103 / 200, val acc: 0.5143603133159269
Epoch 104 / 200, learning rate: 1.953125e-06
Epoch 104 / 200, train loss: 0.4119902551174164
Epoch 104 / 200, val loss: 6.757060527801514
Epoch 104 / 200, val acc: 0.5117493472584856
Epoch 105 / 200, learning rate: 1.953125e-06
Epoch 105 / 200, train loss: 0.4140825867652893
Epoch 105 / 200, val loss: 6.7570648193359375
Epoch 105 / 200, val acc: 0.5143603133159269
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.4148804545402527
Epoch 106 / 200, val loss: 6.757061004638672
Epoch 106 / 200, val acc: 0.5091383812010444
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.41087737679481506
Epoch 107 / 200, val loss: 6.757068157196045
Epoch 107 / 200, val acc: 0.5117493472584856
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.41074100136756897
Epoch 108 / 200, val loss: 6.757075309753418
Epoch 108 / 200, val acc: 0.5143603133159269
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.4127267003059387
Epoch 109 / 200, val loss: 6.757083415985107
Epoch 109 / 200, val acc: 0.5143603133159269
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.4107639789581299
Epoch 110 / 200, val loss: 6.757083892822266
Epoch 110 / 200, val acc: 0.5143603133159269
Epoch 111 / 200, learning rate: 9.765625e-07
Epoch 111 / 200, train loss: 0.4115324914455414
Epoch 111 / 200, val loss: 6.757082939147949
Epoch 111 / 200, val acc: 0.5143603133159269
Epoch 112 / 200, learning rate: 9.765625e-07
Epoch 112 / 200, train loss: 0.41341012716293335
Epoch 112 / 200, val loss: 6.75708532333374
Epoch 112 / 200, val acc: 0.5169712793733682
Epoch 113 / 200, learning rate: 9.765625e-07
Epoch 113 / 200, train loss: 0.411843478679657
Epoch 113 / 200, val loss: 6.7570905685424805
Epoch 113 / 200, val acc: 0.5143603133159269
Epoch 114 / 200, learning rate: 9.765625e-07
Epoch 114 / 200, train loss: 0.411440908908844
Epoch 114 / 200, val loss: 6.7570929527282715
Epoch 114 / 200, val acc: 0.5169712793733682
Epoch 115 / 200, learning rate: 9.765625e-07
Epoch 115 / 200, train loss: 0.4110679030418396
Epoch 115 / 200, val loss: 6.7571024894714355
Epoch 115 / 200, val acc: 0.5169712793733682
Epoch 116 / 200, learning rate: 9.765625e-07
Epoch 116 / 200, train loss: 0.4169977307319641
Epoch 116 / 200, val loss: 6.757106304168701
Epoch 116 / 200, val acc: 0.5169712793733682
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.41109219193458557
Epoch 117 / 200, val loss: 6.757110595703125
Epoch 117 / 200, val acc: 0.5169712793733682
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.4145824611186981
Epoch 118 / 200, val loss: 6.757113933563232
Epoch 118 / 200, val acc: 0.5169712793733682
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.41240185499191284
Epoch 119 / 200, val loss: 6.757115840911865
Epoch 119 / 200, val acc: 0.5143603133159269
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.4124290645122528
Epoch 120 / 200, val loss: 6.757119178771973
Epoch 120 / 200, val acc: 0.5169712793733682
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.4130879044532776
Epoch 121 / 200, val loss: 6.7571210861206055
Epoch 121 / 200, val acc: 0.5143603133159269
Epoch 122 / 200, learning rate: 4.8828125e-07
Epoch 122 / 200, train loss: 0.41188716888427734
Epoch 122 / 200, val loss: 6.757122039794922
Epoch 122 / 200, val acc: 0.5169712793733682
Epoch 123 / 200, learning rate: 4.8828125e-07
Epoch 123 / 200, train loss: 0.4116417467594147
Epoch 123 / 200, val loss: 6.7571258544921875
Epoch 123 / 200, val acc: 0.5143603133159269
Epoch 124 / 200, learning rate: 4.8828125e-07
Epoch 124 / 200, train loss: 0.41344740986824036
Epoch 124 / 200, val loss: 6.7571306228637695
Epoch 124 / 200, val acc: 0.5143603133159269
Epoch 125 / 200, learning rate: 4.8828125e-07
Epoch 125 / 200, train loss: 0.4142153561115265
Epoch 125 / 200, val loss: 6.757129669189453
Epoch 125 / 200, val acc: 0.5169712793733682
Epoch 126 / 200, learning rate: 4.8828125e-07
Epoch 126 / 200, train loss: 0.4132188856601715
Epoch 126 / 200, val loss: 6.757129669189453
Epoch 126 / 200, val acc: 0.5143603133159269
Epoch 127 / 200, learning rate: 4.8828125e-07
Epoch 127 / 200, train loss: 0.41460704803466797
Epoch 127 / 200, val loss: 6.757131576538086
Epoch 127 / 200, val acc: 0.5169712793733682
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.41597479581832886
Epoch 128 / 200, val loss: 6.757132530212402
Epoch 128 / 200, val acc: 0.5169712793733682
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.41401806473731995
Epoch 129 / 200, val loss: 6.7571330070495605
Epoch 129 / 200, val acc: 0.5143603133159269
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.40796223282814026
Epoch 130 / 200, val loss: 6.757135391235352
Epoch 130 / 200, val acc: 0.5169712793733682
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.4149492084980011
Epoch 131 / 200, val loss: 6.757135391235352
Epoch 131 / 200, val acc: 0.5169712793733682
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.41242727637290955
Epoch 132 / 200, val loss: 6.757134437561035
Epoch 132 / 200, val acc: 0.5169712793733682
Epoch 133 / 200, learning rate: 2.44140625e-07
Epoch 133 / 200, train loss: 0.40986260771751404
Epoch 133 / 200, val loss: 6.757136821746826
Epoch 133 / 200, val acc: 0.5169712793733682
Epoch 134 / 200, learning rate: 2.44140625e-07
Epoch 134 / 200, train loss: 0.4113788902759552
Epoch 134 / 200, val loss: 6.757140159606934
Epoch 134 / 200, val acc: 0.5169712793733682
Epoch 135 / 200, learning rate: 2.44140625e-07
Epoch 135 / 200, train loss: 0.4090796113014221
Epoch 135 / 200, val loss: 6.757143974304199
Epoch 135 / 200, val acc: 0.5169712793733682
Epoch 136 / 200, learning rate: 2.44140625e-07
Epoch 136 / 200, train loss: 0.41423866152763367
Epoch 136 / 200, val loss: 6.75714635848999
Epoch 136 / 200, val acc: 0.5143603133159269
Epoch 137 / 200, learning rate: 2.44140625e-07
Epoch 137 / 200, train loss: 0.4097316563129425
Epoch 137 / 200, val loss: 6.757147789001465
Epoch 137 / 200, val acc: 0.5169712793733682
Epoch 138 / 200, learning rate: 2.44140625e-07
Epoch 138 / 200, train loss: 0.4120958149433136
Epoch 138 / 200, val loss: 6.757148742675781
Epoch 138 / 200, val acc: 0.5169712793733682
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.41366174817085266
Epoch 139 / 200, val loss: 6.757150173187256
Epoch 139 / 200, val acc: 0.5143603133159269
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.41397494077682495
Epoch 140 / 200, val loss: 6.7571516036987305
Epoch 140 / 200, val acc: 0.5169712793733682
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.41049638390541077
Epoch 141 / 200, val loss: 6.757152080535889
Epoch 141 / 200, val acc: 0.5143603133159269
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.41110095381736755
Epoch 142 / 200, val loss: 6.757152557373047
Epoch 142 / 200, val acc: 0.5169712793733682
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.41412660479545593
Epoch 143 / 200, val loss: 6.7571539878845215
Epoch 143 / 200, val acc: 0.5143603133159269
Epoch 144 / 200, learning rate: 1.220703125e-07
Epoch 144 / 200, train loss: 0.41474080085754395
Epoch 144 / 200, val loss: 6.7571563720703125
Epoch 144 / 200, val acc: 0.5143603133159269
Epoch 145 / 200, learning rate: 1.220703125e-07
Epoch 145 / 200, train loss: 0.4120047390460968
Epoch 145 / 200, val loss: 6.7571563720703125
Epoch 145 / 200, val acc: 0.5169712793733682
Epoch 146 / 200, learning rate: 1.220703125e-07
Epoch 146 / 200, train loss: 0.4096620976924896
Epoch 146 / 200, val loss: 6.7571563720703125
Epoch 146 / 200, val acc: 0.5143603133159269
Epoch 147 / 200, learning rate: 1.220703125e-07
Epoch 147 / 200, train loss: 0.4141138195991516
Epoch 147 / 200, val loss: 6.757157325744629
Epoch 147 / 200, val acc: 0.5169712793733682
Epoch 148 / 200, learning rate: 1.220703125e-07
Epoch 148 / 200, train loss: 0.4115324318408966
Epoch 148 / 200, val loss: 6.757157802581787
Epoch 148 / 200, val acc: 0.5169712793733682
Epoch 149 / 200, learning rate: 1.220703125e-07
Epoch 149 / 200, train loss: 0.41333332657814026
Epoch 149 / 200, val loss: 6.757157802581787
Epoch 149 / 200, val acc: 0.5143603133159269
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.4122421145439148
Epoch 150 / 200, val loss: 6.757159233093262
Epoch 150 / 200, val acc: 0.5169712793733682
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.4140123426914215
Epoch 151 / 200, val loss: 6.757160186767578
Epoch 151 / 200, val acc: 0.5143603133159269
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.4107849895954132
Epoch 152 / 200, val loss: 6.757161617279053
Epoch 152 / 200, val acc: 0.5169712793733682
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.41502246260643005
Epoch 153 / 200, val loss: 6.757164001464844
Epoch 153 / 200, val acc: 0.5143603133159269
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.4109645485877991
Epoch 154 / 200, val loss: 6.757165431976318
Epoch 154 / 200, val acc: 0.5169712793733682
Epoch 155 / 200, learning rate: 6.103515625e-08
Epoch 155 / 200, train loss: 0.4118291139602661
Epoch 155 / 200, val loss: 6.757167816162109
Epoch 155 / 200, val acc: 0.5169712793733682
Epoch 156 / 200, learning rate: 6.103515625e-08
Epoch 156 / 200, train loss: 0.41034796833992004
Epoch 156 / 200, val loss: 6.757168769836426
Epoch 156 / 200, val acc: 0.5169712793733682
Epoch 157 / 200, learning rate: 6.103515625e-08
Epoch 157 / 200, train loss: 0.4142053425312042
Epoch 157 / 200, val loss: 6.757169246673584
Epoch 157 / 200, val acc: 0.5143603133159269
Epoch 158 / 200, learning rate: 6.103515625e-08
Epoch 158 / 200, train loss: 0.41445398330688477
Epoch 158 / 200, val loss: 6.757169246673584
Epoch 158 / 200, val acc: 0.5169712793733682
Epoch 159 / 200, learning rate: 6.103515625e-08
Epoch 159 / 200, train loss: 0.4126860797405243
Epoch 159 / 200, val loss: 6.757169246673584
Epoch 159 / 200, val acc: 0.5143603133159269
Epoch 160 / 200, learning rate: 6.103515625e-08
Epoch 160 / 200, train loss: 0.41165387630462646
Epoch 160 / 200, val loss: 6.757170677185059
Epoch 160 / 200, val acc: 0.5143603133159269
Epoch 161 / 200, learning rate: 6.103515625e-08
Epoch 161 / 200, train loss: 0.41085711121559143
Epoch 161 / 200, val loss: 6.757171154022217
Epoch 161 / 200, val acc: 0.5143603133159269
Epoch 162 / 200, learning rate: 6.103515625e-08
Epoch 162 / 200, train loss: 0.41261985898017883
Epoch 162 / 200, val loss: 6.757171630859375
Epoch 162 / 200, val acc: 0.5169712793733682
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.41066065430641174
Epoch 163 / 200, val loss: 6.757171630859375
Epoch 163 / 200, val acc: 0.5143603133159269
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.40841224789619446
Epoch 164 / 200, val loss: 6.757172584533691
Epoch 164 / 200, val acc: 0.5143603133159269
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.4159019887447357
Epoch 165 / 200, val loss: 6.757172584533691
Epoch 165 / 200, val acc: 0.5169712793733682
Epoch 166 / 200, learning rate: 3.0517578125e-08
Epoch 166 / 200, train loss: 0.4113619327545166
Epoch 166 / 200, val loss: 6.75717306137085
Epoch 166 / 200, val acc: 0.5169712793733682
Epoch 167 / 200, learning rate: 3.0517578125e-08
Epoch 167 / 200, train loss: 0.4122592508792877
Epoch 167 / 200, val loss: 6.75717306137085
Epoch 167 / 200, val acc: 0.5169712793733682
Epoch 168 / 200, learning rate: 3.0517578125e-08
Epoch 168 / 200, train loss: 0.41227880120277405
Epoch 168 / 200, val loss: 6.75717306137085
Epoch 168 / 200, val acc: 0.5169712793733682
Epoch 169 / 200, learning rate: 3.0517578125e-08
Epoch 169 / 200, train loss: 0.41053497791290283
Epoch 169 / 200, val loss: 6.75717306137085
Epoch 169 / 200, val acc: 0.5169712793733682
Epoch 170 / 200, learning rate: 3.0517578125e-08
Epoch 170 / 200, train loss: 0.41383275389671326
Epoch 170 / 200, val loss: 6.75717306137085
Epoch 170 / 200, val acc: 0.5169712793733682
Epoch 171 / 200, learning rate: 3.0517578125e-08
Epoch 171 / 200, train loss: 0.4109230637550354
Epoch 171 / 200, val loss: 6.75717306137085
Epoch 171 / 200, val acc: 0.5169712793733682
Epoch 172 / 200, learning rate: 3.0517578125e-08
Epoch 172 / 200, train loss: 0.41496163606643677
Epoch 172 / 200, val loss: 6.75717306137085
Epoch 172 / 200, val acc: 0.5169712793733682
Epoch 173 / 200, learning rate: 3.0517578125e-08
Epoch 173 / 200, train loss: 0.4141424298286438
Epoch 173 / 200, val loss: 6.75717306137085
Epoch 173 / 200, val acc: 0.5169712793733682
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.41335242986679077
Epoch 174 / 200, val loss: 6.75717306137085
Epoch 174 / 200, val acc: 0.5143603133159269
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.41506844758987427
Epoch 175 / 200, val loss: 6.75717306137085
Epoch 175 / 200, val acc: 0.5169712793733682
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.41322651505470276
Epoch 176 / 200, val loss: 6.75717306137085
Epoch 176 / 200, val acc: 0.5143603133159269
Epoch 177 / 200, learning rate: 1.52587890625e-08
Epoch 177 / 200, train loss: 0.4119047224521637
Epoch 177 / 200, val loss: 6.757172584533691
Epoch 177 / 200, val acc: 0.5169712793733682
Epoch 178 / 200, learning rate: 1.52587890625e-08
Epoch 178 / 200, train loss: 0.41143709421157837
Epoch 178 / 200, val loss: 6.757172584533691
Epoch 178 / 200, val acc: 0.5169712793733682
Epoch 179 / 200, learning rate: 1.52587890625e-08
Epoch 179 / 200, train loss: 0.4126026928424835
Epoch 179 / 200, val loss: 6.757172584533691
Epoch 179 / 200, val acc: 0.5169712793733682
Epoch 180 / 200, learning rate: 1.52587890625e-08
Epoch 180 / 200, train loss: 0.41448718309402466
Epoch 180 / 200, val loss: 6.757171630859375
Epoch 180 / 200, val acc: 0.5143603133159269
Epoch 181 / 200, learning rate: 1.52587890625e-08
Epoch 181 / 200, train loss: 0.4111705720424652
Epoch 181 / 200, val loss: 6.757171630859375
Epoch 181 / 200, val acc: 0.5169712793733682
Epoch 182 / 200, learning rate: 1.52587890625e-08
Epoch 182 / 200, train loss: 0.41593268513679504
Epoch 182 / 200, val loss: 6.757172584533691
Epoch 182 / 200, val acc: 0.5169712793733682
Epoch 183 / 200, learning rate: 1.52587890625e-08
Epoch 183 / 200, train loss: 0.4097025990486145
Epoch 183 / 200, val loss: 6.757171630859375
Epoch 183 / 200, val acc: 0.5143603133159269
Epoch 184 / 200, learning rate: 1.52587890625e-08
Epoch 184 / 200, train loss: 0.4145265519618988
Epoch 184 / 200, val loss: 6.757171630859375
Epoch 184 / 200, val acc: 0.5169712793733682
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.4160917401313782
Epoch 185 / 200, val loss: 6.757171630859375
Epoch 185 / 200, val acc: 0.5143603133159269
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.41500410437583923
Epoch 186 / 200, val loss: 6.757171630859375
Epoch 186 / 200, val acc: 0.5143603133159269
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.41433972120285034
Epoch 187 / 200, val loss: 6.757171630859375
Epoch 187 / 200, val acc: 0.5169712793733682
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.4107320010662079
Epoch 188 / 200, val loss: 6.757171630859375
Epoch 188 / 200, val acc: 0.5169712793733682
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.4125378131866455
Epoch 189 / 200, val loss: 6.757171630859375
Epoch 189 / 200, val acc: 0.5169712793733682
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.4119744896888733
Epoch 190 / 200, val loss: 6.757171630859375
Epoch 190 / 200, val acc: 0.5143603133159269
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.4149467349052429
Epoch 191 / 200, val loss: 6.757171630859375
Epoch 191 / 200, val acc: 0.5169712793733682
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.41432905197143555
Epoch 192 / 200, val loss: 6.757172584533691
Epoch 192 / 200, val acc: 0.5169712793733682
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.4154970645904541
Epoch 193 / 200, val loss: 6.757172584533691
Epoch 193 / 200, val acc: 0.5169712793733682
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.41437211632728577
Epoch 194 / 200, val loss: 6.75717306137085
Epoch 194 / 200, val acc: 0.5169712793733682
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.41407516598701477
Epoch 195 / 200, val loss: 6.75717306137085
Epoch 195 / 200, val acc: 0.5143603133159269
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.41444748640060425
Epoch 196 / 200, val loss: 6.757172584533691
Epoch 196 / 200, val acc: 0.5169712793733682
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.40710145235061646
Epoch 197 / 200, val loss: 6.757172584533691
Epoch 197 / 200, val acc: 0.5143603133159269
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.4126904308795929
Epoch 198 / 200, val loss: 6.757172584533691
Epoch 198 / 200, val acc: 0.5143603133159269
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.4142584800720215
Epoch 199 / 200, val loss: 6.75717306137085
Epoch 199 / 200, val acc: 0.5143603133159269
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.41151362657546997
Epoch 200 / 200, val loss: 6.757172584533691
Epoch 200 / 200, val acc: 0.5143603133159269
Training finished

Evaluating best model on test set
Trading strategy for stock SPY:
After 384 trading days
Binary accuracy: 0.52219
Fraction of long signals: 0.46875
Fraction of short signals: 0.53125
Overall long return: 0.03127
Overall return: 0.28221
Yearly long return: 0.02052
Yearly return: 0.18520
Daily volatility: 0.01336
Max drawdown baseline: 0.23197
Max drawdown: 0.22974
Sharpe ratio: 0.04905
L1 error baseline: 2.45427
L1 error: 2.64387
Average prediction: -0.18959
Std prediction: 0.00012
