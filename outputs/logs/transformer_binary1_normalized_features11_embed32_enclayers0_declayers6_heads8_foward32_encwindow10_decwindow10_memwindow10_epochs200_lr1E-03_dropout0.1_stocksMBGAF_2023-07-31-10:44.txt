Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 32]              384
├─Time2Vec: 1-2                                    [1, 100, 40]              --
│    └─Linear: 2-1                                 [100, 8]                  16
├─Linear: 1-3                                      [1, 100, 32]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 40]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 40]              --
│    └─MyIdentity: 2-3                             [1, 100, 40]              --
│    └─TransformerDecoder: 2-4                     [1, 100, 40]              --
│    │    └─ModuleList: 3-1                        --                        95,952
│    │    └─LayerNorm: 3-2                         [1, 100, 40]              80
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 20]              820
│    └─Dropout: 2-6                                [1, 100, 20]              --
│    └─ReLU: 2-7                                   [1, 100, 20]              --
│    └─Linear: 2-8                                 [1, 100, 1]               21
├─Sigmoid: 1-7                                     [1, 100, 1]               --
====================================================================================================
Total params: 97,273
Trainable params: 97,273
Non-trainable params: 0
Total mult-adds (M): 0.02
====================================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 1.03
Params size (MB): 0.07
Estimated Total Size (MB): 1.12
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.6968708038330078
Epoch 1 / 200, val loss: 0.6931182146072388
Epoch 1 / 200, val acc: 0.7630522088353414
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.6933731436729431
Epoch 2 / 200, val loss: 0.6939395070075989
Epoch 2 / 200, val acc: 0.7630522088353414
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.6933141946792603
Epoch 3 / 200, val loss: 0.6955980658531189
Epoch 3 / 200, val acc: 0.7630522088353414
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.6936395168304443
Epoch 4 / 200, val loss: 0.6964247822761536
Epoch 4 / 200, val acc: 0.7630522088353414
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.6943284869194031
Epoch 5 / 200, val loss: 0.6962988972663879
Epoch 5 / 200, val acc: 0.7630522088353414
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.6939384937286377
Epoch 6 / 200, val loss: 0.6956765651702881
Epoch 6 / 200, val acc: 0.7630522088353414
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.6929572224617004
Epoch 7 / 200, val loss: 0.6948848366737366
Epoch 7 / 200, val acc: 0.7630522088353414
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.6929669380187988
Epoch 8 / 200, val loss: 0.6941884160041809
Epoch 8 / 200, val acc: 0.7630522088353414
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.6919002532958984
Epoch 9 / 200, val loss: 0.6936489343643188
Epoch 9 / 200, val acc: 0.7630522088353414
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.6938725113868713
Epoch 10 / 200, val loss: 0.6933141350746155
Epoch 10 / 200, val acc: 0.7630522088353414
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.6932277083396912
Epoch 11 / 200, val loss: 0.6931673288345337
Epoch 11 / 200, val acc: 0.7630522088353414
Epoch 12 / 200, learning rate: 0.0005
Epoch 12 / 200, train loss: 0.6929680109024048
Epoch 12 / 200, val loss: 0.6931228637695312
Epoch 12 / 200, val acc: 0.7630522088353414
Epoch 13 / 200, learning rate: 0.0005
Epoch 13 / 200, train loss: 0.6929869055747986
Epoch 13 / 200, val loss: 0.6931179761886597
Epoch 13 / 200, val acc: 0.7630522088353414
Epoch 14 / 200, learning rate: 0.0005
Epoch 14 / 200, train loss: 0.6934640407562256
Epoch 14 / 200, val loss: 0.6931174397468567
Epoch 14 / 200, val acc: 0.7630522088353414
Epoch 15 / 200, learning rate: 0.0005
Epoch 15 / 200, train loss: 0.6922357678413391
Epoch 15 / 200, val loss: 0.6931208968162537
Epoch 15 / 200, val acc: 0.7630522088353414
Epoch 16 / 200, learning rate: 0.0005
Epoch 16 / 200, train loss: 0.6922768950462341
Epoch 16 / 200, val loss: 0.6931309700012207
Epoch 16 / 200, val acc: 0.7630522088353414
Epoch 17 / 200, learning rate: 0.0005
Epoch 17 / 200, train loss: 0.6930136680603027
Epoch 17 / 200, val loss: 0.6931509375572205
Epoch 17 / 200, val acc: 0.7630522088353414
Epoch 18 / 200, learning rate: 0.0005
Epoch 18 / 200, train loss: 0.692375659942627
Epoch 18 / 200, val loss: 0.693187952041626
Epoch 18 / 200, val acc: 0.7630522088353414
Epoch 19 / 200, learning rate: 0.0005
Epoch 19 / 200, train loss: 0.6925572752952576
Epoch 19 / 200, val loss: 0.6932491660118103
Epoch 19 / 200, val acc: 0.7630522088353414
Epoch 20 / 200, learning rate: 0.0005
Epoch 20 / 200, train loss: 0.6933347582817078
Epoch 20 / 200, val loss: 0.6933318376541138
Epoch 20 / 200, val acc: 0.7630522088353414
Epoch 21 / 200, learning rate: 0.0005
Epoch 21 / 200, train loss: 0.6929111480712891
Epoch 21 / 200, val loss: 0.6934432983398438
Epoch 21 / 200, val acc: 0.7630522088353414
Epoch 22 / 200, learning rate: 0.0005
Epoch 22 / 200, train loss: 0.6929299831390381
Epoch 22 / 200, val loss: 0.6935325860977173
Epoch 22 / 200, val acc: 0.7630522088353414
Epoch 23 / 200, learning rate: 0.00025
Epoch 23 / 200, train loss: 0.6924967169761658
Epoch 23 / 200, val loss: 0.6936308741569519
Epoch 23 / 200, val acc: 0.7630522088353414
Epoch 24 / 200, learning rate: 0.00025
Epoch 24 / 200, train loss: 0.6920297741889954
Epoch 24 / 200, val loss: 0.6936818957328796
Epoch 24 / 200, val acc: 0.7630522088353414
Epoch 25 / 200, learning rate: 0.00025
Epoch 25 / 200, train loss: 0.6919736266136169
Epoch 25 / 200, val loss: 0.693727433681488
Epoch 25 / 200, val acc: 0.7630522088353414
Epoch 26 / 200, learning rate: 0.00025
Epoch 26 / 200, train loss: 0.692267894744873
Epoch 26 / 200, val loss: 0.69376540184021
Epoch 26 / 200, val acc: 0.7630522088353414
Epoch 27 / 200, learning rate: 0.00025
Epoch 27 / 200, train loss: 0.6918438673019409
Epoch 27 / 200, val loss: 0.6937907338142395
Epoch 27 / 200, val acc: 0.7630522088353414
Epoch 28 / 200, learning rate: 0.00025
Epoch 28 / 200, train loss: 0.6930897235870361
Epoch 28 / 200, val loss: 0.693820595741272
Epoch 28 / 200, val acc: 0.7630522088353414
Epoch 29 / 200, learning rate: 0.00025
Epoch 29 / 200, train loss: 0.692783534526825
Epoch 29 / 200, val loss: 0.693841278553009
Epoch 29 / 200, val acc: 0.7630522088353414
Epoch 30 / 200, learning rate: 0.00025
Epoch 30 / 200, train loss: 0.692220151424408
Epoch 30 / 200, val loss: 0.6938503980636597
Epoch 30 / 200, val acc: 0.7630522088353414
Epoch 31 / 200, learning rate: 0.00025
Epoch 31 / 200, train loss: 0.6927001476287842
Epoch 31 / 200, val loss: 0.6938573122024536
Epoch 31 / 200, val acc: 0.7630522088353414
Epoch 32 / 200, learning rate: 0.00025
Epoch 32 / 200, train loss: 0.6919847726821899
Epoch 32 / 200, val loss: 0.6938539743423462
Epoch 32 / 200, val acc: 0.7630522088353414
Epoch 33 / 200, learning rate: 0.00025
Epoch 33 / 200, train loss: 0.6919974088668823
Epoch 33 / 200, val loss: 0.6938410401344299
Epoch 33 / 200, val acc: 0.7630522088353414
Epoch 34 / 200, learning rate: 0.000125
Epoch 34 / 200, train loss: 0.6918960809707642
Epoch 34 / 200, val loss: 0.6938197612762451
Epoch 34 / 200, val acc: 0.7630522088353414
Epoch 35 / 200, learning rate: 0.000125
Epoch 35 / 200, train loss: 0.6922040581703186
Epoch 35 / 200, val loss: 0.6938078999519348
Epoch 35 / 200, val acc: 0.7630522088353414
Epoch 36 / 200, learning rate: 0.000125
Epoch 36 / 200, train loss: 0.6922342777252197
Epoch 36 / 200, val loss: 0.6938016414642334
Epoch 36 / 200, val acc: 0.7630522088353414
Epoch 37 / 200, learning rate: 0.000125
Epoch 37 / 200, train loss: 0.6919352412223816
Epoch 37 / 200, val loss: 0.6937926411628723
Epoch 37 / 200, val acc: 0.7630522088353414
Epoch 38 / 200, learning rate: 0.000125
Epoch 38 / 200, train loss: 0.6919363141059875
Epoch 38 / 200, val loss: 0.6937851905822754
Epoch 38 / 200, val acc: 0.7630522088353414
Epoch 39 / 200, learning rate: 0.000125
Epoch 39 / 200, train loss: 0.692427933216095
Epoch 39 / 200, val loss: 0.6937779188156128
Epoch 39 / 200, val acc: 0.7630522088353414
Epoch 40 / 200, learning rate: 0.000125
Epoch 40 / 200, train loss: 0.6919897794723511
Epoch 40 / 200, val loss: 0.6937697529792786
Epoch 40 / 200, val acc: 0.7630522088353414
Epoch 41 / 200, learning rate: 0.000125
Epoch 41 / 200, train loss: 0.6927455067634583
Epoch 41 / 200, val loss: 0.6937583088874817
Epoch 41 / 200, val acc: 0.7630522088353414
Epoch 42 / 200, learning rate: 0.000125
Epoch 42 / 200, train loss: 0.6927717328071594
Epoch 42 / 200, val loss: 0.693748950958252
Epoch 42 / 200, val acc: 0.7630522088353414
Epoch 43 / 200, learning rate: 0.000125
Epoch 43 / 200, train loss: 0.6923883557319641
Epoch 43 / 200, val loss: 0.6937423348426819
Epoch 43 / 200, val acc: 0.7630522088353414
Epoch 44 / 200, learning rate: 0.000125
Epoch 44 / 200, train loss: 0.6917915940284729
Epoch 44 / 200, val loss: 0.6937291622161865
Epoch 44 / 200, val acc: 0.7630522088353414
Epoch 45 / 200, learning rate: 6.25e-05
Epoch 45 / 200, train loss: 0.6922088861465454
Epoch 45 / 200, val loss: 0.6937167048454285
Epoch 45 / 200, val acc: 0.7630522088353414
Epoch 46 / 200, learning rate: 6.25e-05
Epoch 46 / 200, train loss: 0.6921690106391907
Epoch 46 / 200, val loss: 0.69371098279953
Epoch 46 / 200, val acc: 0.7630522088353414
Epoch 47 / 200, learning rate: 6.25e-05
Epoch 47 / 200, train loss: 0.6927980780601501
Epoch 47 / 200, val loss: 0.6937056183815002
Epoch 47 / 200, val acc: 0.7630522088353414
Epoch 48 / 200, learning rate: 6.25e-05
Epoch 48 / 200, train loss: 0.6921237111091614
Epoch 48 / 200, val loss: 0.6936990022659302
Epoch 48 / 200, val acc: 0.7630522088353414
Epoch 49 / 200, learning rate: 6.25e-05
Epoch 49 / 200, train loss: 0.6930949091911316
Epoch 49 / 200, val loss: 0.6936920285224915
Epoch 49 / 200, val acc: 0.7630522088353414
Epoch 50 / 200, learning rate: 6.25e-05
Epoch 50 / 200, train loss: 0.692136287689209
Epoch 50 / 200, val loss: 0.6936845183372498
Epoch 50 / 200, val acc: 0.7630522088353414
Epoch 51 / 200, learning rate: 6.25e-05
Epoch 51 / 200, train loss: 0.6919970512390137
Epoch 51 / 200, val loss: 0.6936782598495483
Epoch 51 / 200, val acc: 0.7630522088353414
Epoch 52 / 200, learning rate: 6.25e-05
Epoch 52 / 200, train loss: 0.6927738189697266
Epoch 52 / 200, val loss: 0.6936731934547424
Epoch 52 / 200, val acc: 0.7630522088353414
Epoch 53 / 200, learning rate: 6.25e-05
Epoch 53 / 200, train loss: 0.6923152208328247
Epoch 53 / 200, val loss: 0.6936673521995544
Epoch 53 / 200, val acc: 0.7630522088353414
Epoch 54 / 200, learning rate: 6.25e-05
Epoch 54 / 200, train loss: 0.6922980546951294
Epoch 54 / 200, val loss: 0.6936623454093933
Epoch 54 / 200, val acc: 0.7630522088353414
Epoch 55 / 200, learning rate: 6.25e-05
Epoch 55 / 200, train loss: 0.6926688551902771
Epoch 55 / 200, val loss: 0.6936577558517456
Epoch 55 / 200, val acc: 0.7630522088353414
Epoch 56 / 200, learning rate: 3.125e-05
Epoch 56 / 200, train loss: 0.6928776502609253
Epoch 56 / 200, val loss: 0.6936531066894531
Epoch 56 / 200, val acc: 0.7630522088353414
Epoch 57 / 200, learning rate: 3.125e-05
Epoch 57 / 200, train loss: 0.6920943856239319
Epoch 57 / 200, val loss: 0.693651020526886
Epoch 57 / 200, val acc: 0.7630522088353414
Epoch 58 / 200, learning rate: 3.125e-05
Epoch 58 / 200, train loss: 0.6918983459472656
Epoch 58 / 200, val loss: 0.6936482191085815
Epoch 58 / 200, val acc: 0.7630522088353414
Epoch 59 / 200, learning rate: 3.125e-05
Epoch 59 / 200, train loss: 0.6926831603050232
Epoch 59 / 200, val loss: 0.693645715713501
Epoch 59 / 200, val acc: 0.7630522088353414
Epoch 60 / 200, learning rate: 3.125e-05
Epoch 60 / 200, train loss: 0.6919602155685425
Epoch 60 / 200, val loss: 0.6936427354812622
Epoch 60 / 200, val acc: 0.7630522088353414
Epoch 61 / 200, learning rate: 3.125e-05
Epoch 61 / 200, train loss: 0.6922401785850525
Epoch 61 / 200, val loss: 0.6936396360397339
Epoch 61 / 200, val acc: 0.7630522088353414
Epoch 62 / 200, learning rate: 3.125e-05
Epoch 62 / 200, train loss: 0.6925531029701233
Epoch 62 / 200, val loss: 0.6936372518539429
Epoch 62 / 200, val acc: 0.7630522088353414
Epoch 63 / 200, learning rate: 3.125e-05
Epoch 63 / 200, train loss: 0.6925288438796997
Epoch 63 / 200, val loss: 0.6936348080635071
Epoch 63 / 200, val acc: 0.7630522088353414
Epoch 64 / 200, learning rate: 3.125e-05
Epoch 64 / 200, train loss: 0.6922080516815186
Epoch 64 / 200, val loss: 0.6936329007148743
Epoch 64 / 200, val acc: 0.7630522088353414
Epoch 65 / 200, learning rate: 3.125e-05
Epoch 65 / 200, train loss: 0.6918589472770691
Epoch 65 / 200, val loss: 0.6936304569244385
Epoch 65 / 200, val acc: 0.7630522088353414
Epoch 66 / 200, learning rate: 3.125e-05
Epoch 66 / 200, train loss: 0.6920360326766968
Epoch 66 / 200, val loss: 0.6936293244361877
Epoch 66 / 200, val acc: 0.7630522088353414
Epoch 67 / 200, learning rate: 1.5625e-05
Epoch 67 / 200, train loss: 0.6924941539764404
Epoch 67 / 200, val loss: 0.6936277151107788
Epoch 67 / 200, val acc: 0.7630522088353414
Epoch 68 / 200, learning rate: 1.5625e-05
Epoch 68 / 200, train loss: 0.6917758584022522
Epoch 68 / 200, val loss: 0.693627119064331
Epoch 68 / 200, val acc: 0.7630522088353414
Epoch 69 / 200, learning rate: 1.5625e-05
Epoch 69 / 200, train loss: 0.6922702193260193
Epoch 69 / 200, val loss: 0.6936265230178833
Epoch 69 / 200, val acc: 0.7630522088353414
Epoch 70 / 200, learning rate: 1.5625e-05
Epoch 70 / 200, train loss: 0.6924678683280945
Epoch 70 / 200, val loss: 0.6936261057853699
Epoch 70 / 200, val acc: 0.7630522088353414
Epoch 71 / 200, learning rate: 1.5625e-05
Epoch 71 / 200, train loss: 0.6924892663955688
Epoch 71 / 200, val loss: 0.6936259865760803
Epoch 71 / 200, val acc: 0.7630522088353414
Epoch 72 / 200, learning rate: 1.5625e-05
Epoch 72 / 200, train loss: 0.6919693946838379
Epoch 72 / 200, val loss: 0.693625271320343
Epoch 72 / 200, val acc: 0.7630522088353414
Epoch 73 / 200, learning rate: 1.5625e-05
Epoch 73 / 200, train loss: 0.692588746547699
Epoch 73 / 200, val loss: 0.6936246752738953
Epoch 73 / 200, val acc: 0.7630522088353414
Epoch 74 / 200, learning rate: 1.5625e-05
Epoch 74 / 200, train loss: 0.692452073097229
Epoch 74 / 200, val loss: 0.6936240792274475
Epoch 74 / 200, val acc: 0.7630522088353414
Epoch 75 / 200, learning rate: 1.5625e-05
Epoch 75 / 200, train loss: 0.6929746866226196
Epoch 75 / 200, val loss: 0.6936233043670654
Epoch 75 / 200, val acc: 0.7630522088353414
Epoch 76 / 200, learning rate: 1.5625e-05
Epoch 76 / 200, train loss: 0.6929100751876831
Epoch 76 / 200, val loss: 0.6936229467391968
Epoch 76 / 200, val acc: 0.7630522088353414
Epoch 77 / 200, learning rate: 1.5625e-05
Epoch 77 / 200, train loss: 0.6925771236419678
Epoch 77 / 200, val loss: 0.6936227083206177
Epoch 77 / 200, val acc: 0.7630522088353414
Epoch 78 / 200, learning rate: 7.8125e-06
Epoch 78 / 200, train loss: 0.6920212507247925
Epoch 78 / 200, val loss: 0.693622350692749
Epoch 78 / 200, val acc: 0.7630522088353414
Epoch 79 / 200, learning rate: 7.8125e-06
Epoch 79 / 200, train loss: 0.6920987367630005
Epoch 79 / 200, val loss: 0.6936220526695251
Epoch 79 / 200, val acc: 0.7630522088353414
Epoch 80 / 200, learning rate: 7.8125e-06
Epoch 80 / 200, train loss: 0.6916308999061584
Epoch 80 / 200, val loss: 0.6936215162277222
Epoch 80 / 200, val acc: 0.7630522088353414
Epoch 81 / 200, learning rate: 7.8125e-06
Epoch 81 / 200, train loss: 0.6919049620628357
Epoch 81 / 200, val loss: 0.6936208009719849
Epoch 81 / 200, val acc: 0.7630522088353414
Epoch 82 / 200, learning rate: 7.8125e-06
Epoch 82 / 200, train loss: 0.6924472451210022
Epoch 82 / 200, val loss: 0.693620502948761
Epoch 82 / 200, val acc: 0.7630522088353414
Epoch 83 / 200, learning rate: 7.8125e-06
Epoch 83 / 200, train loss: 0.6927511096000671
Epoch 83 / 200, val loss: 0.6936203837394714
Epoch 83 / 200, val acc: 0.7630522088353414
Epoch 84 / 200, learning rate: 7.8125e-06
Epoch 84 / 200, train loss: 0.6919078826904297
Epoch 84 / 200, val loss: 0.693620502948761
Epoch 84 / 200, val acc: 0.7630522088353414
Epoch 85 / 200, learning rate: 7.8125e-06
Epoch 85 / 200, train loss: 0.6922772526741028
Epoch 85 / 200, val loss: 0.6936206221580505
Epoch 85 / 200, val acc: 0.7630522088353414
Epoch 86 / 200, learning rate: 7.8125e-06
Epoch 86 / 200, train loss: 0.6920523047447205
Epoch 86 / 200, val loss: 0.6936209201812744
Epoch 86 / 200, val acc: 0.7630522088353414
Epoch 87 / 200, learning rate: 7.8125e-06
Epoch 87 / 200, train loss: 0.6922358870506287
Epoch 87 / 200, val loss: 0.6936208605766296
Epoch 87 / 200, val acc: 0.7630522088353414
Epoch 88 / 200, learning rate: 7.8125e-06
Epoch 88 / 200, train loss: 0.6921093463897705
Epoch 88 / 200, val loss: 0.6936206817626953
Epoch 88 / 200, val acc: 0.7630522088353414
Epoch 89 / 200, learning rate: 3.90625e-06
Epoch 89 / 200, train loss: 0.6915256977081299
Epoch 89 / 200, val loss: 0.6936206221580505
Epoch 89 / 200, val acc: 0.7630522088353414
Epoch 90 / 200, learning rate: 3.90625e-06
Epoch 90 / 200, train loss: 0.6919982433319092
Epoch 90 / 200, val loss: 0.693620502948761
Epoch 90 / 200, val acc: 0.7630522088353414
Epoch 91 / 200, learning rate: 3.90625e-06
Epoch 91 / 200, train loss: 0.692628800868988
Epoch 91 / 200, val loss: 0.693620502948761
Epoch 91 / 200, val acc: 0.7630522088353414
Epoch 92 / 200, learning rate: 3.90625e-06
Epoch 92 / 200, train loss: 0.6924164295196533
Epoch 92 / 200, val loss: 0.6936206221580505
Epoch 92 / 200, val acc: 0.7630522088353414
Epoch 93 / 200, learning rate: 3.90625e-06
Epoch 93 / 200, train loss: 0.6924864649772644
Epoch 93 / 200, val loss: 0.6936207413673401
Epoch 93 / 200, val acc: 0.7630522088353414
Epoch 94 / 200, learning rate: 3.90625e-06
Epoch 94 / 200, train loss: 0.6923034191131592
Epoch 94 / 200, val loss: 0.6936208605766296
Epoch 94 / 200, val acc: 0.7630522088353414
Epoch 95 / 200, learning rate: 3.90625e-06
Epoch 95 / 200, train loss: 0.6917850375175476
Epoch 95 / 200, val loss: 0.6936209797859192
Epoch 95 / 200, val acc: 0.7630522088353414
Epoch 96 / 200, learning rate: 3.90625e-06
Epoch 96 / 200, train loss: 0.6922694444656372
Epoch 96 / 200, val loss: 0.6936209797859192
Epoch 96 / 200, val acc: 0.7630522088353414
Epoch 97 / 200, learning rate: 3.90625e-06
Epoch 97 / 200, train loss: 0.6918075084686279
Epoch 97 / 200, val loss: 0.6936209797859192
Epoch 97 / 200, val acc: 0.7630522088353414
Epoch 98 / 200, learning rate: 3.90625e-06
Epoch 98 / 200, train loss: 0.6923824548721313
Epoch 98 / 200, val loss: 0.6936209797859192
Epoch 98 / 200, val acc: 0.7630522088353414
Epoch 99 / 200, learning rate: 3.90625e-06
Epoch 99 / 200, train loss: 0.6927525997161865
Epoch 99 / 200, val loss: 0.6936209797859192
Epoch 99 / 200, val acc: 0.7630522088353414
Epoch 100 / 200, learning rate: 1.953125e-06
Epoch 100 / 200, train loss: 0.6926436424255371
Epoch 100 / 200, val loss: 0.6936211585998535
Epoch 100 / 200, val acc: 0.7630522088353414
Epoch 101 / 200, learning rate: 1.953125e-06
Epoch 101 / 200, train loss: 0.6918600797653198
Epoch 101 / 200, val loss: 0.6936212778091431
Epoch 101 / 200, val acc: 0.7630522088353414
Epoch 102 / 200, learning rate: 1.953125e-06
Epoch 102 / 200, train loss: 0.6924001574516296
Epoch 102 / 200, val loss: 0.6936212778091431
Epoch 102 / 200, val acc: 0.7630522088353414
Epoch 103 / 200, learning rate: 1.953125e-06
Epoch 103 / 200, train loss: 0.6923750042915344
Epoch 103 / 200, val loss: 0.6936211585998535
Epoch 103 / 200, val acc: 0.7630522088353414
Epoch 104 / 200, learning rate: 1.953125e-06
Epoch 104 / 200, train loss: 0.6921127438545227
Epoch 104 / 200, val loss: 0.6936212778091431
Epoch 104 / 200, val acc: 0.7630522088353414
Epoch 105 / 200, learning rate: 1.953125e-06
Epoch 105 / 200, train loss: 0.6923368573188782
Epoch 105 / 200, val loss: 0.6936211585998535
Epoch 105 / 200, val acc: 0.7630522088353414
Epoch 106 / 200, learning rate: 1.953125e-06
Epoch 106 / 200, train loss: 0.6923234462738037
Epoch 106 / 200, val loss: 0.6936210989952087
Epoch 106 / 200, val acc: 0.7630522088353414
Epoch 107 / 200, learning rate: 1.953125e-06
Epoch 107 / 200, train loss: 0.6924246549606323
Epoch 107 / 200, val loss: 0.6936210989952087
Epoch 107 / 200, val acc: 0.7630522088353414
Epoch 108 / 200, learning rate: 1.953125e-06
Epoch 108 / 200, train loss: 0.6924126744270325
Epoch 108 / 200, val loss: 0.6936210989952087
Epoch 108 / 200, val acc: 0.7630522088353414
Epoch 109 / 200, learning rate: 1.953125e-06
Epoch 109 / 200, train loss: 0.6921733021736145
Epoch 109 / 200, val loss: 0.6936210989952087
Epoch 109 / 200, val acc: 0.7630522088353414
Epoch 110 / 200, learning rate: 1.953125e-06
Epoch 110 / 200, train loss: 0.6916065812110901
Epoch 110 / 200, val loss: 0.6936209797859192
Epoch 110 / 200, val acc: 0.7630522088353414
Epoch 111 / 200, learning rate: 9.765625e-07
Epoch 111 / 200, train loss: 0.6930070519447327
Epoch 111 / 200, val loss: 0.6936208605766296
Epoch 111 / 200, val acc: 0.7630522088353414
Epoch 112 / 200, learning rate: 9.765625e-07
Epoch 112 / 200, train loss: 0.6921820044517517
Epoch 112 / 200, val loss: 0.6936207413673401
Epoch 112 / 200, val acc: 0.7630522088353414
Epoch 113 / 200, learning rate: 9.765625e-07
Epoch 113 / 200, train loss: 0.6922813653945923
Epoch 113 / 200, val loss: 0.6936207413673401
Epoch 113 / 200, val acc: 0.7630522088353414
Epoch 114 / 200, learning rate: 9.765625e-07
Epoch 114 / 200, train loss: 0.692166805267334
Epoch 114 / 200, val loss: 0.6936206817626953
Epoch 114 / 200, val acc: 0.7630522088353414
Epoch 115 / 200, learning rate: 9.765625e-07
Epoch 115 / 200, train loss: 0.691941499710083
Epoch 115 / 200, val loss: 0.6936205625534058
Epoch 115 / 200, val acc: 0.7630522088353414
Epoch 116 / 200, learning rate: 9.765625e-07
Epoch 116 / 200, train loss: 0.6923767328262329
Epoch 116 / 200, val loss: 0.693620502948761
Epoch 116 / 200, val acc: 0.7630522088353414
Epoch 117 / 200, learning rate: 9.765625e-07
Epoch 117 / 200, train loss: 0.6920503973960876
Epoch 117 / 200, val loss: 0.693620502948761
Epoch 117 / 200, val acc: 0.7630522088353414
Epoch 118 / 200, learning rate: 9.765625e-07
Epoch 118 / 200, train loss: 0.6924203634262085
Epoch 118 / 200, val loss: 0.6936203837394714
Epoch 118 / 200, val acc: 0.7630522088353414
Epoch 119 / 200, learning rate: 9.765625e-07
Epoch 119 / 200, train loss: 0.6917457580566406
Epoch 119 / 200, val loss: 0.6936203837394714
Epoch 119 / 200, val acc: 0.7630522088353414
Epoch 120 / 200, learning rate: 9.765625e-07
Epoch 120 / 200, train loss: 0.6928085684776306
Epoch 120 / 200, val loss: 0.6936203837394714
Epoch 120 / 200, val acc: 0.7630522088353414
Epoch 121 / 200, learning rate: 9.765625e-07
Epoch 121 / 200, train loss: 0.6929753422737122
Epoch 121 / 200, val loss: 0.6936203837394714
Epoch 121 / 200, val acc: 0.7630522088353414
Epoch 122 / 200, learning rate: 4.8828125e-07
Epoch 122 / 200, train loss: 0.69172203540802
Epoch 122 / 200, val loss: 0.6936203241348267
Epoch 122 / 200, val acc: 0.7630522088353414
Epoch 123 / 200, learning rate: 4.8828125e-07
Epoch 123 / 200, train loss: 0.6923266649246216
Epoch 123 / 200, val loss: 0.6936202645301819
Epoch 123 / 200, val acc: 0.7630522088353414
Epoch 124 / 200, learning rate: 4.8828125e-07
Epoch 124 / 200, train loss: 0.692277729511261
Epoch 124 / 200, val loss: 0.6936202645301819
Epoch 124 / 200, val acc: 0.7630522088353414
Epoch 125 / 200, learning rate: 4.8828125e-07
Epoch 125 / 200, train loss: 0.6923385262489319
Epoch 125 / 200, val loss: 0.6936202645301819
Epoch 125 / 200, val acc: 0.7630522088353414
Epoch 126 / 200, learning rate: 4.8828125e-07
Epoch 126 / 200, train loss: 0.6921941637992859
Epoch 126 / 200, val loss: 0.6936202645301819
Epoch 126 / 200, val acc: 0.7630522088353414
Epoch 127 / 200, learning rate: 4.8828125e-07
Epoch 127 / 200, train loss: 0.6922202706336975
Epoch 127 / 200, val loss: 0.6936202645301819
Epoch 127 / 200, val acc: 0.7630522088353414
Epoch 128 / 200, learning rate: 4.8828125e-07
Epoch 128 / 200, train loss: 0.6919882297515869
Epoch 128 / 200, val loss: 0.6936202049255371
Epoch 128 / 200, val acc: 0.7630522088353414
Epoch 129 / 200, learning rate: 4.8828125e-07
Epoch 129 / 200, train loss: 0.6918192505836487
Epoch 129 / 200, val loss: 0.6936201453208923
Epoch 129 / 200, val acc: 0.7630522088353414
Epoch 130 / 200, learning rate: 4.8828125e-07
Epoch 130 / 200, train loss: 0.6925469040870667
Epoch 130 / 200, val loss: 0.6936201453208923
Epoch 130 / 200, val acc: 0.7630522088353414
Epoch 131 / 200, learning rate: 4.8828125e-07
Epoch 131 / 200, train loss: 0.6922872066497803
Epoch 131 / 200, val loss: 0.6936201453208923
Epoch 131 / 200, val acc: 0.7630522088353414
Epoch 132 / 200, learning rate: 4.8828125e-07
Epoch 132 / 200, train loss: 0.6928426027297974
Epoch 132 / 200, val loss: 0.6936202645301819
Epoch 132 / 200, val acc: 0.7630522088353414
Epoch 133 / 200, learning rate: 2.44140625e-07
Epoch 133 / 200, train loss: 0.692247211933136
Epoch 133 / 200, val loss: 0.6936202645301819
Epoch 133 / 200, val acc: 0.7630522088353414
Epoch 134 / 200, learning rate: 2.44140625e-07
Epoch 134 / 200, train loss: 0.6915038824081421
Epoch 134 / 200, val loss: 0.6936202645301819
Epoch 134 / 200, val acc: 0.7630522088353414
Epoch 135 / 200, learning rate: 2.44140625e-07
Epoch 135 / 200, train loss: 0.6924086213111877
Epoch 135 / 200, val loss: 0.6936202645301819
Epoch 135 / 200, val acc: 0.7630522088353414
Epoch 136 / 200, learning rate: 2.44140625e-07
Epoch 136 / 200, train loss: 0.693043053150177
Epoch 136 / 200, val loss: 0.6936202645301819
Epoch 136 / 200, val acc: 0.7630522088353414
Epoch 137 / 200, learning rate: 2.44140625e-07
Epoch 137 / 200, train loss: 0.6923239231109619
Epoch 137 / 200, val loss: 0.6936202645301819
Epoch 137 / 200, val acc: 0.7630522088353414
Epoch 138 / 200, learning rate: 2.44140625e-07
Epoch 138 / 200, train loss: 0.6919817924499512
Epoch 138 / 200, val loss: 0.6936202645301819
Epoch 138 / 200, val acc: 0.7630522088353414
Epoch 139 / 200, learning rate: 2.44140625e-07
Epoch 139 / 200, train loss: 0.6921898126602173
Epoch 139 / 200, val loss: 0.6936202645301819
Epoch 139 / 200, val acc: 0.7630522088353414
Epoch 140 / 200, learning rate: 2.44140625e-07
Epoch 140 / 200, train loss: 0.6926019787788391
Epoch 140 / 200, val loss: 0.6936203241348267
Epoch 140 / 200, val acc: 0.7630522088353414
Epoch 141 / 200, learning rate: 2.44140625e-07
Epoch 141 / 200, train loss: 0.6921522617340088
Epoch 141 / 200, val loss: 0.6936203837394714
Epoch 141 / 200, val acc: 0.7630522088353414
Epoch 142 / 200, learning rate: 2.44140625e-07
Epoch 142 / 200, train loss: 0.6921396851539612
Epoch 142 / 200, val loss: 0.6936203837394714
Epoch 142 / 200, val acc: 0.7630522088353414
Epoch 143 / 200, learning rate: 2.44140625e-07
Epoch 143 / 200, train loss: 0.6917132139205933
Epoch 143 / 200, val loss: 0.6936203837394714
Epoch 143 / 200, val acc: 0.7630522088353414
Epoch 144 / 200, learning rate: 1.220703125e-07
Epoch 144 / 200, train loss: 0.6917542219161987
Epoch 144 / 200, val loss: 0.6936203837394714
Epoch 144 / 200, val acc: 0.7630522088353414
Epoch 145 / 200, learning rate: 1.220703125e-07
Epoch 145 / 200, train loss: 0.6924377083778381
Epoch 145 / 200, val loss: 0.6936203837394714
Epoch 145 / 200, val acc: 0.7630522088353414
Epoch 146 / 200, learning rate: 1.220703125e-07
Epoch 146 / 200, train loss: 0.692068874835968
Epoch 146 / 200, val loss: 0.6936203837394714
Epoch 146 / 200, val acc: 0.7630522088353414
Epoch 147 / 200, learning rate: 1.220703125e-07
Epoch 147 / 200, train loss: 0.6915779113769531
Epoch 147 / 200, val loss: 0.6936203837394714
Epoch 147 / 200, val acc: 0.7630522088353414
Epoch 148 / 200, learning rate: 1.220703125e-07
Epoch 148 / 200, train loss: 0.6921995282173157
Epoch 148 / 200, val loss: 0.6936203837394714
Epoch 148 / 200, val acc: 0.7630522088353414
Epoch 149 / 200, learning rate: 1.220703125e-07
Epoch 149 / 200, train loss: 0.6924846768379211
Epoch 149 / 200, val loss: 0.6936203837394714
Epoch 149 / 200, val acc: 0.7630522088353414
Epoch 150 / 200, learning rate: 1.220703125e-07
Epoch 150 / 200, train loss: 0.6927302479743958
Epoch 150 / 200, val loss: 0.6936203837394714
Epoch 150 / 200, val acc: 0.7630522088353414
Epoch 151 / 200, learning rate: 1.220703125e-07
Epoch 151 / 200, train loss: 0.6918110847473145
Epoch 151 / 200, val loss: 0.6936203837394714
Epoch 151 / 200, val acc: 0.7630522088353414
Epoch 152 / 200, learning rate: 1.220703125e-07
Epoch 152 / 200, train loss: 0.6921455264091492
Epoch 152 / 200, val loss: 0.6936203837394714
Epoch 152 / 200, val acc: 0.7630522088353414
Epoch 153 / 200, learning rate: 1.220703125e-07
Epoch 153 / 200, train loss: 0.6925600171089172
Epoch 153 / 200, val loss: 0.6936203837394714
Epoch 153 / 200, val acc: 0.7630522088353414
Epoch 154 / 200, learning rate: 1.220703125e-07
Epoch 154 / 200, train loss: 0.6924815773963928
Epoch 154 / 200, val loss: 0.6936203837394714
Epoch 154 / 200, val acc: 0.7630522088353414
Epoch 155 / 200, learning rate: 6.103515625e-08
Epoch 155 / 200, train loss: 0.6931078433990479
Epoch 155 / 200, val loss: 0.6936203837394714
Epoch 155 / 200, val acc: 0.7630522088353414
Epoch 156 / 200, learning rate: 6.103515625e-08
Epoch 156 / 200, train loss: 0.6917309761047363
Epoch 156 / 200, val loss: 0.6936203837394714
Epoch 156 / 200, val acc: 0.7630522088353414
Epoch 157 / 200, learning rate: 6.103515625e-08
Epoch 157 / 200, train loss: 0.6922882199287415
Epoch 157 / 200, val loss: 0.6936204433441162
Epoch 157 / 200, val acc: 0.7630522088353414
Epoch 158 / 200, learning rate: 6.103515625e-08
Epoch 158 / 200, train loss: 0.6918163895606995
Epoch 158 / 200, val loss: 0.693620502948761
Epoch 158 / 200, val acc: 0.7630522088353414
Epoch 159 / 200, learning rate: 6.103515625e-08
Epoch 159 / 200, train loss: 0.6918479204177856
Epoch 159 / 200, val loss: 0.693620502948761
Epoch 159 / 200, val acc: 0.7630522088353414
Epoch 160 / 200, learning rate: 6.103515625e-08
Epoch 160 / 200, train loss: 0.6920110583305359
Epoch 160 / 200, val loss: 0.6936204433441162
Epoch 160 / 200, val acc: 0.7630522088353414
Epoch 161 / 200, learning rate: 6.103515625e-08
Epoch 161 / 200, train loss: 0.6925153136253357
Epoch 161 / 200, val loss: 0.693620502948761
Epoch 161 / 200, val acc: 0.7630522088353414
Epoch 162 / 200, learning rate: 6.103515625e-08
Epoch 162 / 200, train loss: 0.6924424767494202
Epoch 162 / 200, val loss: 0.693620502948761
Epoch 162 / 200, val acc: 0.7630522088353414
Epoch 163 / 200, learning rate: 6.103515625e-08
Epoch 163 / 200, train loss: 0.6925274729728699
Epoch 163 / 200, val loss: 0.6936204433441162
Epoch 163 / 200, val acc: 0.7630522088353414
Epoch 164 / 200, learning rate: 6.103515625e-08
Epoch 164 / 200, train loss: 0.6919071078300476
Epoch 164 / 200, val loss: 0.6936204433441162
Epoch 164 / 200, val acc: 0.7630522088353414
Epoch 165 / 200, learning rate: 6.103515625e-08
Epoch 165 / 200, train loss: 0.6922346353530884
Epoch 165 / 200, val loss: 0.6936204433441162
Epoch 165 / 200, val acc: 0.7630522088353414
Epoch 166 / 200, learning rate: 3.0517578125e-08
Epoch 166 / 200, train loss: 0.692297637462616
Epoch 166 / 200, val loss: 0.6936203837394714
Epoch 166 / 200, val acc: 0.7630522088353414
Epoch 167 / 200, learning rate: 3.0517578125e-08
Epoch 167 / 200, train loss: 0.6917554140090942
Epoch 167 / 200, val loss: 0.6936204433441162
Epoch 167 / 200, val acc: 0.7630522088353414
Epoch 168 / 200, learning rate: 3.0517578125e-08
Epoch 168 / 200, train loss: 0.6924334764480591
Epoch 168 / 200, val loss: 0.6936204433441162
Epoch 168 / 200, val acc: 0.7630522088353414
Epoch 169 / 200, learning rate: 3.0517578125e-08
Epoch 169 / 200, train loss: 0.6924973726272583
Epoch 169 / 200, val loss: 0.693620502948761
Epoch 169 / 200, val acc: 0.7630522088353414
Epoch 170 / 200, learning rate: 3.0517578125e-08
Epoch 170 / 200, train loss: 0.692018449306488
Epoch 170 / 200, val loss: 0.6936203837394714
Epoch 170 / 200, val acc: 0.7630522088353414
Epoch 171 / 200, learning rate: 3.0517578125e-08
Epoch 171 / 200, train loss: 0.6921210885047913
Epoch 171 / 200, val loss: 0.6936204433441162
Epoch 171 / 200, val acc: 0.7630522088353414
Epoch 172 / 200, learning rate: 3.0517578125e-08
Epoch 172 / 200, train loss: 0.6918953061103821
Epoch 172 / 200, val loss: 0.6936204433441162
Epoch 172 / 200, val acc: 0.7630522088353414
Epoch 173 / 200, learning rate: 3.0517578125e-08
Epoch 173 / 200, train loss: 0.6913819313049316
Epoch 173 / 200, val loss: 0.6936204433441162
Epoch 173 / 200, val acc: 0.7630522088353414
Epoch 174 / 200, learning rate: 3.0517578125e-08
Epoch 174 / 200, train loss: 0.6921671032905579
Epoch 174 / 200, val loss: 0.6936204433441162
Epoch 174 / 200, val acc: 0.7630522088353414
Epoch 175 / 200, learning rate: 3.0517578125e-08
Epoch 175 / 200, train loss: 0.6920623183250427
Epoch 175 / 200, val loss: 0.693620502948761
Epoch 175 / 200, val acc: 0.7630522088353414
Epoch 176 / 200, learning rate: 3.0517578125e-08
Epoch 176 / 200, train loss: 0.6929345726966858
Epoch 176 / 200, val loss: 0.6936204433441162
Epoch 176 / 200, val acc: 0.7630522088353414
Epoch 177 / 200, learning rate: 1.52587890625e-08
Epoch 177 / 200, train loss: 0.6922232508659363
Epoch 177 / 200, val loss: 0.6936204433441162
Epoch 177 / 200, val acc: 0.7630522088353414
Epoch 178 / 200, learning rate: 1.52587890625e-08
Epoch 178 / 200, train loss: 0.6916943192481995
Epoch 178 / 200, val loss: 0.6936204433441162
Epoch 178 / 200, val acc: 0.7630522088353414
Epoch 179 / 200, learning rate: 1.52587890625e-08
Epoch 179 / 200, train loss: 0.6926321983337402
Epoch 179 / 200, val loss: 0.6936204433441162
Epoch 179 / 200, val acc: 0.7630522088353414
Epoch 180 / 200, learning rate: 1.52587890625e-08
Epoch 180 / 200, train loss: 0.6923774480819702
Epoch 180 / 200, val loss: 0.6936204433441162
Epoch 180 / 200, val acc: 0.7630522088353414
Epoch 181 / 200, learning rate: 1.52587890625e-08
Epoch 181 / 200, train loss: 0.6918900609016418
Epoch 181 / 200, val loss: 0.6936203837394714
Epoch 181 / 200, val acc: 0.7630522088353414
Epoch 182 / 200, learning rate: 1.52587890625e-08
Epoch 182 / 200, train loss: 0.6915963888168335
Epoch 182 / 200, val loss: 0.693620502948761
Epoch 182 / 200, val acc: 0.7630522088353414
Epoch 183 / 200, learning rate: 1.52587890625e-08
Epoch 183 / 200, train loss: 0.6925767064094543
Epoch 183 / 200, val loss: 0.693620502948761
Epoch 183 / 200, val acc: 0.7630522088353414
Epoch 184 / 200, learning rate: 1.52587890625e-08
Epoch 184 / 200, train loss: 0.6916645169258118
Epoch 184 / 200, val loss: 0.693620502948761
Epoch 184 / 200, val acc: 0.7630522088353414
Epoch 185 / 200, learning rate: 1.52587890625e-08
Epoch 185 / 200, train loss: 0.6920260787010193
Epoch 185 / 200, val loss: 0.6936204433441162
Epoch 185 / 200, val acc: 0.7630522088353414
Epoch 186 / 200, learning rate: 1.52587890625e-08
Epoch 186 / 200, train loss: 0.6923284530639648
Epoch 186 / 200, val loss: 0.693620502948761
Epoch 186 / 200, val acc: 0.7630522088353414
Epoch 187 / 200, learning rate: 1.52587890625e-08
Epoch 187 / 200, train loss: 0.6924132108688354
Epoch 187 / 200, val loss: 0.693620502948761
Epoch 187 / 200, val acc: 0.7630522088353414
Epoch 188 / 200, learning rate: 1.52587890625e-08
Epoch 188 / 200, train loss: 0.6922701597213745
Epoch 188 / 200, val loss: 0.6936204433441162
Epoch 188 / 200, val acc: 0.7630522088353414
Epoch 189 / 200, learning rate: 1.52587890625e-08
Epoch 189 / 200, train loss: 0.692375123500824
Epoch 189 / 200, val loss: 0.6936204433441162
Epoch 189 / 200, val acc: 0.7630522088353414
Epoch 190 / 200, learning rate: 1.52587890625e-08
Epoch 190 / 200, train loss: 0.6922945976257324
Epoch 190 / 200, val loss: 0.6936204433441162
Epoch 190 / 200, val acc: 0.7630522088353414
Epoch 191 / 200, learning rate: 1.52587890625e-08
Epoch 191 / 200, train loss: 0.6925585269927979
Epoch 191 / 200, val loss: 0.6936204433441162
Epoch 191 / 200, val acc: 0.7630522088353414
Epoch 192 / 200, learning rate: 1.52587890625e-08
Epoch 192 / 200, train loss: 0.6921710968017578
Epoch 192 / 200, val loss: 0.6936204433441162
Epoch 192 / 200, val acc: 0.7630522088353414
Epoch 193 / 200, learning rate: 1.52587890625e-08
Epoch 193 / 200, train loss: 0.6925803422927856
Epoch 193 / 200, val loss: 0.6936204433441162
Epoch 193 / 200, val acc: 0.7630522088353414
Epoch 194 / 200, learning rate: 1.52587890625e-08
Epoch 194 / 200, train loss: 0.6921058297157288
Epoch 194 / 200, val loss: 0.693620502948761
Epoch 194 / 200, val acc: 0.7630522088353414
Epoch 195 / 200, learning rate: 1.52587890625e-08
Epoch 195 / 200, train loss: 0.6926321983337402
Epoch 195 / 200, val loss: 0.6936204433441162
Epoch 195 / 200, val acc: 0.7630522088353414
Epoch 196 / 200, learning rate: 1.52587890625e-08
Epoch 196 / 200, train loss: 0.6922255754470825
Epoch 196 / 200, val loss: 0.6936204433441162
Epoch 196 / 200, val acc: 0.7630522088353414
Epoch 197 / 200, learning rate: 1.52587890625e-08
Epoch 197 / 200, train loss: 0.6918807625770569
Epoch 197 / 200, val loss: 0.6936203837394714
Epoch 197 / 200, val acc: 0.7630522088353414
Epoch 198 / 200, learning rate: 1.52587890625e-08
Epoch 198 / 200, train loss: 0.6920034885406494
Epoch 198 / 200, val loss: 0.6936203837394714
Epoch 198 / 200, val acc: 0.7630522088353414
Epoch 199 / 200, learning rate: 1.52587890625e-08
Epoch 199 / 200, train loss: 0.6915388703346252
Epoch 199 / 200, val loss: 0.6936204433441162
Epoch 199 / 200, val acc: 0.7630522088353414
Epoch 200 / 200, learning rate: 1.52587890625e-08
Epoch 200 / 200, train loss: 0.6920768618583679
Epoch 200 / 200, val loss: 0.6936203837394714
Epoch 200 / 200, val acc: 0.7630522088353414
Training finished

Evaluating best model on entire dataset

Evaluating best model on test dataset
 4999 trading days
Binary accuracy: 0.75070
Fraction of long signals: 0.99820
Fraction of short signals: 0.00180
Overall long return: 110.18803
Overall return: 109.32144
Yearly long return: 5.55459
Yearly return: 5.51090
Daily volatility: 0.21346
Max drawdown baseline: 0.19067
Max drawdown: 0.68973
Sharpe ratio: -0.00079
Average prediction: 0.50557
Std prediction: 0.00908
Trading strategy for stock MBGAF:
After 250 trading days
Binary accuracy: 0.73494
Fraction of long signals: 1.00000
Fraction of short signals: 0.00000
Overall long return: 5.83661
Overall return: 5.83661
Yearly long return: 5.88330
Yearly return: 5.88330
Daily volatility: 0.22001
Max drawdown baseline: 0.19067
Max drawdown: 0.19067
Sharpe ratio: 0.00043
Average prediction: 0.50481
Std prediction: 0.00001
