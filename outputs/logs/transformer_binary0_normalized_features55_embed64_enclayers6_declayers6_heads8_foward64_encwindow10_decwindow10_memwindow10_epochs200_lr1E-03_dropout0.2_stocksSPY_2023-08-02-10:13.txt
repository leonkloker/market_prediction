Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        183,984
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-3                        --                        310,992
│    │    └─LayerNorm: 3-4                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 501,553
Trainable params: 501,553
Non-trainable params: 0
Total mult-adds (M): 0.08
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.95
Params size (MB): 0.26
Estimated Total Size (MB): 2.25
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 0.6960300803184509
Epoch 1 / 200, val loss: 3.1626462936401367
Epoch 1 / 200, val acc: 0.4859437751004016
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.33111605048179626
Epoch 2 / 200, val loss: 2.0626561641693115
Epoch 2 / 200, val acc: 0.4859437751004016
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.17320364713668823
Epoch 3 / 200, val loss: 1.5945708751678467
Epoch 3 / 200, val acc: 0.4859437751004016
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.15269367396831512
Epoch 4 / 200, val loss: 1.3366405963897705
Epoch 4 / 200, val acc: 0.4859437751004016
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.15753622353076935
Epoch 5 / 200, val loss: 1.2115132808685303
Epoch 5 / 200, val acc: 0.4859437751004016
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.15456664562225342
Epoch 6 / 200, val loss: 1.2070232629776
Epoch 6 / 200, val acc: 0.4859437751004016
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.12922167778015137
Epoch 7 / 200, val loss: 1.3043267726898193
Epoch 7 / 200, val acc: 0.4859437751004016
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.11420811712741852
Epoch 8 / 200, val loss: 1.4674152135849
Epoch 8 / 200, val acc: 0.4859437751004016
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.10839969664812088
Epoch 9 / 200, val loss: 1.5433984994888306
Epoch 9 / 200, val acc: 0.4859437751004016
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.10496433079242706
Epoch 10 / 200, val loss: 1.383549690246582
Epoch 10 / 200, val acc: 0.4859437751004016
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.09763447195291519
Epoch 11 / 200, val loss: 1.0898923873901367
Epoch 11 / 200, val acc: 0.4859437751004016
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.08126911520957947
Epoch 12 / 200, val loss: 0.8480486273765564
Epoch 12 / 200, val acc: 0.4859437751004016
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.07436610013246536
Epoch 13 / 200, val loss: 0.7006164789199829
Epoch 13 / 200, val acc: 0.4859437751004016
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.07209116220474243
Epoch 14 / 200, val loss: 0.6111341714859009
Epoch 14 / 200, val acc: 0.4859437751004016
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.06857188791036606
Epoch 15 / 200, val loss: 0.5626550912857056
Epoch 15 / 200, val acc: 0.4859437751004016
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.05965982377529144
Epoch 16 / 200, val loss: 0.5363372564315796
Epoch 16 / 200, val acc: 0.4859437751004016
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.0596088208258152
Epoch 17 / 200, val loss: 0.45913875102996826
Epoch 17 / 200, val acc: 0.4859437751004016
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.05592608451843262
Epoch 18 / 200, val loss: 0.3505129814147949
Epoch 18 / 200, val acc: 0.4939759036144578
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.04774891585111618
Epoch 19 / 200, val loss: 0.287220299243927
Epoch 19 / 200, val acc: 0.4979919678714859
Epoch 20 / 200, learning rate: 0.001
Epoch 20 / 200, train loss: 0.04906999319791794
Epoch 20 / 200, val loss: 0.24316062033176422
Epoch 20 / 200, val acc: 0.4979919678714859
Epoch 21 / 200, learning rate: 0.001
Epoch 21 / 200, train loss: 0.050431281328201294
Epoch 21 / 200, val loss: 0.20551609992980957
Epoch 21 / 200, val acc: 0.4939759036144578
Epoch 22 / 200, learning rate: 0.001
Epoch 22 / 200, train loss: 0.04446515813469887
Epoch 22 / 200, val loss: 0.1770036220550537
Epoch 22 / 200, val acc: 0.4779116465863454
Epoch 23 / 200, learning rate: 0.001
Epoch 23 / 200, train loss: 0.04182855784893036
Epoch 23 / 200, val loss: 0.15146096050739288
Epoch 23 / 200, val acc: 0.4939759036144578
Epoch 24 / 200, learning rate: 0.001
Epoch 24 / 200, train loss: 0.043977878987789154
Epoch 24 / 200, val loss: 0.1265667974948883
Epoch 24 / 200, val acc: 0.4899598393574297
Epoch 25 / 200, learning rate: 0.001
Epoch 25 / 200, train loss: 0.041693832725286484
Epoch 25 / 200, val loss: 0.10559207201004028
Epoch 25 / 200, val acc: 0.4939759036144578
Epoch 26 / 200, learning rate: 0.001
Epoch 26 / 200, train loss: 0.034843459725379944
Epoch 26 / 200, val loss: 0.09042154252529144
Epoch 26 / 200, val acc: 0.4979919678714859
Epoch 27 / 200, learning rate: 0.001
Epoch 27 / 200, train loss: 0.04035380110144615
Epoch 27 / 200, val loss: 0.08295239508152008
Epoch 27 / 200, val acc: 0.4939759036144578
Epoch 28 / 200, learning rate: 0.001
Epoch 28 / 200, train loss: 0.036293238401412964
Epoch 28 / 200, val loss: 0.07681611180305481
Epoch 28 / 200, val acc: 0.5100401606425703
Epoch 29 / 200, learning rate: 0.001
Epoch 29 / 200, train loss: 0.03389805555343628
Epoch 29 / 200, val loss: 0.06719810515642166
Epoch 29 / 200, val acc: 0.5020080321285141
Epoch 30 / 200, learning rate: 0.001
Epoch 30 / 200, train loss: 0.033593762665987015
Epoch 30 / 200, val loss: 0.057259026914834976
Epoch 30 / 200, val acc: 0.4939759036144578
Epoch 31 / 200, learning rate: 0.001
Epoch 31 / 200, train loss: 0.03388801962137222
Epoch 31 / 200, val loss: 0.052354440093040466
Epoch 31 / 200, val acc: 0.5060240963855421
Epoch 32 / 200, learning rate: 0.001
Epoch 32 / 200, train loss: 0.0330900177359581
Epoch 32 / 200, val loss: 0.04907645657658577
Epoch 32 / 200, val acc: 0.4939759036144578
Epoch 33 / 200, learning rate: 0.001
Epoch 33 / 200, train loss: 0.03172559291124344
Epoch 33 / 200, val loss: 0.047223418951034546
Epoch 33 / 200, val acc: 0.4899598393574297
Epoch 34 / 200, learning rate: 0.001
Epoch 34 / 200, train loss: 0.030146535485982895
Epoch 34 / 200, val loss: 0.04671168327331543
Epoch 34 / 200, val acc: 0.4779116465863454
Epoch 35 / 200, learning rate: 0.001
Epoch 35 / 200, train loss: 0.029388386756181717
Epoch 35 / 200, val loss: 0.047208916395902634
Epoch 35 / 200, val acc: 0.4899598393574297
Epoch 36 / 200, learning rate: 0.001
Epoch 36 / 200, train loss: 0.02914639562368393
Epoch 36 / 200, val loss: 0.04856878146529198
Epoch 36 / 200, val acc: 0.5060240963855421
Epoch 37 / 200, learning rate: 0.001
Epoch 37 / 200, train loss: 0.02934320829808712
Epoch 37 / 200, val loss: 0.0485977940261364
Epoch 37 / 200, val acc: 0.4939759036144578
Epoch 38 / 200, learning rate: 0.001
Epoch 38 / 200, train loss: 0.02997533231973648
Epoch 38 / 200, val loss: 0.05546140298247337
Epoch 38 / 200, val acc: 0.5100401606425703
Epoch 39 / 200, learning rate: 0.001
Epoch 39 / 200, train loss: 0.02788466028869152
Epoch 39 / 200, val loss: 0.0704939141869545
Epoch 39 / 200, val acc: 0.5100401606425703
Epoch 40 / 200, learning rate: 0.001
Epoch 40 / 200, train loss: 0.02975127100944519
Epoch 40 / 200, val loss: 0.07236267626285553
Epoch 40 / 200, val acc: 0.5100401606425703
Epoch 41 / 200, learning rate: 0.001
Epoch 41 / 200, train loss: 0.027792226523160934
Epoch 41 / 200, val loss: 0.06635361909866333
Epoch 41 / 200, val acc: 0.5100401606425703
Epoch 42 / 200, learning rate: 0.001
Epoch 42 / 200, train loss: 0.02581232227385044
Epoch 42 / 200, val loss: 0.05739787593483925
Epoch 42 / 200, val acc: 0.5060240963855421
Epoch 43 / 200, learning rate: 0.001
Epoch 43 / 200, train loss: 0.026752004399895668
Epoch 43 / 200, val loss: 0.04814229905605316
Epoch 43 / 200, val acc: 0.5100401606425703
Epoch 44 / 200, learning rate: 0.001
Epoch 44 / 200, train loss: 0.026020633056759834
Epoch 44 / 200, val loss: 0.05065150558948517
Epoch 44 / 200, val acc: 0.5020080321285141
Epoch 45 / 200, learning rate: 0.0005
Epoch 45 / 200, train loss: 0.025125186890363693
Epoch 45 / 200, val loss: 0.052332278341054916
Epoch 45 / 200, val acc: 0.5020080321285141
Epoch 46 / 200, learning rate: 0.0005
Epoch 46 / 200, train loss: 0.025798020884394646
Epoch 46 / 200, val loss: 0.05031827092170715
Epoch 46 / 200, val acc: 0.4979919678714859
Epoch 47 / 200, learning rate: 0.0005
Epoch 47 / 200, train loss: 0.02567107230424881
Epoch 47 / 200, val loss: 0.05001169070601463
Epoch 47 / 200, val acc: 0.5020080321285141
Epoch 48 / 200, learning rate: 0.0005
Epoch 48 / 200, train loss: 0.025393562391400337
Epoch 48 / 200, val loss: 0.050171058624982834
Epoch 48 / 200, val acc: 0.5020080321285141
Epoch 49 / 200, learning rate: 0.0005
Epoch 49 / 200, train loss: 0.02541009709239006
Epoch 49 / 200, val loss: 0.05361710488796234
Epoch 49 / 200, val acc: 0.5100401606425703
Epoch 50 / 200, learning rate: 0.0005
Epoch 50 / 200, train loss: 0.02530692145228386
Epoch 50 / 200, val loss: 0.05806251987814903
Epoch 50 / 200, val acc: 0.5020080321285141
Epoch 51 / 200, learning rate: 0.0005
Epoch 51 / 200, train loss: 0.025481238961219788
Epoch 51 / 200, val loss: 0.06262338906526566
Epoch 51 / 200, val acc: 0.5100401606425703
Epoch 52 / 200, learning rate: 0.0005
Epoch 52 / 200, train loss: 0.024763628840446472
Epoch 52 / 200, val loss: 0.06383389979600906
Epoch 52 / 200, val acc: 0.5100401606425703
Epoch 53 / 200, learning rate: 0.0005
Epoch 53 / 200, train loss: 0.023735854774713516
Epoch 53 / 200, val loss: 0.06564117968082428
Epoch 53 / 200, val acc: 0.5060240963855421
Epoch 54 / 200, learning rate: 0.0005
Epoch 54 / 200, train loss: 0.025721115991473198
Epoch 54 / 200, val loss: 0.06651455909013748
Epoch 54 / 200, val acc: 0.5020080321285141
Epoch 55 / 200, learning rate: 0.0005
Epoch 55 / 200, train loss: 0.024050315842032433
Epoch 55 / 200, val loss: 0.07066576182842255
Epoch 55 / 200, val acc: 0.5220883534136547
Epoch 56 / 200, learning rate: 0.00025
Epoch 56 / 200, train loss: 0.025894464924931526
Epoch 56 / 200, val loss: 0.06530700623989105
Epoch 56 / 200, val acc: 0.5060240963855421
Epoch 57 / 200, learning rate: 0.00025
Epoch 57 / 200, train loss: 0.02433597855269909
Epoch 57 / 200, val loss: 0.06220879778265953
Epoch 57 / 200, val acc: 0.5060240963855421
Epoch 58 / 200, learning rate: 0.00025
Epoch 58 / 200, train loss: 0.024853484705090523
Epoch 58 / 200, val loss: 0.059363797307014465
Epoch 58 / 200, val acc: 0.5100401606425703
Epoch 59 / 200, learning rate: 0.00025
Epoch 59 / 200, train loss: 0.024109672755002975
Epoch 59 / 200, val loss: 0.059987545013427734
Epoch 59 / 200, val acc: 0.5060240963855421
Epoch 60 / 200, learning rate: 0.00025
Epoch 60 / 200, train loss: 0.024900812655687332
Epoch 60 / 200, val loss: 0.06073785573244095
Epoch 60 / 200, val acc: 0.5020080321285141
Epoch 61 / 200, learning rate: 0.00025
Epoch 61 / 200, train loss: 0.023218218237161636
Epoch 61 / 200, val loss: 0.0617857463657856
Epoch 61 / 200, val acc: 0.5060240963855421
Epoch 62 / 200, learning rate: 0.00025
Epoch 62 / 200, train loss: 0.023269515484571457
Epoch 62 / 200, val loss: 0.06271015107631683
Epoch 62 / 200, val acc: 0.5100401606425703
Epoch 63 / 200, learning rate: 0.00025
Epoch 63 / 200, train loss: 0.024180226027965546
Epoch 63 / 200, val loss: 0.061746105551719666
Epoch 63 / 200, val acc: 0.5020080321285141
Epoch 64 / 200, learning rate: 0.00025
Epoch 64 / 200, train loss: 0.023687127977609634
Epoch 64 / 200, val loss: 0.06021576374769211
Epoch 64 / 200, val acc: 0.5020080321285141
Epoch 65 / 200, learning rate: 0.00025
Epoch 65 / 200, train loss: 0.022869093343615532
Epoch 65 / 200, val loss: 0.05891910940408707
Epoch 65 / 200, val acc: 0.4979919678714859
Epoch 66 / 200, learning rate: 0.00025
Epoch 66 / 200, train loss: 0.024606876075267792
Epoch 66 / 200, val loss: 0.056799475103616714
Epoch 66 / 200, val acc: 0.5060240963855421
Epoch 67 / 200, learning rate: 0.000125
Epoch 67 / 200, train loss: 0.024015340954065323
Epoch 67 / 200, val loss: 0.0560021698474884
Epoch 67 / 200, val acc: 0.5100401606425703
Epoch 68 / 200, learning rate: 0.000125
Epoch 68 / 200, train loss: 0.02346014231443405
Epoch 68 / 200, val loss: 0.05582398176193237
Epoch 68 / 200, val acc: 0.5140562248995983
Epoch 69 / 200, learning rate: 0.000125
Epoch 69 / 200, train loss: 0.022845905274152756
Epoch 69 / 200, val loss: 0.05514706298708916
Epoch 69 / 200, val acc: 0.5140562248995983
Epoch 70 / 200, learning rate: 0.000125
Epoch 70 / 200, train loss: 0.0234270840883255
Epoch 70 / 200, val loss: 0.0547935925424099
Epoch 70 / 200, val acc: 0.5140562248995983
Epoch 71 / 200, learning rate: 0.000125
Epoch 71 / 200, train loss: 0.022780651226639748
Epoch 71 / 200, val loss: 0.0544428750872612
Epoch 71 / 200, val acc: 0.5020080321285141
Epoch 72 / 200, learning rate: 0.000125
Epoch 72 / 200, train loss: 0.024518948048353195
Epoch 72 / 200, val loss: 0.054791439324617386
Epoch 72 / 200, val acc: 0.5140562248995983
Epoch 73 / 200, learning rate: 0.000125
Epoch 73 / 200, train loss: 0.022619465366005898
Epoch 73 / 200, val loss: 0.05491087585687637
Epoch 73 / 200, val acc: 0.5140562248995983
Epoch 74 / 200, learning rate: 0.000125
Epoch 74 / 200, train loss: 0.023739008232951164
Epoch 74 / 200, val loss: 0.054569441825151443
Epoch 74 / 200, val acc: 0.5020080321285141
Epoch 75 / 200, learning rate: 0.000125
Epoch 75 / 200, train loss: 0.02352934144437313
Epoch 75 / 200, val loss: 0.05432150885462761
Epoch 75 / 200, val acc: 0.4979919678714859
Epoch 76 / 200, learning rate: 0.000125
Epoch 76 / 200, train loss: 0.023185042664408684
Epoch 76 / 200, val loss: 0.05400211736559868
Epoch 76 / 200, val acc: 0.5060240963855421
Epoch 77 / 200, learning rate: 0.000125
Epoch 77 / 200, train loss: 0.022297872230410576
Epoch 77 / 200, val loss: 0.053720638155937195
Epoch 77 / 200, val acc: 0.5060240963855421
Epoch 78 / 200, learning rate: 6.25e-05
Epoch 78 / 200, train loss: 0.023483188822865486
Epoch 78 / 200, val loss: 0.054509472101926804
Epoch 78 / 200, val acc: 0.5020080321285141
Epoch 79 / 200, learning rate: 6.25e-05
Epoch 79 / 200, train loss: 0.02268943004310131
Epoch 79 / 200, val loss: 0.05465684086084366
Epoch 79 / 200, val acc: 0.4979919678714859
Epoch 80 / 200, learning rate: 6.25e-05
Epoch 80 / 200, train loss: 0.02323889546096325
Epoch 80 / 200, val loss: 0.05488506704568863
Epoch 80 / 200, val acc: 0.5060240963855421
Epoch 81 / 200, learning rate: 6.25e-05
Epoch 81 / 200, train loss: 0.023148449137806892
Epoch 81 / 200, val loss: 0.05564561113715172
Epoch 81 / 200, val acc: 0.5060240963855421
Epoch 82 / 200, learning rate: 6.25e-05
Epoch 82 / 200, train loss: 0.02326970361173153
Epoch 82 / 200, val loss: 0.056396301835775375
Epoch 82 / 200, val acc: 0.5140562248995983
Epoch 83 / 200, learning rate: 6.25e-05
Epoch 83 / 200, train loss: 0.023142732679843903
Epoch 83 / 200, val loss: 0.05713315308094025
Epoch 83 / 200, val acc: 0.5100401606425703
Epoch 84 / 200, learning rate: 6.25e-05
Epoch 84 / 200, train loss: 0.022612066939473152
Epoch 84 / 200, val loss: 0.05761847272515297
Epoch 84 / 200, val acc: 0.5140562248995983
Epoch 85 / 200, learning rate: 6.25e-05
Epoch 85 / 200, train loss: 0.022660644724965096
Epoch 85 / 200, val loss: 0.05771223083138466
Epoch 85 / 200, val acc: 0.5140562248995983
Epoch 86 / 200, learning rate: 6.25e-05
Epoch 86 / 200, train loss: 0.021848855540156364
Epoch 86 / 200, val loss: 0.05741153284907341
Epoch 86 / 200, val acc: 0.5140562248995983
Epoch 87 / 200, learning rate: 6.25e-05
Epoch 87 / 200, train loss: 0.023303724825382233
Epoch 87 / 200, val loss: 0.05668429657816887
Epoch 87 / 200, val acc: 0.5100401606425703
Epoch 88 / 200, learning rate: 6.25e-05
Epoch 88 / 200, train loss: 0.021748999133706093
Epoch 88 / 200, val loss: 0.05569859594106674
Epoch 88 / 200, val acc: 0.5020080321285141
Epoch 89 / 200, learning rate: 3.125e-05
Epoch 89 / 200, train loss: 0.022634707391262054
Epoch 89 / 200, val loss: 0.054980143904685974
Epoch 89 / 200, val acc: 0.5100401606425703
Epoch 90 / 200, learning rate: 3.125e-05
Epoch 90 / 200, train loss: 0.022902775555849075
Epoch 90 / 200, val loss: 0.05485790595412254
Epoch 90 / 200, val acc: 0.5060240963855421
Epoch 91 / 200, learning rate: 3.125e-05
Epoch 91 / 200, train loss: 0.022548284381628036
Epoch 91 / 200, val loss: 0.05495268106460571
Epoch 91 / 200, val acc: 0.5100401606425703
Epoch 92 / 200, learning rate: 3.125e-05
Epoch 92 / 200, train loss: 0.024389982223510742
Epoch 92 / 200, val loss: 0.05522199347615242
Epoch 92 / 200, val acc: 0.5060240963855421
Epoch 93 / 200, learning rate: 3.125e-05
Epoch 93 / 200, train loss: 0.0227175485342741
Epoch 93 / 200, val loss: 0.055618032813072205
Epoch 93 / 200, val acc: 0.5060240963855421
Epoch 94 / 200, learning rate: 3.125e-05
Epoch 94 / 200, train loss: 0.0225091353058815
Epoch 94 / 200, val loss: 0.0559566468000412
Epoch 94 / 200, val acc: 0.5020080321285141
Epoch 95 / 200, learning rate: 3.125e-05
Epoch 95 / 200, train loss: 0.02224322222173214
Epoch 95 / 200, val loss: 0.056302111595869064
Epoch 95 / 200, val acc: 0.5140562248995983
Epoch 96 / 200, learning rate: 3.125e-05
Epoch 96 / 200, train loss: 0.022969305515289307
Epoch 96 / 200, val loss: 0.056790828704833984
Epoch 96 / 200, val acc: 0.5100401606425703
Epoch 97 / 200, learning rate: 3.125e-05
Epoch 97 / 200, train loss: 0.023209646344184875
Epoch 97 / 200, val loss: 0.05723036453127861
Epoch 97 / 200, val acc: 0.5100401606425703
Epoch 98 / 200, learning rate: 3.125e-05
Epoch 98 / 200, train loss: 0.022071393206715584
Epoch 98 / 200, val loss: 0.057564184069633484
Epoch 98 / 200, val acc: 0.5140562248995983
Epoch 99 / 200, learning rate: 3.125e-05
Epoch 99 / 200, train loss: 0.02249639481306076
Epoch 99 / 200, val loss: 0.05788248032331467
Epoch 99 / 200, val acc: 0.5140562248995983
Epoch 100 / 200, learning rate: 1.5625e-05
Epoch 100 / 200, train loss: 0.02313786931335926
Epoch 100 / 200, val loss: 0.058163102716207504
Epoch 100 / 200, val acc: 0.5100401606425703
Epoch 101 / 200, learning rate: 1.5625e-05
Epoch 101 / 200, train loss: 0.02309732511639595
Epoch 101 / 200, val loss: 0.058202601969242096
Epoch 101 / 200, val acc: 0.5100401606425703
Epoch 102 / 200, learning rate: 1.5625e-05
Epoch 102 / 200, train loss: 0.022753730416297913
Epoch 102 / 200, val loss: 0.05815981701016426
Epoch 102 / 200, val acc: 0.5100401606425703
Epoch 103 / 200, learning rate: 1.5625e-05
Epoch 103 / 200, train loss: 0.022745857015252113
Epoch 103 / 200, val loss: 0.058168210089206696
Epoch 103 / 200, val acc: 0.5100401606425703
Epoch 104 / 200, learning rate: 1.5625e-05
Epoch 104 / 200, train loss: 0.02204873412847519
Epoch 104 / 200, val loss: 0.05823971703648567
Epoch 104 / 200, val acc: 0.5100401606425703
Epoch 105 / 200, learning rate: 1.5625e-05
Epoch 105 / 200, train loss: 0.022219829261302948
Epoch 105 / 200, val loss: 0.058267153799533844
Epoch 105 / 200, val acc: 0.5100401606425703
Epoch 106 / 200, learning rate: 1.5625e-05
Epoch 106 / 200, train loss: 0.022685756906867027
Epoch 106 / 200, val loss: 0.05826403200626373
Epoch 106 / 200, val acc: 0.5100401606425703
Epoch 107 / 200, learning rate: 1.5625e-05
Epoch 107 / 200, train loss: 0.022647816687822342
Epoch 107 / 200, val loss: 0.0581914559006691
Epoch 107 / 200, val acc: 0.5100401606425703
Epoch 108 / 200, learning rate: 1.5625e-05
Epoch 108 / 200, train loss: 0.022688306868076324
Epoch 108 / 200, val loss: 0.058115847408771515
Epoch 108 / 200, val acc: 0.5100401606425703
Epoch 109 / 200, learning rate: 1.5625e-05
Epoch 109 / 200, train loss: 0.022235093638300896
Epoch 109 / 200, val loss: 0.058003008365631104
Epoch 109 / 200, val acc: 0.5100401606425703
Epoch 110 / 200, learning rate: 1.5625e-05
Epoch 110 / 200, train loss: 0.022142546251416206
Epoch 110 / 200, val loss: 0.05793485417962074
Epoch 110 / 200, val acc: 0.5140562248995983
Epoch 111 / 200, learning rate: 7.8125e-06
Epoch 111 / 200, train loss: 0.021955689415335655
Epoch 111 / 200, val loss: 0.05794874578714371
Epoch 111 / 200, val acc: 0.5140562248995983
Epoch 112 / 200, learning rate: 7.8125e-06
Epoch 112 / 200, train loss: 0.022053029388189316
Epoch 112 / 200, val loss: 0.057978831231594086
Epoch 112 / 200, val acc: 0.5100401606425703
Epoch 113 / 200, learning rate: 7.8125e-06
Epoch 113 / 200, train loss: 0.024435920640826225
Epoch 113 / 200, val loss: 0.05795935168862343
Epoch 113 / 200, val acc: 0.5100401606425703
Epoch 114 / 200, learning rate: 7.8125e-06
Epoch 114 / 200, train loss: 0.023670056834816933
Epoch 114 / 200, val loss: 0.05790044367313385
Epoch 114 / 200, val acc: 0.5140562248995983
Epoch 115 / 200, learning rate: 7.8125e-06
Epoch 115 / 200, train loss: 0.021711664274334908
Epoch 115 / 200, val loss: 0.05784723162651062
Epoch 115 / 200, val acc: 0.5140562248995983
Epoch 116 / 200, learning rate: 7.8125e-06
Epoch 116 / 200, train loss: 0.022146880626678467
Epoch 116 / 200, val loss: 0.05786476284265518
Epoch 116 / 200, val acc: 0.5140562248995983
Epoch 117 / 200, learning rate: 7.8125e-06
Epoch 117 / 200, train loss: 0.023424237966537476
Epoch 117 / 200, val loss: 0.05784055218100548
Epoch 117 / 200, val acc: 0.5140562248995983
Epoch 118 / 200, learning rate: 7.8125e-06
Epoch 118 / 200, train loss: 0.022748328745365143
Epoch 118 / 200, val loss: 0.05778558552265167
Epoch 118 / 200, val acc: 0.5140562248995983
Epoch 119 / 200, learning rate: 7.8125e-06
Epoch 119 / 200, train loss: 0.023146184161305428
Epoch 119 / 200, val loss: 0.057725876569747925
Epoch 119 / 200, val acc: 0.5140562248995983
Epoch 120 / 200, learning rate: 7.8125e-06
Epoch 120 / 200, train loss: 0.02150270901620388
Epoch 120 / 200, val loss: 0.05764482915401459
Epoch 120 / 200, val acc: 0.5140562248995983
Epoch 121 / 200, learning rate: 7.8125e-06
Epoch 121 / 200, train loss: 0.02161114104092121
Epoch 121 / 200, val loss: 0.057570744305849075
Epoch 121 / 200, val acc: 0.5140562248995983
Epoch 122 / 200, learning rate: 3.90625e-06
Epoch 122 / 200, train loss: 0.021933410316705704
Epoch 122 / 200, val loss: 0.05749502032995224
Epoch 122 / 200, val acc: 0.5100401606425703
Epoch 123 / 200, learning rate: 3.90625e-06
Epoch 123 / 200, train loss: 0.02181309275329113
Epoch 123 / 200, val loss: 0.057476721704006195
Epoch 123 / 200, val acc: 0.5100401606425703
Epoch 124 / 200, learning rate: 3.90625e-06
Epoch 124 / 200, train loss: 0.023718882352113724
Epoch 124 / 200, val loss: 0.05744391307234764
Epoch 124 / 200, val acc: 0.5100401606425703
Epoch 125 / 200, learning rate: 3.90625e-06
Epoch 125 / 200, train loss: 0.02338467724621296
Epoch 125 / 200, val loss: 0.057433322072029114
Epoch 125 / 200, val acc: 0.5100401606425703
Epoch 126 / 200, learning rate: 3.90625e-06
Epoch 126 / 200, train loss: 0.02177390456199646
Epoch 126 / 200, val loss: 0.0574229471385479
Epoch 126 / 200, val acc: 0.5100401606425703
Epoch 127 / 200, learning rate: 3.90625e-06
Epoch 127 / 200, train loss: 0.023064320906996727
Epoch 127 / 200, val loss: 0.057410988956689835
Epoch 127 / 200, val acc: 0.5100401606425703
Epoch 128 / 200, learning rate: 3.90625e-06
Epoch 128 / 200, train loss: 0.022171184420585632
Epoch 128 / 200, val loss: 0.057378679513931274
Epoch 128 / 200, val acc: 0.5100401606425703
Epoch 129 / 200, learning rate: 3.90625e-06
Epoch 129 / 200, train loss: 0.022208696231245995
Epoch 129 / 200, val loss: 0.057345665991306305
Epoch 129 / 200, val acc: 0.5100401606425703
Epoch 130 / 200, learning rate: 3.90625e-06
Epoch 130 / 200, train loss: 0.023578133434057236
Epoch 130 / 200, val loss: 0.05733098089694977
Epoch 130 / 200, val acc: 0.5100401606425703
Epoch 131 / 200, learning rate: 3.90625e-06
Epoch 131 / 200, train loss: 0.0223408080637455
Epoch 131 / 200, val loss: 0.057306211441755295
Epoch 131 / 200, val acc: 0.5100401606425703
Epoch 132 / 200, learning rate: 3.90625e-06
Epoch 132 / 200, train loss: 0.02157672867178917
Epoch 132 / 200, val loss: 0.057299476116895676
Epoch 132 / 200, val acc: 0.5100401606425703
Epoch 133 / 200, learning rate: 1.953125e-06
Epoch 133 / 200, train loss: 0.023921657353639603
Epoch 133 / 200, val loss: 0.05729227513074875
Epoch 133 / 200, val acc: 0.5100401606425703
Epoch 134 / 200, learning rate: 1.953125e-06
Epoch 134 / 200, train loss: 0.022874321788549423
Epoch 134 / 200, val loss: 0.05727958679199219
Epoch 134 / 200, val acc: 0.5100401606425703
Epoch 135 / 200, learning rate: 1.953125e-06
Epoch 135 / 200, train loss: 0.022172052413225174
Epoch 135 / 200, val loss: 0.05726531893014908
Epoch 135 / 200, val acc: 0.5100401606425703
Epoch 136 / 200, learning rate: 1.953125e-06
Epoch 136 / 200, train loss: 0.021940529346466064
Epoch 136 / 200, val loss: 0.05726481229066849
Epoch 136 / 200, val acc: 0.5100401606425703
Epoch 137 / 200, learning rate: 1.953125e-06
Epoch 137 / 200, train loss: 0.023275624960660934
Epoch 137 / 200, val loss: 0.05727609246969223
Epoch 137 / 200, val acc: 0.5100401606425703
Epoch 138 / 200, learning rate: 1.953125e-06
Epoch 138 / 200, train loss: 0.023239485919475555
Epoch 138 / 200, val loss: 0.0572846494615078
Epoch 138 / 200, val acc: 0.5100401606425703
Epoch 139 / 200, learning rate: 1.953125e-06
Epoch 139 / 200, train loss: 0.02324824221432209
Epoch 139 / 200, val loss: 0.05730186030268669
Epoch 139 / 200, val acc: 0.5100401606425703
Epoch 140 / 200, learning rate: 1.953125e-06
Epoch 140 / 200, train loss: 0.02210179902613163
Epoch 140 / 200, val loss: 0.0573112815618515
Epoch 140 / 200, val acc: 0.5100401606425703
Epoch 141 / 200, learning rate: 1.953125e-06
Epoch 141 / 200, train loss: 0.02248402312397957
Epoch 141 / 200, val loss: 0.05733221769332886
Epoch 141 / 200, val acc: 0.5100401606425703
Epoch 142 / 200, learning rate: 1.953125e-06
Epoch 142 / 200, train loss: 0.023597465828061104
Epoch 142 / 200, val loss: 0.05736842751502991
Epoch 142 / 200, val acc: 0.5100401606425703
Epoch 143 / 200, learning rate: 1.953125e-06
Epoch 143 / 200, train loss: 0.022556474432349205
Epoch 143 / 200, val loss: 0.05738944560289383
Epoch 143 / 200, val acc: 0.5100401606425703
Epoch 144 / 200, learning rate: 9.765625e-07
Epoch 144 / 200, train loss: 0.022522510960698128
Epoch 144 / 200, val loss: 0.0574052594602108
Epoch 144 / 200, val acc: 0.5100401606425703
Epoch 145 / 200, learning rate: 9.765625e-07
Epoch 145 / 200, train loss: 0.021812280640006065
Epoch 145 / 200, val loss: 0.05741306394338608
Epoch 145 / 200, val acc: 0.5100401606425703
Epoch 146 / 200, learning rate: 9.765625e-07
Epoch 146 / 200, train loss: 0.02419927716255188
Epoch 146 / 200, val loss: 0.05742261931300163
Epoch 146 / 200, val acc: 0.5100401606425703
Epoch 147 / 200, learning rate: 9.765625e-07
Epoch 147 / 200, train loss: 0.022210266441106796
Epoch 147 / 200, val loss: 0.05742698907852173
Epoch 147 / 200, val acc: 0.5100401606425703
Epoch 148 / 200, learning rate: 9.765625e-07
Epoch 148 / 200, train loss: 0.022394152358174324
Epoch 148 / 200, val loss: 0.05742507427930832
Epoch 148 / 200, val acc: 0.5100401606425703
Epoch 149 / 200, learning rate: 9.765625e-07
Epoch 149 / 200, train loss: 0.022171227261424065
Epoch 149 / 200, val loss: 0.057425763458013535
Epoch 149 / 200, val acc: 0.5100401606425703
Epoch 150 / 200, learning rate: 9.765625e-07
Epoch 150 / 200, train loss: 0.021783920004963875
Epoch 150 / 200, val loss: 0.05743525177240372
Epoch 150 / 200, val acc: 0.5100401606425703
Epoch 151 / 200, learning rate: 9.765625e-07
Epoch 151 / 200, train loss: 0.0222566407173872
Epoch 151 / 200, val loss: 0.05744096264243126
Epoch 151 / 200, val acc: 0.5100401606425703
Epoch 152 / 200, learning rate: 9.765625e-07
Epoch 152 / 200, train loss: 0.02184111252427101
Epoch 152 / 200, val loss: 0.057445112615823746
Epoch 152 / 200, val acc: 0.5100401606425703
Epoch 153 / 200, learning rate: 9.765625e-07
Epoch 153 / 200, train loss: 0.020816724747419357
Epoch 153 / 200, val loss: 0.05744847655296326
Epoch 153 / 200, val acc: 0.5100401606425703
Epoch 154 / 200, learning rate: 9.765625e-07
Epoch 154 / 200, train loss: 0.023236097767949104
Epoch 154 / 200, val loss: 0.05744873359799385
Epoch 154 / 200, val acc: 0.5100401606425703
Epoch 155 / 200, learning rate: 4.8828125e-07
Epoch 155 / 200, train loss: 0.02209983952343464
Epoch 155 / 200, val loss: 0.05744710937142372
Epoch 155 / 200, val acc: 0.5100401606425703
Epoch 156 / 200, learning rate: 4.8828125e-07
Epoch 156 / 200, train loss: 0.02215193212032318
Epoch 156 / 200, val loss: 0.0574490912258625
Epoch 156 / 200, val acc: 0.5100401606425703
Epoch 157 / 200, learning rate: 4.8828125e-07
Epoch 157 / 200, train loss: 0.022843535989522934
Epoch 157 / 200, val loss: 0.05745112895965576
Epoch 157 / 200, val acc: 0.5100401606425703
Epoch 158 / 200, learning rate: 4.8828125e-07
Epoch 158 / 200, train loss: 0.022797387093305588
Epoch 158 / 200, val loss: 0.05745416507124901
Epoch 158 / 200, val acc: 0.5100401606425703
Epoch 159 / 200, learning rate: 4.8828125e-07
Epoch 159 / 200, train loss: 0.023712050169706345
Epoch 159 / 200, val loss: 0.05745888128876686
Epoch 159 / 200, val acc: 0.5100401606425703
Epoch 160 / 200, learning rate: 4.8828125e-07
Epoch 160 / 200, train loss: 0.023195702582597733
Epoch 160 / 200, val loss: 0.057460930198431015
Epoch 160 / 200, val acc: 0.5100401606425703
Epoch 161 / 200, learning rate: 4.8828125e-07
Epoch 161 / 200, train loss: 0.022703133523464203
Epoch 161 / 200, val loss: 0.05746012181043625
Epoch 161 / 200, val acc: 0.5100401606425703
Epoch 162 / 200, learning rate: 4.8828125e-07
Epoch 162 / 200, train loss: 0.022065497934818268
Epoch 162 / 200, val loss: 0.057460229843854904
Epoch 162 / 200, val acc: 0.5100401606425703
Epoch 163 / 200, learning rate: 4.8828125e-07
Epoch 163 / 200, train loss: 0.022968526929616928
Epoch 163 / 200, val loss: 0.057460982352495193
Epoch 163 / 200, val acc: 0.5100401606425703
Epoch 164 / 200, learning rate: 4.8828125e-07
Epoch 164 / 200, train loss: 0.021557193249464035
Epoch 164 / 200, val loss: 0.05746210739016533
Epoch 164 / 200, val acc: 0.5100401606425703
Epoch 165 / 200, learning rate: 4.8828125e-07
Epoch 165 / 200, train loss: 0.022896355018019676
Epoch 165 / 200, val loss: 0.05746186524629593
Epoch 165 / 200, val acc: 0.5100401606425703
Epoch 166 / 200, learning rate: 2.44140625e-07
Epoch 166 / 200, train loss: 0.022457176819443703
Epoch 166 / 200, val loss: 0.05746205523610115
Epoch 166 / 200, val acc: 0.5100401606425703
Epoch 167 / 200, learning rate: 2.44140625e-07
Epoch 167 / 200, train loss: 0.022214844822883606
Epoch 167 / 200, val loss: 0.05746251344680786
Epoch 167 / 200, val acc: 0.5100401606425703
Epoch 168 / 200, learning rate: 2.44140625e-07
Epoch 168 / 200, train loss: 0.02212156169116497
Epoch 168 / 200, val loss: 0.0574650764465332
Epoch 168 / 200, val acc: 0.5100401606425703
Epoch 169 / 200, learning rate: 2.44140625e-07
Epoch 169 / 200, train loss: 0.02216031774878502
Epoch 169 / 200, val loss: 0.05747072771191597
Epoch 169 / 200, val acc: 0.5100401606425703
Epoch 170 / 200, learning rate: 2.44140625e-07
Epoch 170 / 200, train loss: 0.022075077518820763
Epoch 170 / 200, val loss: 0.05747753381729126
Epoch 170 / 200, val acc: 0.5100401606425703
Epoch 171 / 200, learning rate: 2.44140625e-07
Epoch 171 / 200, train loss: 0.02284708432853222
Epoch 171 / 200, val loss: 0.05748366191983223
Epoch 171 / 200, val acc: 0.5100401606425703
Epoch 172 / 200, learning rate: 2.44140625e-07
Epoch 172 / 200, train loss: 0.02272101864218712
Epoch 172 / 200, val loss: 0.05748818442225456
Epoch 172 / 200, val acc: 0.5100401606425703
Epoch 173 / 200, learning rate: 2.44140625e-07
Epoch 173 / 200, train loss: 0.023176949471235275
Epoch 173 / 200, val loss: 0.057491861283779144
Epoch 173 / 200, val acc: 0.5100401606425703
Epoch 174 / 200, learning rate: 2.44140625e-07
Epoch 174 / 200, train loss: 0.023291610181331635
Epoch 174 / 200, val loss: 0.05749557539820671
Epoch 174 / 200, val acc: 0.5100401606425703
Epoch 175 / 200, learning rate: 2.44140625e-07
Epoch 175 / 200, train loss: 0.022325880825519562
Epoch 175 / 200, val loss: 0.057500146329402924
Epoch 175 / 200, val acc: 0.5100401606425703
Epoch 176 / 200, learning rate: 2.44140625e-07
Epoch 176 / 200, train loss: 0.022790126502513885
Epoch 176 / 200, val loss: 0.057505808770656586
Epoch 176 / 200, val acc: 0.5100401606425703
Epoch 177 / 200, learning rate: 1.220703125e-07
Epoch 177 / 200, train loss: 0.023264652118086815
Epoch 177 / 200, val loss: 0.0575111098587513
Epoch 177 / 200, val acc: 0.5100401606425703
Epoch 178 / 200, learning rate: 1.220703125e-07
Epoch 178 / 200, train loss: 0.02199036069214344
Epoch 178 / 200, val loss: 0.05751384049654007
Epoch 178 / 200, val acc: 0.5100401606425703
Epoch 179 / 200, learning rate: 1.220703125e-07
Epoch 179 / 200, train loss: 0.023230696097016335
Epoch 179 / 200, val loss: 0.05751658231019974
Epoch 179 / 200, val acc: 0.5100401606425703
Epoch 180 / 200, learning rate: 1.220703125e-07
Epoch 180 / 200, train loss: 0.021355414763092995
Epoch 180 / 200, val loss: 0.05751954764127731
Epoch 180 / 200, val acc: 0.5100401606425703
Epoch 181 / 200, learning rate: 1.220703125e-07
Epoch 181 / 200, train loss: 0.023946136236190796
Epoch 181 / 200, val loss: 0.057523008435964584
Epoch 181 / 200, val acc: 0.5100401606425703
Epoch 182 / 200, learning rate: 1.220703125e-07
Epoch 182 / 200, train loss: 0.022518211975693703
Epoch 182 / 200, val loss: 0.057525165379047394
Epoch 182 / 200, val acc: 0.5100401606425703
Epoch 183 / 200, learning rate: 1.220703125e-07
Epoch 183 / 200, train loss: 0.023128218948841095
Epoch 183 / 200, val loss: 0.05752629414200783
Epoch 183 / 200, val acc: 0.5100401606425703
Epoch 184 / 200, learning rate: 1.220703125e-07
Epoch 184 / 200, train loss: 0.021807143464684486
Epoch 184 / 200, val loss: 0.057527653872966766
Epoch 184 / 200, val acc: 0.5100401606425703
Epoch 185 / 200, learning rate: 1.220703125e-07
Epoch 185 / 200, train loss: 0.022383717820048332
Epoch 185 / 200, val loss: 0.0575290322303772
Epoch 185 / 200, val acc: 0.5100401606425703
Epoch 186 / 200, learning rate: 1.220703125e-07
Epoch 186 / 200, train loss: 0.02324821613729
Epoch 186 / 200, val loss: 0.0575300008058548
Epoch 186 / 200, val acc: 0.5100401606425703
Epoch 187 / 200, learning rate: 1.220703125e-07
Epoch 187 / 200, train loss: 0.022791406139731407
Epoch 187 / 200, val loss: 0.057530444115400314
Epoch 187 / 200, val acc: 0.5100401606425703
Epoch 188 / 200, learning rate: 1e-07
Epoch 188 / 200, train loss: 0.023179927840828896
Epoch 188 / 200, val loss: 0.0575292743742466
Epoch 188 / 200, val acc: 0.5100401606425703
Epoch 189 / 200, learning rate: 1e-07
Epoch 189 / 200, train loss: 0.02209065854549408
Epoch 189 / 200, val loss: 0.05752897262573242
Epoch 189 / 200, val acc: 0.5100401606425703
Epoch 190 / 200, learning rate: 1e-07
Epoch 190 / 200, train loss: 0.021837931126356125
Epoch 190 / 200, val loss: 0.057529013603925705
Epoch 190 / 200, val acc: 0.5100401606425703
Epoch 191 / 200, learning rate: 1e-07
Epoch 191 / 200, train loss: 0.022862322628498077
Epoch 191 / 200, val loss: 0.057528574019670486
Epoch 191 / 200, val acc: 0.5100401606425703
Epoch 192 / 200, learning rate: 1e-07
Epoch 192 / 200, train loss: 0.023006971925497055
Epoch 192 / 200, val loss: 0.0575285479426384
Epoch 192 / 200, val acc: 0.5100401606425703
Epoch 193 / 200, learning rate: 1e-07
Epoch 193 / 200, train loss: 0.02248954027891159
Epoch 193 / 200, val loss: 0.05752919241786003
Epoch 193 / 200, val acc: 0.5100401606425703
Epoch 194 / 200, learning rate: 1e-07
Epoch 194 / 200, train loss: 0.022807512432336807
Epoch 194 / 200, val loss: 0.05752915143966675
Epoch 194 / 200, val acc: 0.5100401606425703
Epoch 195 / 200, learning rate: 1e-07
Epoch 195 / 200, train loss: 0.02230806089937687
Epoch 195 / 200, val loss: 0.057529155164957047
Epoch 195 / 200, val acc: 0.5100401606425703
Epoch 196 / 200, learning rate: 1e-07
Epoch 196 / 200, train loss: 0.02442004531621933
Epoch 196 / 200, val loss: 0.057528719305992126
Epoch 196 / 200, val acc: 0.5100401606425703
Epoch 197 / 200, learning rate: 1e-07
Epoch 197 / 200, train loss: 0.02361716330051422
Epoch 197 / 200, val loss: 0.05752835422754288
Epoch 197 / 200, val acc: 0.5100401606425703
Epoch 198 / 200, learning rate: 1e-07
Epoch 198 / 200, train loss: 0.021671373397111893
Epoch 198 / 200, val loss: 0.0575280636548996
Epoch 198 / 200, val acc: 0.5100401606425703
Epoch 199 / 200, learning rate: 1e-07
Epoch 199 / 200, train loss: 0.022322317585349083
Epoch 199 / 200, val loss: 0.05752749368548393
Epoch 199 / 200, val acc: 0.5100401606425703
Epoch 200 / 200, learning rate: 1e-07
Epoch 200 / 200, train loss: 0.023638274520635605
Epoch 200 / 200, val loss: 0.057527389377355576
Epoch 200 / 200, val acc: 0.5100401606425703
Training finished

Evaluating best model
Trading strategy for stock SPY:
After 4999 trading days
Binary accuracy: 0.48800
Fraction of long signals: 0.43069
Fraction of short signals: 0.56911
Overall long return: 2.21814
Overall return: 1.21891
Yearly long return: 0.11182
Yearly return: 0.06145
Daily volatility: 0.01199
Max drawdown baseline: 0.46135
Max drawdown: 0.36110
Sharpe ratio: -0.01667
L1 error baseline: 0.01244
L1 error: 0.10440
Average prediction: -0.01358
Std prediction: 1.07683


Trading strategy for stock SPY:
After 250 trading days
Binary accuracy: 0.45382
Fraction of long signals: 0.81600
Fraction of short signals: 0.18400
Overall long return: 0.12031
Overall return: 0.02624
Yearly long return: 0.12127
Yearly return: 0.02645
Daily volatility: 0.01180
Max drawdown baseline: 0.17114
Max drawdown: 0.15333
Sharpe ratio: -0.03186
L1 error baseline: 0.03140
L1 error: 0.20927
Average prediction: 2.13348
Std prediction: 0.04802


