Using cuda
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
Transformer                                        [1, 100, 1]               --
├─Linear: 1-1                                      [1, 100, 64]              3,584
├─Time2Vec: 1-2                                    [1, 100, 72]              --
│    └─Linear: 2-1                                 [100, 8]                  40
├─Linear: 1-3                                      [1, 100, 64]              (recursive)
├─Time2Vec: 1-4                                    [1, 100, 72]              (recursive)
│    └─Linear: 2-2                                 [100, 8]                  (recursive)
├─Transformer: 1-5                                 [1, 100, 72]              --
│    └─TransformerEncoder: 2-3                     [1, 100, 72]              --
│    │    └─ModuleList: 3-1                        --                        183,984
│    │    └─LayerNorm: 3-2                         [1, 100, 72]              144
│    └─TransformerDecoder: 2-4                     [1, 100, 72]              --
│    │    └─ModuleList: 3-3                        --                        310,992
│    │    └─LayerNorm: 3-4                         [1, 100, 72]              144
├─Sequential: 1-6                                  [1, 100, 1]               --
│    └─Linear: 2-5                                 [1, 100, 36]              2,628
│    └─Dropout: 2-6                                [1, 100, 36]              --
│    └─ReLU: 2-7                                   [1, 100, 36]              --
│    └─Linear: 2-8                                 [1, 100, 1]               37
├─Identity: 1-7                                    [1, 100, 1]               --
====================================================================================================
Total params: 501,553
Trainable params: 501,553
Non-trainable params: 0
Total mult-adds (M): 0.08
====================================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 1.95
Params size (MB): 0.26
Estimated Total Size (MB): 2.25
====================================================================================================
Epoch 1 / 200, learning rate: 0.001
Epoch 1 / 200, train loss: 1.1974852085113525
Epoch 1 / 200, val loss: 1.1066718101501465
Epoch 1 / 200, val acc: 0.5040322580645161
Epoch 2 / 200, learning rate: 0.001
Epoch 2 / 200, train loss: 0.3785858452320099
Epoch 2 / 200, val loss: 0.547768771648407
Epoch 2 / 200, val acc: 0.5040322580645161
Epoch 3 / 200, learning rate: 0.001
Epoch 3 / 200, train loss: 0.1903834342956543
Epoch 3 / 200, val loss: 0.31144773960113525
Epoch 3 / 200, val acc: 0.5201612903225806
Epoch 4 / 200, learning rate: 0.001
Epoch 4 / 200, train loss: 0.18080678582191467
Epoch 4 / 200, val loss: 0.2671416103839874
Epoch 4 / 200, val acc: 0.532258064516129
Epoch 5 / 200, learning rate: 0.001
Epoch 5 / 200, train loss: 0.1900121569633484
Epoch 5 / 200, val loss: 0.3297397196292877
Epoch 5 / 200, val acc: 0.5201612903225806
Epoch 6 / 200, learning rate: 0.001
Epoch 6 / 200, train loss: 0.1695602536201477
Epoch 6 / 200, val loss: 0.45223256945610046
Epoch 6 / 200, val acc: 0.5080645161290323
Epoch 7 / 200, learning rate: 0.001
Epoch 7 / 200, train loss: 0.15661580860614777
Epoch 7 / 200, val loss: 0.527944028377533
Epoch 7 / 200, val acc: 0.5040322580645161
Epoch 8 / 200, learning rate: 0.001
Epoch 8 / 200, train loss: 0.15972758829593658
Epoch 8 / 200, val loss: 0.43693798780441284
Epoch 8 / 200, val acc: 0.5080645161290323
Epoch 9 / 200, learning rate: 0.001
Epoch 9 / 200, train loss: 0.13983845710754395
Epoch 9 / 200, val loss: 0.2743567228317261
Epoch 9 / 200, val acc: 0.5201612903225806
Epoch 10 / 200, learning rate: 0.001
Epoch 10 / 200, train loss: 0.12575574219226837
Epoch 10 / 200, val loss: 0.16011318564414978
Epoch 10 / 200, val acc: 0.5362903225806451
Epoch 11 / 200, learning rate: 0.001
Epoch 11 / 200, train loss: 0.121787428855896
Epoch 11 / 200, val loss: 0.11377690732479095
Epoch 11 / 200, val acc: 0.5282258064516129
Epoch 12 / 200, learning rate: 0.001
Epoch 12 / 200, train loss: 0.11303460597991943
Epoch 12 / 200, val loss: 0.10544034093618393
Epoch 12 / 200, val acc: 0.5282258064516129
Epoch 13 / 200, learning rate: 0.001
Epoch 13 / 200, train loss: 0.11469241976737976
Epoch 13 / 200, val loss: 0.11923866719007492
Epoch 13 / 200, val acc: 0.5362903225806451
Epoch 14 / 200, learning rate: 0.001
Epoch 14 / 200, train loss: 0.09586557745933533
Epoch 14 / 200, val loss: 0.13465335965156555
Epoch 14 / 200, val acc: 0.5362903225806451
Epoch 15 / 200, learning rate: 0.001
Epoch 15 / 200, train loss: 0.10198315232992172
Epoch 15 / 200, val loss: 0.12456346303224564
Epoch 15 / 200, val acc: 0.532258064516129
Epoch 16 / 200, learning rate: 0.001
Epoch 16 / 200, train loss: 0.09193122386932373
Epoch 16 / 200, val loss: 0.10027656704187393
Epoch 16 / 200, val acc: 0.5282258064516129
Epoch 17 / 200, learning rate: 0.001
Epoch 17 / 200, train loss: 0.09975500404834747
Epoch 17 / 200, val loss: 0.0920669212937355
Epoch 17 / 200, val acc: 0.5161290322580645
Epoch 18 / 200, learning rate: 0.001
Epoch 18 / 200, train loss: 0.09149627387523651
Epoch 18 / 200, val loss: 0.08709301054477692
Epoch 18 / 200, val acc: 0.5120967741935484
Epoch 19 / 200, learning rate: 0.001
Epoch 19 / 200, train loss: 0.09304846078157425
Epoch 19 / 200, val loss: 0.08526917546987534
Epoch 19 / 200, val acc: 0.5120967741935484
Epoch 20 / 200, learning rate: 0.001
Epoch 20 / 200, train loss: 0.07401088625192642
Epoch 20 / 200, val loss: 0.08736004680395126
Epoch 20 / 200, val acc: 0.5241935483870968
Epoch 21 / 200, learning rate: 0.001
Epoch 21 / 200, train loss: 0.08405499160289764
Epoch 21 / 200, val loss: 0.09887389838695526
Epoch 21 / 200, val acc: 0.532258064516129
Epoch 22 / 200, learning rate: 0.001
Epoch 22 / 200, train loss: 0.07701022177934647
Epoch 22 / 200, val loss: 0.10608503967523575
Epoch 22 / 200, val acc: 0.5403225806451613
Epoch 23 / 200, learning rate: 0.001
Epoch 23 / 200, train loss: 0.07272090762853622
Epoch 23 / 200, val loss: 0.09183681011199951
Epoch 23 / 200, val acc: 0.5241935483870968
Epoch 24 / 200, learning rate: 0.001
Epoch 24 / 200, train loss: 0.07888346910476685
Epoch 24 / 200, val loss: 0.07855187356472015
Epoch 24 / 200, val acc: 0.5040322580645161
Epoch 25 / 200, learning rate: 0.001
Epoch 25 / 200, train loss: 0.07198023051023483
Epoch 25 / 200, val loss: 0.0745512992143631
Epoch 25 / 200, val acc: 0.4959677419354839
Epoch 26 / 200, learning rate: 0.001
Epoch 26 / 200, train loss: 0.07540862262248993
Epoch 26 / 200, val loss: 0.07365050911903381
Epoch 26 / 200, val acc: 0.5040322580645161
Epoch 27 / 200, learning rate: 0.001
Epoch 27 / 200, train loss: 0.07043618708848953
Epoch 27 / 200, val loss: 0.08255801349878311
Epoch 27 / 200, val acc: 0.5161290322580645
Epoch 28 / 200, learning rate: 0.001
Epoch 28 / 200, train loss: 0.06170342490077019
Epoch 28 / 200, val loss: 0.09287255257368088
Epoch 28 / 200, val acc: 0.532258064516129
Epoch 29 / 200, learning rate: 0.001
Epoch 29 / 200, train loss: 0.0663721114397049
Epoch 29 / 200, val loss: 0.07847890257835388
Epoch 29 / 200, val acc: 0.5201612903225806
Epoch 30 / 200, learning rate: 0.001
Epoch 30 / 200, train loss: 0.06031552702188492
Epoch 30 / 200, val loss: 0.0681222453713417
Epoch 30 / 200, val acc: 0.5
Epoch 31 / 200, learning rate: 0.001
Epoch 31 / 200, train loss: 0.05800563097000122
Epoch 31 / 200, val loss: 0.06600794196128845
Epoch 31 / 200, val acc: 0.4838709677419355
Epoch 32 / 200, learning rate: 0.001
Epoch 32 / 200, train loss: 0.05833715200424194
Epoch 32 / 200, val loss: 0.06380175799131393
Epoch 32 / 200, val acc: 0.4879032258064516
Epoch 33 / 200, learning rate: 0.001
Epoch 33 / 200, train loss: 0.05766524747014046
Epoch 33 / 200, val loss: 0.06252060830593109
Epoch 33 / 200, val acc: 0.5040322580645161
Epoch 34 / 200, learning rate: 0.001
Epoch 34 / 200, train loss: 0.05573928356170654
Epoch 34 / 200, val loss: 0.06122664734721184
Epoch 34 / 200, val acc: 0.5
Epoch 35 / 200, learning rate: 0.001
Epoch 35 / 200, train loss: 0.05622120946645737
Epoch 35 / 200, val loss: 0.05926301330327988
Epoch 35 / 200, val acc: 0.4879032258064516
Epoch 36 / 200, learning rate: 0.001
Epoch 36 / 200, train loss: 0.05548296496272087
Epoch 36 / 200, val loss: 0.061109479516744614
Epoch 36 / 200, val acc: 0.4959677419354839
Epoch 37 / 200, learning rate: 0.001
Epoch 37 / 200, train loss: 0.05002374202013016
Epoch 37 / 200, val loss: 0.06308144330978394
Epoch 37 / 200, val acc: 0.5
Epoch 38 / 200, learning rate: 0.001
Epoch 38 / 200, train loss: 0.05266363173723221
Epoch 38 / 200, val loss: 0.06039543077349663
Epoch 38 / 200, val acc: 0.5080645161290323
Epoch 39 / 200, learning rate: 0.001
Epoch 39 / 200, train loss: 0.05055619776248932
Epoch 39 / 200, val loss: 0.055719826370477676
Epoch 39 / 200, val acc: 0.5040322580645161
Epoch 40 / 200, learning rate: 0.001
Epoch 40 / 200, train loss: 0.05138866603374481
Epoch 40 / 200, val loss: 0.05521116033196449
Epoch 40 / 200, val acc: 0.5120967741935484
Epoch 41 / 200, learning rate: 0.001
Epoch 41 / 200, train loss: 0.051233984529972076
Epoch 41 / 200, val loss: 0.06078279763460159
Epoch 41 / 200, val acc: 0.5161290322580645
Epoch 42 / 200, learning rate: 0.001
Epoch 42 / 200, train loss: 0.048249501734972
Epoch 42 / 200, val loss: 0.06393016874790192
Epoch 42 / 200, val acc: 0.49193548387096775
Epoch 43 / 200, learning rate: 0.001
Epoch 43 / 200, train loss: 0.05094810575246811
Epoch 43 / 200, val loss: 0.0576971098780632
Epoch 43 / 200, val acc: 0.5241935483870968
Epoch 44 / 200, learning rate: 0.001
Epoch 44 / 200, train loss: 0.049813833087682724
Epoch 44 / 200, val loss: 0.054014675319194794
Epoch 44 / 200, val acc: 0.5282258064516129
Epoch 45 / 200, learning rate: 0.001
Epoch 45 / 200, train loss: 0.04710143059492111
Epoch 45 / 200, val loss: 0.05515500530600548
Epoch 45 / 200, val acc: 0.5080645161290323
Epoch 46 / 200, learning rate: 0.001
Epoch 46 / 200, train loss: 0.048023149371147156
Epoch 46 / 200, val loss: 0.06301680952310562
Epoch 46 / 200, val acc: 0.4959677419354839
Epoch 47 / 200, learning rate: 0.001
Epoch 47 / 200, train loss: 0.04535198584198952
Epoch 47 / 200, val loss: 0.06494845449924469
Epoch 47 / 200, val acc: 0.5040322580645161
Epoch 48 / 200, learning rate: 0.001
Epoch 48 / 200, train loss: 0.04363425821065903
Epoch 48 / 200, val loss: 0.06534206122159958
Epoch 48 / 200, val acc: 0.5
Epoch 49 / 200, learning rate: 0.001
Epoch 49 / 200, train loss: 0.046677783131599426
Epoch 49 / 200, val loss: 0.06800823658704758
Epoch 49 / 200, val acc: 0.5120967741935484
Epoch 50 / 200, learning rate: 0.001
Epoch 50 / 200, train loss: 0.04545171186327934
Epoch 50 / 200, val loss: 0.07340513169765472
Epoch 50 / 200, val acc: 0.5120967741935484
Epoch 51 / 200, learning rate: 0.001
Epoch 51 / 200, train loss: 0.042731042951345444
Epoch 51 / 200, val loss: 0.07296407967805862
Epoch 51 / 200, val acc: 0.5161290322580645
Epoch 52 / 200, learning rate: 0.001
Epoch 52 / 200, train loss: 0.04292133077979088
Epoch 52 / 200, val loss: 0.07436414062976837
Epoch 52 / 200, val acc: 0.4959677419354839
Epoch 53 / 200, learning rate: 0.001
Epoch 53 / 200, train loss: 0.042979396879673004
Epoch 53 / 200, val loss: 0.0744873508810997
Epoch 53 / 200, val acc: 0.4959677419354839
Epoch 54 / 200, learning rate: 0.001
Epoch 54 / 200, train loss: 0.04197428375482559
Epoch 54 / 200, val loss: 0.07422354817390442
Epoch 54 / 200, val acc: 0.4959677419354839
Epoch 55 / 200, learning rate: 0.0005
Epoch 55 / 200, train loss: 0.04027502238750458
Epoch 55 / 200, val loss: 0.07070055603981018
Epoch 55 / 200, val acc: 0.4959677419354839
Epoch 56 / 200, learning rate: 0.0005
Epoch 56 / 200, train loss: 0.04041557013988495
Epoch 56 / 200, val loss: 0.06751646846532822
Epoch 56 / 200, val acc: 0.49193548387096775
Epoch 57 / 200, learning rate: 0.0005
Epoch 57 / 200, train loss: 0.04459274560213089
Epoch 57 / 200, val loss: 0.06672986596822739
Epoch 57 / 200, val acc: 0.4959677419354839
Epoch 58 / 200, learning rate: 0.0005
Epoch 58 / 200, train loss: 0.04196025803685188
Epoch 58 / 200, val loss: 0.0628264918923378
Epoch 58 / 200, val acc: 0.5120967741935484
Epoch 59 / 200, learning rate: 0.0005
Epoch 59 / 200, train loss: 0.041053518652915955
Epoch 59 / 200, val loss: 0.06053362414240837
Epoch 59 / 200, val acc: 0.5120967741935484
Epoch 60 / 200, learning rate: 0.0005
Epoch 60 / 200, train loss: 0.04062366113066673
Epoch 60 / 200, val loss: 0.060226500034332275
Epoch 60 / 200, val acc: 0.5161290322580645
Epoch 61 / 200, learning rate: 0.0005
Epoch 61 / 200, train loss: 0.04150448366999626
Epoch 61 / 200, val loss: 0.059158239513635635
Epoch 61 / 200, val acc: 0.5241935483870968
Epoch 62 / 200, learning rate: 0.0005
Epoch 62 / 200, train loss: 0.040692396461963654
Epoch 62 / 200, val loss: 0.06008937954902649
Epoch 62 / 200, val acc: 0.5080645161290323
Epoch 63 / 200, learning rate: 0.0005
Epoch 63 / 200, train loss: 0.04063060134649277
Epoch 63 / 200, val loss: 0.0648217722773552
Epoch 63 / 200, val acc: 0.4959677419354839
Epoch 64 / 200, learning rate: 0.0005
Epoch 64 / 200, train loss: 0.03956429660320282
Epoch 64 / 200, val loss: 0.07050047814846039
Epoch 64 / 200, val acc: 0.49193548387096775
Epoch 65 / 200, learning rate: 0.0005
Epoch 65 / 200, train loss: 0.038553569465875626
Epoch 65 / 200, val loss: 0.0724918395280838
Epoch 65 / 200, val acc: 0.4879032258064516
Epoch 66 / 200, learning rate: 0.00025
Epoch 66 / 200, train loss: 0.039457231760025024
Epoch 66 / 200, val loss: 0.06968826800584793
Epoch 66 / 200, val acc: 0.4879032258064516
Epoch 67 / 200, learning rate: 0.00025
Epoch 67 / 200, train loss: 0.03919191285967827
Epoch 67 / 200, val loss: 0.07055337727069855
Epoch 67 / 200, val acc: 0.4798387096774194
Epoch 68 / 200, learning rate: 0.00025
Epoch 68 / 200, train loss: 0.040770623832941055
Epoch 68 / 200, val loss: 0.07213762402534485
Epoch 68 / 200, val acc: 0.4798387096774194
Epoch 69 / 200, learning rate: 0.00025
Epoch 69 / 200, train loss: 0.03983249142765999
Epoch 69 / 200, val loss: 0.0739634707570076
Epoch 69 / 200, val acc: 0.4879032258064516
Epoch 70 / 200, learning rate: 0.00025
Epoch 70 / 200, train loss: 0.03878102824091911
Epoch 70 / 200, val loss: 0.0751929059624672
Epoch 70 / 200, val acc: 0.4838709677419355
Epoch 71 / 200, learning rate: 0.00025
Epoch 71 / 200, train loss: 0.03818875923752785
Epoch 71 / 200, val loss: 0.07550767064094543
Epoch 71 / 200, val acc: 0.4838709677419355
Epoch 72 / 200, learning rate: 0.00025
Epoch 72 / 200, train loss: 0.038597192615270615
Epoch 72 / 200, val loss: 0.07227738946676254
Epoch 72 / 200, val acc: 0.4879032258064516
Epoch 73 / 200, learning rate: 0.00025
Epoch 73 / 200, train loss: 0.03986527770757675
Epoch 73 / 200, val loss: 0.0688055232167244
Epoch 73 / 200, val acc: 0.4838709677419355
Epoch 74 / 200, learning rate: 0.00025
Epoch 74 / 200, train loss: 0.04018154367804527
Epoch 74 / 200, val loss: 0.06642439216375351
Epoch 74 / 200, val acc: 0.4838709677419355
Epoch 75 / 200, learning rate: 0.00025
Epoch 75 / 200, train loss: 0.03993291035294533
Epoch 75 / 200, val loss: 0.06533738225698471
Epoch 75 / 200, val acc: 0.4879032258064516
Epoch 76 / 200, learning rate: 0.00025
Epoch 76 / 200, train loss: 0.04080440476536751
Epoch 76 / 200, val loss: 0.06842778623104095
Epoch 76 / 200, val acc: 0.4879032258064516
Epoch 77 / 200, learning rate: 0.000125
Epoch 77 / 200, train loss: 0.04156317561864853
Epoch 77 / 200, val loss: 0.07489734143018723
Epoch 77 / 200, val acc: 0.4838709677419355
Epoch 78 / 200, learning rate: 0.000125
Epoch 78 / 200, train loss: 0.0383247472345829
Epoch 78 / 200, val loss: 0.0779239758849144
Epoch 78 / 200, val acc: 0.47580645161290325
Epoch 79 / 200, learning rate: 0.000125
Epoch 79 / 200, train loss: 0.03960619494318962
Epoch 79 / 200, val loss: 0.0789346769452095
Epoch 79 / 200, val acc: 0.47580645161290325
Epoch 80 / 200, learning rate: 0.000125
Epoch 80 / 200, train loss: 0.037805382162332535
Epoch 80 / 200, val loss: 0.07847591489553452
Epoch 80 / 200, val acc: 0.47580645161290325
Epoch 81 / 200, learning rate: 0.000125
Epoch 81 / 200, train loss: 0.039829157292842865
Epoch 81 / 200, val loss: 0.07708000391721725
Epoch 81 / 200, val acc: 0.47580645161290325
Epoch 82 / 200, learning rate: 0.000125
Epoch 82 / 200, train loss: 0.040527649223804474
Epoch 82 / 200, val loss: 0.07588605582714081
Epoch 82 / 200, val acc: 0.4798387096774194
Epoch 83 / 200, learning rate: 0.000125
Epoch 83 / 200, train loss: 0.03791827708482742
Epoch 83 / 200, val loss: 0.07445736229419708
Epoch 83 / 200, val acc: 0.4798387096774194
Epoch 84 / 200, learning rate: 0.000125
Epoch 84 / 200, train loss: 0.03844056278467178
Epoch 84 / 200, val loss: 0.07384780049324036
Epoch 84 / 200, val acc: 0.4798387096774194
Epoch 85 / 200, learning rate: 0.000125
Epoch 85 / 200, train loss: 0.039377111941576004
Epoch 85 / 200, val loss: 0.07403746247291565
Epoch 85 / 200, val acc: 0.4798387096774194
Epoch 86 / 200, learning rate: 0.000125
Epoch 86 / 200, train loss: 0.03713371977210045
Epoch 86 / 200, val loss: 0.07417148351669312
Epoch 86 / 200, val acc: 0.4798387096774194
Epoch 87 / 200, learning rate: 0.000125
Epoch 87 / 200, train loss: 0.03786071017384529
Epoch 87 / 200, val loss: 0.0749301016330719
Epoch 87 / 200, val acc: 0.4798387096774194
Epoch 88 / 200, learning rate: 6.25e-05
Epoch 88 / 200, train loss: 0.03838024288415909
Epoch 88 / 200, val loss: 0.0766119584441185
Epoch 88 / 200, val acc: 0.4838709677419355
Epoch 89 / 200, learning rate: 6.25e-05
Epoch 89 / 200, train loss: 0.037758518010377884
Epoch 89 / 200, val loss: 0.07727859169244766
Epoch 89 / 200, val acc: 0.4838709677419355
Epoch 90 / 200, learning rate: 6.25e-05
Epoch 90 / 200, train loss: 0.03780309110879898
Epoch 90 / 200, val loss: 0.07779967039823532
Epoch 90 / 200, val acc: 0.4838709677419355
Epoch 91 / 200, learning rate: 6.25e-05
Epoch 91 / 200, train loss: 0.03885839879512787
Epoch 91 / 200, val loss: 0.07843046635389328
Epoch 91 / 200, val acc: 0.4838709677419355
Epoch 92 / 200, learning rate: 6.25e-05
Epoch 92 / 200, train loss: 0.036263130605220795
Epoch 92 / 200, val loss: 0.07863891124725342
Epoch 92 / 200, val acc: 0.4838709677419355
Epoch 93 / 200, learning rate: 6.25e-05
Epoch 93 / 200, train loss: 0.037255026400089264
Epoch 93 / 200, val loss: 0.07802824676036835
Epoch 93 / 200, val acc: 0.4838709677419355
Epoch 94 / 200, learning rate: 6.25e-05
Epoch 94 / 200, train loss: 0.039830636233091354
Epoch 94 / 200, val loss: 0.07638979703187943
Epoch 94 / 200, val acc: 0.4838709677419355
Epoch 95 / 200, learning rate: 6.25e-05
Epoch 95 / 200, train loss: 0.03750922530889511
Epoch 95 / 200, val loss: 0.07535210996866226
Epoch 95 / 200, val acc: 0.4798387096774194
Epoch 96 / 200, learning rate: 6.25e-05
Epoch 96 / 200, train loss: 0.03813740983605385
Epoch 96 / 200, val loss: 0.07434362918138504
Epoch 96 / 200, val acc: 0.4798387096774194
Epoch 97 / 200, learning rate: 6.25e-05
Epoch 97 / 200, train loss: 0.036654409021139145
Epoch 97 / 200, val loss: 0.07361697405576706
Epoch 97 / 200, val acc: 0.4798387096774194
Epoch 98 / 200, learning rate: 6.25e-05
Epoch 98 / 200, train loss: 0.03845062106847763
Epoch 98 / 200, val loss: 0.07359369844198227
Epoch 98 / 200, val acc: 0.4798387096774194
Epoch 99 / 200, learning rate: 3.125e-05
Epoch 99 / 200, train loss: 0.0402536615729332
Epoch 99 / 200, val loss: 0.07371382415294647
Epoch 99 / 200, val acc: 0.4798387096774194
Epoch 100 / 200, learning rate: 3.125e-05
Epoch 100 / 200, train loss: 0.04022316634654999
Epoch 100 / 200, val loss: 0.07361219823360443
Epoch 100 / 200, val acc: 0.4798387096774194
Epoch 101 / 200, learning rate: 3.125e-05
Epoch 101 / 200, train loss: 0.03882984444499016
Epoch 101 / 200, val loss: 0.07341019809246063
Epoch 101 / 200, val acc: 0.4798387096774194
Epoch 102 / 200, learning rate: 3.125e-05
Epoch 102 / 200, train loss: 0.037428658455610275
Epoch 102 / 200, val loss: 0.07313987612724304
Epoch 102 / 200, val acc: 0.4798387096774194
Epoch 103 / 200, learning rate: 3.125e-05
Epoch 103 / 200, train loss: 0.03703668713569641
Epoch 103 / 200, val loss: 0.07280648499727249
Epoch 103 / 200, val acc: 0.4838709677419355
Epoch 104 / 200, learning rate: 3.125e-05
Epoch 104 / 200, train loss: 0.03653426840901375
Epoch 104 / 200, val loss: 0.07260947674512863
Epoch 104 / 200, val acc: 0.4838709677419355
Epoch 105 / 200, learning rate: 3.125e-05
Epoch 105 / 200, train loss: 0.03797285258769989
Epoch 105 / 200, val loss: 0.07240920513868332
Epoch 105 / 200, val acc: 0.4838709677419355
Epoch 106 / 200, learning rate: 3.125e-05
Epoch 106 / 200, train loss: 0.03744617477059364
Epoch 106 / 200, val loss: 0.07237349450588226
Epoch 106 / 200, val acc: 0.4838709677419355
Epoch 107 / 200, learning rate: 3.125e-05
Epoch 107 / 200, train loss: 0.037371329963207245
Epoch 107 / 200, val loss: 0.07249221950769424
Epoch 107 / 200, val acc: 0.4838709677419355
Epoch 108 / 200, learning rate: 3.125e-05
Epoch 108 / 200, train loss: 0.038492780178785324
Epoch 108 / 200, val loss: 0.07256698608398438
Epoch 108 / 200, val acc: 0.4838709677419355
Epoch 109 / 200, learning rate: 3.125e-05
Epoch 109 / 200, train loss: 0.03699535131454468
Epoch 109 / 200, val loss: 0.07288845628499985
Epoch 109 / 200, val acc: 0.4838709677419355
Epoch 110 / 200, learning rate: 1.5625e-05
Epoch 110 / 200, train loss: 0.037551749497652054
Epoch 110 / 200, val loss: 0.0733836367726326
Epoch 110 / 200, val acc: 0.4798387096774194
Epoch 111 / 200, learning rate: 1.5625e-05
Epoch 111 / 200, train loss: 0.036687083542346954
Epoch 111 / 200, val loss: 0.07373780757188797
Epoch 111 / 200, val acc: 0.4798387096774194
Epoch 112 / 200, learning rate: 1.5625e-05
Epoch 112 / 200, train loss: 0.038828782737255096
Epoch 112 / 200, val loss: 0.0740535706281662
Epoch 112 / 200, val acc: 0.4798387096774194
Epoch 113 / 200, learning rate: 1.5625e-05
Epoch 113 / 200, train loss: 0.036127589643001556
Epoch 113 / 200, val loss: 0.07439569383859634
Epoch 113 / 200, val acc: 0.4798387096774194
Epoch 114 / 200, learning rate: 1.5625e-05
Epoch 114 / 200, train loss: 0.03812025859951973
Epoch 114 / 200, val loss: 0.07483747601509094
Epoch 114 / 200, val acc: 0.4838709677419355
Epoch 115 / 200, learning rate: 1.5625e-05
Epoch 115 / 200, train loss: 0.03773723542690277
Epoch 115 / 200, val loss: 0.07520010322332382
Epoch 115 / 200, val acc: 0.4838709677419355
Epoch 116 / 200, learning rate: 1.5625e-05
Epoch 116 / 200, train loss: 0.03657933697104454
Epoch 116 / 200, val loss: 0.07538054138422012
Epoch 116 / 200, val acc: 0.4838709677419355
Epoch 117 / 200, learning rate: 1.5625e-05
Epoch 117 / 200, train loss: 0.03808165341615677
Epoch 117 / 200, val loss: 0.07548996061086655
Epoch 117 / 200, val acc: 0.4838709677419355
Epoch 118 / 200, learning rate: 1.5625e-05
Epoch 118 / 200, train loss: 0.036582980304956436
Epoch 118 / 200, val loss: 0.07535895705223083
Epoch 118 / 200, val acc: 0.4838709677419355
Epoch 119 / 200, learning rate: 1.5625e-05
Epoch 119 / 200, train loss: 0.03950545936822891
Epoch 119 / 200, val loss: 0.07514946907758713
Epoch 119 / 200, val acc: 0.4838709677419355
Epoch 120 / 200, learning rate: 1.5625e-05
Epoch 120 / 200, train loss: 0.036861468106508255
Epoch 120 / 200, val loss: 0.07501519471406937
Epoch 120 / 200, val acc: 0.4838709677419355
Epoch 121 / 200, learning rate: 7.8125e-06
Epoch 121 / 200, train loss: 0.03641198202967644
Epoch 121 / 200, val loss: 0.07480602711439133
Epoch 121 / 200, val acc: 0.4838709677419355
Epoch 122 / 200, learning rate: 7.8125e-06
Epoch 122 / 200, train loss: 0.03830115869641304
Epoch 122 / 200, val loss: 0.07471723109483719
Epoch 122 / 200, val acc: 0.4838709677419355
Epoch 123 / 200, learning rate: 7.8125e-06
Epoch 123 / 200, train loss: 0.03948341682553291
Epoch 123 / 200, val loss: 0.07457898557186127
Epoch 123 / 200, val acc: 0.4838709677419355
Epoch 124 / 200, learning rate: 7.8125e-06
Epoch 124 / 200, train loss: 0.03758428990840912
Epoch 124 / 200, val loss: 0.0745224803686142
Epoch 124 / 200, val acc: 0.4838709677419355
Epoch 125 / 200, learning rate: 7.8125e-06
Epoch 125 / 200, train loss: 0.03822771832346916
Epoch 125 / 200, val loss: 0.07450636476278305
Epoch 125 / 200, val acc: 0.4838709677419355
Epoch 126 / 200, learning rate: 7.8125e-06
Epoch 126 / 200, train loss: 0.036539576947689056
Epoch 126 / 200, val loss: 0.07452501356601715
Epoch 126 / 200, val acc: 0.4838709677419355
Epoch 127 / 200, learning rate: 7.8125e-06
Epoch 127 / 200, train loss: 0.03679581359028816
Epoch 127 / 200, val loss: 0.074529729783535
Epoch 127 / 200, val acc: 0.4838709677419355
Epoch 128 / 200, learning rate: 7.8125e-06
Epoch 128 / 200, train loss: 0.038635771721601486
Epoch 128 / 200, val loss: 0.0745052695274353
Epoch 128 / 200, val acc: 0.4838709677419355
Epoch 129 / 200, learning rate: 7.8125e-06
Epoch 129 / 200, train loss: 0.039657965302467346
Epoch 129 / 200, val loss: 0.07439904659986496
Epoch 129 / 200, val acc: 0.4838709677419355
Epoch 130 / 200, learning rate: 7.8125e-06
Epoch 130 / 200, train loss: 0.03780854493379593
Epoch 130 / 200, val loss: 0.07423814386129379
Epoch 130 / 200, val acc: 0.4838709677419355
Epoch 131 / 200, learning rate: 7.8125e-06
Epoch 131 / 200, train loss: 0.03665563091635704
Epoch 131 / 200, val loss: 0.07412172853946686
Epoch 131 / 200, val acc: 0.4838709677419355
Epoch 132 / 200, learning rate: 3.90625e-06
Epoch 132 / 200, train loss: 0.03707319498062134
Epoch 132 / 200, val loss: 0.07401202619075775
Epoch 132 / 200, val acc: 0.4838709677419355
Epoch 133 / 200, learning rate: 3.90625e-06
Epoch 133 / 200, train loss: 0.037212617695331573
Epoch 133 / 200, val loss: 0.0739777460694313
Epoch 133 / 200, val acc: 0.4838709677419355
Epoch 134 / 200, learning rate: 3.90625e-06
Epoch 134 / 200, train loss: 0.0379921980202198
Epoch 134 / 200, val loss: 0.073941670358181
Epoch 134 / 200, val acc: 0.4798387096774194
Epoch 135 / 200, learning rate: 3.90625e-06
Epoch 135 / 200, train loss: 0.036001745611429214
Epoch 135 / 200, val loss: 0.07392886281013489
Epoch 135 / 200, val acc: 0.4798387096774194
Epoch 136 / 200, learning rate: 3.90625e-06
Epoch 136 / 200, train loss: 0.0394187793135643
Epoch 136 / 200, val loss: 0.07391870021820068
Epoch 136 / 200, val acc: 0.4798387096774194
Epoch 137 / 200, learning rate: 3.90625e-06
Epoch 137 / 200, train loss: 0.03828363120555878
Epoch 137 / 200, val loss: 0.07385275512933731
Epoch 137 / 200, val acc: 0.4798387096774194
Epoch 138 / 200, learning rate: 3.90625e-06
Epoch 138 / 200, train loss: 0.03727984055876732
Epoch 138 / 200, val loss: 0.07383149862289429
Epoch 138 / 200, val acc: 0.4798387096774194
Epoch 139 / 200, learning rate: 3.90625e-06
Epoch 139 / 200, train loss: 0.03939269110560417
Epoch 139 / 200, val loss: 0.07378967106342316
Epoch 139 / 200, val acc: 0.4798387096774194
Epoch 140 / 200, learning rate: 3.90625e-06
Epoch 140 / 200, train loss: 0.037555031478405
Epoch 140 / 200, val loss: 0.0737474113702774
Epoch 140 / 200, val acc: 0.4798387096774194
Epoch 141 / 200, learning rate: 3.90625e-06
Epoch 141 / 200, train loss: 0.03817563131451607
Epoch 141 / 200, val loss: 0.07373649626970291
Epoch 141 / 200, val acc: 0.4798387096774194
Epoch 142 / 200, learning rate: 3.90625e-06
Epoch 142 / 200, train loss: 0.03832066059112549
Epoch 142 / 200, val loss: 0.07371151447296143
Epoch 142 / 200, val acc: 0.4798387096774194
Epoch 143 / 200, learning rate: 1.953125e-06
Epoch 143 / 200, train loss: 0.03573072329163551
Epoch 143 / 200, val loss: 0.0737089216709137
Epoch 143 / 200, val acc: 0.4798387096774194
Epoch 144 / 200, learning rate: 1.953125e-06
Epoch 144 / 200, train loss: 0.03695005178451538
Epoch 144 / 200, val loss: 0.07368344813585281
Epoch 144 / 200, val acc: 0.4798387096774194
Epoch 145 / 200, learning rate: 1.953125e-06
Epoch 145 / 200, train loss: 0.03919433429837227
Epoch 145 / 200, val loss: 0.07365506142377853
Epoch 145 / 200, val acc: 0.4798387096774194
Epoch 146 / 200, learning rate: 1.953125e-06
Epoch 146 / 200, train loss: 0.03944409638643265
Epoch 146 / 200, val loss: 0.07363969087600708
Epoch 146 / 200, val acc: 0.4798387096774194
Epoch 147 / 200, learning rate: 1.953125e-06
Epoch 147 / 200, train loss: 0.037176214158535004
Epoch 147 / 200, val loss: 0.0736224576830864
Epoch 147 / 200, val acc: 0.4798387096774194
Epoch 148 / 200, learning rate: 1.953125e-06
Epoch 148 / 200, train loss: 0.03676920756697655
Epoch 148 / 200, val loss: 0.07363951206207275
Epoch 148 / 200, val acc: 0.4798387096774194
Epoch 149 / 200, learning rate: 1.953125e-06
Epoch 149 / 200, train loss: 0.03677089512348175
Epoch 149 / 200, val loss: 0.07365766912698746
Epoch 149 / 200, val acc: 0.4798387096774194
Epoch 150 / 200, learning rate: 1.953125e-06
Epoch 150 / 200, train loss: 0.03705071285367012
Epoch 150 / 200, val loss: 0.07368659228086472
Epoch 150 / 200, val acc: 0.4798387096774194
Epoch 151 / 200, learning rate: 1.953125e-06
Epoch 151 / 200, train loss: 0.03711113706231117
Epoch 151 / 200, val loss: 0.07368607074022293
Epoch 151 / 200, val acc: 0.4798387096774194
Epoch 152 / 200, learning rate: 1.953125e-06
Epoch 152 / 200, train loss: 0.03653862327337265
Epoch 152 / 200, val loss: 0.0736910030245781
Epoch 152 / 200, val acc: 0.4798387096774194
Epoch 153 / 200, learning rate: 1.953125e-06
Epoch 153 / 200, train loss: 0.03751019760966301
Epoch 153 / 200, val loss: 0.07370129972696304
Epoch 153 / 200, val acc: 0.4798387096774194
Epoch 154 / 200, learning rate: 9.765625e-07
Epoch 154 / 200, train loss: 0.03900196775794029
Epoch 154 / 200, val loss: 0.07372000813484192
Epoch 154 / 200, val acc: 0.4798387096774194
Epoch 155 / 200, learning rate: 9.765625e-07
Epoch 155 / 200, train loss: 0.03676599636673927
Epoch 155 / 200, val loss: 0.07373155653476715
Epoch 155 / 200, val acc: 0.4798387096774194
Epoch 156 / 200, learning rate: 9.765625e-07
Epoch 156 / 200, train loss: 0.03722397983074188
Epoch 156 / 200, val loss: 0.07372566312551498
Epoch 156 / 200, val acc: 0.4798387096774194
Epoch 157 / 200, learning rate: 9.765625e-07
Epoch 157 / 200, train loss: 0.03770773112773895
Epoch 157 / 200, val loss: 0.073714479804039
Epoch 157 / 200, val acc: 0.4798387096774194
Epoch 158 / 200, learning rate: 9.765625e-07
Epoch 158 / 200, train loss: 0.037874288856983185
Epoch 158 / 200, val loss: 0.07371402531862259
Epoch 158 / 200, val acc: 0.4798387096774194
Epoch 159 / 200, learning rate: 9.765625e-07
Epoch 159 / 200, train loss: 0.03661276400089264
Epoch 159 / 200, val loss: 0.0737212747335434
Epoch 159 / 200, val acc: 0.4798387096774194
Epoch 160 / 200, learning rate: 9.765625e-07
Epoch 160 / 200, train loss: 0.04007301479578018
Epoch 160 / 200, val loss: 0.07372638583183289
Epoch 160 / 200, val acc: 0.4798387096774194
Epoch 161 / 200, learning rate: 9.765625e-07
Epoch 161 / 200, train loss: 0.03909904137253761
Epoch 161 / 200, val loss: 0.07373209297657013
Epoch 161 / 200, val acc: 0.4798387096774194
Epoch 162 / 200, learning rate: 9.765625e-07
Epoch 162 / 200, train loss: 0.03951980173587799
Epoch 162 / 200, val loss: 0.07372519373893738
Epoch 162 / 200, val acc: 0.4798387096774194
Epoch 163 / 200, learning rate: 9.765625e-07
Epoch 163 / 200, train loss: 0.03717053309082985
Epoch 163 / 200, val loss: 0.07371827214956284
Epoch 163 / 200, val acc: 0.4798387096774194
Epoch 164 / 200, learning rate: 9.765625e-07
Epoch 164 / 200, train loss: 0.03957356512546539
Epoch 164 / 200, val loss: 0.0737106129527092
Epoch 164 / 200, val acc: 0.4798387096774194
Epoch 165 / 200, learning rate: 4.8828125e-07
Epoch 165 / 200, train loss: 0.039516381919384
Epoch 165 / 200, val loss: 0.07370434701442719
Epoch 165 / 200, val acc: 0.4798387096774194
Epoch 166 / 200, learning rate: 4.8828125e-07
Epoch 166 / 200, train loss: 0.03663641959428787
Epoch 166 / 200, val loss: 0.07370181381702423
Epoch 166 / 200, val acc: 0.4798387096774194
Epoch 167 / 200, learning rate: 4.8828125e-07
Epoch 167 / 200, train loss: 0.03712200000882149
Epoch 167 / 200, val loss: 0.07369983196258545
Epoch 167 / 200, val acc: 0.4798387096774194
Epoch 168 / 200, learning rate: 4.8828125e-07
Epoch 168 / 200, train loss: 0.03730206936597824
Epoch 168 / 200, val loss: 0.07370507717132568
Epoch 168 / 200, val acc: 0.4798387096774194
Epoch 169 / 200, learning rate: 4.8828125e-07
Epoch 169 / 200, train loss: 0.03732001408934593
Epoch 169 / 200, val loss: 0.07370541244745255
Epoch 169 / 200, val acc: 0.4798387096774194
Epoch 170 / 200, learning rate: 4.8828125e-07
Epoch 170 / 200, train loss: 0.03868987783789635
Epoch 170 / 200, val loss: 0.07370319962501526
Epoch 170 / 200, val acc: 0.4798387096774194
Epoch 171 / 200, learning rate: 4.8828125e-07
Epoch 171 / 200, train loss: 0.03860964998602867
Epoch 171 / 200, val loss: 0.07370443642139435
Epoch 171 / 200, val acc: 0.4798387096774194
Epoch 172 / 200, learning rate: 4.8828125e-07
Epoch 172 / 200, train loss: 0.036525219678878784
Epoch 172 / 200, val loss: 0.07370954006910324
Epoch 172 / 200, val acc: 0.4798387096774194
Epoch 173 / 200, learning rate: 4.8828125e-07
Epoch 173 / 200, train loss: 0.038164667785167694
Epoch 173 / 200, val loss: 0.07371623814105988
Epoch 173 / 200, val acc: 0.4798387096774194
Epoch 174 / 200, learning rate: 4.8828125e-07
Epoch 174 / 200, train loss: 0.03920884057879448
Epoch 174 / 200, val loss: 0.07372576743364334
Epoch 174 / 200, val acc: 0.4798387096774194
Epoch 175 / 200, learning rate: 4.8828125e-07
Epoch 175 / 200, train loss: 0.03807124122977257
Epoch 175 / 200, val loss: 0.07373421639204025
Epoch 175 / 200, val acc: 0.4798387096774194
Epoch 176 / 200, learning rate: 2.44140625e-07
Epoch 176 / 200, train loss: 0.036714136600494385
Epoch 176 / 200, val loss: 0.0737437754869461
Epoch 176 / 200, val acc: 0.4798387096774194
Epoch 177 / 200, learning rate: 2.44140625e-07
Epoch 177 / 200, train loss: 0.0367785319685936
Epoch 177 / 200, val loss: 0.07374999672174454
Epoch 177 / 200, val acc: 0.4798387096774194
Epoch 178 / 200, learning rate: 2.44140625e-07
Epoch 178 / 200, train loss: 0.03864123299717903
Epoch 178 / 200, val loss: 0.07375701516866684
Epoch 178 / 200, val acc: 0.4798387096774194
Epoch 179 / 200, learning rate: 2.44140625e-07
Epoch 179 / 200, train loss: 0.0363033264875412
Epoch 179 / 200, val loss: 0.07376224547624588
Epoch 179 / 200, val acc: 0.4798387096774194
Epoch 180 / 200, learning rate: 2.44140625e-07
Epoch 180 / 200, train loss: 0.03803538531064987
Epoch 180 / 200, val loss: 0.07376693189144135
Epoch 180 / 200, val acc: 0.4798387096774194
Epoch 181 / 200, learning rate: 2.44140625e-07
Epoch 181 / 200, train loss: 0.04061632230877876
Epoch 181 / 200, val loss: 0.07377305626869202
Epoch 181 / 200, val acc: 0.4798387096774194
Epoch 182 / 200, learning rate: 2.44140625e-07
Epoch 182 / 200, train loss: 0.03763085976243019
Epoch 182 / 200, val loss: 0.07377763837575912
Epoch 182 / 200, val acc: 0.4798387096774194
Epoch 183 / 200, learning rate: 2.44140625e-07
Epoch 183 / 200, train loss: 0.03917847201228142
Epoch 183 / 200, val loss: 0.07378064095973969
Epoch 183 / 200, val acc: 0.4798387096774194
Epoch 184 / 200, learning rate: 2.44140625e-07
Epoch 184 / 200, train loss: 0.0369410440325737
Epoch 184 / 200, val loss: 0.07378119230270386
Epoch 184 / 200, val acc: 0.4798387096774194
Epoch 185 / 200, learning rate: 2.44140625e-07
Epoch 185 / 200, train loss: 0.03754108399152756
Epoch 185 / 200, val loss: 0.07378126680850983
Epoch 185 / 200, val acc: 0.4798387096774194
Epoch 186 / 200, learning rate: 2.44140625e-07
Epoch 186 / 200, train loss: 0.038899801671504974
Epoch 186 / 200, val loss: 0.07378049194812775
Epoch 186 / 200, val acc: 0.4798387096774194
Epoch 187 / 200, learning rate: 1.220703125e-07
Epoch 187 / 200, train loss: 0.03674132376909256
Epoch 187 / 200, val loss: 0.0737801194190979
Epoch 187 / 200, val acc: 0.4798387096774194
Epoch 188 / 200, learning rate: 1.220703125e-07
Epoch 188 / 200, train loss: 0.039339423179626465
Epoch 188 / 200, val loss: 0.07377904653549194
Epoch 188 / 200, val acc: 0.4798387096774194
Epoch 189 / 200, learning rate: 1.220703125e-07
Epoch 189 / 200, train loss: 0.037079039961099625
Epoch 189 / 200, val loss: 0.07377971708774567
Epoch 189 / 200, val acc: 0.4798387096774194
Epoch 190 / 200, learning rate: 1.220703125e-07
Epoch 190 / 200, train loss: 0.0368310883641243
Epoch 190 / 200, val loss: 0.07378038763999939
Epoch 190 / 200, val acc: 0.4798387096774194
Epoch 191 / 200, learning rate: 1.220703125e-07
Epoch 191 / 200, train loss: 0.0375228226184845
Epoch 191 / 200, val loss: 0.07378184050321579
Epoch 191 / 200, val acc: 0.4798387096774194
Epoch 192 / 200, learning rate: 1.220703125e-07
Epoch 192 / 200, train loss: 0.037199996411800385
Epoch 192 / 200, val loss: 0.07378466427326202
Epoch 192 / 200, val acc: 0.4798387096774194
Epoch 193 / 200, learning rate: 1.220703125e-07
Epoch 193 / 200, train loss: 0.038011617958545685
Epoch 193 / 200, val loss: 0.07378600537776947
Epoch 193 / 200, val acc: 0.4798387096774194
Epoch 194 / 200, learning rate: 1.220703125e-07
Epoch 194 / 200, train loss: 0.03686893731355667
Epoch 194 / 200, val loss: 0.07378794997930527
Epoch 194 / 200, val acc: 0.4798387096774194
Epoch 195 / 200, learning rate: 1.220703125e-07
Epoch 195 / 200, train loss: 0.03993618115782738
Epoch 195 / 200, val loss: 0.07378821074962616
Epoch 195 / 200, val acc: 0.4798387096774194
Epoch 196 / 200, learning rate: 1.220703125e-07
Epoch 196 / 200, train loss: 0.037333182990550995
Epoch 196 / 200, val loss: 0.07378745824098587
Epoch 196 / 200, val acc: 0.4798387096774194
Epoch 197 / 200, learning rate: 1.220703125e-07
Epoch 197 / 200, train loss: 0.03759371489286423
Epoch 197 / 200, val loss: 0.07378701120615005
Epoch 197 / 200, val acc: 0.4798387096774194
Epoch 198 / 200, learning rate: 1e-07
Epoch 198 / 200, train loss: 0.03653006628155708
Epoch 198 / 200, val loss: 0.07378773391246796
Epoch 198 / 200, val acc: 0.4798387096774194
Epoch 199 / 200, learning rate: 1e-07
Epoch 199 / 200, train loss: 0.037520721554756165
Epoch 199 / 200, val loss: 0.07378821074962616
Epoch 199 / 200, val acc: 0.4798387096774194
Epoch 200 / 200, learning rate: 1e-07
Epoch 200 / 200, train loss: 0.03670073673129082
Epoch 200 / 200, val loss: 0.07378794252872467
Epoch 200 / 200, val acc: 0.4798387096774194
Training finished

Evaluating best model
Trading strategy for stock ^GDAXI:
After 4982 trading days
Binary accuracy: 0.48886
Fraction of long signals: 0.30490
Fraction of short signals: 0.69490
Overall long return: 1.87543
Overall return: 0.18207
Yearly long return: 0.09486
Yearly return: 0.00921
Daily volatility: 0.01322
Max drawdown baseline: 0.39405
Max drawdown: 0.88488
Sharpe ratio: -0.02571
L1 error baseline: 0.02251
L1 error: 0.14008
Average prediction: -0.06213
Std prediction: 1.06318


Trading strategy for stock ^GDAXI:
After 250 trading days
Binary accuracy: 0.46988
Fraction of long signals: 0.30400
Fraction of short signals: 0.69600
Overall long return: 0.18388
Overall return: -0.11721
Yearly long return: 0.18535
Yearly return: -0.11815
Daily volatility: 0.01036
Max drawdown baseline: 0.14422
Max drawdown: 0.18768
Sharpe ratio: -0.11647
L1 error baseline: 0.03099
L1 error: 0.21807
Average prediction: 1.53041
Std prediction: 0.18756


